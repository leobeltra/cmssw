#include <memory> /* clang -E -fkeep-system-includes */
#include <tuple>  /* clang -E -fkeep-system-includes */
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"
#include <cmath> /* clang -E -fkeep-system-includes */

namespace Eigen {
  namespace internal {
    template <typename T>
    inline constexpr void ignore_unused_variable(const T&) {}
  }  // namespace internal
}  // namespace Eigen
namespace Eigen {
  namespace internal {
    inline bool all() { return true; }
    template <typename T, typename... Ts>
    bool all(T t, Ts... ts) {
      return t && all(ts...);
    }
  }  // namespace internal
}  // namespace Eigen
extern "C" {
#include <mmintrin.h> /* clang -E -fkeep-system-includes */

#include <emmintrin.h> /* clang -E -fkeep-system-includes */

#include <xmmintrin.h> /* clang -E -fkeep-system-includes */
#include <pmmintrin.h> /* clang -E -fkeep-system-includes */

#include <tmmintrin.h> /* clang -E -fkeep-system-includes */

#include <smmintrin.h> /* clang -E -fkeep-system-includes */
#include <nmmintrin.h> /* clang -E -fkeep-system-includes */
}

namespace Eigen {
  inline static const char* SimdInstructionSetsInUse(void) { return "SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2"; }
}  // namespace Eigen
#include <new>     /* clang -E -fkeep-system-includes */
#include <complex> /* clang -E -fkeep-system-includes */

namespace Eigen {
  typedef std::complex<double> dcomplex;
  typedef std::complex<float> scomplex;
  typedef int BlasIndex;
}  // namespace Eigen
#include <cerrno> /* clang -E -fkeep-system-includes */

#include <cstddef> /* clang -E -fkeep-system-includes */

#include <cstdlib> /* clang -E -fkeep-system-includes */

#include <cmath> /* clang -E -fkeep-system-includes */

#include <cassert>    /* clang -E -fkeep-system-includes */
#include <functional> /* clang -E -fkeep-system-includes */

#include <sstream> /* clang -E -fkeep-system-includes */
#include <iosfwd>  /* clang -E -fkeep-system-includes */
#include <cstring> /* clang -E -fkeep-system-includes */

#include <string>  /* clang -E -fkeep-system-includes */
#include <limits>  /* clang -E -fkeep-system-includes */
#include <climits> /* clang -E -fkeep-system-includes */

#include <algorithm> /* clang -E -fkeep-system-includes */

#include <array>       /* clang -E -fkeep-system-includes */
#include <type_traits> /* clang -E -fkeep-system-includes */
namespace Eigen {
  using std::ptrdiff_t;
  using std::size_t;
}  // namespace Eigen

namespace Eigen {
  const int Dynamic = -1;
  const int DynamicIndex = 0xffffff;
  const int UndefinedIncr = 0xfffffe;
  const int Infinity = -1;
  const int HugeCost = 10000;
  const unsigned int RowMajorBit = 0x1;
  const unsigned int EvalBeforeNestingBit = 0x2;
  __attribute__((deprecated)) const unsigned int EvalBeforeAssigningBit = 0x4;
  const unsigned int PacketAccessBit = 0x8;
  const unsigned int ActualPacketAccessBit = PacketAccessBit;
  const unsigned int LinearAccessBit = 0x10;
  const unsigned int LvalueBit = 0x20;
  const unsigned int DirectAccessBit = 0x40;
  __attribute__((deprecated)) const unsigned int AlignedBit = 0x80;
  const unsigned int NestByRefBit = 0x100;
  const unsigned int NoPreferredStorageOrderBit = 0x200;
  const unsigned int CompressedAccessBit = 0x400;
  const unsigned int HereditaryBits = RowMajorBit | EvalBeforeNestingBit;
  enum UpLoType {
    Lower = 0x1,
    Upper = 0x2,
    UnitDiag = 0x4,
    ZeroDiag = 0x8,
    UnitLower = UnitDiag | Lower,
    UnitUpper = UnitDiag | Upper,
    StrictlyLower = ZeroDiag | Lower,
    StrictlyUpper = ZeroDiag | Upper,
    SelfAdjoint = 0x10,
    Symmetric = 0x20
  };
  enum AlignmentType {
    Unaligned = 0,
    Aligned8 = 8,
    Aligned16 = 16,
    Aligned32 = 32,
    Aligned64 = 64,
    Aligned128 = 128,
    AlignedMask = 255,
    Aligned = 16,
    AlignedMax = Aligned64
  };
  enum DirectionType { Vertical, Horizontal, BothDirections };
  enum TraversalType {
    DefaultTraversal,
    LinearTraversal,
    InnerVectorizedTraversal,
    LinearVectorizedTraversal,
    SliceVectorizedTraversal,
    InvalidTraversal,
    AllAtOnceTraversal
  };
  enum UnrollingType { NoUnrolling, InnerUnrolling, CompleteUnrolling };
  enum SpecializedType { Specialized, BuiltIn };
  enum StorageOptions { ColMajor = 0, RowMajor = 0x1, AutoAlign = 0, DontAlign = 0x2 };
  enum SideType { OnTheLeft = 1, OnTheRight = 2 };
  enum NaNPropagationOptions { PropagateFast = 0, PropagateNaN, PropagateNumbers };
  enum NoChange_t { NoChange };
  enum Sequential_t { Sequential };
  enum Default_t { Default };
  enum AmbiVectorMode { IsDense = 0, IsSparse };
  enum AccessorLevels { ReadOnlyAccessors, WriteAccessors, DirectAccessors, DirectWriteAccessors };
  enum DecompositionOptions {
    Pivoting = 0x01,
    NoPivoting = 0x02,
    ComputeFullU = 0x04,
    ComputeThinU = 0x08,
    ComputeFullV = 0x10,
    ComputeThinV = 0x20,
    EigenvaluesOnly = 0x40,
    ComputeEigenvectors = 0x80,
    EigVecMask = EigenvaluesOnly | ComputeEigenvectors,
    Ax_lBx = 0x100,
    ABx_lx = 0x200,
    BAx_lx = 0x400,
    GenEigMask = Ax_lBx | ABx_lx | BAx_lx
  };
  enum QRPreconditioners {
    ColPivHouseholderQRPreconditioner = 0x0,
    NoQRPreconditioner = 0x40,
    HouseholderQRPreconditioner = 0x80,
    FullPivHouseholderQRPreconditioner = 0xC0,
    DisableQRDecomposition = NoQRPreconditioner
  };
  enum ComputationInfo { Success = 0, NumericalIssue = 1, NoConvergence = 2, InvalidInput = 3 };
  enum TransformTraits { Isometry = 0x1, Affine = 0x2, AffineCompact = 0x10 | Affine, Projective = 0x20 };
  namespace Architecture {
    enum Type { Generic = 0x0, SSE = 0x1, AltiVec = 0x2, VSX = 0x3, NEON = 0x4, MSA = 0x5, SVE = 0x6, Target = SSE };
  }
  enum ProductImplType {
    DefaultProduct = 0,
    LazyProduct,
    AliasFreeProduct,
    CoeffBasedProductMode,
    LazyCoeffBasedProductMode,
    OuterProduct,
    InnerProduct,
    GemvProduct,
    GemmProduct
  };
  enum Action { GetAction, SetAction };
  struct Dense {};
  struct Sparse {};
  struct SolverStorage {};
  struct PermutationStorage {};
  struct TranspositionsStorage {};
  struct MatrixXpr {};
  struct ArrayXpr {};
  struct DenseShape {
    static std::string debugName() { return "DenseShape"; }
  };
  struct SolverShape {
    static std::string debugName() { return "SolverShape"; }
  };
  struct HomogeneousShape {
    static std::string debugName() { return "HomogeneousShape"; }
  };
  struct DiagonalShape {
    static std::string debugName() { return "DiagonalShape"; }
  };
  struct SkewSymmetricShape {
    static std::string debugName() { return "SkewSymmetricShape"; }
  };
  struct BandShape {
    static std::string debugName() { return "BandShape"; }
  };
  struct TriangularShape {
    static std::string debugName() { return "TriangularShape"; }
  };
  struct SelfAdjointShape {
    static std::string debugName() { return "SelfAdjointShape"; }
  };
  struct PermutationShape {
    static std::string debugName() { return "PermutationShape"; }
  };
  struct TranspositionsShape {
    static std::string debugName() { return "TranspositionsShape"; }
  };
  struct SparseShape {
    static std::string debugName() { return "SparseShape"; }
  };
  namespace internal {
    struct IndexBased {};
    struct IteratorBased {};
    enum ComparisonName : unsigned int {
      cmp_EQ = 0,
      cmp_LT = 1,
      cmp_LE = 2,
      cmp_UNORD = 3,
      cmp_NEQ = 4,
      cmp_GT = 5,
      cmp_GE = 6
    };
  }  // namespace internal
}  // namespace Eigen
#include <cstdint> /* clang -E -fkeep-system-includes */
namespace Eigen {
  namespace numext {
    typedef std::uint8_t uint8_t;
    typedef std::int8_t int8_t;
    typedef std::uint16_t uint16_t;
    typedef std::int16_t int16_t;
    typedef std::uint32_t uint32_t;
    typedef std::int32_t int32_t;
    typedef std::uint64_t uint64_t;
    typedef std::int64_t int64_t;
  }  // namespace numext
}  // namespace Eigen
namespace Eigen {
  typedef std::ptrdiff_t DenseIndex;
  typedef std::ptrdiff_t Index;
  namespace internal {
    typedef std::ptrdiff_t IntPtr;
    typedef std::size_t UIntPtr;
    struct true_type {
      enum { value = 1 };
    };
    struct false_type {
      enum { value = 0 };
    };
    template <bool Condition>
    struct bool_constant;
    template <>
    struct bool_constant<true> : true_type {};
    template <>
    struct bool_constant<false> : false_type {};
    using std::conditional;
    using std::remove_const;
    using std::remove_pointer;
    using std::remove_reference;
    template <typename T>
    struct remove_all {
      typedef T type;
    };
    template <typename T>
    struct remove_all<const T> {
      typedef typename remove_all<T>::type type;
    };
    template <typename T>
    struct remove_all<T const&> {
      typedef typename remove_all<T>::type type;
    };
    template <typename T>
    struct remove_all<T&> {
      typedef typename remove_all<T>::type type;
    };
    template <typename T>
    struct remove_all<T const*> {
      typedef typename remove_all<T>::type type;
    };
    template <typename T>
    struct remove_all<T*> {
      typedef typename remove_all<T>::type type;
    };
    template <typename T>
    using remove_all_t = typename remove_all<T>::type;
    template <typename T>
    struct is_arithmetic {
      enum { value = false };
    };
    template <>
    struct is_arithmetic<float> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<double> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<long double> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<bool> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<char> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<signed char> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<unsigned char> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<signed short> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<unsigned short> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<signed int> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<unsigned int> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<signed long> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<unsigned long> {
      enum { value = true };
    };
    template <typename T, typename U>
    struct is_same {
      enum { value = 0 };
    };
    template <typename T>
    struct is_same<T, T> {
      enum { value = 1 };
    };
    template <class T>
    struct is_void : is_same<void, std::remove_const_t<T>> {};
    template <>
    struct is_arithmetic<signed long long> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<unsigned long long> {
      enum { value = true };
    };
    using std::is_integral;
    using std::make_unsigned;
    template <typename T>
    struct is_const {
      enum { value = 0 };
    };
    template <typename T>
    struct is_const<T const> {
      enum { value = 1 };
    };
    template <typename T>
    struct add_const_on_value_type {
      typedef const T type;
    };
    template <typename T>
    struct add_const_on_value_type<T&> {
      typedef T const& type;
    };
    template <typename T>
    struct add_const_on_value_type<T*> {
      typedef T const* type;
    };
    template <typename T>
    struct add_const_on_value_type<T* const> {
      typedef T const* const type;
    };
    template <typename T>
    struct add_const_on_value_type<T const* const> {
      typedef T const* const type;
    };
    template <typename T>
    using add_const_on_value_type_t = typename add_const_on_value_type<T>::type;
    using std::is_convertible;
    class noncopyable {
      noncopyable(const noncopyable&);
      const noncopyable& operator=(const noncopyable&);

    protected:
      noncopyable() {}
      ~noncopyable() {}
    };
    template <typename T, typename EnableIf = void>
    struct array_size {
      enum { value = Dynamic };
    };
    template <typename T>
    struct array_size<T, std::enable_if_t<((T::SizeAtCompileTime & 0) == 0)>> {
      enum { value = T::SizeAtCompileTime };
    };
    template <typename T, int N>
    struct array_size<const T (&)[N]> {
      enum { value = N };
    };
    template <typename T, int N>
    struct array_size<T (&)[N]> {
      enum { value = N };
    };
    template <typename T, std::size_t N>
    struct array_size<const std::array<T, N>> {
      enum { value = N };
    };
    template <typename T, std::size_t N>
    struct array_size<std::array<T, N>> {
      enum { value = N };
    };
    template <typename T>
    constexpr auto index_list_size(const T& x) {
      using R = std::common_type_t<std::ptrdiff_t, std::make_signed_t<decltype(x.size())>>;
      return static_cast<R>(x.size());
    }
    template <typename T, std::ptrdiff_t N>
    constexpr std::ptrdiff_t index_list_size(const T (&)[N]) {
      return N;
    }
    template <typename T>
    struct result_of;
    template <typename F, typename... ArgTypes>
    struct result_of<F(ArgTypes...)> {
      typedef typename std::invoke_result<F, ArgTypes...>::type type1;
      typedef remove_all_t<type1> type;
    };
    template <typename F, typename... ArgTypes>
    struct invoke_result {
      typedef typename std::invoke_result<F, ArgTypes...>::type type1;
      typedef remove_all_t<type1> type;
    };
    template <bool... values>
    using reduce_all =
        std::is_same<std::integer_sequence<bool, values..., true>, std::integer_sequence<bool, true, values...>>;
    template <bool... values>
    using reduce_any = std::integral_constant<bool,
                                              !std::is_same<std::integer_sequence<bool, values..., false>,
                                                            std::integer_sequence<bool, false, values...>>::value>;
    struct meta_yes {
      char a[1];
    };
    struct meta_no {
      char a[2];
    };
    template <typename T>
    struct has_ReturnType {
      template <typename C>
      static meta_yes testFunctor(C const*, typename C::ReturnType const* = 0);
      template <typename C>
      static meta_no testFunctor(...);
      enum { value = sizeof(testFunctor<T>(static_cast<T*>(0))) == sizeof(meta_yes) };
    };
    template <typename T>
    const T* return_ptr();
    template <typename T, typename IndexType = Index>
    struct has_nullary_operator {
      template <typename C>
      static meta_yes testFunctor(C const*, std::enable_if_t<(sizeof(return_ptr<C>()->operator()()) > 0)>* = 0);
      static meta_no testFunctor(...);
      enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
    };
    template <typename T, typename IndexType = Index>
    struct has_unary_operator {
      template <typename C>
      static meta_yes testFunctor(C const*,
                                  std::enable_if_t<(sizeof(return_ptr<C>()->operator()(IndexType(0))) > 0)>* = 0);
      static meta_no testFunctor(...);
      enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
    };
    template <typename T, typename IndexType = Index>
    struct has_binary_operator {
      template <typename C>
      static meta_yes testFunctor(
          C const*, std::enable_if_t<(sizeof(return_ptr<C>()->operator()(IndexType(0), IndexType(0))) > 0)>* = 0);
      static meta_no testFunctor(...);
      enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
    };
    template <int Y,
              int InfX = 0,
              int SupX = ((Y == 1) ? 1 : Y / 2),
              bool Done = ((SupX - InfX) <= 1 || ((SupX * SupX <= Y) && ((SupX + 1) * (SupX + 1) > Y)))>
    class meta_sqrt {
      enum {
        MidX = (InfX + SupX) / 2,
        TakeInf = MidX * MidX > Y ? 1 : 0,
        NewInf = int(TakeInf) ? InfX : int(MidX),
        NewSup = int(TakeInf) ? int(MidX) : SupX
      };

    public:
      enum { ret = meta_sqrt<Y, NewInf, NewSup>::ret };
    };
    template <int Y, int InfX, int SupX>
    class meta_sqrt<Y, InfX, SupX, true> {
    public:
      enum { ret = (SupX * SupX <= Y) ? SupX : InfX };
    };
    template <int A, int B, int K = 1, bool Done = ((A * K) % B) == 0, bool Big = (A >= B)>
    struct meta_least_common_multiple {
      enum { ret = meta_least_common_multiple<A, B, K + 1>::ret };
    };
    template <int A, int B, int K, bool Done>
    struct meta_least_common_multiple<A, B, K, Done, false> {
      enum { ret = meta_least_common_multiple<B, A, K>::ret };
    };
    template <int A, int B, int K>
    struct meta_least_common_multiple<A, B, K, true, true> {
      enum { ret = A * K };
    };
    template <typename T, typename U>
    struct scalar_product_traits {
      enum { Defined = 0 };
    };
    template <unsigned Len, unsigned Align>
    struct aligned_storage {
      struct type {
        alignas(Align) unsigned char data[Len];
      };
    };
  }  // namespace internal
  template <typename T>
  struct NumTraits;
  namespace numext {
    template <typename T>
    inline void swap(T& a, T& b) {
      std::swap(a, b);
    }
    using std::numeric_limits;
    template <typename T>
    T div_ceil(const T& a, const T& b) {
      return (a + b - 1) / b;
    }
    template <typename X, typename Y>
    inline bool equal_strict(const X& x, const Y& y) {
      return x == y;
    }
    template <>
    inline bool equal_strict(const float& x, const float& y) {
      return std::equal_to<float>()(x, y);
    }
    template <>
    inline bool equal_strict(const double& x, const double& y) {
      return std::equal_to<double>()(x, y);
    }
    template <typename X>
    inline bool is_exactly_zero(const X& x) {
      return equal_strict(x, typename NumTraits<X>::Literal{0});
    }
    template <typename X>
    inline bool is_exactly_one(const X& x) {
      return equal_strict(x, typename NumTraits<X>::Literal{1});
    }
    template <typename X, typename Y>
    inline bool not_equal_strict(const X& x, const Y& y) {
      return x != y;
    }
    template <>
    inline bool not_equal_strict(const float& x, const float& y) {
      return std::not_equal_to<float>()(x, y);
    }
    template <>
    inline bool not_equal_strict(const double& x, const double& y) {
      return std::not_equal_to<double>()(x, y);
    }
  }  // namespace numext
  namespace internal {
    template <typename Scalar>
    struct is_identically_zero_impl {
      static inline bool run(const Scalar& s) { return numext::is_exactly_zero(s); }
    };
    template <typename Scalar>
    inline bool is_identically_zero(const Scalar& s) {
      return is_identically_zero_impl<Scalar>::run(s);
    }
    template <typename A>
    constexpr bool is_int_or_enum_v = std::is_enum<A>::value || std::is_integral<A>::value;
    template <typename A, typename B>
    inline constexpr int plain_enum_min(A a, B b) {
      static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
      static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
      return ((int)a <= (int)b) ? (int)a : (int)b;
    }
    template <typename A, typename B>
    inline constexpr int plain_enum_max(A a, B b) {
      static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
      static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
      return ((int)a >= (int)b) ? (int)a : (int)b;
    }
    template <typename A, typename B>
    inline constexpr int min_size_prefer_dynamic(A a, B b) {
      static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
      static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
      if ((int)a == 0 || (int)b == 0)
        return 0;
      if ((int)a == 1 || (int)b == 1)
        return 1;
      if ((int)a == Dynamic || (int)b == Dynamic)
        return Dynamic;
      return plain_enum_min(a, b);
    }
    template <typename A, typename B>
    inline constexpr int min_size_prefer_fixed(A a, B b) {
      static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
      static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
      if ((int)a == 0 || (int)b == 0)
        return 0;
      if ((int)a == 1 || (int)b == 1)
        return 1;
      if ((int)a == Dynamic && (int)b == Dynamic)
        return Dynamic;
      if ((int)a == Dynamic)
        return (int)b;
      if ((int)b == Dynamic)
        return (int)a;
      return plain_enum_min(a, b);
    }
    template <typename A, typename B>
    inline constexpr int max_size_prefer_dynamic(A a, B b) {
      static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
      static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
      if ((int)a == Dynamic || (int)b == Dynamic)
        return Dynamic;
      return plain_enum_max(a, b);
    }
    inline constexpr bool logical_xor(bool a, bool b) { return a != b; }
    inline constexpr bool check_implication(bool a, bool b) { return !a || b; }
    using std::is_constant_evaluated;
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T>
    struct traits;
    template <typename T>
    struct traits<const T> : traits<T> {};
    template <typename Derived>
    struct has_direct_access {
      enum { ret = (traits<Derived>::Flags & DirectAccessBit) ? 1 : 0 };
    };
    template <typename Derived>
    struct accessors_level {
      enum {
        has_direct_access = (traits<Derived>::Flags & DirectAccessBit) ? 1 : 0,
        has_write_access = (traits<Derived>::Flags & LvalueBit) ? 1 : 0,
        value = has_direct_access ? (has_write_access ? DirectWriteAccessors : DirectAccessors)
                                  : (has_write_access ? WriteAccessors : ReadOnlyAccessors)
      };
    };
    template <typename T>
    struct evaluator_traits;
    template <typename T>
    struct evaluator;
  }  // namespace internal
  template <typename T>
  struct NumTraits;
  template <typename Derived>
  struct EigenBase;
  template <typename Derived>
  class DenseBase;
  template <typename Derived>
  class PlainObjectBase;
  template <typename Derived, int Level>
  class DenseCoeffsBase;
  template <typename Scalar_,
            int Rows_,
            int Cols_,
            int Options_ = AutoAlign | ((Rows_ == 1 && Cols_ != 1)   ? Eigen::RowMajor
                                        : (Cols_ == 1 && Rows_ != 1) ? Eigen::ColMajor
                                                                     : Eigen::ColMajor),
            int MaxRows_ = Rows_,
            int MaxCols_ = Cols_>
  class Matrix;
  template <typename Derived>
  class MatrixBase;
  template <typename Derived>
  class ArrayBase;
  template <typename ExpressionType, unsigned int Added, unsigned int Removed>
  class Flagged;
  template <typename ExpressionType, template <typename> class StorageBase>
  class NoAlias;
  template <typename ExpressionType>
  class NestByValue;
  template <typename ExpressionType>
  class ForceAlignedAccess;
  template <typename ExpressionType>
  class SwapWrapper;
  template <typename XprType, int BlockRows = Dynamic, int BlockCols = Dynamic, bool InnerPanel = false>
  class Block;
  template <typename XprType, typename RowIndices, typename ColIndices>
  class IndexedView;
  template <typename XprType, int Rows = Dynamic, int Cols = Dynamic, int Order = 0>
  class Reshaped;
  template <typename MatrixType, int Size = Dynamic>
  class VectorBlock;
  template <typename MatrixType>
  class Transpose;
  template <typename MatrixType>
  class Conjugate;
  template <typename NullaryOp, typename MatrixType>
  class CwiseNullaryOp;
  template <typename UnaryOp, typename MatrixType>
  class CwiseUnaryOp;
  template <typename BinaryOp, typename Lhs, typename Rhs>
  class CwiseBinaryOp;
  template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
  class CwiseTernaryOp;
  template <typename Decomposition, typename Rhstype>
  class Solve;
  template <typename XprType>
  class Inverse;
  template <typename Lhs, typename Rhs, int Option = DefaultProduct>
  class Product;
  template <typename Derived>
  class DiagonalBase;
  template <typename DiagonalVectorType_>
  class DiagonalWrapper;
  template <typename Scalar_, int SizeAtCompileTime, int MaxSizeAtCompileTime = SizeAtCompileTime>
  class DiagonalMatrix;
  template <typename MatrixType, typename DiagonalType, int ProductOrder>
  class DiagonalProduct;
  template <typename MatrixType, int Index = 0>
  class Diagonal;
  template <typename Derived>
  class SkewSymmetricBase;
  template <typename VectorType_>
  class SkewSymmetricWrapper;
  template <typename Scalar_>
  class SkewSymmetricMatrix3;
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime = SizeAtCompileTime, typename IndexType = int>
  class PermutationMatrix;
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime = SizeAtCompileTime, typename IndexType = int>
  class Transpositions;
  template <typename Derived>
  class PermutationBase;
  template <typename Derived>
  class TranspositionsBase;
  template <typename IndicesType_>
  class PermutationWrapper;
  template <typename IndicesType_>
  class TranspositionsWrapper;
  template <typename Derived,
            int Level = internal::accessors_level<Derived>::has_write_access ? WriteAccessors : ReadOnlyAccessors>
  class MapBase;
  template <int OuterStrideAtCompileTime, int InnerStrideAtCompileTime>
  class Stride;
  template <int Value = Dynamic>
  class InnerStride;
  template <int Value = Dynamic>
  class OuterStride;
  template <typename MatrixType, int MapOptions = Unaligned, typename StrideType = Stride<0, 0>>
  class Map;
  template <typename Derived>
  class RefBase;
  template <typename PlainObjectType,
            int Options = 0,
            typename StrideType =
                typename std::conditional_t<PlainObjectType::IsVectorAtCompileTime, InnerStride<1>, OuterStride<>>>
  class Ref;
  template <typename ViewOp, typename MatrixType, typename StrideType = Stride<0, 0>>
  class CwiseUnaryView;
  template <typename Derived>
  class TriangularBase;
  template <typename MatrixType, unsigned int Mode>
  class TriangularView;
  template <typename MatrixType, unsigned int Mode>
  class SelfAdjointView;
  template <typename MatrixType>
  class SparseView;
  template <typename ExpressionType>
  class WithFormat;
  template <typename MatrixType>
  struct CommaInitializer;
  template <typename Derived>
  class ReturnByValue;
  template <typename ExpressionType>
  class ArrayWrapper;
  template <typename ExpressionType>
  class MatrixWrapper;
  template <typename Derived>
  class SolverBase;
  template <typename XprType>
  class InnerIterator;
  namespace internal {
    template <typename XprType>
    class generic_randaccess_stl_iterator;
    template <typename XprType>
    class pointer_based_stl_iterator;
    template <typename XprType, DirectionType Direction>
    class subvector_stl_iterator;
    template <typename XprType, DirectionType Direction>
    class subvector_stl_reverse_iterator;
    template <typename DecompositionType>
    struct kernel_retval_base;
    template <typename DecompositionType>
    struct kernel_retval;
    template <typename DecompositionType>
    struct image_retval_base;
    template <typename DecompositionType>
    struct image_retval;
  }  // namespace internal
  namespace internal {
    template <typename Scalar_,
              int Rows = Dynamic,
              int Cols = Dynamic,
              int Supers = Dynamic,
              int Subs = Dynamic,
              int Options = 0>
    class BandMatrix;
  }
  namespace internal {
    template <typename Lhs, typename Rhs>
    struct product_type;
    template <bool>
    struct EnableIf;
    template <typename T,
              int ProductTag = internal::product_type<typename T::Lhs, typename T::Rhs>::ret,
              typename LhsShape = typename evaluator_traits<typename T::Lhs>::Shape,
              typename RhsShape = typename evaluator_traits<typename T::Rhs>::Shape,
              typename LhsScalar = typename traits<typename T::Lhs>::Scalar,
              typename RhsScalar = typename traits<typename T::Rhs>::Scalar>
    struct product_evaluator;
  }  // namespace internal
  template <typename Lhs, typename Rhs, int ProductType = internal::product_type<Lhs, Rhs>::value>
  struct ProductReturnType;
  template <typename Lhs, typename Rhs>
  struct LazyProductReturnType;
  namespace internal {
    template <typename LhsScalar, typename RhsScalar, bool ConjLhs = false, bool ConjRhs = false>
    struct conj_helper;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_sum_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_difference_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_conj_product_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar, int NaNPropagation = PropagateFast>
    struct scalar_min_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar, int NaNPropagation = PropagateFast>
    struct scalar_max_op;
    template <typename Scalar>
    struct scalar_opposite_op;
    template <typename Scalar>
    struct scalar_conjugate_op;
    template <typename Scalar>
    struct scalar_real_op;
    template <typename Scalar>
    struct scalar_imag_op;
    template <typename Scalar>
    struct scalar_abs_op;
    template <typename Scalar>
    struct scalar_abs2_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_absolute_difference_op;
    template <typename Scalar>
    struct scalar_sqrt_op;
    template <typename Scalar>
    struct scalar_rsqrt_op;
    template <typename Scalar>
    struct scalar_exp_op;
    template <typename Scalar>
    struct scalar_log_op;
    template <typename Scalar>
    struct scalar_cos_op;
    template <typename Scalar>
    struct scalar_sin_op;
    template <typename Scalar>
    struct scalar_acos_op;
    template <typename Scalar>
    struct scalar_asin_op;
    template <typename Scalar>
    struct scalar_tan_op;
    template <typename Scalar>
    struct scalar_inverse_op;
    template <typename Scalar>
    struct scalar_square_op;
    template <typename Scalar>
    struct scalar_cube_op;
    template <typename Scalar, typename NewType>
    struct scalar_cast_op;
    template <typename Scalar>
    struct scalar_random_op;
    template <typename Scalar>
    struct scalar_constant_op;
    template <typename Scalar>
    struct scalar_identity_op;
    template <typename Scalar>
    struct scalar_sign_op;
    template <typename Scalar, typename ScalarExponent>
    struct scalar_pow_op;
    template <typename Scalar,
              typename ScalarExponent,
              bool BaseIsInteger,
              bool ExponentIsInteger,
              bool BaseIsComplex,
              bool ExponentIsComplex>
    struct scalar_unary_pow_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_hypot_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_product_op;
    template <typename LhsScalar, typename RhsScalar = LhsScalar>
    struct scalar_quotient_op;
    template <typename Scalar>
    struct scalar_lgamma_op;
    template <typename Scalar>
    struct scalar_digamma_op;
    template <typename Scalar>
    struct scalar_erf_op;
    template <typename Scalar>
    struct scalar_erfc_op;
    template <typename Scalar>
    struct scalar_ndtri_op;
    template <typename Scalar>
    struct scalar_igamma_op;
    template <typename Scalar>
    struct scalar_igammac_op;
    template <typename Scalar>
    struct scalar_zeta_op;
    template <typename Scalar>
    struct scalar_betainc_op;
    template <typename Scalar>
    struct scalar_bessel_i0_op;
    template <typename Scalar>
    struct scalar_bessel_i0e_op;
    template <typename Scalar>
    struct scalar_bessel_i1_op;
    template <typename Scalar>
    struct scalar_bessel_i1e_op;
    template <typename Scalar>
    struct scalar_bessel_j0_op;
    template <typename Scalar>
    struct scalar_bessel_y0_op;
    template <typename Scalar>
    struct scalar_bessel_j1_op;
    template <typename Scalar>
    struct scalar_bessel_y1_op;
    template <typename Scalar>
    struct scalar_bessel_k0_op;
    template <typename Scalar>
    struct scalar_bessel_k0e_op;
    template <typename Scalar>
    struct scalar_bessel_k1_op;
    template <typename Scalar>
    struct scalar_bessel_k1e_op;
  }  // namespace internal
  struct IOFormat;
  template <typename Scalar_,
            int Rows_,
            int Cols_,
            int Options_ = AutoAlign | ((Rows_ == 1 && Cols_ != 1)   ? Eigen::RowMajor
                                        : (Cols_ == 1 && Rows_ != 1) ? Eigen::ColMajor
                                                                     : Eigen::ColMajor),
            int MaxRows_ = Rows_,
            int MaxCols_ = Cols_>
  class Array;
  template <typename ConditionMatrixType, typename ThenMatrixType, typename ElseMatrixType>
  class Select;
  template <typename MatrixType, typename BinaryOp, int Direction>
  class PartialReduxExpr;
  template <typename ExpressionType, int Direction>
  class VectorwiseOp;
  template <typename MatrixType, int RowFactor, int ColFactor>
  class Replicate;
  template <typename MatrixType, int Direction = BothDirections>
  class Reverse;
  template <typename MatrixType>
  class FullPivLU;
  template <typename MatrixType>
  class PartialPivLU;
  namespace internal {
    template <typename MatrixType>
    struct inverse_impl;
  }
  template <typename MatrixType>
  class HouseholderQR;
  template <typename MatrixType>
  class ColPivHouseholderQR;
  template <typename MatrixType>
  class FullPivHouseholderQR;
  template <typename MatrixType>
  class CompleteOrthogonalDecomposition;
  template <typename MatrixType>
  class SVDBase;
  template <typename MatrixType, int Options = 0>
  class JacobiSVD;
  template <typename MatrixType, int Options = 0>
  class BDCSVD;
  template <typename MatrixType, int UpLo = Lower>
  class LLT;
  template <typename MatrixType, int UpLo = Lower>
  class LDLT;
  template <typename VectorsType, typename CoeffsType, int Side = OnTheLeft>
  class HouseholderSequence;
  template <typename Scalar>
  class JacobiRotation;
  template <typename Derived, int Dim_>
  class RotationBase;
  template <typename Lhs, typename Rhs>
  class Cross;
  template <typename Derived>
  class QuaternionBase;
  template <typename Scalar>
  class Rotation2D;
  template <typename Scalar>
  class AngleAxis;
  template <typename Scalar, int Dim>
  class Translation;
  template <typename Scalar, int Dim>
  class AlignedBox;
  template <typename Scalar, int Options = AutoAlign>
  class Quaternion;
  template <typename Scalar, int Dim, int Mode, int Options_ = AutoAlign>
  class Transform;
  template <typename Scalar_, int AmbientDim_, int Options = AutoAlign>
  class ParametrizedLine;
  template <typename Scalar_, int AmbientDim_, int Options = AutoAlign>
  class Hyperplane;
  template <typename Scalar>
  class UniformScaling;
  template <typename MatrixType, int Direction>
  class Homogeneous;
  template <typename Derived>
  class SparseMatrixBase;
  template <typename Derived>
  struct MatrixExponentialReturnValue;
  template <typename Derived>
  class MatrixFunctionReturnValue;
  template <typename Derived>
  class MatrixSquareRootReturnValue;
  template <typename Derived>
  class MatrixLogarithmReturnValue;
  template <typename Derived>
  class MatrixPowerReturnValue;
  template <typename Derived>
  class MatrixComplexPowerReturnValue;
  namespace internal {
    template <typename Scalar>
    struct stem_function {
      typedef std::complex<typename NumTraits<Scalar>::Real> ComplexScalar;
      typedef ComplexScalar type(ComplexScalar, int);
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename IndexDest, typename IndexSrc>
    inline IndexDest convert_index(const IndexSrc& idx) {
      ;
      return IndexDest(idx);
    }
    template <typename T>
    struct is_valid_index_type {
      enum { value = internal::is_integral<T>::value || std::is_enum<T>::value };
    };
    template <typename RowIndices, typename ColIndices>
    struct valid_indexed_view_overload {
      enum {
        value = !(internal::is_valid_index_type<RowIndices>::value && internal::is_valid_index_type<ColIndices>::value)
      };
    };
    template <typename ExprScalar, typename T, bool IsSupported>
    struct promote_scalar_arg;
    template <typename S, typename T>
    struct promote_scalar_arg<S, T, true> {
      typedef T type;
    };
    template <typename ExprScalar,
              typename T,
              typename PromotedType,
              bool ConvertibleToLiteral = internal::is_convertible<T, PromotedType>::value,
              bool IsSafe = NumTraits<T>::IsInteger || !NumTraits<PromotedType>::IsInteger>
    struct promote_scalar_arg_unsupported;
    template <typename S, typename T>
    struct promote_scalar_arg<S, T, false> : promote_scalar_arg_unsupported<S, T, typename NumTraits<S>::Literal> {};
    template <typename S, typename T, typename PromotedType>
    struct promote_scalar_arg_unsupported<S, T, PromotedType, true, true> {
      typedef PromotedType type;
    };
    template <typename ExprScalar, typename T, typename PromotedType>
    struct promote_scalar_arg_unsupported<ExprScalar, T, PromotedType, false, true>
        : promote_scalar_arg_unsupported<ExprScalar, T, ExprScalar> {};
    template <typename S, typename T, typename PromotedType, bool ConvertibleToLiteral>
    struct promote_scalar_arg_unsupported<S, T, PromotedType, ConvertibleToLiteral, false> {};
    template <typename S, typename T>
    struct promote_scalar_arg_unsupported<S, T, S, false, true> {};
    class no_assignment_operator {
    private:
      no_assignment_operator& operator=(const no_assignment_operator&);

    protected:
      no_assignment_operator(const no_assignment_operator&) = default;
      no_assignment_operator() = default;
      ~no_assignment_operator() = default;
    };
    template <typename I1, typename I2>
    struct promote_index_type {
      typedef std::conditional_t<(sizeof(I1) < sizeof(I2)), I2, I1> type;
    };
    template <typename T, int Value>
    class variable_if_dynamic {
    public:
      variable_if_dynamic() = default;
      ~variable_if_dynamic() = default;
      inline explicit variable_if_dynamic(T v) {
        ;
        (static_cast<bool>(v == T(Value))
             ? void(0)
             : __assert_fail("v == T(Value)",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/XprHelper.h",
                             116,
                             __extension__ __PRETTY_FUNCTION__));
      }
      static inline constexpr T value() { return T(Value); }
      inline constexpr operator T() const { return T(Value); }
      inline void setValue(T v) const {
        ;
        (static_cast<bool>(v == T(Value))
             ? void(0)
             : __assert_fail("v == T(Value)",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/XprHelper.h",
                             122,
                             __extension__ __PRETTY_FUNCTION__));
      }
    };
    template <typename T>
    class variable_if_dynamic<T, Dynamic> {
      T m_value;

    public:
      inline explicit variable_if_dynamic(T value = 0) noexcept(true) : m_value(value) {}
      inline T value() const { return m_value; }
      inline operator T() const { return m_value; }
      inline void setValue(T value) { m_value = value; }
    };
    template <typename T, int Value>
    class variable_if_dynamicindex {
    public:
      inline explicit variable_if_dynamicindex(T v) {
        ;
        (static_cast<bool>(v == T(Value))
             ? void(0)
             : __assert_fail("v == T(Value)",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/XprHelper.h",
                             140,
                             __extension__ __PRETTY_FUNCTION__));
      }
      static inline constexpr T value() { return T(Value); }
      inline void setValue(T) {}
    };
    template <typename T>
    class variable_if_dynamicindex<T, DynamicIndex> {
      T m_value;
      variable_if_dynamicindex() {
        (static_cast<bool>(false)
             ? void(0)
             : __assert_fail("false",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/XprHelper.h",
                             150,
                             __extension__ __PRETTY_FUNCTION__));
      }

    public:
      inline explicit variable_if_dynamicindex(T value) : m_value(value) {}
      T inline value() const { return m_value; }
      inline void setValue(T value) { m_value = value; }
    };
    template <typename T>
    struct functor_traits {
      enum { Cost = 10, PacketAccess = false, IsRepeatable = false };
    };
    template <typename T>
    struct packet_traits;
    template <typename T>
    struct unpacket_traits;
    template <int Size,
              typename PacketType,
              bool Stop = Size == Dynamic || (Size % unpacket_traits<PacketType>::size) == 0 ||
                          is_same<PacketType, typename unpacket_traits<PacketType>::half>::value>
    struct find_best_packet_helper;
    template <int Size, typename PacketType>
    struct find_best_packet_helper<Size, PacketType, true> {
      typedef PacketType type;
    };
    template <int Size, typename PacketType>
    struct find_best_packet_helper<Size, PacketType, false> {
      typedef typename find_best_packet_helper<Size, typename unpacket_traits<PacketType>::half>::type type;
    };
    template <typename T, int Size>
    struct find_best_packet {
      typedef typename find_best_packet_helper<Size, typename packet_traits<T>::type>::type type;
    };
    constexpr inline int compute_default_alignment_helper(int ArrayBytes, int AlignmentBytes) {
      if ((ArrayBytes % AlignmentBytes) == 0) {
        return AlignmentBytes;
      } else if (16 < AlignmentBytes) {
        return compute_default_alignment_helper(ArrayBytes, AlignmentBytes / 2);
      } else {
        return 0;
      }
    }
    template <typename T, int Size>
    struct compute_default_alignment {
      enum { value = compute_default_alignment_helper(Size * sizeof(T), 16) };
    };
    template <typename T>
    struct compute_default_alignment<T, Dynamic> {
      enum { value = 64 };
    };
    template <typename Scalar_,
              int Rows_,
              int Cols_,
              int Options_ = AutoAlign | ((Rows_ == 1 && Cols_ != 1)   ? RowMajor
                                          : (Cols_ == 1 && Rows_ != 1) ? ColMajor
                                                                       : Eigen::ColMajor),
              int MaxRows_ = Rows_,
              int MaxCols_ = Cols_>
    class make_proper_matrix_type {
      enum {
        IsColVector = Cols_ == 1 && Rows_ != 1,
        IsRowVector = Rows_ == 1 && Cols_ != 1,
        Options = IsColVector   ? (Options_ | ColMajor) & ~RowMajor
                  : IsRowVector ? (Options_ | RowMajor) & ~ColMajor
                                : Options_
      };

    public:
      typedef Matrix<Scalar_, Rows_, Cols_, Options, MaxRows_, MaxCols_> type;
    };
    constexpr inline unsigned compute_matrix_flags(int Options) {
      unsigned row_major_bit = Options & RowMajor ? RowMajorBit : 0;
      return DirectAccessBit | LvalueBit | NestByRefBit | row_major_bit;
    }
    constexpr inline int size_at_compile_time(int rows, int cols) {
      return (rows == Dynamic || cols == Dynamic) ? Dynamic : rows * cols;
    }
    template <typename XprType>
    struct size_of_xpr_at_compile_time {
      enum { ret = size_at_compile_time(traits<XprType>::RowsAtCompileTime, traits<XprType>::ColsAtCompileTime) };
    };
    template <typename T, typename StorageKind = typename traits<T>::StorageKind>
    struct plain_matrix_type;
    template <typename T, typename BaseClassType, int Flags>
    struct plain_matrix_type_dense;
    template <typename T>
    struct plain_matrix_type<T, Dense> {
      typedef typename plain_matrix_type_dense<T, typename traits<T>::XprKind, traits<T>::Flags>::type type;
    };
    template <typename T>
    struct plain_matrix_type<T, DiagonalShape> {
      typedef typename T::PlainObject type;
    };
    template <typename T>
    struct plain_matrix_type<T, SkewSymmetricShape> {
      typedef typename T::PlainObject type;
    };
    template <typename T, int Flags>
    struct plain_matrix_type_dense<T, MatrixXpr, Flags> {
      typedef Matrix<typename traits<T>::Scalar,
                     traits<T>::RowsAtCompileTime,
                     traits<T>::ColsAtCompileTime,
                     AutoAlign | (Flags & RowMajorBit ? RowMajor : ColMajor),
                     traits<T>::MaxRowsAtCompileTime,
                     traits<T>::MaxColsAtCompileTime>
          type;
    };
    template <typename T, int Flags>
    struct plain_matrix_type_dense<T, ArrayXpr, Flags> {
      typedef Array<typename traits<T>::Scalar,
                    traits<T>::RowsAtCompileTime,
                    traits<T>::ColsAtCompileTime,
                    AutoAlign | (Flags & RowMajorBit ? RowMajor : ColMajor),
                    traits<T>::MaxRowsAtCompileTime,
                    traits<T>::MaxColsAtCompileTime>
          type;
    };
    template <typename T, typename StorageKind = typename traits<T>::StorageKind>
    struct eval;
    template <typename T>
    struct eval<T, Dense> {
      typedef typename plain_matrix_type<T>::type type;
    };
    template <typename T>
    struct eval<T, DiagonalShape> {
      typedef typename plain_matrix_type<T>::type type;
    };
    template <typename T>
    struct eval<T, SkewSymmetricShape> {
      typedef typename plain_matrix_type<T>::type type;
    };
    template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
    struct eval<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>, Dense> {
      typedef const Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>& type;
    };
    template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
    struct eval<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>, Dense> {
      typedef const Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>& type;
    };
    template <typename T, typename StorageKind = typename traits<T>::StorageKind>
    struct plain_object_eval;
    template <typename T>
    struct plain_object_eval<T, Dense> {
      typedef typename plain_matrix_type_dense<T, typename traits<T>::XprKind, evaluator<T>::Flags>::type type;
    };
    template <typename T>
    struct plain_matrix_type_column_major {
      enum {
        Rows = traits<T>::RowsAtCompileTime,
        Cols = traits<T>::ColsAtCompileTime,
        MaxRows = traits<T>::MaxRowsAtCompileTime,
        MaxCols = traits<T>::MaxColsAtCompileTime
      };
      typedef Matrix<typename traits<T>::Scalar,
                     Rows,
                     Cols,
                     (MaxRows == 1 && MaxCols != 1) ? RowMajor : ColMajor,
                     MaxRows,
                     MaxCols>
          type;
    };
    template <typename T>
    struct plain_matrix_type_row_major {
      enum {
        Rows = traits<T>::RowsAtCompileTime,
        Cols = traits<T>::ColsAtCompileTime,
        MaxRows = traits<T>::MaxRowsAtCompileTime,
        MaxCols = traits<T>::MaxColsAtCompileTime
      };
      typedef Matrix<typename traits<T>::Scalar,
                     Rows,
                     Cols,
                     (MaxCols == 1 && MaxRows != 1) ? ColMajor : RowMajor,
                     MaxRows,
                     MaxCols>
          type;
    };
    template <typename T>
    struct ref_selector {
      typedef std::conditional_t<bool(traits<T>::Flags& NestByRefBit), T const&, const T> type;
      typedef std::conditional_t<bool(traits<T>::Flags& NestByRefBit), T&, T> non_const_type;
    };
    template <typename T1, typename T2>
    struct transfer_constness {
      typedef std::conditional_t<bool(internal::is_const<T1>::value), add_const_on_value_type_t<T2>, T2> type;
    };
    template <typename T, int n, typename PlainObject = typename plain_object_eval<T>::type>
    struct nested_eval {
      enum {
        ScalarReadCost = NumTraits<typename traits<T>::Scalar>::ReadCost,
        CoeffReadCost = evaluator<T>::CoeffReadCost,
        NAsInteger = n == Dynamic ? HugeCost : n,
        CostEval = (NAsInteger + 1) * ScalarReadCost + CoeffReadCost,
        CostNoEval = NAsInteger * CoeffReadCost,
        Evaluate = (int(evaluator<T>::Flags) & EvalBeforeNestingBit) || (int(CostEval) < int(CostNoEval))
      };
      typedef std::conditional_t<Evaluate, PlainObject, typename ref_selector<T>::type> type;
    };
    template <typename T>
    inline T* const_cast_ptr(const T* ptr) {
      return const_cast<T*>(ptr);
    }
    template <typename Derived, typename XprKind = typename traits<Derived>::XprKind>
    struct dense_xpr_base {};
    template <typename Derived>
    struct dense_xpr_base<Derived, MatrixXpr> {
      typedef MatrixBase<Derived> type;
    };
    template <typename Derived>
    struct dense_xpr_base<Derived, ArrayXpr> {
      typedef ArrayBase<Derived> type;
    };
    template <typename Derived,
              typename XprKind = typename traits<Derived>::XprKind,
              typename StorageKind = typename traits<Derived>::StorageKind>
    struct generic_xpr_base;
    template <typename Derived, typename XprKind>
    struct generic_xpr_base<Derived, XprKind, Dense> {
      typedef typename dense_xpr_base<Derived, XprKind>::type type;
    };
    template <typename XprType, typename CastType>
    struct cast_return_type {
      typedef typename XprType::Scalar CurrentScalarType;
      typedef remove_all_t<CastType> CastType_;
      typedef typename CastType_::Scalar NewScalarType;
      typedef std::conditional_t<is_same<CurrentScalarType, NewScalarType>::value, const XprType&, CastType> type;
    };
    template <typename A, typename B>
    struct promote_storage_type;
    template <typename A>
    struct promote_storage_type<A, A> {
      typedef A ret;
    };
    template <typename A>
    struct promote_storage_type<A, const A> {
      typedef A ret;
    };
    template <typename A>
    struct promote_storage_type<const A, A> {
      typedef A ret;
    };
    template <typename A, typename B, typename Functor>
    struct cwise_promote_storage_type;
    template <typename A, typename Functor>
    struct cwise_promote_storage_type<A, A, Functor> {
      typedef A ret;
    };
    template <typename Functor>
    struct cwise_promote_storage_type<Dense, Dense, Functor> {
      typedef Dense ret;
    };
    template <typename A, typename Functor>
    struct cwise_promote_storage_type<A, Dense, Functor> {
      typedef Dense ret;
    };
    template <typename B, typename Functor>
    struct cwise_promote_storage_type<Dense, B, Functor> {
      typedef Dense ret;
    };
    template <typename Functor>
    struct cwise_promote_storage_type<Sparse, Dense, Functor> {
      typedef Sparse ret;
    };
    template <typename Functor>
    struct cwise_promote_storage_type<Dense, Sparse, Functor> {
      typedef Sparse ret;
    };
    template <typename LhsKind, typename RhsKind, int LhsOrder, int RhsOrder>
    struct cwise_promote_storage_order {
      enum { value = LhsOrder };
    };
    template <typename LhsKind, int LhsOrder, int RhsOrder>
    struct cwise_promote_storage_order<LhsKind, Sparse, LhsOrder, RhsOrder> {
      enum { value = RhsOrder };
    };
    template <typename RhsKind, int LhsOrder, int RhsOrder>
    struct cwise_promote_storage_order<Sparse, RhsKind, LhsOrder, RhsOrder> {
      enum { value = LhsOrder };
    };
    template <int Order>
    struct cwise_promote_storage_order<Sparse, Sparse, Order, Order> {
      enum { value = Order };
    };
    template <typename A, typename B, int ProductTag>
    struct product_promote_storage_type;
    template <typename A, int ProductTag>
    struct product_promote_storage_type<A, A, ProductTag> {
      typedef A ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<Dense, Dense, ProductTag> {
      typedef Dense ret;
    };
    template <typename A, int ProductTag>
    struct product_promote_storage_type<A, Dense, ProductTag> {
      typedef Dense ret;
    };
    template <typename B, int ProductTag>
    struct product_promote_storage_type<Dense, B, ProductTag> {
      typedef Dense ret;
    };
    template <typename A, int ProductTag>
    struct product_promote_storage_type<A, DiagonalShape, ProductTag> {
      typedef A ret;
    };
    template <typename B, int ProductTag>
    struct product_promote_storage_type<DiagonalShape, B, ProductTag> {
      typedef B ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<Dense, DiagonalShape, ProductTag> {
      typedef Dense ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<DiagonalShape, Dense, ProductTag> {
      typedef Dense ret;
    };
    template <typename A, int ProductTag>
    struct product_promote_storage_type<A, SkewSymmetricShape, ProductTag> {
      typedef A ret;
    };
    template <typename B, int ProductTag>
    struct product_promote_storage_type<SkewSymmetricShape, B, ProductTag> {
      typedef B ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<Dense, SkewSymmetricShape, ProductTag> {
      typedef Dense ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<SkewSymmetricShape, Dense, ProductTag> {
      typedef Dense ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<SkewSymmetricShape, SkewSymmetricShape, ProductTag> {
      typedef Dense ret;
    };
    template <typename A, int ProductTag>
    struct product_promote_storage_type<A, PermutationStorage, ProductTag> {
      typedef A ret;
    };
    template <typename B, int ProductTag>
    struct product_promote_storage_type<PermutationStorage, B, ProductTag> {
      typedef B ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<Dense, PermutationStorage, ProductTag> {
      typedef Dense ret;
    };
    template <int ProductTag>
    struct product_promote_storage_type<PermutationStorage, Dense, ProductTag> {
      typedef Dense ret;
    };
    template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
    struct plain_row_type {
      typedef Matrix<Scalar,
                     1,
                     ExpressionType::ColsAtCompileTime,
                     int(ExpressionType::PlainObject::Options) | int(RowMajor),
                     1,
                     ExpressionType::MaxColsAtCompileTime>
          MatrixRowType;
      typedef Array<Scalar,
                    1,
                    ExpressionType::ColsAtCompileTime,
                    int(ExpressionType::PlainObject::Options) | int(RowMajor),
                    1,
                    ExpressionType::MaxColsAtCompileTime>
          ArrayRowType;
      typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value,
                                 MatrixRowType,
                                 ArrayRowType>
          type;
    };
    template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
    struct plain_col_type {
      typedef Matrix<Scalar,
                     ExpressionType::RowsAtCompileTime,
                     1,
                     ExpressionType::PlainObject::Options & ~RowMajor,
                     ExpressionType::MaxRowsAtCompileTime,
                     1>
          MatrixColType;
      typedef Array<Scalar,
                    ExpressionType::RowsAtCompileTime,
                    1,
                    ExpressionType::PlainObject::Options & ~RowMajor,
                    ExpressionType::MaxRowsAtCompileTime,
                    1>
          ArrayColType;
      typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value,
                                 MatrixColType,
                                 ArrayColType>
          type;
    };
    template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
    struct plain_diag_type {
      enum {
        diag_size =
            internal::min_size_prefer_dynamic(ExpressionType::RowsAtCompileTime, ExpressionType::ColsAtCompileTime),
        max_diag_size =
            min_size_prefer_fixed(ExpressionType::MaxRowsAtCompileTime, ExpressionType::MaxColsAtCompileTime)
      };
      typedef Matrix<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1>
          MatrixDiagType;
      typedef Array<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1>
          ArrayDiagType;
      typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value,
                                 MatrixDiagType,
                                 ArrayDiagType>
          type;
    };
    template <typename Expr, typename Scalar = typename Expr::Scalar>
    struct plain_constant_type {
      enum { Options = (traits<Expr>::Flags & RowMajorBit) ? RowMajor : 0 };
      typedef Array<Scalar,
                    traits<Expr>::RowsAtCompileTime,
                    traits<Expr>::ColsAtCompileTime,
                    Options,
                    traits<Expr>::MaxRowsAtCompileTime,
                    traits<Expr>::MaxColsAtCompileTime>
          array_type;
      typedef Matrix<Scalar,
                     traits<Expr>::RowsAtCompileTime,
                     traits<Expr>::ColsAtCompileTime,
                     Options,
                     traits<Expr>::MaxRowsAtCompileTime,
                     traits<Expr>::MaxColsAtCompileTime>
          matrix_type;
      typedef CwiseNullaryOp<
          scalar_constant_op<Scalar>,
          const std::conditional_t<is_same<typename traits<Expr>::XprKind, MatrixXpr>::value, matrix_type, array_type>>
          type;
    };
    template <typename ExpressionType>
    struct is_lvalue {
      enum { value = (!bool(is_const<ExpressionType>::value)) && bool(traits<ExpressionType>::Flags & LvalueBit) };
    };
    template <typename T>
    struct is_diagonal {
      enum { ret = false };
    };
    template <typename T>
    struct is_diagonal<DiagonalBase<T>> {
      enum { ret = true };
    };
    template <typename T>
    struct is_diagonal<DiagonalWrapper<T>> {
      enum { ret = true };
    };
    template <typename T, int S>
    struct is_diagonal<DiagonalMatrix<T, S>> {
      enum { ret = true };
    };
    template <typename T>
    struct is_identity {
      enum { value = false };
    };
    template <typename T>
    struct is_identity<CwiseNullaryOp<internal::scalar_identity_op<typename T::Scalar>, T>> {
      enum { value = true };
    };
    template <typename S1, typename S2>
    struct glue_shapes;
    template <>
    struct glue_shapes<DenseShape, TriangularShape> {
      typedef TriangularShape type;
    };
    template <typename T1, typename T2>
    struct possibly_same_dense {
      enum {
        value = has_direct_access<T1>::ret && has_direct_access<T2>::ret &&
                is_same<typename T1::Scalar, typename T2::Scalar>::value
      };
    };
    template <typename T1, typename T2>
    bool is_same_dense(const T1& mat1, const T2& mat2, std::enable_if_t<possibly_same_dense<T1, T2>::value>* = 0) {
      return (mat1.data() == mat2.data()) && (mat1.innerStride() == mat2.innerStride()) &&
             (mat1.outerStride() == mat2.outerStride());
    }
    template <typename T1, typename T2>
    bool is_same_dense(const T1&, const T2&, std::enable_if_t<!possibly_same_dense<T1, T2>::value>* = 0) {
      return false;
    }
    template <typename T, bool Vectorized = false, typename EnableIf = void>
    struct scalar_div_cost {
      enum { value = 8 * NumTraits<T>::MulCost };
    };
    template <typename T, bool Vectorized>
    struct scalar_div_cost<std::complex<T>, Vectorized> {
      enum { value = 2 * scalar_div_cost<T>::value + 6 * NumTraits<T>::MulCost + 3 * NumTraits<T>::AddCost };
    };
    template <bool Vectorized>
    struct scalar_div_cost<signed long, Vectorized, std::conditional_t<sizeof(long) == 8, void, false_type>> {
      enum { value = 24 };
    };
    template <bool Vectorized>
    struct scalar_div_cost<unsigned long, Vectorized, std::conditional_t<sizeof(long) == 8, void, false_type>> {
      enum { value = 21 };
    };
  }  // namespace internal
  template <typename ScalarA, typename ScalarB, typename BinaryOp = internal::scalar_product_op<ScalarA, ScalarB>>
  struct ScalarBinaryOpTraits : internal::scalar_product_traits<ScalarA, ScalarB> {};
  template <typename T, typename BinaryOp>
  struct ScalarBinaryOpTraits<T, T, BinaryOp> {
    typedef T ReturnType;
  };
  template <typename T, typename BinaryOp>
  struct ScalarBinaryOpTraits<T, typename NumTraits<std::enable_if_t<NumTraits<T>::IsComplex, T>>::Real, BinaryOp> {
    typedef T ReturnType;
  };
  template <typename T, typename BinaryOp>
  struct ScalarBinaryOpTraits<typename NumTraits<std::enable_if_t<NumTraits<T>::IsComplex, T>>::Real, T, BinaryOp> {
    typedef T ReturnType;
  };
  template <typename T, typename BinaryOp>
  struct ScalarBinaryOpTraits<T, void, BinaryOp> {
    typedef T ReturnType;
  };
  template <typename T, typename BinaryOp>
  struct ScalarBinaryOpTraits<void, T, BinaryOp> {
    typedef T ReturnType;
  };
  template <typename BinaryOp>
  struct ScalarBinaryOpTraits<void, void, BinaryOp> {
    typedef void ReturnType;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    inline void throw_std_bad_alloc() { throw std::bad_alloc(); }
    inline void* handmade_aligned_malloc(std::size_t size, std::size_t alignment = 64) {
      (static_cast<bool>(alignment >= sizeof(void*) && (alignment & (alignment - 1)) == 0 &&
                         "Alignment must be at least sizeof(void*) and a power of 2")
           ? void(0)
           : __assert_fail("alignment >= sizeof(void*) && (alignment & (alignment-1)) == 0 && \"Alignment must be at "
                           "least sizeof(void*) and a power of 2\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/util/Memory.h",
                           104,
                           __extension__ __PRETTY_FUNCTION__));
      using std::malloc;
      void* original = malloc(size + alignment);
      if (original == 0)
        return 0;
      void* aligned = reinterpret_cast<void*>(
          (reinterpret_cast<std::size_t>(original) & ~(std::size_t(alignment - 1))) + alignment);
      *(reinterpret_cast<void**>(aligned) - 1) = original;
      return aligned;
    }
    inline void handmade_aligned_free(void* ptr) {
      if (ptr) {
        using std::free;
        free(*(reinterpret_cast<void**>(ptr) - 1));
      }
    }
    inline void* handmade_aligned_realloc(void* ptr, std::size_t size, std::size_t = 0) {
      if (ptr == 0)
        return handmade_aligned_malloc(size);
      void* original = *(reinterpret_cast<void**>(ptr) - 1);
      std::ptrdiff_t previous_offset = static_cast<char*>(ptr) - static_cast<char*>(original);
      original = std::realloc(original, size + 64);
      if (original == 0)
        return 0;
      void* aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(64 - 1))) + 64);
      void* previous_aligned = static_cast<char*>(original) + previous_offset;
      if (aligned != previous_aligned)
        std::memmove(aligned, previous_aligned, size);
      *(reinterpret_cast<void**>(aligned) - 1) = original;
      return aligned;
    }
    inline void check_that_malloc_is_allowed() {}
    inline void* aligned_malloc(std::size_t size) {
      check_that_malloc_is_allowed();
      void* result;
      result = handmade_aligned_malloc(size);
      if (!result && size)
        throw_std_bad_alloc();
      return result;
    }
    inline void aligned_free(void* ptr) { handmade_aligned_free(ptr); }
    inline void* aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {
      if (ptr == 0)
        return aligned_malloc(new_size);
      Eigen::internal::ignore_unused_variable(old_size);
      void* result;
      result = handmade_aligned_realloc(ptr, new_size, old_size);
      if (!result && new_size)
        throw_std_bad_alloc();
      return result;
    }
    template <bool Align>
    inline void* conditional_aligned_malloc(std::size_t size) {
      return aligned_malloc(size);
    }
    template <>
    inline void* conditional_aligned_malloc<false>(std::size_t size) {
      check_that_malloc_is_allowed();
      using std::malloc;
      void* result = malloc(size);
      if (!result && size)
        throw_std_bad_alloc();
      return result;
    }
    template <bool Align>
    inline void conditional_aligned_free(void* ptr) {
      aligned_free(ptr);
    }
    template <>
    inline void conditional_aligned_free<false>(void* ptr) {
      using std::free;
      free(ptr);
    }
    template <bool Align>
    inline void* conditional_aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {
      return aligned_realloc(ptr, new_size, old_size);
    }
    template <>
    inline void* conditional_aligned_realloc<false>(void* ptr, std::size_t new_size, std::size_t) {
      return std::realloc(ptr, new_size);
    }
    template <typename T>
    inline void destruct_elements_of_array(T* ptr, std::size_t size) {
      if (ptr)
        while (size)
          ptr[--size].~T();
    }
    template <typename T>
    inline T* default_construct_elements_of_array(T* ptr, std::size_t size) {
      std::size_t i = 0;
      try {
        for (i = 0; i < size; ++i)
          ::new (ptr + i) T;
      } catch (...) {
        destruct_elements_of_array(ptr, i);
        throw;
      }
      return ptr;
    }
    template <typename T>
    inline T* copy_construct_elements_of_array(T* ptr, const T* src, std::size_t size) {
      std::size_t i = 0;
      try {
        for (i = 0; i < size; ++i)
          ::new (ptr + i) T(*(src + i));
      } catch (...) {
        destruct_elements_of_array(ptr, i);
        throw;
      }
      return ptr;
    }
    template <typename T>
    inline T* move_construct_elements_of_array(T* ptr, T* src, std::size_t size) {
      std::size_t i = 0;
      try {
        for (i = 0; i < size; ++i)
          ::new (ptr + i) T(std::move(*(src + i)));
      } catch (...) {
        destruct_elements_of_array(ptr, i);
        throw;
      }
      return ptr;
    }
    template <typename T>
    __attribute__((always_inline)) inline void check_size_for_overflow(std::size_t size) {
      if (size > std::size_t(-1) / sizeof(T))
        throw_std_bad_alloc();
    }
    template <typename T>
    inline T* aligned_new(std::size_t size) {
      check_size_for_overflow<T>(size);
      T* result = static_cast<T*>(aligned_malloc(sizeof(T) * size));
      try {
        return default_construct_elements_of_array(result, size);
      } catch (...) {
        aligned_free(result);
        throw;
      }
      return result;
    }
    template <typename T, bool Align>
    inline T* conditional_aligned_new(std::size_t size) {
      check_size_for_overflow<T>(size);
      T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * size));
      try {
        return default_construct_elements_of_array(result, size);
      } catch (...) {
        conditional_aligned_free<Align>(result);
        throw;
      }
      return result;
    }
    template <typename T>
    inline void aligned_delete(T* ptr, std::size_t size) {
      destruct_elements_of_array<T>(ptr, size);
      Eigen::internal::aligned_free(ptr);
    }
    template <typename T, bool Align>
    inline void conditional_aligned_delete(T* ptr, std::size_t size) {
      destruct_elements_of_array<T>(ptr, size);
      conditional_aligned_free<Align>(ptr);
    }
    template <typename T, bool Align>
    inline T* conditional_aligned_realloc_new(T* pts, std::size_t new_size, std::size_t old_size) {
      check_size_for_overflow<T>(new_size);
      check_size_for_overflow<T>(old_size);
      T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * new_size));
      try {
        std::size_t copy_size = (std::min)(old_size, new_size);
        move_construct_elements_of_array(result, pts, copy_size);
        if (new_size > old_size) {
          default_construct_elements_of_array(result + copy_size, new_size - old_size);
        }
        conditional_aligned_delete<T, Align>(pts, old_size);
      } catch (...) {
        conditional_aligned_free<Align>(result);
        throw;
      }
      return result;
    }
    template <typename T, bool Align>
    inline T* conditional_aligned_new_auto(std::size_t size) {
      if (size == 0)
        return 0;
      check_size_for_overflow<T>(size);
      T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * size));
      if (NumTraits<T>::RequireInitialization) {
        try {
          default_construct_elements_of_array(result, size);
        } catch (...) {
          conditional_aligned_free<Align>(result);
          throw;
        }
      }
      return result;
    }
    template <typename T, bool Align>
    inline T* conditional_aligned_realloc_new_auto(T* pts, std::size_t new_size, std::size_t old_size) {
      if (NumTraits<T>::RequireInitialization) {
        return conditional_aligned_realloc_new<T, Align>(pts, new_size, old_size);
      }
      check_size_for_overflow<T>(new_size);
      check_size_for_overflow<T>(old_size);
      return static_cast<T*>(
          conditional_aligned_realloc<Align>(static_cast<void*>(pts), sizeof(T) * new_size, sizeof(T) * old_size));
    }
    template <typename T, bool Align>
    inline void conditional_aligned_delete_auto(T* ptr, std::size_t size) {
      if (NumTraits<T>::RequireInitialization)
        destruct_elements_of_array<T>(ptr, size);
      conditional_aligned_free<Align>(ptr);
    }
    template <int Alignment, typename Scalar, typename Index>
    inline Index first_aligned(const Scalar* array, Index size) {
      const Index ScalarSize = sizeof(Scalar);
      const Index AlignmentSize = Alignment / ScalarSize;
      const Index AlignmentMask = AlignmentSize - 1;
      if (AlignmentSize <= 1) {
        return 0;
      } else if ((UIntPtr(array) & (sizeof(Scalar) - 1)) || (Alignment % ScalarSize) != 0) {
        return size;
      } else {
        Index first = (AlignmentSize - (Index((UIntPtr(array) / sizeof(Scalar))) & AlignmentMask)) & AlignmentMask;
        return (first < size) ? first : size;
      }
    }
    template <typename Scalar, typename Index>
    inline Index first_default_aligned(const Scalar* array, Index size) {
      typedef typename packet_traits<Scalar>::type DefaultPacketType;
      return first_aligned<unpacket_traits<DefaultPacketType>::alignment>(array, size);
    }
    template <typename Index>
    inline Index first_multiple(Index size, Index base) {
      return ((size + base - 1) / base) * base;
    }
    template <typename T, bool UseMemcpy>
    struct smart_copy_helper;
    template <typename T>
    void smart_copy(const T* start, const T* end, T* target) {
      smart_copy_helper<T, !NumTraits<T>::RequireInitialization>::run(start, end, target);
    }
    template <typename T>
    struct smart_copy_helper<T, true> {
      static inline void run(const T* start, const T* end, T* target) {
        IntPtr size = IntPtr(end) - IntPtr(start);
        if (size == 0)
          return;
        ;
        using std::memcpy;
        memcpy(target, start, size);
      }
    };
    template <typename T>
    struct smart_copy_helper<T, false> {
      static inline void run(const T* start, const T* end, T* target) { std::copy(start, end, target); }
    };
    template <typename T, bool UseMemmove>
    struct smart_memmove_helper;
    template <typename T>
    void smart_memmove(const T* start, const T* end, T* target) {
      smart_memmove_helper<T, !NumTraits<T>::RequireInitialization>::run(start, end, target);
    }
    template <typename T>
    struct smart_memmove_helper<T, true> {
      static inline void run(const T* start, const T* end, T* target) {
        IntPtr size = IntPtr(end) - IntPtr(start);
        if (size == 0)
          return;
        ;
        std::memmove(target, start, size);
      }
    };
    template <typename T>
    struct smart_memmove_helper<T, false> {
      static inline void run(const T* start, const T* end, T* target) {
        if (UIntPtr(target) < UIntPtr(start)) {
          std::copy(start, end, target);
        } else {
          std::ptrdiff_t count = (std::ptrdiff_t(end) - std::ptrdiff_t(start)) / sizeof(T);
          std::copy_backward(start, end, target + count);
        }
      }
    };
    template <typename T>
    T* smart_move(T* start, T* end, T* target) {
      return std::move(start, end, target);
    }
    template <typename T>
    class aligned_stack_memory_handler : noncopyable {
    public:
      aligned_stack_memory_handler(T* ptr, std::size_t size, bool dealloc)
          : m_ptr(ptr), m_size(size), m_deallocate(dealloc) {
        if (NumTraits<T>::RequireInitialization && m_ptr)
          Eigen::internal::default_construct_elements_of_array(m_ptr, size);
      }
      ~aligned_stack_memory_handler() {
        if (NumTraits<T>::RequireInitialization && m_ptr)
          Eigen::internal::destruct_elements_of_array<T>(m_ptr, m_size);
        if (m_deallocate)
          Eigen::internal::aligned_free(m_ptr);
      }

    protected:
      T* m_ptr;
      std::size_t m_size;
      bool m_deallocate;
    };
    template <typename Xpr,
              int NbEvaluations,
              bool MapExternalBuffer = nested_eval<Xpr, NbEvaluations>::Evaluate && Xpr::MaxSizeAtCompileTime == Dynamic>
    struct local_nested_eval_wrapper {
      static constexpr bool NeedExternalBuffer = false;
      typedef typename Xpr::Scalar Scalar;
      typedef typename nested_eval<Xpr, NbEvaluations>::type ObjectType;
      ObjectType object;
      local_nested_eval_wrapper(const Xpr& xpr, Scalar* ptr) : object(xpr) {
        Eigen::internal::ignore_unused_variable(ptr);
        ;
        ;
      }
    };
    template <typename Xpr, int NbEvaluations>
    struct local_nested_eval_wrapper<Xpr, NbEvaluations, true> {
      static constexpr bool NeedExternalBuffer = true;
      typedef typename Xpr::Scalar Scalar;
      typedef typename plain_object_eval<Xpr>::type PlainObject;
      typedef Map<PlainObject, 64> ObjectType;
      ObjectType object;
      local_nested_eval_wrapper(const Xpr& xpr, Scalar* ptr)
          : object(ptr == 0 ? reinterpret_cast<Scalar*>(Eigen::internal::aligned_malloc(sizeof(Scalar) * xpr.size()))
                            : ptr,
                   xpr.rows(),
                   xpr.cols()),
            m_deallocate(ptr == 0) {
        if (NumTraits<Scalar>::RequireInitialization && object.data())
          Eigen::internal::default_construct_elements_of_array(object.data(), object.size());
        object = xpr;
      }
      ~local_nested_eval_wrapper() {
        if (NumTraits<Scalar>::RequireInitialization && object.data())
          Eigen::internal::destruct_elements_of_array(object.data(), object.size());
        if (m_deallocate)
          Eigen::internal::aligned_free(object.data());
      }

    private:
      bool m_deallocate;
    };
    template <typename T>
    class scoped_array : noncopyable {
      T* m_ptr;

    public:
      explicit scoped_array(std::ptrdiff_t size) { m_ptr = new T[size]; }
      ~scoped_array() { delete[] m_ptr; }
      T& operator[](std::ptrdiff_t i) { return m_ptr[i]; }
      const T& operator[](std::ptrdiff_t i) const { return m_ptr[i]; }
      T*& ptr() { return m_ptr; }
      const T* ptr() const { return m_ptr; }
      operator const T*() const { return m_ptr; }
    };
    template <typename T>
    void swap(scoped_array<T>& a, scoped_array<T>& b) {
      std::swap(a.ptr(), b.ptr());
    }
  }  // namespace internal
  template <class T>
  class aligned_allocator : public std::allocator<T> {
  public:
    typedef std::size_t size_type;
    typedef std::ptrdiff_t difference_type;
    typedef T* pointer;
    typedef const T* const_pointer;
    typedef T& reference;
    typedef const T& const_reference;
    typedef T value_type;
    template <class U>
    struct rebind {
      typedef aligned_allocator<U> other;
    };
    aligned_allocator() : std::allocator<T>() {}
    aligned_allocator(const aligned_allocator& other) : std::allocator<T>(other) {}
    template <class U>
    aligned_allocator(const aligned_allocator<U>& other) : std::allocator<T>(other) {}
    ~aligned_allocator() {}
    pointer allocate(size_type num, const void* = 0) {
      internal::check_size_for_overflow<T>(num);
      return static_cast<pointer>(internal::aligned_malloc(num * sizeof(T)));
    }
    void deallocate(pointer p, size_type) { internal::aligned_free(p); }
  };
  namespace internal {
    inline bool cpuid_is_vendor(int abcd[4], const int vendor[3]) {
      return abcd[1] == vendor[0] && abcd[3] == vendor[1] && abcd[2] == vendor[2];
    }
    inline void queryCacheSizes_intel_direct(int& l1, int& l2, int& l3) {
      int abcd[4];
      l1 = l2 = l3 = 0;
      int cache_id = 0;
      int cache_type = 0;
      do {
        abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
        __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                             : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                             : "0"(0x4), "2"(cache_id));
        ;
        cache_type = (abcd[0] & 0x0F) >> 0;
        if (cache_type == 1 || cache_type == 3) {
          int cache_level = (abcd[0] & 0xE0) >> 5;
          int ways = (abcd[1] & 0xFFC00000) >> 22;
          int partitions = (abcd[1] & 0x003FF000) >> 12;
          int line_size = (abcd[1] & 0x00000FFF) >> 0;
          int sets = (abcd[2]);
          int cache_size = (ways + 1) * (partitions + 1) * (line_size + 1) * (sets + 1);
          switch (cache_level) {
            case 1:
              l1 = cache_size;
              break;
            case 2:
              l2 = cache_size;
              break;
            case 3:
              l3 = cache_size;
              break;
            default:
              break;
          }
        }
        cache_id++;
      } while (cache_type > 0 && cache_id < 16);
    }
    inline void queryCacheSizes_intel_codes(int& l1, int& l2, int& l3) {
      int abcd[4];
      abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
      l1 = l2 = l3 = 0;
      __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                           : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                           : "0"(0x00000002), "2"(0));
      ;
      unsigned char* bytes = reinterpret_cast<unsigned char*>(abcd) + 2;
      bool check_for_p2_core2 = false;
      for (int i = 0; i < 14; ++i) {
        switch (bytes[i]) {
          case 0x0A:
            l1 = 8;
            break;
          case 0x0C:
            l1 = 16;
            break;
          case 0x0E:
            l1 = 24;
            break;
          case 0x10:
            l1 = 16;
            break;
          case 0x15:
            l1 = 16;
            break;
          case 0x2C:
            l1 = 32;
            break;
          case 0x30:
            l1 = 32;
            break;
          case 0x60:
            l1 = 16;
            break;
          case 0x66:
            l1 = 8;
            break;
          case 0x67:
            l1 = 16;
            break;
          case 0x68:
            l1 = 32;
            break;
          case 0x1A:
            l2 = 96;
            break;
          case 0x22:
            l3 = 512;
            break;
          case 0x23:
            l3 = 1024;
            break;
          case 0x25:
            l3 = 2048;
            break;
          case 0x29:
            l3 = 4096;
            break;
          case 0x39:
            l2 = 128;
            break;
          case 0x3A:
            l2 = 192;
            break;
          case 0x3B:
            l2 = 128;
            break;
          case 0x3C:
            l2 = 256;
            break;
          case 0x3D:
            l2 = 384;
            break;
          case 0x3E:
            l2 = 512;
            break;
          case 0x40:
            l2 = 0;
            break;
          case 0x41:
            l2 = 128;
            break;
          case 0x42:
            l2 = 256;
            break;
          case 0x43:
            l2 = 512;
            break;
          case 0x44:
            l2 = 1024;
            break;
          case 0x45:
            l2 = 2048;
            break;
          case 0x46:
            l3 = 4096;
            break;
          case 0x47:
            l3 = 8192;
            break;
          case 0x48:
            l2 = 3072;
            break;
          case 0x49:
            if (l2 != 0)
              l3 = 4096;
            else {
              check_for_p2_core2 = true;
              l3 = l2 = 4096;
            }
            break;
          case 0x4A:
            l3 = 6144;
            break;
          case 0x4B:
            l3 = 8192;
            break;
          case 0x4C:
            l3 = 12288;
            break;
          case 0x4D:
            l3 = 16384;
            break;
          case 0x4E:
            l2 = 6144;
            break;
          case 0x78:
            l2 = 1024;
            break;
          case 0x79:
            l2 = 128;
            break;
          case 0x7A:
            l2 = 256;
            break;
          case 0x7B:
            l2 = 512;
            break;
          case 0x7C:
            l2 = 1024;
            break;
          case 0x7D:
            l2 = 2048;
            break;
          case 0x7E:
            l2 = 256;
            break;
          case 0x7F:
            l2 = 512;
            break;
          case 0x80:
            l2 = 512;
            break;
          case 0x81:
            l2 = 128;
            break;
          case 0x82:
            l2 = 256;
            break;
          case 0x83:
            l2 = 512;
            break;
          case 0x84:
            l2 = 1024;
            break;
          case 0x85:
            l2 = 2048;
            break;
          case 0x86:
            l2 = 512;
            break;
          case 0x87:
            l2 = 1024;
            break;
          case 0x88:
            l3 = 2048;
            break;
          case 0x89:
            l3 = 4096;
            break;
          case 0x8A:
            l3 = 8192;
            break;
          case 0x8D:
            l3 = 3072;
            break;
          default:
            break;
        }
      }
      if (check_for_p2_core2 && l2 == l3)
        l3 = 0;
      l1 *= 1024;
      l2 *= 1024;
      l3 *= 1024;
    }
    inline void queryCacheSizes_intel(int& l1, int& l2, int& l3, int max_std_funcs) {
      if (max_std_funcs >= 4)
        queryCacheSizes_intel_direct(l1, l2, l3);
      else if (max_std_funcs >= 2)
        queryCacheSizes_intel_codes(l1, l2, l3);
      else
        l1 = l2 = l3 = 0;
    }
    inline void queryCacheSizes_amd(int& l1, int& l2, int& l3) {
      int abcd[4];
      abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
      __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                           : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                           : "0"(0x80000000), "2"(0));
      ;
      if (static_cast<numext::uint32_t>(abcd[0]) >= static_cast<numext::uint32_t>(0x80000006)) {
        __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                             : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                             : "0"(0x80000005), "2"(0));
        ;
        l1 = (abcd[2] >> 24) * 1024;
        abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
        __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                             : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                             : "0"(0x80000006), "2"(0));
        ;
        l2 = (abcd[2] >> 16) * 1024;
        l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024;
      } else {
        l1 = l2 = l3 = 0;
      }
    }
    inline void queryCacheSizes(int& l1, int& l2, int& l3) {
      int abcd[4];
      const int GenuineIntel[] = {0x756e6547, 0x49656e69, 0x6c65746e};
      const int AuthenticAMD[] = {0x68747541, 0x69746e65, 0x444d4163};
      const int AMDisbetter_[] = {0x69444d41, 0x74656273, 0x21726574};
      __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"
                           : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3])
                           : "0"(0x0), "2"(0));
      ;
      int max_std_funcs = abcd[0];
      if (cpuid_is_vendor(abcd, GenuineIntel))
        queryCacheSizes_intel(l1, l2, l3, max_std_funcs);
      else if (cpuid_is_vendor(abcd, AuthenticAMD) || cpuid_is_vendor(abcd, AMDisbetter_))
        queryCacheSizes_amd(l1, l2, l3);
      else
        queryCacheSizes_intel(l1, l2, l3, max_std_funcs);
    }
    inline int queryL1CacheSize() {
      int l1(-1), l2, l3;
      queryCacheSizes(l1, l2, l3);
      return l1;
    }
    inline int queryTopLevelCacheSize() {
      int l1, l2(-1), l3(-1);
      queryCacheSizes(l1, l2, l3);
      return (std::max)(l2, l3);
    }
    using std::construct_at;
    using std::destroy_at;
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <int N>
    class FixedInt;
    template <int N>
    class VariableAndFixedInt;
    template <int N>
    class FixedInt {
    public:
      static const int value = N;
      constexpr operator int() const { return value; }
      constexpr FixedInt() = default;
      constexpr FixedInt(std::integral_constant<int, N>) {}
      constexpr FixedInt(VariableAndFixedInt<N> other) {
        Eigen::internal::ignore_unused_variable(other);
        ;
        ;
      }
      constexpr FixedInt<-N> operator-() const { return FixedInt<-N>(); }
      template <int M>
      constexpr FixedInt<N + M> operator+(FixedInt<M>) const {
        return FixedInt<N + M>();
      }
      template <int M>
      constexpr FixedInt<N - M> operator-(FixedInt<M>) const {
        return FixedInt<N - M>();
      }
      template <int M>
      constexpr FixedInt<N * M> operator*(FixedInt<M>) const {
        return FixedInt<N * M>();
      }
      template <int M>
      constexpr FixedInt<N / M> operator/(FixedInt<M>) const {
        return FixedInt<N / M>();
      }
      template <int M>
      constexpr FixedInt<N % M> operator%(FixedInt<M>) const {
        return FixedInt<N % M>();
      }
      template <int M>
      constexpr FixedInt<N | M> operator|(FixedInt<M>) const {
        return FixedInt<N | M>();
      }
      template <int M>
      constexpr FixedInt<N & M> operator&(FixedInt<M>) const {
        return FixedInt<N & M>();
      }
      constexpr FixedInt operator()() const { return *this; }
      constexpr VariableAndFixedInt<N> operator()(int val) const { return VariableAndFixedInt<N>(val); }
    };
    template <int N>
    class VariableAndFixedInt {
    public:
      static const int value = N;
      constexpr operator int() const { return m_value; }
      VariableAndFixedInt(int val) { m_value = val; }

    protected:
      int m_value;
    };
    template <typename T, int Default = Dynamic>
    struct get_fixed_value {
      static const int value = Default;
    };
    template <int N, int Default>
    struct get_fixed_value<FixedInt<N>, Default> {
      static const int value = N;
    };
    template <int N, int Default>
    struct get_fixed_value<VariableAndFixedInt<N>, Default> {
      static const int value = N;
    };
    template <typename T, int N, int Default>
    struct get_fixed_value<variable_if_dynamic<T, N>, Default> {
      static const int value = N;
    };
    template <typename T>
    Index get_runtime_value(const T& x) {
      return x;
    }
    template <typename T, int DynamicKey = Dynamic, typename EnableIf = void>
    struct cleanup_index_type {
      typedef T type;
    };
    template <typename T, int DynamicKey>
    struct cleanup_index_type<T, DynamicKey, std::enable_if_t<internal::is_integral<T>::value>> {
      typedef Index type;
    };
    template <int N, int DynamicKey>
    struct cleanup_index_type<VariableAndFixedInt<N>, DynamicKey> {
      typedef FixedInt<N> type;
    };
    template <int DynamicKey>
    struct cleanup_index_type<VariableAndFixedInt<DynamicKey>, DynamicKey> {
      typedef Index type;
    };
    template <int N, int DynamicKey>
    struct cleanup_index_type<std::integral_constant<int, N>, DynamicKey> {
      typedef FixedInt<N> type;
    };
  }  // namespace internal
  template <int N>
  constexpr internal::FixedInt<N> fix{};
}  // namespace Eigen
#include <type_traits> /* clang -E -fkeep-system-includes */
namespace Eigen {
  template <typename T, typename EnableIf = void>
  class Serializer;
  template <typename T>
  class Serializer<T, typename std::enable_if_t<std::is_trivial<T>::value && std::is_standard_layout<T>::value>> {
  public:
    size_t size(const T& value) const { return sizeof(value); }
    uint8_t* serialize(uint8_t* dest, uint8_t* end, const T& value) {
      if ((__builtin_expect(dest == nullptr, false)))
        return nullptr;
      if ((__builtin_expect(dest + sizeof(value) > end, false)))
        return nullptr;
      using std::memcpy;
      memcpy(dest, &value, sizeof(value));
      return dest + sizeof(value);
    }
    const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, T& value) const {
      if ((__builtin_expect(src == nullptr, false)))
        return nullptr;
      if ((__builtin_expect(src + sizeof(value) > end, false)))
        return nullptr;
      using std::memcpy;
      memcpy(&value, src, sizeof(value));
      return src + sizeof(value);
    }
  };
  template <typename Derived>
  class Serializer<DenseBase<Derived>, void> {
  public:
    typedef typename Derived::Scalar Scalar;
    struct Header {
      typename Derived::Index rows;
      typename Derived::Index cols;
    };
    size_t size(const Derived& value) const { return sizeof(Header) + sizeof(Scalar) * value.size(); }
    uint8_t* serialize(uint8_t* dest, uint8_t* end, const Derived& value) {
      if ((__builtin_expect(dest == nullptr, false)))
        return nullptr;
      if ((__builtin_expect(dest + size(value) > end, false)))
        return nullptr;
      const size_t header_bytes = sizeof(Header);
      const size_t data_bytes = sizeof(Scalar) * value.size();
      Header header = {value.rows(), value.cols()};
      using std::memcpy;
      memcpy(dest, &header, header_bytes);
      dest += header_bytes;
      memcpy(dest, value.data(), data_bytes);
      return dest + data_bytes;
    }
    const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, Derived& value) const {
      if ((__builtin_expect(src == nullptr, false)))
        return nullptr;
      if ((__builtin_expect(src + sizeof(Header) > end, false)))
        return nullptr;
      const size_t header_bytes = sizeof(Header);
      Header header;
      using std::memcpy;
      memcpy(&header, src, header_bytes);
      src += header_bytes;
      const size_t data_bytes = sizeof(Scalar) * header.rows * header.cols;
      if ((__builtin_expect(src + data_bytes > end, false)))
        return nullptr;
      value.resize(header.rows, header.cols);
      memcpy(value.data(), src, data_bytes);
      return src + data_bytes;
    }
  };
  template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  class Serializer<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
      : public Serializer<DenseBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {};
  template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  class Serializer<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
      : public Serializer<DenseBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {};
  namespace internal {
    template <size_t N, typename... Types>
    struct serialize_impl;
    template <size_t N, typename T1, typename... Ts>
    struct serialize_impl<N, T1, Ts...> {
      using Serializer = Eigen::Serializer<typename std::decay<T1>::type>;
      static inline size_t serialize_size(const T1& value, const Ts&... args) {
        Serializer serializer;
        size_t size = serializer.size(value);
        return size + serialize_impl<N - 1, Ts...>::serialize_size(args...);
      }
      static inline uint8_t* serialize(uint8_t* dest, uint8_t* end, const T1& value, const Ts&... args) {
        Serializer serializer;
        dest = serializer.serialize(dest, end, value);
        return serialize_impl<N - 1, Ts...>::serialize(dest, end, args...);
      }
      static inline const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, T1& value, Ts&... args) {
        Serializer serializer;
        src = serializer.deserialize(src, end, value);
        return serialize_impl<N - 1, Ts...>::deserialize(src, end, args...);
      }
    };
    template <>
    struct serialize_impl<0> {
      static inline size_t serialize_size() { return 0; }
      static inline uint8_t* serialize(uint8_t* dest, uint8_t*) { return dest; }
      static inline const uint8_t* deserialize(const uint8_t* src, const uint8_t*) { return src; }
    };
  }  // namespace internal
  template <typename... Args>
  inline size_t serialize_size(const Args&... args) {
    return internal::serialize_impl<sizeof...(args), Args...>::serialize_size(args...);
  }
  template <typename... Args>
  inline uint8_t* serialize(uint8_t* dest, uint8_t* end, const Args&... args) {
    return internal::serialize_impl<sizeof...(args), Args...>::serialize(dest, end, args...);
  }
  template <typename... Args>
  inline const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, Args&... args) {
    return internal::serialize_impl<sizeof...(args), Args...>::deserialize(src, end, args...);
  }
}  // namespace Eigen

namespace Eigen {
  namespace symbolic {
    template <typename Tag>
    class Symbol;
    template <typename Arg0>
    class NegateExpr;
    template <typename Arg1, typename Arg2>
    class AddExpr;
    template <typename Arg1, typename Arg2>
    class ProductExpr;
    template <typename Arg1, typename Arg2>
    class QuotientExpr;
    template <typename IndexType = Index>
    class ValueExpr {
    public:
      ValueExpr(IndexType val) : m_value(val) {}
      template <typename T>
      IndexType eval_impl(const T&) const {
        return m_value;
      }

    protected:
      IndexType m_value;
    };
    template <int N>
    class ValueExpr<internal::FixedInt<N>> {
    public:
      ValueExpr() {}
      template <typename T>
      constexpr Index eval_impl(const T&) const {
        return N;
      }
    };
    template <typename Derived>
    class BaseExpr {
    public:
      const Derived& derived() const { return *static_cast<const Derived*>(this); }
      template <typename T>
      Index eval(const T& values) const {
        return derived().eval_impl(values);
      }
      template <typename... Types>
      Index eval(Types&&... values) const {
        return derived().eval_impl(std::make_tuple(values...));
      }
      NegateExpr<Derived> operator-() const { return NegateExpr<Derived>(derived()); }
      AddExpr<Derived, ValueExpr<>> operator+(Index b) const { return AddExpr<Derived, ValueExpr<>>(derived(), b); }
      AddExpr<Derived, ValueExpr<>> operator-(Index a) const { return AddExpr<Derived, ValueExpr<>>(derived(), -a); }
      ProductExpr<Derived, ValueExpr<>> operator*(Index a) const {
        return ProductExpr<Derived, ValueExpr<>>(derived(), a);
      }
      QuotientExpr<Derived, ValueExpr<>> operator/(Index a) const {
        return QuotientExpr<Derived, ValueExpr<>>(derived(), a);
      }
      friend AddExpr<Derived, ValueExpr<>> operator+(Index a, const BaseExpr& b) {
        return AddExpr<Derived, ValueExpr<>>(b.derived(), a);
      }
      friend AddExpr<NegateExpr<Derived>, ValueExpr<>> operator-(Index a, const BaseExpr& b) {
        return AddExpr<NegateExpr<Derived>, ValueExpr<>>(-b.derived(), a);
      }
      friend ProductExpr<ValueExpr<>, Derived> operator*(Index a, const BaseExpr& b) {
        return ProductExpr<ValueExpr<>, Derived>(a, b.derived());
      }
      friend QuotientExpr<ValueExpr<>, Derived> operator/(Index a, const BaseExpr& b) {
        return QuotientExpr<ValueExpr<>, Derived>(a, b.derived());
      }
      template <int N>
      AddExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator+(internal::FixedInt<N>) const {
        return AddExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
      }
      template <int N>
      AddExpr<Derived, ValueExpr<internal::FixedInt<-N>>> operator-(internal::FixedInt<N>) const {
        return AddExpr<Derived, ValueExpr<internal::FixedInt<-N>>>(derived(), ValueExpr<internal::FixedInt<-N>>());
      }
      template <int N>
      ProductExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator*(internal::FixedInt<N>) const {
        return ProductExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
      }
      template <int N>
      QuotientExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator/(internal::FixedInt<N>) const {
        return QuotientExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
      }
      template <int N>
      friend AddExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator+(internal::FixedInt<N>, const BaseExpr& b) {
        return AddExpr<Derived, ValueExpr<internal::FixedInt<N>>>(b.derived(), ValueExpr<internal::FixedInt<N>>());
      }
      template <int N>
      friend AddExpr<NegateExpr<Derived>, ValueExpr<internal::FixedInt<N>>> operator-(internal::FixedInt<N>,
                                                                                      const BaseExpr& b) {
        return AddExpr<NegateExpr<Derived>, ValueExpr<internal::FixedInt<N>>>(-b.derived(),
                                                                              ValueExpr<internal::FixedInt<N>>());
      }
      template <int N>
      friend ProductExpr<ValueExpr<internal::FixedInt<N>>, Derived> operator*(internal::FixedInt<N>,
                                                                              const BaseExpr& b) {
        return ProductExpr<ValueExpr<internal::FixedInt<N>>, Derived>(ValueExpr<internal::FixedInt<N>>(), b.derived());
      }
      template <int N>
      friend QuotientExpr<ValueExpr<internal::FixedInt<N>>, Derived> operator/(internal::FixedInt<N>,
                                                                               const BaseExpr& b) {
        return QuotientExpr<ValueExpr<internal::FixedInt<N>>, Derived>(ValueExpr<internal::FixedInt<N>>(), b.derived());
      }
      template <typename OtherDerived>
      AddExpr<Derived, OtherDerived> operator+(const BaseExpr<OtherDerived>& b) const {
        return AddExpr<Derived, OtherDerived>(derived(), b.derived());
      }
      template <typename OtherDerived>
      AddExpr<Derived, NegateExpr<OtherDerived>> operator-(const BaseExpr<OtherDerived>& b) const {
        return AddExpr<Derived, NegateExpr<OtherDerived>>(derived(), -b.derived());
      }
      template <typename OtherDerived>
      ProductExpr<Derived, OtherDerived> operator*(const BaseExpr<OtherDerived>& b) const {
        return ProductExpr<Derived, OtherDerived>(derived(), b.derived());
      }
      template <typename OtherDerived>
      QuotientExpr<Derived, OtherDerived> operator/(const BaseExpr<OtherDerived>& b) const {
        return QuotientExpr<Derived, OtherDerived>(derived(), b.derived());
      }
    };
    template <typename T>
    struct is_symbolic {
      enum { value = internal::is_convertible<T, BaseExpr<T>>::value };
    };
    template <typename Tag>
    class SymbolValue {
    public:
      SymbolValue(Index val) : m_value(val) {}
      Index value() const { return m_value; }

    protected:
      Index m_value;
    };
    template <typename tag>
    class SymbolExpr : public BaseExpr<SymbolExpr<tag>> {
    public:
      typedef tag Tag;
      SymbolExpr() {}
      SymbolValue<Tag> operator=(Index val) const { return SymbolValue<Tag>(val); }
      Index eval_impl(const SymbolValue<Tag>& values) const { return values.value(); }
      template <typename... Types>
      Index eval_impl(const std::tuple<Types...>& values) const {
        return std::get<SymbolValue<Tag>>(values).value();
      }
    };
    template <typename Arg0>
    class NegateExpr : public BaseExpr<NegateExpr<Arg0>> {
    public:
      NegateExpr(const Arg0& arg0) : m_arg0(arg0) {}
      template <typename T>
      Index eval_impl(const T& values) const {
        return -m_arg0.eval_impl(values);
      }

    protected:
      Arg0 m_arg0;
    };
    template <typename Arg0, typename Arg1>
    class AddExpr : public BaseExpr<AddExpr<Arg0, Arg1>> {
    public:
      AddExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
      template <typename T>
      Index eval_impl(const T& values) const {
        return m_arg0.eval_impl(values) + m_arg1.eval_impl(values);
      }

    protected:
      Arg0 m_arg0;
      Arg1 m_arg1;
    };
    template <typename Arg0, typename Arg1>
    class ProductExpr : public BaseExpr<ProductExpr<Arg0, Arg1>> {
    public:
      ProductExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
      template <typename T>
      Index eval_impl(const T& values) const {
        return m_arg0.eval_impl(values) * m_arg1.eval_impl(values);
      }

    protected:
      Arg0 m_arg0;
      Arg1 m_arg1;
    };
    template <typename Arg0, typename Arg1>
    class QuotientExpr : public BaseExpr<QuotientExpr<Arg0, Arg1>> {
    public:
      QuotientExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
      template <typename T>
      Index eval_impl(const T& values) const {
        return m_arg0.eval_impl(values) / m_arg1.eval_impl(values);
      }

    protected:
      Arg0 m_arg0;
      Arg1 m_arg1;
    };
  }  // namespace symbolic
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T,
              bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
              bool is_integer = NumTraits<T>::IsInteger>
    struct default_digits10_impl {
      constexpr static int run() { return std::numeric_limits<T>::digits10; }
    };
    template <typename T>
    struct default_digits10_impl<T, false, false> {
      constexpr static int run() {
        using std::ceil;
        using std::log10;
        typedef typename NumTraits<T>::Real Real;
        return int(ceil(-log10(NumTraits<Real>::epsilon())));
      }
    };
    template <typename T>
    struct default_digits10_impl<T, false, true> {
      constexpr static int run() { return 0; }
    };
    template <typename T,
              bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
              bool is_integer = NumTraits<T>::IsInteger>
    struct default_digits_impl {
      constexpr static int run() { return std::numeric_limits<T>::digits; }
    };
    template <typename T>
    struct default_digits_impl<T, false, false> {
      constexpr static int run() {
        using std::ceil;
        using std::log2;
        typedef typename NumTraits<T>::Real Real;
        return int(ceil(-log2(NumTraits<Real>::epsilon())));
      }
    };
    template <typename T>
    struct default_digits_impl<T, false, true> {
      constexpr static int run() { return 0; }
    };
  }  // namespace internal
  namespace numext {
    template <typename Tgt, typename Src>
    inline Tgt bit_cast(const Src& src) {
      static_assert(std::is_trivially_copyable<Src>::value, "THIS_TYPE_IS_NOT_SUPPORTED");
      ;
      static_assert(std::is_trivially_copyable<Tgt>::value && std::is_default_constructible<Tgt>::value,
                    "THIS_TYPE_IS_NOT_SUPPORTED");
      ;
      static_assert(sizeof(Src) == sizeof(Tgt), "THIS_TYPE_IS_NOT_SUPPORTED");
      ;
      Tgt tgt;
      const Src staged = src;
      using std::memcpy;
      memcpy(&tgt, &staged, sizeof(Tgt));
      return tgt;
    }
  }  // namespace numext
  template <typename T>
  struct GenericNumTraits {
    enum {
      IsInteger = std::numeric_limits<T>::is_integer,
      IsSigned = std::numeric_limits<T>::is_signed,
      IsComplex = 0,
      RequireInitialization = internal::is_arithmetic<T>::value ? 0 : 1,
      ReadCost = 1,
      AddCost = 1,
      MulCost = 1
    };
    typedef T Real;
    typedef std::conditional_t<IsInteger, std::conditional_t<sizeof(T) <= 2, float, double>, T> NonInteger;
    typedef T Nested;
    typedef T Literal;
    constexpr static inline Real epsilon() { return numext::numeric_limits<T>::epsilon(); }
    constexpr static inline int digits10() { return internal::default_digits10_impl<T>::run(); }
    constexpr static inline int digits() { return internal::default_digits_impl<T>::run(); }
    constexpr static inline int min_exponent() { return numext::numeric_limits<T>::min_exponent; }
    constexpr static inline int max_exponent() { return numext::numeric_limits<T>::max_exponent; }
    constexpr static inline Real dummy_precision() { return Real(0); }
    constexpr static inline T highest() { return (numext::numeric_limits<T>::max)(); }
    constexpr static inline T lowest() {
      return IsInteger ? (numext::numeric_limits<T>::min)() : static_cast<T>(-(numext::numeric_limits<T>::max)());
    }
    constexpr static inline T infinity() { return numext::numeric_limits<T>::infinity(); }
    constexpr static inline T quiet_NaN() { return numext::numeric_limits<T>::quiet_NaN(); }
  };
  template <typename T>
  struct NumTraits : GenericNumTraits<T> {};
  template <>
  struct NumTraits<float> : GenericNumTraits<float> {
    constexpr static inline float dummy_precision() { return 1e-5f; }
  };
  template <>
  struct NumTraits<double> : GenericNumTraits<double> {
    constexpr static inline double dummy_precision() { return 1e-12; }
  };
  template <>
  struct NumTraits<long double> : GenericNumTraits<long double> {
    constexpr static inline long double dummy_precision() { return 1e-15l; }
  };
  template <typename Real_>
  struct NumTraits<std::complex<Real_>> : GenericNumTraits<std::complex<Real_>> {
    typedef Real_ Real;
    typedef typename NumTraits<Real_>::Literal Literal;
    enum {
      IsComplex = 1,
      RequireInitialization = NumTraits<Real_>::RequireInitialization,
      ReadCost = 2 * NumTraits<Real_>::ReadCost,
      AddCost = 2 * NumTraits<Real>::AddCost,
      MulCost = 4 * NumTraits<Real>::MulCost + 2 * NumTraits<Real>::AddCost
    };
    constexpr static inline Real epsilon() { return NumTraits<Real>::epsilon(); }
    constexpr static inline Real dummy_precision() { return NumTraits<Real>::dummy_precision(); }
    constexpr static inline int digits10() { return NumTraits<Real>::digits10(); }
  };
  template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  struct NumTraits<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>> {
    typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> ArrayType;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Array<RealScalar, Rows, Cols, Options, MaxRows, MaxCols> Real;
    typedef typename NumTraits<Scalar>::NonInteger NonIntegerScalar;
    typedef Array<NonIntegerScalar, Rows, Cols, Options, MaxRows, MaxCols> NonInteger;
    typedef ArrayType& Nested;
    typedef typename NumTraits<Scalar>::Literal Literal;
    enum {
      IsComplex = NumTraits<Scalar>::IsComplex,
      IsInteger = NumTraits<Scalar>::IsInteger,
      IsSigned = NumTraits<Scalar>::IsSigned,
      RequireInitialization = 1,
      ReadCost = ArrayType::SizeAtCompileTime == Dynamic
                     ? HugeCost
                     : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::ReadCost),
      AddCost = ArrayType::SizeAtCompileTime == Dynamic
                    ? HugeCost
                    : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::AddCost),
      MulCost = ArrayType::SizeAtCompileTime == Dynamic ? HugeCost
                                                        : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::MulCost)
    };
    constexpr static inline RealScalar epsilon() { return NumTraits<RealScalar>::epsilon(); }
    constexpr static inline RealScalar dummy_precision() { return NumTraits<RealScalar>::dummy_precision(); }
    constexpr static inline int digits10() { return NumTraits<Scalar>::digits10(); }
  };
  template <>
  struct NumTraits<std::string> : GenericNumTraits<std::string> {
    enum { RequireInitialization = 1, ReadCost = HugeCost, AddCost = HugeCost, MulCost = HugeCost };
    constexpr static inline int digits10() { return 0; }

  private:
    static inline std::string epsilon();
    static inline std::string dummy_precision();
    static inline std::string lowest();
    static inline std::string highest();
    static inline std::string infinity();
    static inline std::string quiet_NaN();
  };
  template <>
  struct NumTraits<void> {};
  template <>
  struct NumTraits<bool> : GenericNumTraits<bool> {};
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T, typename dummy = void>
    struct global_math_functions_filtering_base {
      typedef T type;
    };
    template <typename T>
    struct always_void {
      typedef void type;
    };
    template <typename T>
    struct global_math_functions_filtering_base<
        T,
        typename always_void<typename T::Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl>::type> {
      typedef typename T::Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl type;
    };
    template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
    struct real_default_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) { return x; }
    };
    template <typename Scalar>
    struct real_default_impl<Scalar, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        using std::real;
        return real(x);
      }
    };
    template <typename Scalar>
    struct real_impl : real_default_impl<Scalar> {};
    template <typename Scalar>
    struct real_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
    struct imag_default_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar&) { return RealScalar(0); }
    };
    template <typename Scalar>
    struct imag_default_impl<Scalar, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        using std::imag;
        return imag(x);
      }
    };
    template <typename Scalar>
    struct imag_impl : imag_default_impl<Scalar> {};
    template <typename Scalar>
    struct imag_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    template <typename Scalar>
    struct real_ref_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar& run(Scalar& x) { return reinterpret_cast<RealScalar*>(&x)[0]; }
      static inline const RealScalar& run(const Scalar& x) { return reinterpret_cast<const RealScalar*>(&x)[0]; }
    };
    template <typename Scalar>
    struct real_ref_retval {
      typedef typename NumTraits<Scalar>::Real& type;
    };
    template <typename Scalar, bool IsComplex>
    struct imag_ref_default_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar& run(Scalar& x) { return reinterpret_cast<RealScalar*>(&x)[1]; }
      static inline const RealScalar& run(const Scalar& x) { return reinterpret_cast<RealScalar*>(&x)[1]; }
    };
    template <typename Scalar>
    struct imag_ref_default_impl<Scalar, false> {
      constexpr static inline Scalar run(Scalar&) { return Scalar(0); }
      constexpr static inline const Scalar run(const Scalar&) { return Scalar(0); }
    };
    template <typename Scalar>
    struct imag_ref_impl : imag_ref_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
    template <typename Scalar>
    struct imag_ref_retval {
      typedef typename NumTraits<Scalar>::Real& type;
    };
    template <typename Scalar,
              bool IsComplex = (NumTraits<Scalar>::IsComplex != 0),
              bool IsInteger = (NumTraits<Scalar>::IsInteger != 0)>
    struct sign_impl {
      static inline Scalar run(const Scalar& a) { return Scalar((a > Scalar(0)) - (a < Scalar(0))); }
    };
    template <typename Scalar>
    struct sign_impl<Scalar, false, false> {
      static inline Scalar run(const Scalar& a) {
        return (std::isnan)(a) ? a : Scalar((a > Scalar(0)) - (a < Scalar(0)));
      }
    };
    template <typename Scalar, bool IsInteger>
    struct sign_impl<Scalar, true, IsInteger> {
      static inline Scalar run(const Scalar& a) {
        using real_type = typename NumTraits<Scalar>::Real;
        real_type aa = std::abs(a);
        if (aa == real_type(0))
          return Scalar(0);
        aa = real_type(1) / aa;
        return Scalar(a.real() * aa, a.imag() * aa);
      }
    };
    template <>
    struct sign_impl<bool, false, true> {
      static inline bool run(const bool& a) { return a; }
    };
    template <typename Scalar>
    struct sign_retval {
      typedef Scalar type;
    };
    template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
    struct conj_default_impl {
      static inline Scalar run(const Scalar& x) { return x; }
    };
    template <typename Scalar>
    struct conj_default_impl<Scalar, true> {
      static inline Scalar run(const Scalar& x) {
        using std::conj;
        return conj(x);
      }
    };
    template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
    struct conj_impl : conj_default_impl<Scalar, IsComplex> {};
    template <typename Scalar>
    struct conj_retval {
      typedef Scalar type;
    };
    template <typename Scalar, bool IsComplex>
    struct abs2_impl_default {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) { return x * x; }
    };
    template <typename Scalar>
    struct abs2_impl_default<Scalar, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) { return x.real() * x.real() + x.imag() * x.imag(); }
    };
    template <typename Scalar>
    struct abs2_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        return abs2_impl_default<Scalar, NumTraits<Scalar>::IsComplex>::run(x);
      }
    };
    template <typename Scalar>
    struct abs2_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    template <typename Scalar>
    struct sqrt_impl {
      static __attribute__((always_inline)) inline Scalar run(const Scalar& x) {
        using std::sqrt;
        ;
        return sqrt(x);
      }
    };
    template <typename T>
    std::complex<T> complex_sqrt(const std::complex<T>& a_x);
    template <typename T>
    struct sqrt_impl<std::complex<T>> {
      static __attribute__((always_inline)) inline std::complex<T> run(const std::complex<T>& x) {
        return complex_sqrt<T>(x);
      }
    };
    template <typename Scalar>
    struct sqrt_retval {
      typedef Scalar type;
    };
    template <typename T>
    struct rsqrt_impl;
    template <typename T>
    std::complex<T> complex_rsqrt(const std::complex<T>& a_x);
    template <typename T>
    struct rsqrt_impl<std::complex<T>> {
      static __attribute__((always_inline)) inline std::complex<T> run(const std::complex<T>& x) {
        return complex_rsqrt<T>(x);
      }
    };
    template <typename Scalar>
    struct rsqrt_retval {
      typedef Scalar type;
    };
    template <typename Scalar, bool IsComplex>
    struct norm1_default_impl;
    template <typename Scalar>
    struct norm1_default_impl<Scalar, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        using std::abs;
        ;
        return abs(x.real()) + abs(x.imag());
      }
    };
    template <typename Scalar>
    struct norm1_default_impl<Scalar, false> {
      static inline Scalar run(const Scalar& x) {
        using std::abs;
        ;
        return abs(x);
      }
    };
    template <typename Scalar>
    struct norm1_impl : norm1_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
    template <typename Scalar>
    struct norm1_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    template <typename Scalar>
    struct hypot_impl;
    template <typename Scalar>
    struct hypot_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    template <typename OldType, typename NewType, typename EnableIf = void>
    struct cast_impl {
      static inline NewType run(const OldType& x) { return static_cast<NewType>(x); }
    };
    template <typename OldType, typename NewType>
    struct cast_impl<OldType,
                     NewType,
                     typename std::enable_if_t<!NumTraits<OldType>::IsComplex && NumTraits<NewType>::IsComplex>> {
      static inline NewType run(const OldType& x) {
        typedef typename NumTraits<NewType>::Real NewReal;
        return static_cast<NewType>(static_cast<NewReal>(x));
      }
    };
    template <typename OldType, typename NewType>
    inline NewType cast(const OldType& x) {
      return cast_impl<OldType, NewType>::run(x);
    }
    template <typename Scalar>
    struct round_impl {
      static_assert((!NumTraits<Scalar>::IsComplex), "NUMERIC_TYPE_MUST_BE_REAL");
      static inline Scalar run(const Scalar& x) {
        using std::round;
        ;
        return Scalar(round(x));
      }
    };
    template <typename Scalar>
    struct round_retval {
      typedef Scalar type;
    };
    template <typename Scalar>
    struct rint_impl {
      static_assert((!NumTraits<Scalar>::IsComplex), "NUMERIC_TYPE_MUST_BE_REAL");
      static inline Scalar run(const Scalar& x) {
        using std::rint;
        ;
        return rint(x);
      }
    };
    template <typename Scalar>
    struct rint_retval {
      typedef Scalar type;
    };
    template <typename Scalar,
              bool HasStdImpl = NumTraits<Scalar>::IsComplex || is_integral<Scalar>::value ||
                                is_same<Scalar, float>::value || is_same<Scalar, double>::value ||
                                is_same<Scalar, long double>::value>
    struct arg_default_impl;
    template <typename Scalar>
    struct arg_default_impl<Scalar, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        using std::arg;
        ;
        return static_cast<RealScalar>(arg(x));
      }
    };
    template <typename Scalar>
    struct arg_default_impl<Scalar, false> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x) {
        return (x < Scalar(0)) ? RealScalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L)
                               : RealScalar(0);
      }
    };
    template <typename Scalar>
    struct arg_impl : arg_default_impl<Scalar> {};
    template <typename Scalar>
    struct arg_retval {
      typedef typename NumTraits<Scalar>::Real type;
    };
    namespace std_fallback {
      template <typename Scalar>
      inline Scalar expm1(const Scalar& x) {
        static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
        typedef typename NumTraits<Scalar>::Real RealScalar;
        using std::exp;
        ;
        Scalar u = exp(x);
        if (numext::equal_strict(u, Scalar(1))) {
          return x;
        }
        Scalar um1 = u - RealScalar(1);
        if (numext::equal_strict(um1, Scalar(-1))) {
          return RealScalar(-1);
        }
        using std::log;
        ;
        Scalar logu = log(u);
        return numext::equal_strict(u, logu) ? u : (u - RealScalar(1)) * x / logu;
      }
    }  // namespace std_fallback
    template <typename Scalar>
    struct expm1_impl {
      static inline Scalar run(const Scalar& x) {
        static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
        using std::expm1;
        return expm1(x);
      }
    };
    template <typename Scalar>
    struct expm1_retval {
      typedef Scalar type;
    };
    template <typename T>
    std::complex<T> complex_log(const std::complex<T>& z);
    template <typename Scalar>
    struct log_impl {
      static inline Scalar run(const Scalar& x) {
        using std::log;
        ;
        return static_cast<Scalar>(log(x));
      }
    };
    template <typename Scalar>
    struct log_impl<std::complex<Scalar>> {
      static inline std::complex<Scalar> run(const std::complex<Scalar>& z) { return complex_log(z); }
    };
    namespace std_fallback {
      template <typename Scalar>
      inline Scalar log1p(const Scalar& x) {
        static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
        typedef typename NumTraits<Scalar>::Real RealScalar;
        using std::log;
        ;
        Scalar x1p = RealScalar(1) + x;
        Scalar log_1p = log_impl<Scalar>::run(x1p);
        const bool is_small = numext::equal_strict(x1p, Scalar(1));
        const bool is_inf = numext::equal_strict(x1p, log_1p);
        return (is_small || is_inf) ? x : x * (log_1p / (x1p - RealScalar(1)));
      }
    }  // namespace std_fallback
    template <typename Scalar>
    struct log1p_impl {
      static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
      static inline Scalar run(const Scalar& x) {
        using std::log1p;
        return log1p(x);
      }
    };
    template <typename RealScalar>
    struct log1p_impl<std::complex<RealScalar>> {
      static_assert(!Eigen::NumTraits<RealScalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
      static inline std::complex<RealScalar> run(const std::complex<RealScalar>& x) { return std_fallback::log1p(x); }
    };
    template <typename Scalar>
    struct log1p_retval {
      typedef Scalar type;
    };
    template <typename ScalarX,
              typename ScalarY,
              bool IsInteger = NumTraits<ScalarX>::IsInteger && NumTraits<ScalarY>::IsInteger>
    struct pow_impl {
      typedef typename ScalarBinaryOpTraits<ScalarX, ScalarY, internal::scalar_pow_op<ScalarX, ScalarY>>::ReturnType
          result_type;
      static inline result_type run(const ScalarX& x, const ScalarY& y) {
        using std::pow;
        ;
        return pow(x, y);
      }
    };
    template <typename ScalarX, typename ScalarY>
    struct pow_impl<ScalarX, ScalarY, true> {
      typedef ScalarX result_type;
      static inline ScalarX run(ScalarX x, ScalarY y) {
        ScalarX res(1);
        (static_cast<bool>(!NumTraits<ScalarY>::IsSigned || y >= 0)
             ? void(0)
             : __assert_fail("!NumTraits<ScalarY>::IsSigned || y >= 0",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/MathFunctions.h",
                             773,
                             __extension__ __PRETTY_FUNCTION__));
        if (y & 1)
          res *= x;
        y >>= 1;
        while (y) {
          x *= x;
          if (y & 1)
            res *= x;
          y >>= 1;
        }
        return res;
      }
    };
    template <typename Scalar, bool IsComplex, bool IsInteger>
    struct random_default_impl {};
    template <typename Scalar>
    struct random_impl : random_default_impl<Scalar, NumTraits<Scalar>::IsComplex, NumTraits<Scalar>::IsInteger> {};
    template <typename Scalar>
    struct random_retval {
      typedef Scalar type;
    };
    template <typename Scalar>
    inline typename Eigen::internal::random_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    random(const Scalar& x, const Scalar& y);
    template <typename Scalar>
    inline typename Eigen::internal::random_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    random();
    template <typename Scalar>
    struct random_default_impl<Scalar, false, false> {
      static inline Scalar run(const Scalar& x, const Scalar& y) {
        return x + (y - x) * Scalar(std::rand()) / Scalar(2147483647);
      }
      static inline Scalar run() { return run(Scalar(NumTraits<Scalar>::IsSigned ? -1 : 0), Scalar(1)); }
    };
    enum { meta_floor_log2_terminate, meta_floor_log2_move_up, meta_floor_log2_move_down, meta_floor_log2_bogus };
    template <unsigned int n, int lower, int upper>
    struct meta_floor_log2_selector {
      enum {
        middle = (lower + upper) / 2,
        value = (upper <= lower + 1)  ? int(meta_floor_log2_terminate)
                : (n < (1 << middle)) ? int(meta_floor_log2_move_down)
                : (n == 0)            ? int(meta_floor_log2_bogus)
                                      : int(meta_floor_log2_move_up)
      };
    };
    template <unsigned int n,
              int lower = 0,
              int upper = sizeof(unsigned int) * 8 - 1,
              int selector = meta_floor_log2_selector<n, lower, upper>::value>
    struct meta_floor_log2 {};
    template <unsigned int n, int lower, int upper>
    struct meta_floor_log2<n, lower, upper, meta_floor_log2_move_down> {
      enum { value = meta_floor_log2<n, lower, meta_floor_log2_selector<n, lower, upper>::middle>::value };
    };
    template <unsigned int n, int lower, int upper>
    struct meta_floor_log2<n, lower, upper, meta_floor_log2_move_up> {
      enum { value = meta_floor_log2<n, meta_floor_log2_selector<n, lower, upper>::middle, upper>::value };
    };
    template <unsigned int n, int lower, int upper>
    struct meta_floor_log2<n, lower, upper, meta_floor_log2_terminate> {
      enum { value = (n >= ((unsigned int)(1) << (lower + 1))) ? lower + 1 : lower };
    };
    template <unsigned int n, int lower, int upper>
    struct meta_floor_log2<n, lower, upper, meta_floor_log2_bogus> {};
    template <typename Scalar>
    struct random_default_impl<Scalar, false, true> {
      static inline Scalar run(const Scalar& x, const Scalar& y) {
        if (y <= x)
          return x;
        typedef typename make_unsigned<Scalar>::type ScalarU;
        typedef std::conditional_t<(ScalarU(-1) > unsigned(-1)), ScalarU, unsigned> ScalarX;
        ScalarX range = ScalarX(y) - ScalarX(x);
        ScalarX offset = 0;
        ScalarX divisor = 1;
        ScalarX multiplier = 1;
        const unsigned rand_max = 2147483647;
        if (range <= rand_max)
          divisor = (rand_max + 1) / (range + 1);
        else
          multiplier = 1 + range / (rand_max + 1);
        do {
          offset = (unsigned(std::rand()) * multiplier) / divisor;
        } while (offset > range);
        return Scalar(ScalarX(x) + offset);
      }
      static inline Scalar run() {
        enum {
          rand_bits = meta_floor_log2<(unsigned int)(2147483647) + 1>::value,
          scalar_bits = sizeof(Scalar) * 8,
          shift = plain_enum_max(0, int(rand_bits) - int(scalar_bits)),
          offset = NumTraits<Scalar>::IsSigned ? (1 << (plain_enum_min(rand_bits, scalar_bits) - 1)) : 0
        };
        return Scalar((std::rand() >> shift) - offset);
      }
    };
    template <typename Scalar>
    struct random_default_impl<Scalar, true, false> {
      static inline Scalar run(const Scalar& x, const Scalar& y) {
        return Scalar(random(x.real(), y.real()), random(x.imag(), y.imag()));
      }
      static inline Scalar run() {
        typedef typename NumTraits<Scalar>::Real RealScalar;
        return Scalar(random<RealScalar>(), random<RealScalar>());
      }
    };
    template <typename Scalar>
    inline typename Eigen::internal::random_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    random(const Scalar& x, const Scalar& y) {
      return Eigen::internal::random_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x, y);
    }
    template <typename Scalar>
    inline typename Eigen::internal::random_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    random() {
      return Eigen::internal::random_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run();
    }
    template <typename T>
    std::enable_if_t<internal::is_integral<T>::value, bool> isnan_impl(const T&) {
      return false;
    }
    template <typename T>
    std::enable_if_t<internal::is_integral<T>::value, bool> isinf_impl(const T&) {
      return false;
    }
    template <typename T>
    std::enable_if_t<internal::is_integral<T>::value, bool> isfinite_impl(const T&) {
      return true;
    }
    template <typename T>
    std::enable_if_t<(!internal::is_integral<T>::value) && (!NumTraits<T>::IsComplex), bool> isfinite_impl(const T& x) {
      using std::isfinite;
      return isfinite(x);
    }
    template <typename T>
    std::enable_if_t<(!internal::is_integral<T>::value) && (!NumTraits<T>::IsComplex), bool> isinf_impl(const T& x) {
      using std::isinf;
      return isinf(x);
    }
    template <typename T>
    std::enable_if_t<(!internal::is_integral<T>::value) && (!NumTraits<T>::IsComplex), bool> isnan_impl(const T& x) {
      using std::isnan;
      return isnan(x);
    }
    template <typename T>
    bool isfinite_impl(const std::complex<T>& x);
    template <typename T>
    bool isnan_impl(const std::complex<T>& x);
    template <typename T>
    bool isinf_impl(const std::complex<T>& x);
    template <typename T>
    T generic_fast_tanh_float(const T& a_x);
  }  // namespace internal
  namespace numext {
    template <typename T>
    __attribute__((always_inline)) inline T mini(const T& x, const T& y) {
      using std::min;
      return min(x, y);
    }
    template <typename T>
    __attribute__((always_inline)) inline T maxi(const T& x, const T& y) {
      using std::max;
      return max(x, y);
    }
    template <typename Scalar>
    inline typename Eigen::internal::real_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    real(const Scalar& x) {
      return Eigen::internal::real_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline internal::add_const_on_value_type_t<typename Eigen::internal::real_ref_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type>
    real_ref(const Scalar& x) {
      return internal::real_ref_impl<Scalar>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::real_ref_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    real_ref(Scalar& x) {
      return Eigen::internal::real_ref_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::imag_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    imag(const Scalar& x) {
      return Eigen::internal::imag_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::arg_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    arg(const Scalar& x) {
      return Eigen::internal::arg_impl<typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(
          x);
    }
    template <typename Scalar>
    inline internal::add_const_on_value_type_t<typename Eigen::internal::imag_ref_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type>
    imag_ref(const Scalar& x) {
      return internal::imag_ref_impl<Scalar>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::imag_ref_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    imag_ref(Scalar& x) {
      return Eigen::internal::imag_ref_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::conj_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    conj(const Scalar& x) {
      return Eigen::internal::conj_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::sign_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    sign(const Scalar& x) {
      return Eigen::internal::sign_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::abs2_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    abs2(const Scalar& x) {
      return Eigen::internal::abs2_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    inline bool abs2(bool x) { return x; }
    template <typename T>
    __attribute__((always_inline)) inline T absdiff(const T& x, const T& y) {
      return x > y ? x - y : y - x;
    }
    template <>
    __attribute__((always_inline)) inline float absdiff(const float& x, const float& y) {
      return fabsf(x - y);
    }
    template <>
    __attribute__((always_inline)) inline double absdiff(const double& x, const double& y) {
      return fabs(x - y);
    }
    template <>
    __attribute__((always_inline)) inline long double absdiff(const long double& x, const long double& y) {
      return fabsl(x - y);
    }
    template <typename Scalar>
    inline typename Eigen::internal::norm1_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    norm1(const Scalar& x) {
      return Eigen::internal::norm1_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::hypot_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    hypot(const Scalar& x, const Scalar& y) {
      return Eigen::internal::hypot_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x, y);
    }
    template <typename Scalar>
    inline typename Eigen::internal::log1p_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    log1p(const Scalar& x) {
      return Eigen::internal::log1p_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename ScalarX, typename ScalarY>
    inline typename internal::pow_impl<ScalarX, ScalarY>::result_type pow(const ScalarX& x, const ScalarY& y) {
      return internal::pow_impl<ScalarX, ScalarY>::run(x, y);
    }
    template <typename T>
    bool(isnan)(const T& x) {
      return internal::isnan_impl(x);
    }
    template <typename T>
    bool(isinf)(const T& x) {
      return internal::isinf_impl(x);
    }
    template <typename T>
    bool(isfinite)(const T& x) {
      return internal::isfinite_impl(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::rint_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    rint(const Scalar& x) {
      return Eigen::internal::rint_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::round_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    round(const Scalar& x) {
      return Eigen::internal::round_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename T>
    T(floor)
    (const T& x) {
      using std::floor;
      return floor(x);
    }
    template <typename T>
    T(ceil)
    (const T& x) {
      using std::ceil;
      ;
      return ceil(x);
    }
    inline int log2(int x) {
      (static_cast<bool>(x >= 0)
           ? void(0)
           : __assert_fail("x>=0",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/MathFunctions.h",
                           1433,
                           __extension__ __PRETTY_FUNCTION__));
      unsigned int v(x);
      static const int table[32] = {0, 9,  1,  10, 13, 21, 2,  29, 11, 14, 16, 18, 22, 25, 3, 30,
                                    8, 12, 20, 28, 15, 17, 24, 7,  19, 27, 23, 6,  26, 5,  4, 31};
      v |= v >> 1;
      v |= v >> 2;
      v |= v >> 4;
      v |= v >> 8;
      v |= v >> 16;
      return table[(v * 0x07C4ACDDU) >> 27];
    }
    template <typename Scalar>
    __attribute__((always_inline)) inline typename Eigen::internal::sqrt_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    sqrt(const Scalar& x) {
      return Eigen::internal::sqrt_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <>
    inline bool sqrt<bool>(const bool& x) {
      return x;
    }
    template <typename T>
    __attribute__((always_inline)) inline T rsqrt(const T& x) {
      return internal::rsqrt_impl<T>::run(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T log(const T& x) {
      return internal::log_impl<T>::run(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline std::enable_if_t<NumTraits<T>::IsSigned || NumTraits<T>::IsComplex,
                                                           typename NumTraits<T>::Real>
    abs(const T& x) {
      using std::abs;
      ;
      return abs(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline std::enable_if_t<!(NumTraits<T>::IsSigned || NumTraits<T>::IsComplex),
                                                           typename NumTraits<T>::Real>
    abs(const T& x) {
      return x;
    }
    template <typename T>
    __attribute__((always_inline)) inline T exp(const T& x) {
      using std::exp;
      ;
      return exp(x);
    }
    template <typename Scalar>
    inline typename Eigen::internal::expm1_retval<
        typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::type
    expm1(const Scalar& x) {
      return Eigen::internal::expm1_impl<
          typename Eigen::internal::global_math_functions_filtering_base<Scalar>::type>::run(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T cos(const T& x) {
      using std::cos;
      ;
      return cos(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T sin(const T& x) {
      using std::sin;
      ;
      return sin(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T tan(const T& x) {
      using std::tan;
      ;
      return tan(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T acos(const T& x) {
      using std::acos;
      ;
      return acos(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T acosh(const T& x) {
      using std::acosh;
      ;
      return static_cast<T>(acosh(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T asin(const T& x) {
      using std::asin;
      ;
      return asin(x);
    }
    template <typename T>
    __attribute__((always_inline)) inline T asinh(const T& x) {
      using std::asinh;
      ;
      return static_cast<T>(asinh(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T atan(const T& x) {
      using std::atan;
      ;
      return static_cast<T>(atan(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T atanh(const T& x) {
      using std::atanh;
      ;
      return static_cast<T>(atanh(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T cosh(const T& x) {
      using std::cosh;
      ;
      return static_cast<T>(cosh(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T sinh(const T& x) {
      using std::sinh;
      ;
      return static_cast<T>(sinh(x));
    }
    template <typename T>
    __attribute__((always_inline)) inline T tanh(const T& x) {
      using std::tanh;
      ;
      return tanh(x);
    }
    __attribute__((always_inline)) inline float tanh(float x) { return internal::generic_fast_tanh_float(x); }
    template <typename T>
    __attribute__((always_inline)) inline T fmod(const T& a, const T& b) {
      using std::fmod;
      ;
      return fmod(a, b);
    }
  }  // namespace numext
  namespace internal {
    template <typename T>
    bool isfinite_impl(const std::complex<T>& x) {
      return (numext::isfinite)(numext::real(x)) && (numext::isfinite)(numext::imag(x));
    }
    template <typename T>
    bool isnan_impl(const std::complex<T>& x) {
      return (numext::isnan)(numext::real(x)) || (numext::isnan)(numext::imag(x));
    }
    template <typename T>
    bool isinf_impl(const std::complex<T>& x) {
      return ((numext::isinf)(numext::real(x)) || (numext::isinf)(numext::imag(x))) && (!(numext::isnan)(x));
    }
    template <typename Scalar, bool IsComplex, bool IsInteger>
    struct scalar_fuzzy_default_impl {};
    template <typename Scalar>
    struct scalar_fuzzy_default_impl<Scalar, false, false> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      template <typename OtherScalar>
      static inline bool isMuchSmallerThan(const Scalar& x, const OtherScalar& y, const RealScalar& prec) {
        return numext::abs(x) <= numext::abs(y) * prec;
      }
      static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar& prec) {
        return numext::abs(x - y) <= numext::mini(numext::abs(x), numext::abs(y)) * prec;
      }
      static inline bool isApproxOrLessThan(const Scalar& x, const Scalar& y, const RealScalar& prec) {
        return x <= y || isApprox(x, y, prec);
      }
    };
    template <typename Scalar>
    struct scalar_fuzzy_default_impl<Scalar, false, true> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      template <typename OtherScalar>
      static inline bool isMuchSmallerThan(const Scalar& x, const Scalar&, const RealScalar&) {
        return x == Scalar(0);
      }
      static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar&) { return x == y; }
      static inline bool isApproxOrLessThan(const Scalar& x, const Scalar& y, const RealScalar&) { return x <= y; }
    };
    template <typename Scalar>
    struct scalar_fuzzy_default_impl<Scalar, true, false> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      template <typename OtherScalar>
      static inline bool isMuchSmallerThan(const Scalar& x, const OtherScalar& y, const RealScalar& prec) {
        return numext::abs2(x) <= numext::abs2(y) * prec * prec;
      }
      static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar& prec) {
        return numext::abs2(x - y) <= numext::mini(numext::abs2(x), numext::abs2(y)) * prec * prec;
      }
    };
    template <typename Scalar>
    struct scalar_fuzzy_impl
        : scalar_fuzzy_default_impl<Scalar, NumTraits<Scalar>::IsComplex, NumTraits<Scalar>::IsInteger> {};
    template <typename Scalar, typename OtherScalar>
    inline bool isMuchSmallerThan(
        const Scalar& x,
        const OtherScalar& y,
        const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
      return scalar_fuzzy_impl<Scalar>::template isMuchSmallerThan<OtherScalar>(x, y, precision);
    }
    template <typename Scalar>
    inline bool isApprox(const Scalar& x,
                         const Scalar& y,
                         const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
      return scalar_fuzzy_impl<Scalar>::isApprox(x, y, precision);
    }
    template <typename Scalar>
    inline bool isApproxOrLessThan(
        const Scalar& x,
        const Scalar& y,
        const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
      return scalar_fuzzy_impl<Scalar>::isApproxOrLessThan(x, y, precision);
    }
    template <>
    struct random_impl<bool> {
      static inline bool run() { return random<int>(0, 1) == 0 ? false : true; }
      static inline bool run(const bool& a, const bool& b) { return random<int>(a, b) == 0 ? false : true; }
    };
    template <>
    struct scalar_fuzzy_impl<bool> {
      typedef bool RealScalar;
      template <typename OtherScalar>
      static inline bool isMuchSmallerThan(const bool& x, const bool&, const bool&) {
        return !x;
      }
      static inline bool isApprox(bool x, bool y, bool) { return x == y; }
      static inline bool isApproxOrLessThan(const bool& x, const bool& y, const bool&) { return (!x) || y; }
    };
  }  // namespace internal
  namespace internal {
    template <typename RealScalar>
    struct expm1_impl<std::complex<RealScalar>> {
      static_assert(!Eigen::NumTraits<RealScalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
      static inline std::complex<RealScalar> run(const std::complex<RealScalar>& x) {
        RealScalar xr = x.real();
        RealScalar xi = x.imag();
        RealScalar erm1 = numext::expm1<RealScalar>(xr);
        RealScalar er = erm1 + RealScalar(1.);
        RealScalar sin2 = numext::sin(xi / RealScalar(2.));
        sin2 = sin2 * sin2;
        RealScalar s = numext::sin(xi);
        RealScalar real_part = erm1 - RealScalar(2.) * er * sin2;
        return std::complex<RealScalar>(real_part, er * s);
      }
    };
    template <typename T>
    struct rsqrt_impl {
      static __attribute__((always_inline)) inline T run(const T& x) { return T(1) / numext::sqrt(x); }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    struct default_packet_traits {
      enum {
        HasHalfPacket = 0,
        HasAdd = 1,
        HasSub = 1,
        HasShift = 1,
        HasMul = 1,
        HasNegate = 1,
        HasAbs = 1,
        HasArg = 0,
        HasAbs2 = 1,
        HasAbsDiff = 0,
        HasMin = 1,
        HasMax = 1,
        HasConj = 1,
        HasSetLinear = 1,
        HasSign = 1,
        HasBlend = 0,
        HasCmp = 0,
        HasDiv = 0,
        HasReciprocal = 0,
        HasSqrt = 0,
        HasRsqrt = 0,
        HasExp = 0,
        HasExpm1 = 0,
        HasLog = 0,
        HasLog1p = 0,
        HasLog10 = 0,
        HasPow = 0,
        HasSin = 0,
        HasCos = 0,
        HasTan = 0,
        HasASin = 0,
        HasACos = 0,
        HasATan = 0,
        HasSinh = 0,
        HasCosh = 0,
        HasTanh = 0,
        HasLGamma = 0,
        HasDiGamma = 0,
        HasZeta = 0,
        HasPolygamma = 0,
        HasErf = 0,
        HasErfc = 0,
        HasNdtri = 0,
        HasBessel = 0,
        HasIGamma = 0,
        HasIGammaDerA = 0,
        HasGammaSampleDerAlpha = 0,
        HasIGammac = 0,
        HasBetaInc = 0,
        HasRound = 0,
        HasRint = 0,
        HasFloor = 0,
        HasCeil = 0
      };
    };
    template <typename T>
    struct packet_traits : default_packet_traits {
      typedef T type;
      typedef T half;
      enum { Vectorizable = 0, size = 1, AlignedOnScalar = 0, HasHalfPacket = 0 };
      enum {
        HasAdd = 0,
        HasSub = 0,
        HasMul = 0,
        HasNegate = 0,
        HasAbs = 0,
        HasAbs2 = 0,
        HasMin = 0,
        HasMax = 0,
        HasConj = 0,
        HasSetLinear = 0
      };
    };
    template <typename T>
    struct packet_traits<const T> : packet_traits<T> {};
    template <typename T>
    struct unpacket_traits {
      typedef T type;
      typedef T half;
      enum {
        size = 1,
        alignment = 1,
        vectorizable = false,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <typename T>
    struct unpacket_traits<const T> : unpacket_traits<T> {};
    template <typename Src, typename Tgt>
    struct type_casting_traits {
      enum { VectorizedCast = 0, SrcCoeffRatio = 1, TgtCoeffRatio = 1 };
    };
    template <typename T, int unique_id = 0>
    struct eigen_packet_wrapper {
      __attribute__((always_inline)) inline operator T&() { return m_val; }
      __attribute__((always_inline)) inline operator const T&() const { return m_val; }
      __attribute__((always_inline)) inline eigen_packet_wrapper() = default;
      __attribute__((always_inline)) inline eigen_packet_wrapper(const T& v) : m_val(v) {}
      __attribute__((always_inline)) inline eigen_packet_wrapper& operator=(const T& v) {
        m_val = v;
        return *this;
      }
      T m_val;
    };
    template <typename Packet>
    struct is_scalar {
      using Scalar = typename unpacket_traits<Packet>::type;
      enum { value = internal::is_same<Packet, Scalar>::value };
    };
    template <typename SrcPacket, typename TgtPacket>
    inline TgtPacket pcast(const SrcPacket& a) {
      return static_cast<TgtPacket>(a);
    }
    template <typename SrcPacket, typename TgtPacket>
    inline TgtPacket pcast(const SrcPacket& a, const SrcPacket&) {
      return static_cast<TgtPacket>(a);
    }
    template <typename SrcPacket, typename TgtPacket>
    inline TgtPacket pcast(const SrcPacket& a, const SrcPacket&, const SrcPacket&, const SrcPacket&) {
      return static_cast<TgtPacket>(a);
    }
    template <typename SrcPacket, typename TgtPacket>
    inline TgtPacket pcast(const SrcPacket& a,
                           const SrcPacket&,
                           const SrcPacket&,
                           const SrcPacket&,
                           const SrcPacket&,
                           const SrcPacket&,
                           const SrcPacket&,
                           const SrcPacket&) {
      return static_cast<TgtPacket>(a);
    }
    template <typename Target, typename Packet>
    inline Target preinterpret(const Packet& a);
    template <typename Packet>
    inline Packet padd(const Packet& a, const Packet& b) {
      return a + b;
    }
    template <>
    inline bool padd(const bool& a, const bool& b) {
      return a || b;
    }
    template <typename Packet>
    inline std::enable_if_t<unpacket_traits<Packet>::masked_fpops_available, Packet> padd(
        const Packet& a, const Packet& b, typename unpacket_traits<Packet>::mask_t umask);
    template <typename Packet>
    inline Packet psub(const Packet& a, const Packet& b) {
      return a - b;
    }
    template <typename Packet>
    inline Packet pnegate(const Packet& a) {
      return -a;
    }
    template <>
    inline bool pnegate(const bool& a) {
      return !a;
    }
    template <typename Packet>
    inline Packet pconj(const Packet& a) {
      return numext::conj(a);
    }
    template <typename Packet>
    inline Packet pmul(const Packet& a, const Packet& b) {
      return a * b;
    }
    template <>
    inline bool pmul(const bool& a, const bool& b) {
      return a && b;
    }
    template <typename Packet>
    inline Packet pdiv(const Packet& a, const Packet& b) {
      return a / b;
    }
    template <typename Packet, typename EnableIf = void>
    struct ptrue_impl {
      static inline Packet run(const Packet&) {
        Packet b;
        memset(static_cast<void*>(&b), 0xff, sizeof(Packet));
        return b;
      }
    };
    template <typename T>
    struct ptrue_impl<T, std::enable_if_t<is_scalar<T>::value && NumTraits<T>::RequireInitialization>> {
      static inline T run(const T&) { return T(1); }
    };
    template <typename Packet>
    inline Packet ptrue(const Packet& a) {
      return ptrue_impl<Packet>::run(a);
    }
    template <typename Packet, typename EnableIf = void>
    struct pzero_impl {
      static inline Packet run(const Packet&) {
        Packet b;
        memset(static_cast<void*>(&b), 0x00, sizeof(Packet));
        return b;
      }
    };
    template <typename T>
    struct pzero_impl<T, std::enable_if_t<is_scalar<T>::value>> {
      static inline T run(const T&) { return T(0); }
    };
    template <typename Packet>
    inline Packet pzero(const Packet& a) {
      return pzero_impl<Packet>::run(a);
    }
    template <typename Packet>
    inline Packet pcmp_le(const Packet& a, const Packet& b) {
      return a <= b ? ptrue(a) : pzero(a);
    }
    template <typename Packet>
    inline Packet pcmp_lt(const Packet& a, const Packet& b) {
      return a < b ? ptrue(a) : pzero(a);
    }
    template <typename Packet>
    inline Packet pcmp_eq(const Packet& a, const Packet& b) {
      return a == b ? ptrue(a) : pzero(a);
    }
    template <typename Packet>
    inline Packet pcmp_lt_or_nan(const Packet& a, const Packet& b) {
      return a >= b ? pzero(a) : ptrue(a);
    }
    template <typename T>
    struct bit_and {
      constexpr __attribute__((always_inline)) inline T operator()(const T& a, const T& b) const { return a & b; }
    };
    template <typename T>
    struct bit_or {
      constexpr __attribute__((always_inline)) inline T operator()(const T& a, const T& b) const { return a | b; }
    };
    template <typename T>
    struct bit_xor {
      constexpr __attribute__((always_inline)) inline T operator()(const T& a, const T& b) const { return a ^ b; }
    };
    template <typename T>
    struct bit_not {
      constexpr __attribute__((always_inline)) inline T operator()(const T& a) const { return ~a; }
    };
    template <typename T>
    struct operator_bitwise_helper {
      static inline T bitwise_and(const T& a, const T& b) { return bit_and<T>()(a, b); }
      static inline T bitwise_or(const T& a, const T& b) { return bit_or<T>()(a, b); }
      static inline T bitwise_xor(const T& a, const T& b) { return bit_xor<T>()(a, b); }
      static inline T bitwise_not(const T& a) { return bit_not<T>()(a); }
    };
    template <typename T>
    struct bytewise_bitwise_helper {
      static inline T bitwise_and(const T& a, const T& b) { return binary(a, b, bit_and<unsigned char>()); }
      static inline T bitwise_or(const T& a, const T& b) { return binary(a, b, bit_or<unsigned char>()); }
      static inline T bitwise_xor(const T& a, const T& b) { return binary(a, b, bit_xor<unsigned char>()); }
      static inline T bitwise_not(const T& a) { return unary(a, bit_not<unsigned char>()); }

    private:
      template <typename Op>
      static inline T unary(const T& a, Op op) {
        const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
        T c;
        unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
        for (size_t i = 0; i < sizeof(T); ++i) {
          *c_ptr++ = op(*a_ptr++);
        }
        return c;
      }
      template <typename Op>
      static inline T binary(const T& a, const T& b, Op op) {
        const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
        const unsigned char* b_ptr = reinterpret_cast<const unsigned char*>(&b);
        T c;
        unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
        for (size_t i = 0; i < sizeof(T); ++i) {
          *c_ptr++ = op(*a_ptr++, *b_ptr++);
        }
        return c;
      }
    };
    template <typename T, typename EnableIf = void>
    struct bitwise_helper : public bytewise_bitwise_helper<T> {};
    template <typename T>
    struct bitwise_helper<T,
                          typename std::enable_if_t<is_scalar<T>::value &&
                                                    (NumTraits<T>::IsInteger || NumTraits<T>::RequireInitialization)>>
        : public operator_bitwise_helper<T> {};
    template <typename Packet>
    inline Packet pand(const Packet& a, const Packet& b) {
      return bitwise_helper<Packet>::bitwise_and(a, b);
    }
    template <typename Packet>
    inline Packet por(const Packet& a, const Packet& b) {
      return bitwise_helper<Packet>::bitwise_or(a, b);
    }
    template <typename Packet>
    inline Packet pxor(const Packet& a, const Packet& b) {
      return bitwise_helper<Packet>::bitwise_xor(a, b);
    }
    template <typename Packet>
    inline Packet pnot(const Packet& a) {
      return bitwise_helper<Packet>::bitwise_not(a);
    }
    template <typename Packet>
    inline Packet pandnot(const Packet& a, const Packet& b) {
      return pand(a, pnot(b));
    }
    template <typename Packet, typename EnableIf = void>
    struct pselect_impl {
      static inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
        return por(pand(a, mask), pandnot(b, mask));
      }
    };
    template <typename Packet>
    struct pselect_impl<Packet, std::enable_if_t<is_scalar<Packet>::value>> {
      static inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
        return numext::equal_strict(mask, Packet(0)) ? b : a;
      }
    };
    template <typename Packet>
    inline Packet pselect(const Packet& mask, const Packet& a, const Packet& b) {
      return pselect_impl<Packet>::run(mask, a, b);
    }
    template <>
    inline bool pselect<bool>(const bool& cond, const bool& a, const bool& b) {
      return cond ? a : b;
    }
    template <int NaNPropagation>
    struct pminmax_impl {
      template <typename Packet, typename Op>
      static inline Packet run(const Packet& a, const Packet& b, Op op) {
        return op(a, b);
      }
    };
    template <>
    struct pminmax_impl<PropagateNaN> {
      template <typename Packet, typename Op>
      static inline Packet run(const Packet& a, const Packet& b, Op op) {
        Packet not_nan_mask_a = pcmp_eq(a, a);
        Packet not_nan_mask_b = pcmp_eq(b, b);
        return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), b), a);
      }
    };
    template <>
    struct pminmax_impl<PropagateNumbers> {
      template <typename Packet, typename Op>
      static inline Packet run(const Packet& a, const Packet& b, Op op) {
        Packet not_nan_mask_a = pcmp_eq(a, a);
        Packet not_nan_mask_b = pcmp_eq(b, b);
        return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), a), b);
      }
    };
    template <typename Packet>
    inline Packet pmin(const Packet& a, const Packet& b) {
      return numext::mini(a, b);
    }
    template <int NaNPropagation, typename Packet>
    inline Packet pmin(const Packet& a, const Packet& b) {
      return pminmax_impl<NaNPropagation>::run(a, b, (pmin<Packet>));
    }
    template <typename Packet>
    inline Packet pmax(const Packet& a, const Packet& b) {
      return numext::maxi(a, b);
    }
    template <int NaNPropagation, typename Packet>
    inline Packet pmax(const Packet& a, const Packet& b) {
      return pminmax_impl<NaNPropagation>::run(a, b, (pmax<Packet>));
    }
    template <typename Packet>
    inline Packet pabs(const Packet& a) {
      return numext::abs(a);
    }
    template <>
    inline unsigned int pabs(const unsigned int& a) {
      return a;
    }
    template <>
    inline unsigned long pabs(const unsigned long& a) {
      return a;
    }
    template <>
    inline unsigned long long pabs(const unsigned long long& a) {
      return a;
    }
    template <typename Packet>
    inline Packet paddsub(const Packet& a, const Packet& b) {
      return pselect(peven_mask(a), padd(a, b), psub(a, b));
    }
    template <typename Packet>
    inline Packet parg(const Packet& a) {
      using numext::arg;
      return arg(a);
    }
    template <int N>
    inline int parithmetic_shift_right(const int& a) {
      return a >> N;
    }
    template <int N>
    inline long int parithmetic_shift_right(const long int& a) {
      return a >> N;
    }
    template <int N>
    inline int plogical_shift_right(const int& a) {
      return static_cast<int>(static_cast<unsigned int>(a) >> N);
    }
    template <int N>
    inline long int plogical_shift_right(const long int& a) {
      return static_cast<long>(static_cast<unsigned long>(a) >> N);
    }
    template <int N>
    inline int plogical_shift_left(const int& a) {
      return a << N;
    }
    template <int N>
    inline long int plogical_shift_left(const long int& a) {
      return a << N;
    }
    template <typename Packet>
    inline Packet pfrexp(const Packet& a, Packet& exponent) {
      int exp;
      using std::frexp;
      ;
      Packet result = static_cast<Packet>(frexp(a, &exp));
      exponent = static_cast<Packet>(exp);
      return result;
    }
    template <typename Packet>
    inline Packet pldexp(const Packet& a, const Packet& exponent) {
      using std::ldexp;
      return static_cast<Packet>(ldexp(a, static_cast<int>(exponent)));
    }
    template <typename Packet>
    inline Packet pabsdiff(const Packet& a, const Packet& b) {
      return pselect(pcmp_lt(a, b), psub(b, a), psub(a, b));
    }
    template <typename Packet>
    inline Packet pload(const typename unpacket_traits<Packet>::type* from) {
      return *from;
    }
    template <typename Packet>
    inline Packet pload_partial(const typename unpacket_traits<Packet>::type* from,
                                const Index n,
                                const Index offset = 0) {
      const Index packet_size = unpacket_traits<Packet>::size;
      (static_cast<bool>(n + offset <= packet_size && "number of elements plus offset will read past end of packet")
           ? void(0)
           : __assert_fail(
                 "n + offset <= packet_size && \"number of elements plus offset will read past end of packet\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/GenericPacketMath.h",
                 621,
                 __extension__ __PRETTY_FUNCTION__));
      typedef typename unpacket_traits<Packet>::type Scalar;
      alignas(16) Scalar elements[packet_size] = {Scalar(0)};
      for (Index i = offset; i < numext::mini(n + offset, packet_size); i++) {
        elements[i] = from[i - offset];
      }
      return pload<Packet>(elements);
    }
    template <typename Packet>
    inline Packet ploadu(const typename unpacket_traits<Packet>::type* from) {
      return *from;
    }
    template <typename Packet>
    inline Packet ploadu_partial(const typename unpacket_traits<Packet>::type* from, const Index n) {
      const Index packet_size = unpacket_traits<Packet>::size;
      (static_cast<bool>(n <= packet_size && "number of elements will read past end of packet")
           ? void(0)
           : __assert_fail("n <= packet_size && \"number of elements will read past end of packet\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/GenericPacketMath.h",
                           640,
                           __extension__ __PRETTY_FUNCTION__));
      typedef typename unpacket_traits<Packet>::type Scalar;
      alignas(16) Scalar elements[packet_size] = {Scalar(0)};
      for (Index i = 0; i < numext::mini(n, packet_size); i++) {
        elements[i] = from[i];
      }
      return pload<Packet>(elements);
    }
    template <typename Packet>
    inline std::enable_if_t<unpacket_traits<Packet>::masked_load_available, Packet> ploadu(
        const typename unpacket_traits<Packet>::type* from, typename unpacket_traits<Packet>::mask_t umask);
    template <typename Packet>
    inline Packet pset1(const typename unpacket_traits<Packet>::type& a) {
      return a;
    }
    template <typename Packet, typename BitsType>
    inline Packet pset1frombits(BitsType a);
    template <typename Packet>
    inline Packet pload1(const typename unpacket_traits<Packet>::type* a) {
      return pset1<Packet>(*a);
    }
    template <typename Packet>
    inline Packet ploaddup(const typename unpacket_traits<Packet>::type* from) {
      return *from;
    }
    template <typename Packet>
    inline Packet ploadquad(const typename unpacket_traits<Packet>::type* from) {
      return pload1<Packet>(from);
    }
    template <typename Packet>
    inline void pbroadcast4(
        const typename unpacket_traits<Packet>::type* a, Packet& a0, Packet& a1, Packet& a2, Packet& a3) {
      a0 = pload1<Packet>(a + 0);
      a1 = pload1<Packet>(a + 1);
      a2 = pload1<Packet>(a + 2);
      a3 = pload1<Packet>(a + 3);
    }
    template <typename Packet>
    inline void pbroadcast2(const typename unpacket_traits<Packet>::type* a, Packet& a0, Packet& a1) {
      a0 = pload1<Packet>(a + 0);
      a1 = pload1<Packet>(a + 1);
    }
    template <typename Packet>
    inline Packet plset(const typename unpacket_traits<Packet>::type& a) {
      return a;
    }
    template <typename Packet>
    inline Packet peven_mask(const Packet&) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      const size_t n = unpacket_traits<Packet>::size;
      alignas(sizeof(Packet)) Scalar elements[n];
      for (size_t i = 0; i < n; ++i) {
        memset(elements + i, ((i & 1) == 0 ? 0xff : 0), sizeof(Scalar));
      }
      return ploadu<Packet>(elements);
    }
    template <typename Scalar, typename Packet>
    inline void pstore(Scalar* to, const Packet& from) {
      (*to) = from;
    }
    template <typename Scalar, typename Packet>
    inline void pstore_partial(Scalar* to, const Packet& from, const Index n, const Index offset = 0) {
      const Index packet_size = unpacket_traits<Packet>::size;
      (static_cast<bool>(n + offset <= packet_size && "number of elements plus offset will write past end of packet")
           ? void(0)
           : __assert_fail(
                 "n + offset <= packet_size && \"number of elements plus offset will write past end of packet\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/GenericPacketMath.h",
                 749,
                 __extension__ __PRETTY_FUNCTION__));
      alignas(16) Scalar elements[packet_size];
      pstore<Scalar>(elements, from);
      for (Index i = 0; i < numext::mini(n, packet_size - offset); i++) {
        to[i] = elements[i + offset];
      }
    }
    template <typename Scalar, typename Packet>
    inline void pstoreu(Scalar* to, const Packet& from) {
      (*to) = from;
    }
    template <typename Scalar, typename Packet>
    inline void pstoreu_partial(Scalar* to, const Packet& from, const Index n) {
      const Index packet_size = unpacket_traits<Packet>::size;
      (static_cast<bool>(n <= packet_size && "number of elements will write past end of packet")
           ? void(0)
           : __assert_fail("n <= packet_size && \"number of elements will write past end of packet\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/GenericPacketMath.h",
                           765,
                           __extension__ __PRETTY_FUNCTION__));
      alignas(16) Scalar elements[packet_size];
      pstore<Scalar>(elements, from);
      for (Index i = 0; i < numext::mini(n, packet_size); i++) {
        to[i] = elements[i];
      }
    }
    template <typename Scalar, typename Packet>
    inline std::enable_if_t<unpacket_traits<Packet>::masked_store_available, void> pstoreu(
        Scalar* to, const Packet& from, typename unpacket_traits<Packet>::mask_t umask);
    template <typename Scalar, typename Packet>
    inline Packet pgather(const Scalar* from, Index) {
      return ploadu<Packet>(from);
    }
    template <typename Scalar, typename Packet>
    inline Packet pgather_partial(const Scalar* from, Index stride, const Index n) {
      const Index packet_size = unpacket_traits<Packet>::size;
      alignas(16) Scalar elements[packet_size] = {Scalar(0)};
      for (Index i = 0; i < numext::mini(n, packet_size); i++) {
        elements[i] = from[i * stride];
      }
      return pload<Packet>(elements);
    }
    template <typename Scalar, typename Packet>
    inline void pscatter(Scalar* to, const Packet& from, Index) {
      pstore(to, from);
    }
    template <typename Scalar, typename Packet>
    inline void pscatter_partial(Scalar* to, const Packet& from, Index stride, const Index n) {
      const Index packet_size = unpacket_traits<Packet>::size;
      alignas(16) Scalar elements[packet_size];
      pstore<Scalar>(elements, from);
      for (Index i = 0; i < numext::mini(n, packet_size); i++) {
        to[i * stride] = elements[i];
      }
    }
    template <typename Scalar>
    inline void prefetch(const Scalar* addr) {
      __builtin_prefetch(addr);
    }
    template <typename Packet>
    inline Packet preverse(const Packet& a) {
      return a;
    }
    template <typename Packet>
    inline Packet pcplxflip(const Packet& a) {
      return Packet(numext::imag(a), numext::real(a));
    }
    template <typename Packet>
    Packet psin(const Packet& a) {
      using std::sin;
      ;
      return sin(a);
    }
    template <typename Packet>
    Packet pcos(const Packet& a) {
      using std::cos;
      ;
      return cos(a);
    }
    template <typename Packet>
    Packet ptan(const Packet& a) {
      using std::tan;
      ;
      return tan(a);
    }
    template <typename Packet>
    Packet pasin(const Packet& a) {
      using std::asin;
      ;
      return asin(a);
    }
    template <typename Packet>
    Packet pacos(const Packet& a) {
      using std::acos;
      ;
      return acos(a);
    }
    template <typename Packet>
    Packet patan(const Packet& a) {
      using std::atan;
      ;
      return atan(a);
    }
    template <typename Packet>
    Packet psinh(const Packet& a) {
      using std::sinh;
      ;
      return sinh(a);
    }
    template <typename Packet>
    Packet pcosh(const Packet& a) {
      using std::cosh;
      ;
      return cosh(a);
    }
    template <typename Packet>
    Packet ptanh(const Packet& a) {
      using std::tanh;
      ;
      return tanh(a);
    }
    template <typename Packet>
    Packet pexp(const Packet& a) {
      using std::exp;
      ;
      return exp(a);
    }
    template <typename Packet>
    Packet pexpm1(const Packet& a) {
      return numext::expm1(a);
    }
    template <typename Packet>
    Packet plog(const Packet& a) {
      using std::log;
      ;
      return log(a);
    }
    template <typename Packet>
    Packet plog1p(const Packet& a) {
      return numext::log1p(a);
    }
    template <typename Packet>
    Packet plog10(const Packet& a) {
      using std::log10;
      ;
      return log10(a);
    }
    template <typename Packet>
    Packet plog2(const Packet& a) {
      typedef typename internal::unpacket_traits<Packet>::type Scalar;
      return pmul(pset1<Packet>(Scalar(1.442695040888963407359924681001892137426645954152985934135449406931109219L)),
                  plog(a));
    }
    template <typename Packet>
    Packet psqrt(const Packet& a) {
      return numext::sqrt(a);
    }
    template <typename Packet>
    Packet pround(const Packet& a) {
      using numext::round;
      return round(a);
    }
    template <typename Packet>
    Packet pfloor(const Packet& a) {
      using numext::floor;
      return floor(a);
    }
    template <typename Packet>
    Packet print(const Packet& a) {
      using numext::rint;
      return rint(a);
    }
    template <typename Packet>
    Packet pceil(const Packet& a) {
      using numext::ceil;
      return ceil(a);
    }
    template <typename Packet, typename EnableIf = void>
    struct psign_impl {
      static inline Packet run(const Packet& a) { return numext::sign(a); }
    };
    template <typename Packet>
    inline Packet psign(const Packet& a) {
      return psign_impl<Packet>::run(a);
    }
    template <>
    inline bool psign(const bool& a) {
      return a;
    }
    template <typename Packet>
    inline typename unpacket_traits<Packet>::type pfirst(const Packet& a) {
      return a;
    }
    template <typename Packet>
    inline std::conditional_t<(unpacket_traits<Packet>::size % 8) == 0, typename unpacket_traits<Packet>::half, Packet>
    predux_half_dowto4(const Packet& a) {
      return a;
    }
    template <typename Packet, typename Op>
    inline typename unpacket_traits<Packet>::type predux_helper(const Packet& a, Op op) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      const size_t n = unpacket_traits<Packet>::size;
      alignas(sizeof(Packet)) Scalar elements[n];
      pstoreu<Scalar>(elements, a);
      for (size_t k = n / 2; k > 0; k /= 2) {
        for (size_t i = 0; i < k; ++i) {
          elements[i] = op(elements[i], elements[i + k]);
        }
      }
      return elements[0];
    }
    template <typename Packet>
    inline typename unpacket_traits<Packet>::type predux(const Packet& a) {
      return a;
    }
    template <typename Packet>
    inline typename unpacket_traits<Packet>::type predux_mul(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return predux_helper(a, (pmul<Scalar>));
    }
    template <typename Packet>
    inline typename unpacket_traits<Packet>::type predux_min(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return predux_helper(a, (pmin<PropagateFast, Scalar>));
    }
    template <int NaNPropagation, typename Packet>
    inline typename unpacket_traits<Packet>::type predux_min(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return predux_helper(a, (pmin<NaNPropagation, Scalar>));
    }
    template <typename Packet>
    inline typename unpacket_traits<Packet>::type predux_max(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return predux_helper(a, (pmax<PropagateFast, Scalar>));
    }
    template <int NaNPropagation, typename Packet>
    inline typename unpacket_traits<Packet>::type predux_max(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return predux_helper(a, (pmax<NaNPropagation, Scalar>));
    }
    template <typename Packet>
    inline bool predux_any(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      return numext::not_equal_strict(predux(a), Scalar(0));
    }
    template <typename Packet>
    inline Packet pmadd(const Packet& a, const Packet& b, const Packet& c) {
      return padd(pmul(a, b), c);
    }
    template <typename Packet>
    inline Packet pmsub(const Packet& a, const Packet& b, const Packet& c) {
      return psub(pmul(a, b), c);
    }
    template <typename Packet>
    inline Packet pnmadd(const Packet& a, const Packet& b, const Packet& c) {
      return padd(pnegate(pmul(a, b)), c);
    }
    template <typename Packet>
    inline Packet pnmsub(const Packet& a, const Packet& b, const Packet& c) {
      return psub(pnegate(pmul(a, b)), c);
    }
    template <typename Packet>
    inline void pstore1(typename unpacket_traits<Packet>::type* to, const typename unpacket_traits<Packet>::type& a) {
      pstore(to, pset1<Packet>(a));
    }
    template <typename Packet, int Alignment>
    __attribute__((always_inline)) inline Packet ploadt(const typename unpacket_traits<Packet>::type* from) {
      if (Alignment >= unpacket_traits<Packet>::alignment)
        return pload<Packet>(from);
      else
        return ploadu<Packet>(from);
    }
    template <typename Packet, int Alignment>
    __attribute__((always_inline)) inline Packet ploadt_partial(const typename unpacket_traits<Packet>::type* from,
                                                                const Index n,
                                                                const Index offset = 0) {
      if (Alignment >= unpacket_traits<Packet>::alignment)
        return pload_partial<Packet>(from, n, offset);
      else
        return ploadu_partial<Packet>(from, n);
    }
    template <typename Scalar, typename Packet, int Alignment>
    __attribute__((always_inline)) inline void pstoret(Scalar* to, const Packet& from) {
      if (Alignment >= unpacket_traits<Packet>::alignment)
        pstore(to, from);
      else
        pstoreu(to, from);
    }
    template <typename Scalar, typename Packet, int Alignment>
    __attribute__((always_inline)) inline void pstoret_partial(Scalar* to,
                                                               const Packet& from,
                                                               const Index n,
                                                               const Index offset = 0) {
      if (Alignment >= unpacket_traits<Packet>::alignment)
        pstore_partial(to, from, n, offset);
      else
        pstoreu_partial(to, from, n);
    }
    template <typename Packet, int LoadMode>
    __attribute__((always_inline)) inline Packet ploadt_ro(const typename unpacket_traits<Packet>::type* from) {
      return ploadt<Packet, LoadMode>(from);
    }
    template <>
    inline std::complex<float> pmul(const std::complex<float>& a, const std::complex<float>& b) {
      return std::complex<float>(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());
    }
    template <>
    inline std::complex<double> pmul(const std::complex<double>& a, const std::complex<double>& b) {
      return std::complex<double>(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());
    }
    template <typename Packet, int N = unpacket_traits<Packet>::size>
    struct PacketBlock {
      Packet packet[N];
    };
    template <typename Packet>
    inline void ptranspose(PacketBlock<Packet, 1>&) {}
    template <size_t N>
    struct Selector {
      bool select[N];
    };
    template <typename Packet>
    inline Packet pblend(const Selector<unpacket_traits<Packet>::size>& ifPacket,
                         const Packet& thenPacket,
                         const Packet& elsePacket) {
      return ifPacket.select[0] ? thenPacket : elsePacket;
    }
    template <typename Packet>
    inline Packet preciprocal(const Packet& a) {
      using Scalar = typename unpacket_traits<Packet>::type;
      return pdiv(pset1<Packet>(Scalar(1)), a);
    }
    template <typename Packet>
    Packet prsqrt(const Packet& a) {
      return preciprocal<Packet>(psqrt(a));
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Packet, int Steps>
    struct generic_reciprocal_newton_step {
      static_assert(Steps > 0, "Steps must be at least 1.");
      static inline Packet run(const Packet& a, const Packet& approx_a_recip) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet two = pset1<Packet>(Scalar(2));
        const Packet x = generic_reciprocal_newton_step<Packet, Steps - 1>::run(a, approx_a_recip);
        const Packet tmp = pnmadd(a, x, two);
        const Packet is_not_nan = pcmp_eq(tmp, tmp);
        return pselect(is_not_nan, pmul(x, tmp), x);
      }
    };
    template <typename Packet>
    struct generic_reciprocal_newton_step<Packet, 0> {
      static inline Packet run(const Packet&, const Packet& approx_rsqrt) { return approx_rsqrt; }
    };
    template <typename Packet, int Steps>
    struct generic_rsqrt_newton_step {
      static_assert(Steps > 0, "Steps must be at least 1.");
      static inline Packet run(const Packet& a, const Packet& approx_rsqrt) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet one_point_five = pset1<Packet>(Scalar(1.5));
        const Packet minus_half = pset1<Packet>(Scalar(-0.5));
        Packet x_newton =
            pmul(approx_rsqrt, pmadd(pmul(minus_half, approx_rsqrt), pmul(a, approx_rsqrt), one_point_five));
        for (int step = 1; step < Steps; ++step) {
          x_newton = pmul(x_newton, pmadd(pmul(minus_half, x_newton), pmul(a, x_newton), one_point_five));
        }
        const Packet return_approx = por(pcmp_eq(approx_rsqrt, pzero(a)),
                                         pcmp_eq(pabs(approx_rsqrt), pset1<Packet>(NumTraits<Scalar>::infinity())));
        return pselect(return_approx, approx_rsqrt, x_newton);
      }
    };
    template <typename Packet>
    struct generic_rsqrt_newton_step<Packet, 0> {
      static inline Packet run(const Packet&, const Packet& approx_rsqrt) { return approx_rsqrt; }
    };
    template <typename Packet, int Steps = 1>
    struct generic_sqrt_newton_step {
      static_assert(Steps > 0, "Steps must be at least 1.");
      static inline Packet run(const Packet& a, const Packet& approx_rsqrt) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet one_point_five = pset1<Packet>(Scalar(1.5));
        const Packet minus_half = pset1<Packet>(Scalar(-0.5));
        const Packet inf_mask = pcmp_eq(a, pset1<Packet>(NumTraits<Scalar>::infinity()));
        const Packet return_a = por(pcmp_eq(a, pzero(a)), inf_mask);
        Packet rsqrt = pmul(approx_rsqrt, pmadd(pmul(minus_half, approx_rsqrt), pmul(a, approx_rsqrt), one_point_five));
        for (int step = 1; step < Steps; ++step) {
          rsqrt = pmul(rsqrt, pmadd(pmul(minus_half, rsqrt), pmul(a, rsqrt), one_point_five));
        }
        return pselect(return_a, a, pmul(a, rsqrt));
      }
    };
    template <typename T>
    T generic_fast_tanh_float(const T& a_x) {
      const T plus_clamp = pset1<T>(7.90531110763549805f);
      const T minus_clamp = pset1<T>(-7.90531110763549805f);
      const T tiny = pset1<T>(0.0004f);
      const T x = pmax(pmin(a_x, plus_clamp), minus_clamp);
      const T tiny_mask = pcmp_lt(pabs(a_x), tiny);
      const T alpha_1 = pset1<T>(4.89352455891786e-03f);
      const T alpha_3 = pset1<T>(6.37261928875436e-04f);
      const T alpha_5 = pset1<T>(1.48572235717979e-05f);
      const T alpha_7 = pset1<T>(5.12229709037114e-08f);
      const T alpha_9 = pset1<T>(-8.60467152213735e-11f);
      const T alpha_11 = pset1<T>(2.00018790482477e-13f);
      const T alpha_13 = pset1<T>(-2.76076847742355e-16f);
      const T beta_0 = pset1<T>(4.89352518554385e-03f);
      const T beta_2 = pset1<T>(2.26843463243900e-03f);
      const T beta_4 = pset1<T>(1.18534705686654e-04f);
      const T beta_6 = pset1<T>(1.19825839466702e-06f);
      const T x2 = pmul(x, x);
      T p = pmadd(x2, alpha_13, alpha_11);
      p = pmadd(x2, p, alpha_9);
      p = pmadd(x2, p, alpha_7);
      p = pmadd(x2, p, alpha_5);
      p = pmadd(x2, p, alpha_3);
      p = pmadd(x2, p, alpha_1);
      p = pmul(x, p);
      T q = pmadd(x2, beta_6, beta_4);
      q = pmadd(x2, q, beta_2);
      q = pmadd(x2, q, beta_0);
      return pselect(tiny_mask, x, pdiv(p, q));
    }
    template <typename RealScalar>
    inline RealScalar positive_real_hypot(const RealScalar& x, const RealScalar& y) {
      if ((numext::isinf)(x) || (numext::isinf)(y))
        return NumTraits<RealScalar>::infinity();
      if ((numext::isnan)(x) || (numext::isnan)(y))
        return NumTraits<RealScalar>::quiet_NaN();
      using std::sqrt;
      ;
      RealScalar p, qp;
      p = numext::maxi(x, y);
      if (numext::is_exactly_zero(p))
        return RealScalar(0);
      qp = numext::mini(y, x) / p;
      return p * sqrt(RealScalar(1) + qp * qp);
    }
    template <typename Scalar>
    struct hypot_impl {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline RealScalar run(const Scalar& x, const Scalar& y) {
        using std::abs;
        ;
        return positive_real_hypot<RealScalar>(abs(x), abs(y));
      }
    };
    template <typename T>
    std::complex<T> complex_sqrt(const std::complex<T>& z) {
      const T x = numext::real(z);
      const T y = numext::imag(z);
      const T zero = T(0);
      const T w = numext::sqrt(T(0.5) * (numext::abs(x) + numext::hypot(x, y)));
      return (numext::isinf)(y)           ? std::complex<T>(NumTraits<T>::infinity(), y)
             : numext::is_exactly_zero(x) ? std::complex<T>(w, y < zero ? -w : w)
             : x > zero                   ? std::complex<T>(w, y / (2 * w))
                                          : std::complex<T>(numext::abs(y) / (2 * w), y < zero ? -w : w);
    }
    template <typename T>
    std::complex<T> complex_rsqrt(const std::complex<T>& z) {
      const T x = numext::real(z);
      const T y = numext::imag(z);
      const T zero = T(0);
      const T abs_z = numext::hypot(x, y);
      const T w = numext::sqrt(T(0.5) * (numext::abs(x) + abs_z));
      const T woz = w / abs_z;
      return numext::is_exactly_zero(abs_z) ? std::complex<T>(NumTraits<T>::infinity(), NumTraits<T>::quiet_NaN())
             : ((numext::isinf)(x) || (numext::isinf)(y)) ? std::complex<T>(zero, zero)
             : numext::is_exactly_zero(x)                 ? std::complex<T>(woz, y < zero ? woz : -woz)
             : x > zero                                   ? std::complex<T>(woz, -y / (2 * w * abs_z))
                        : std::complex<T>(numext::abs(y) / (2 * w * abs_z), y < zero ? woz : -woz);
    }
    template <typename T>
    std::complex<T> complex_log(const std::complex<T>& z) {
      T a = numext::abs(z);
      using std::atan2;
      ;
      T b = atan2(z.imag(), z.real());
      return std::complex<T>(numext::log(a), b);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <bool Conjugate>
    struct conj_if;
    template <>
    struct conj_if<true> {
      template <typename T>
      inline T operator()(const T& x) const {
        return numext::conj(x);
      }
      template <typename T>
      inline T pconj(const T& x) const {
        return internal::pconj(x);
      }
    };
    template <>
    struct conj_if<false> {
      template <typename T>
      inline const T& operator()(const T& x) const {
        return x;
      }
      template <typename T>
      inline const T& pconj(const T& x) const {
        return x;
      }
    };
    template <typename LhsType, typename RhsType, bool ConjLhs, bool ConjRhs>
    struct conj_helper {
      typedef typename ScalarBinaryOpTraits<LhsType, RhsType>::ReturnType ResultType;
      inline ResultType pmadd(const LhsType& x, const RhsType& y, const ResultType& c) const {
        return this->pmul(x, y) + c;
      }
      inline ResultType pmul(const LhsType& x, const RhsType& y) const {
        return conj_if<ConjLhs>()(x) * conj_if<ConjRhs>()(y);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct conj_helper<LhsScalar, RhsScalar, true, true> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResultType;
      inline ResultType pmadd(const LhsScalar& x, const RhsScalar& y, const ResultType& c) const {
        return this->pmul(x, y) + c;
      }
      inline ResultType pmul(const LhsScalar& x, const RhsScalar& y) const { return numext::conj(x * y); }
    };
    template <typename Packet, bool ConjLhs, bool ConjRhs>
    struct conj_helper<Packet, Packet, ConjLhs, ConjRhs> {
      typedef Packet ResultType;
      inline Packet pmadd(const Packet& x, const Packet& y, const Packet& c) const {
        return Eigen::internal::pmadd(conj_if<ConjLhs>().pconj(x), conj_if<ConjRhs>().pconj(y), c);
      }
      inline Packet pmul(const Packet& x, const Packet& y) const {
        return Eigen::internal::pmul(conj_if<ConjLhs>().pconj(x), conj_if<ConjRhs>().pconj(y));
      }
    };
    template <typename Packet>
    struct conj_helper<Packet, Packet, true, true> {
      typedef Packet ResultType;
      inline Packet pmadd(const Packet& x, const Packet& y, const Packet& c) const {
        return Eigen::internal::pmadd(pconj(x), pconj(y), c);
      }
      inline Packet pmul(const Packet& x, const Packet& y) const { return pconj(Eigen::internal::pmul(x, y)); }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  struct half;
  namespace half_impl {
    struct __half_raw {
      constexpr __half_raw() : x(0) {}
      explicit constexpr __half_raw(numext::uint16_t raw) : x(raw) {}
      numext::uint16_t x;
    };
    inline constexpr __half_raw raw_uint16_to_half(numext::uint16_t x);
    inline __half_raw float_to_half_rtne(float ff);
    inline float half_to_float(__half_raw h);
    struct half_base : public __half_raw {
      constexpr half_base() {}
      constexpr half_base(const __half_raw& h) : __half_raw(h) {}
    };
  }  // namespace half_impl
  struct half : public half_impl::half_base {
    typedef half_impl::__half_raw __half_raw;
    constexpr half() {}
    constexpr half(const __half_raw& h) : half_impl::half_base(h) {}
    explicit constexpr half(bool b) : half_impl::half_base(half_impl::raw_uint16_to_half(b ? 0x3c00 : 0)) {}
    template <class T>
    explicit half(T val) : half_impl::half_base(half_impl::float_to_half_rtne(static_cast<float>(val))) {}
    explicit half(float f) : half_impl::half_base(half_impl::float_to_half_rtne(f)) {}
    template <typename RealScalar>
    explicit half(std::complex<RealScalar> c)
        : half_impl::half_base(half_impl::float_to_half_rtne(static_cast<float>(c.real()))) {}
    operator float() const { return half_impl::half_to_float(*this); }
  };
  namespace half_impl {
    template <typename = void>
    struct numeric_limits_half_impl {
      static constexpr const bool is_specialized = true;
      static constexpr const bool is_signed = true;
      static constexpr const bool is_integer = false;
      static constexpr const bool is_exact = false;
      static constexpr const bool has_infinity = true;
      static constexpr const bool has_quiet_NaN = true;
      static constexpr const bool has_signaling_NaN = true;
      static constexpr const std::float_denorm_style has_denorm = std::denorm_present;
      static constexpr const bool has_denorm_loss = false;
      static constexpr const std::float_round_style round_style = std::round_to_nearest;
      static constexpr const bool is_iec559 = true;
      static constexpr const bool is_bounded = true;
      static constexpr const bool is_modulo = false;
      static constexpr const int digits = 11;
      static constexpr const int digits10 = 3;
      static constexpr const int max_digits10 = 5;
      static constexpr const int radix = std::numeric_limits<float>::radix;
      static constexpr const int min_exponent = -13;
      static constexpr const int min_exponent10 = -4;
      static constexpr const int max_exponent = 16;
      static constexpr const int max_exponent10 = 4;
      static constexpr const bool traps = std::numeric_limits<float>::traps;
      static constexpr const bool tinyness_before = std::numeric_limits<float>::tinyness_before;
      static constexpr Eigen::half(min)() { return Eigen::half_impl::raw_uint16_to_half(0x0400); }
      static constexpr Eigen::half lowest() { return Eigen::half_impl::raw_uint16_to_half(0xfbff); }
      static constexpr Eigen::half(max)() { return Eigen::half_impl::raw_uint16_to_half(0x7bff); }
      static constexpr Eigen::half epsilon() { return Eigen::half_impl::raw_uint16_to_half(0x1400); }
      static constexpr Eigen::half round_error() { return Eigen::half_impl::raw_uint16_to_half(0x3800); }
      static constexpr Eigen::half infinity() { return Eigen::half_impl::raw_uint16_to_half(0x7c00); }
      static constexpr Eigen::half quiet_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7e00); }
      static constexpr Eigen::half signaling_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7d00); }
      static constexpr Eigen::half denorm_min() { return Eigen::half_impl::raw_uint16_to_half(0x0001); }
    };
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_specialized;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_signed;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_integer;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_exact;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::has_infinity;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::has_quiet_NaN;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::has_signaling_NaN;
    template <typename T>
    constexpr const std::float_denorm_style numeric_limits_half_impl<T>::has_denorm;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::has_denorm_loss;
    template <typename T>
    constexpr const std::float_round_style numeric_limits_half_impl<T>::round_style;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_iec559;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_bounded;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::is_modulo;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::digits;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::digits10;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::max_digits10;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::radix;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::min_exponent;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::min_exponent10;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::max_exponent;
    template <typename T>
    constexpr const int numeric_limits_half_impl<T>::max_exponent10;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::traps;
    template <typename T>
    constexpr const bool numeric_limits_half_impl<T>::tinyness_before;
  }  // namespace half_impl
}  // namespace Eigen
namespace std {
  template <>
  class numeric_limits<Eigen::half> : public Eigen::half_impl::numeric_limits_half_impl<> {};
  template <>
  class numeric_limits<const Eigen::half> : public numeric_limits<Eigen::half> {};
  template <>
  class numeric_limits<volatile Eigen::half> : public numeric_limits<Eigen::half> {};
  template <>
  class numeric_limits<const volatile Eigen::half> : public numeric_limits<Eigen::half> {};
}  // namespace std
namespace Eigen {
  namespace half_impl {
    inline half operator+(const half& a, const half& b) { return half(float(a) + float(b)); }
    inline half operator*(const half& a, const half& b) { return half(float(a) * float(b)); }
    inline half operator-(const half& a, const half& b) { return half(float(a) - float(b)); }
    inline half operator/(const half& a, const half& b) { return half(float(a) / float(b)); }
    inline half operator-(const half& a) {
      half result;
      result.x = a.x ^ 0x8000;
      return result;
    }
    inline half& operator+=(half& a, const half& b) {
      a = half(float(a) + float(b));
      return a;
    }
    inline half& operator*=(half& a, const half& b) {
      a = half(float(a) * float(b));
      return a;
    }
    inline half& operator-=(half& a, const half& b) {
      a = half(float(a) - float(b));
      return a;
    }
    inline half& operator/=(half& a, const half& b) {
      a = half(float(a) / float(b));
      return a;
    }
    inline bool operator==(const half& a, const half& b) { return numext::equal_strict(float(a), float(b)); }
    inline bool operator!=(const half& a, const half& b) { return numext::not_equal_strict(float(a), float(b)); }
    inline bool operator<(const half& a, const half& b) { return float(a) < float(b); }
    inline bool operator<=(const half& a, const half& b) { return float(a) <= float(b); }
    inline bool operator>(const half& a, const half& b) { return float(a) > float(b); }
    inline bool operator>=(const half& a, const half& b) { return float(a) >= float(b); }
    inline half operator/(const half& a, Index b) { return half(static_cast<float>(a) / static_cast<float>(b)); }
    inline half operator++(half& a) {
      a += half(1);
      return a;
    }
    inline half operator--(half& a) {
      a -= half(1);
      return a;
    }
    inline half operator++(half& a, int) {
      half original_value = a;
      ++a;
      return original_value;
    }
    inline half operator--(half& a, int) {
      half original_value = a;
      --a;
      return original_value;
    }
    inline constexpr __half_raw raw_uint16_to_half(numext::uint16_t x) { return __half_raw(x); }
    inline numext::uint16_t raw_half_as_uint16(const __half_raw& h) { return h.x; }
    union float32_bits {
      unsigned int u;
      float f;
    };
    inline __half_raw float_to_half_rtne(float ff) {
      float32_bits f;
      f.f = ff;
      const float32_bits f32infty = {255 << 23};
      const float32_bits f16max = {(127 + 16) << 23};
      const float32_bits denorm_magic = {((127 - 15) + (23 - 10) + 1) << 23};
      unsigned int sign_mask = 0x80000000u;
      __half_raw o;
      o.x = static_cast<numext::uint16_t>(0x0u);
      unsigned int sign = f.u & sign_mask;
      f.u ^= sign;
      if (f.u >= f16max.u) {
        o.x = (f.u > f32infty.u) ? 0x7e00 : 0x7c00;
      } else {
        if (f.u < (113 << 23)) {
          f.f += denorm_magic.f;
          o.x = static_cast<numext::uint16_t>(f.u - denorm_magic.u);
        } else {
          unsigned int mant_odd = (f.u >> 13) & 1;
          f.u += 0xc8000fffU;
          f.u += mant_odd;
          o.x = static_cast<numext::uint16_t>(f.u >> 13);
        }
      }
      o.x |= static_cast<numext::uint16_t>(sign >> 16);
      return o;
    }
    inline float half_to_float(__half_raw h) {
      const float32_bits magic = {113 << 23};
      const unsigned int shifted_exp = 0x7c00 << 13;
      float32_bits o;
      o.u = (h.x & 0x7fff) << 13;
      unsigned int exp = shifted_exp & o.u;
      o.u += (127 - 15) << 23;
      if (exp == shifted_exp) {
        o.u += (128 - 16) << 23;
      } else if (exp == 0) {
        o.u += 1 << 23;
        o.f -= magic.f;
      }
      o.u |= (h.x & 0x8000) << 16;
      return o.f;
    }
    inline bool(isinf)(const half& a) { return (a.x & 0x7fff) == 0x7c00; }
    inline bool(isnan)(const half& a) { return (a.x & 0x7fff) > 0x7c00; }
    inline bool(isfinite)(const half& a) { return !(isinf(a)) && !(isnan(a)); }
    inline half abs(const half& a) {
      half result;
      result.x = a.x & 0x7FFF;
      return result;
    }
    inline half exp(const half& a) { return half(::expf(float(a))); }
    inline half expm1(const half& a) { return half(numext::expm1(float(a))); }
    inline half log(const half& a) { return half(::logf(float(a))); }
    inline half log1p(const half& a) { return half(numext::log1p(float(a))); }
    inline half log10(const half& a) { return half(::log10f(float(a))); }
    inline half log2(const half& a) {
      return half(static_cast<float>(1.442695040888963407359924681001892137426645954152985934135449406931109219L) *
                  ::logf(float(a)));
    }
    inline half sqrt(const half& a) { return half(::sqrtf(float(a))); }
    inline half pow(const half& a, const half& b) { return half(::powf(float(a), float(b))); }
    inline half atan2(const half& a, const half& b) { return half(::atan2f(float(a), float(b))); }
    inline half sin(const half& a) { return half(::sinf(float(a))); }
    inline half cos(const half& a) { return half(::cosf(float(a))); }
    inline half tan(const half& a) { return half(::tanf(float(a))); }
    inline half tanh(const half& a) { return half(::tanhf(float(a))); }
    inline half asin(const half& a) { return half(::asinf(float(a))); }
    inline half acos(const half& a) { return half(::acosf(float(a))); }
    inline half floor(const half& a) { return half(::floorf(float(a))); }
    inline half ceil(const half& a) { return half(::ceilf(float(a))); }
    inline half rint(const half& a) { return half(::rintf(float(a))); }
    inline half round(const half& a) { return half(::roundf(float(a))); }
    inline half fmod(const half& a, const half& b) { return half(::fmodf(float(a), float(b))); }
    inline half(min)(const half& a, const half& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return f2 < f1 ? b : a;
    }
    inline half(max)(const half& a, const half& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return f1 < f2 ? b : a;
    }
    __attribute__((always_inline)) inline std::ostream& operator<<(std::ostream& os, const half& v) {
      os << static_cast<float>(v);
      return os;
    }
  }  // namespace half_impl
  namespace internal {
    template <>
    struct random_default_impl<half, false, false> {
      static inline half run(const half& x, const half& y) {
        return x + (y - x) * half(float(std::rand()) / float(2147483647));
      }
      static inline half run() { return run(half(-1.f), half(1.f)); }
    };
    template <>
    struct is_arithmetic<half> {
      enum { value = true };
    };
  }  // namespace internal
  template <>
  struct NumTraits<Eigen::half> : GenericNumTraits<Eigen::half> {
    enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };
    constexpr static inline Eigen::half epsilon() { return half_impl::raw_uint16_to_half(0x0800); }
    constexpr static inline Eigen::half dummy_precision() { return half_impl::raw_uint16_to_half(0x211f); }
    constexpr static inline Eigen::half highest() { return half_impl::raw_uint16_to_half(0x7bff); }
    constexpr static inline Eigen::half lowest() { return half_impl::raw_uint16_to_half(0xfbff); }
    constexpr static inline Eigen::half infinity() { return half_impl::raw_uint16_to_half(0x7c00); }
    constexpr static inline Eigen::half quiet_NaN() { return half_impl::raw_uint16_to_half(0x7e00); }
  };
}  // namespace Eigen
namespace Eigen {
  namespace numext {
    template <>
    inline Eigen::half bit_cast<Eigen::half, uint16_t>(const uint16_t& src) {
      return Eigen::half(Eigen::half_impl::raw_uint16_to_half(src));
    }
    template <>
    inline uint16_t bit_cast<uint16_t, Eigen::half>(const Eigen::half& src) {
      return Eigen::half_impl::raw_half_as_uint16(src);
    }
  }  // namespace numext
}  // namespace Eigen
namespace std {
  template <>
  struct hash<Eigen::half> {
    inline std::size_t operator()(const Eigen::half& a) const {
      return static_cast<std::size_t>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(a));
    }
  };
}  // namespace std
namespace Eigen {
  struct bfloat16;
  namespace numext {
    template <>
    inline Eigen::bfloat16 bit_cast<Eigen::bfloat16, uint16_t>(const uint16_t& src);
    template <>
    inline uint16_t bit_cast<uint16_t, Eigen::bfloat16>(const Eigen::bfloat16& src);
  }  // namespace numext
  namespace bfloat16_impl {
    struct __bfloat16_raw {
      constexpr __bfloat16_raw() : value(0) {}
      explicit constexpr __bfloat16_raw(unsigned short raw) : value(raw) {}
      unsigned short value;
    };
    inline constexpr __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value);
    template <bool AssumeArgumentIsNormalOrInfinityOrZero>
    inline __bfloat16_raw float_to_bfloat16_rtne(float ff);
    template <>
    inline __bfloat16_raw float_to_bfloat16_rtne<false>(float ff);
    template <>
    inline __bfloat16_raw float_to_bfloat16_rtne<true>(float ff);
    inline float bfloat16_to_float(__bfloat16_raw h);
    struct bfloat16_base : public __bfloat16_raw {
      constexpr bfloat16_base() {}
      constexpr bfloat16_base(const __bfloat16_raw& h) : __bfloat16_raw(h) {}
    };
  }  // namespace bfloat16_impl
  struct bfloat16 : public bfloat16_impl::bfloat16_base {
    typedef bfloat16_impl::__bfloat16_raw __bfloat16_raw;
    constexpr bfloat16() {}
    constexpr bfloat16(const __bfloat16_raw& h) : bfloat16_impl::bfloat16_base(h) {}
    explicit constexpr bfloat16(bool b)
        : bfloat16_impl::bfloat16_base(bfloat16_impl::raw_uint16_to_bfloat16(b ? 0x3f80 : 0)) {}
    template <class T>
    explicit constexpr bfloat16(T val)
        : bfloat16_impl::bfloat16_base(
              bfloat16_impl::float_to_bfloat16_rtne<internal::is_integral<T>::value>(static_cast<float>(val))) {}
    explicit bfloat16(float f) : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(f)) {}
    template <typename RealScalar>
    explicit constexpr bfloat16(const std::complex<RealScalar>& val)
        : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(static_cast<float>(val.real()))) {}
    operator float() const { return bfloat16_impl::bfloat16_to_float(*this); }
  };
  namespace bfloat16_impl {
    template <typename = void>
    struct numeric_limits_bfloat16_impl {
      static constexpr const bool is_specialized = true;
      static constexpr const bool is_signed = true;
      static constexpr const bool is_integer = false;
      static constexpr const bool is_exact = false;
      static constexpr const bool has_infinity = true;
      static constexpr const bool has_quiet_NaN = true;
      static constexpr const bool has_signaling_NaN = true;
      static constexpr const std::float_denorm_style has_denorm = std::denorm_present;
      static constexpr const bool has_denorm_loss = false;
      static constexpr const std::float_round_style round_style = std::numeric_limits<float>::round_style;
      static constexpr const bool is_iec559 = true;
      static constexpr const bool is_bounded = true;
      static constexpr const bool is_modulo = false;
      static constexpr const int digits = 8;
      static constexpr const int digits10 = 2;
      static constexpr const int max_digits10 = 4;
      static constexpr const int radix = std::numeric_limits<float>::radix;
      static constexpr const int min_exponent = std::numeric_limits<float>::min_exponent;
      static constexpr const int min_exponent10 = std::numeric_limits<float>::min_exponent10;
      static constexpr const int max_exponent = std::numeric_limits<float>::max_exponent;
      static constexpr const int max_exponent10 = std::numeric_limits<float>::max_exponent10;
      static constexpr const bool traps = std::numeric_limits<float>::traps;
      static constexpr const bool tinyness_before = std::numeric_limits<float>::tinyness_before;
      static constexpr Eigen::bfloat16(min)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0080); }
      static constexpr Eigen::bfloat16 lowest() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0xff7f); }
      static constexpr Eigen::bfloat16(max)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f7f); }
      static constexpr Eigen::bfloat16 epsilon() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3c00); }
      static constexpr Eigen::bfloat16 round_error() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3f00); }
      static constexpr Eigen::bfloat16 infinity() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f80); }
      static constexpr Eigen::bfloat16 quiet_NaN() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0); }
      static constexpr Eigen::bfloat16 signaling_NaN() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fa0); }
      static constexpr Eigen::bfloat16 denorm_min() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0001); }
    };
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_specialized;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_signed;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_integer;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_exact;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::has_infinity;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::has_quiet_NaN;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::has_signaling_NaN;
    template <typename T>
    constexpr const std::float_denorm_style numeric_limits_bfloat16_impl<T>::has_denorm;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::has_denorm_loss;
    template <typename T>
    constexpr const std::float_round_style numeric_limits_bfloat16_impl<T>::round_style;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_iec559;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_bounded;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::is_modulo;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::digits;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::digits10;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::max_digits10;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::radix;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::min_exponent;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::min_exponent10;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::max_exponent;
    template <typename T>
    constexpr const int numeric_limits_bfloat16_impl<T>::max_exponent10;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::traps;
    template <typename T>
    constexpr const bool numeric_limits_bfloat16_impl<T>::tinyness_before;
  }  // namespace bfloat16_impl
}  // namespace Eigen
namespace std {
  template <>
  class numeric_limits<Eigen::bfloat16> : public Eigen::bfloat16_impl::numeric_limits_bfloat16_impl<> {};
  template <>
  class numeric_limits<const Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
  template <>
  class numeric_limits<volatile Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
  template <>
  class numeric_limits<const volatile Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
}  // namespace std
namespace Eigen {
  namespace bfloat16_impl {
    inline bfloat16 operator+(const bfloat16& a, const bfloat16& b) { return bfloat16(float(a) + float(b)); }
    inline bfloat16 operator+(const bfloat16& a, const int& b) { return bfloat16(float(a) + static_cast<float>(b)); }
    inline bfloat16 operator+(const int& a, const bfloat16& b) { return bfloat16(static_cast<float>(a) + float(b)); }
    inline bfloat16 operator*(const bfloat16& a, const bfloat16& b) { return bfloat16(float(a) * float(b)); }
    inline bfloat16 operator-(const bfloat16& a, const bfloat16& b) { return bfloat16(float(a) - float(b)); }
    inline bfloat16 operator/(const bfloat16& a, const bfloat16& b) { return bfloat16(float(a) / float(b)); }
    inline bfloat16 operator-(const bfloat16& a) {
      numext::uint16_t x = numext::bit_cast<uint16_t>(a) ^ 0x8000;
      return numext::bit_cast<bfloat16>(x);
    }
    inline bfloat16& operator+=(bfloat16& a, const bfloat16& b) {
      a = bfloat16(float(a) + float(b));
      return a;
    }
    inline bfloat16& operator*=(bfloat16& a, const bfloat16& b) {
      a = bfloat16(float(a) * float(b));
      return a;
    }
    inline bfloat16& operator-=(bfloat16& a, const bfloat16& b) {
      a = bfloat16(float(a) - float(b));
      return a;
    }
    inline bfloat16& operator/=(bfloat16& a, const bfloat16& b) {
      a = bfloat16(float(a) / float(b));
      return a;
    }
    inline bfloat16 operator++(bfloat16& a) {
      a += bfloat16(1);
      return a;
    }
    inline bfloat16 operator--(bfloat16& a) {
      a -= bfloat16(1);
      return a;
    }
    inline bfloat16 operator++(bfloat16& a, int) {
      bfloat16 original_value = a;
      ++a;
      return original_value;
    }
    inline bfloat16 operator--(bfloat16& a, int) {
      bfloat16 original_value = a;
      --a;
      return original_value;
    }
    inline bool operator==(const bfloat16& a, const bfloat16& b) { return numext::equal_strict(float(a), float(b)); }
    inline bool operator!=(const bfloat16& a, const bfloat16& b) {
      return numext::not_equal_strict(float(a), float(b));
    }
    inline bool operator<(const bfloat16& a, const bfloat16& b) { return float(a) < float(b); }
    inline bool operator<=(const bfloat16& a, const bfloat16& b) { return float(a) <= float(b); }
    inline bool operator>(const bfloat16& a, const bfloat16& b) { return float(a) > float(b); }
    inline bool operator>=(const bfloat16& a, const bfloat16& b) { return float(a) >= float(b); }
    inline bfloat16 operator/(const bfloat16& a, Index b) {
      return bfloat16(static_cast<float>(a) / static_cast<float>(b));
    }
    inline __bfloat16_raw truncate_to_bfloat16(const float v) {
      __bfloat16_raw output;
      if (numext::isnan(v)) {
        output.value = std::signbit(v) ? 0xFFC0 : 0x7FC0;
        return output;
      }
      output.value = static_cast<numext::uint16_t>(numext::bit_cast<numext::uint32_t>(v) >> 16);
      return output;
    }
    inline constexpr __bfloat16_raw raw_uint16_to_bfloat16(numext::uint16_t value) { return __bfloat16_raw(value); }
    inline constexpr numext::uint16_t raw_bfloat16_as_uint16(const __bfloat16_raw& bf) { return bf.value; }
    template <>
    inline __bfloat16_raw float_to_bfloat16_rtne<false>(float ff) {
      __bfloat16_raw output;
      if (numext::isnan(ff)) {
        output.value = std::signbit(ff) ? 0xFFC0 : 0x7FC0;
      } else {
        output = float_to_bfloat16_rtne<true>(ff);
      }
      return output;
    }
    template <>
    inline __bfloat16_raw float_to_bfloat16_rtne<true>(float ff) {
      numext::uint32_t input = numext::bit_cast<numext::uint32_t>(ff);
      __bfloat16_raw output;
      numext::uint32_t lsb = (input >> 16) & 1;
      numext::uint32_t rounding_bias = 0x7fff + lsb;
      input += rounding_bias;
      output.value = static_cast<numext::uint16_t>(input >> 16);
      return output;
    }
    inline float bfloat16_to_float(__bfloat16_raw h) {
      return numext::bit_cast<float>(static_cast<numext::uint32_t>(h.value) << 16);
    }
    inline bool(isinf)(const bfloat16& a) {
      using std::isinf;
      ;
      return (isinf)(float(a));
    }
    inline bool(isnan)(const bfloat16& a) {
      using std::isnan;
      ;
      return (isnan)(float(a));
    }
    inline bool(isfinite)(const bfloat16& a) { return !(isinf(a)) && !(isnan(a)); }
    inline bfloat16 abs(const bfloat16& a) {
      numext::uint16_t x = numext::bit_cast<numext::uint16_t>(a) & 0x7FFF;
      return numext::bit_cast<bfloat16>(x);
    }
    inline bfloat16 exp(const bfloat16& a) { return bfloat16(::expf(float(a))); }
    inline bfloat16 expm1(const bfloat16& a) { return bfloat16(numext::expm1(float(a))); }
    inline bfloat16 log(const bfloat16& a) { return bfloat16(::logf(float(a))); }
    inline bfloat16 log1p(const bfloat16& a) { return bfloat16(numext::log1p(float(a))); }
    inline bfloat16 log10(const bfloat16& a) { return bfloat16(::log10f(float(a))); }
    inline bfloat16 log2(const bfloat16& a) {
      return bfloat16(static_cast<float>(1.442695040888963407359924681001892137426645954152985934135449406931109219L) *
                      ::logf(float(a)));
    }
    inline bfloat16 sqrt(const bfloat16& a) { return bfloat16(::sqrtf(float(a))); }
    inline bfloat16 pow(const bfloat16& a, const bfloat16& b) { return bfloat16(::powf(float(a), float(b))); }
    inline bfloat16 atan2(const bfloat16& a, const bfloat16& b) { return bfloat16(::atan2f(float(a), float(b))); }
    inline bfloat16 sin(const bfloat16& a) { return bfloat16(::sinf(float(a))); }
    inline bfloat16 cos(const bfloat16& a) { return bfloat16(::cosf(float(a))); }
    inline bfloat16 tan(const bfloat16& a) { return bfloat16(::tanf(float(a))); }
    inline bfloat16 asin(const bfloat16& a) { return bfloat16(::asinf(float(a))); }
    inline bfloat16 acos(const bfloat16& a) { return bfloat16(::acosf(float(a))); }
    inline bfloat16 atan(const bfloat16& a) { return bfloat16(::atanf(float(a))); }
    inline bfloat16 sinh(const bfloat16& a) { return bfloat16(::sinhf(float(a))); }
    inline bfloat16 cosh(const bfloat16& a) { return bfloat16(::coshf(float(a))); }
    inline bfloat16 tanh(const bfloat16& a) { return bfloat16(::tanhf(float(a))); }
    inline bfloat16 asinh(const bfloat16& a) { return bfloat16(::asinhf(float(a))); }
    inline bfloat16 acosh(const bfloat16& a) { return bfloat16(::acoshf(float(a))); }
    inline bfloat16 atanh(const bfloat16& a) { return bfloat16(::atanhf(float(a))); }
    inline bfloat16 floor(const bfloat16& a) { return bfloat16(::floorf(float(a))); }
    inline bfloat16 ceil(const bfloat16& a) { return bfloat16(::ceilf(float(a))); }
    inline bfloat16 rint(const bfloat16& a) { return bfloat16(::rintf(float(a))); }
    inline bfloat16 round(const bfloat16& a) { return bfloat16(::roundf(float(a))); }
    inline bfloat16 fmod(const bfloat16& a, const bfloat16& b) { return bfloat16(::fmodf(float(a), float(b))); }
    inline bfloat16(min)(const bfloat16& a, const bfloat16& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return f2 < f1 ? b : a;
    }
    inline bfloat16(max)(const bfloat16& a, const bfloat16& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return f1 < f2 ? b : a;
    }
    inline bfloat16 fmin(const bfloat16& a, const bfloat16& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return bfloat16(::fminf(f1, f2));
    }
    inline bfloat16 fmax(const bfloat16& a, const bfloat16& b) {
      const float f1 = static_cast<float>(a);
      const float f2 = static_cast<float>(b);
      return bfloat16(::fmaxf(f1, f2));
    }
    __attribute__((always_inline)) inline std::ostream& operator<<(std::ostream& os, const bfloat16& v) {
      os << static_cast<float>(v);
      return os;
    }
  }  // namespace bfloat16_impl
  namespace internal {
    template <>
    struct random_default_impl<bfloat16, false, false> {
      static inline bfloat16 run(const bfloat16& x, const bfloat16& y) {
        return x + (y - x) * bfloat16(float(std::rand()) / float(2147483647));
      }
      static inline bfloat16 run() { return run(bfloat16(-1.f), bfloat16(1.f)); }
    };
    template <>
    struct is_arithmetic<bfloat16> {
      enum { value = true };
    };
  }  // namespace internal
  template <>
  struct NumTraits<Eigen::bfloat16> : GenericNumTraits<Eigen::bfloat16> {
    enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };
    constexpr static inline Eigen::bfloat16 epsilon() { return bfloat16_impl::raw_uint16_to_bfloat16(0x3c00); }
    constexpr static inline Eigen::bfloat16 dummy_precision() { return bfloat16_impl::raw_uint16_to_bfloat16(0x3D4D); }
    constexpr static inline Eigen::bfloat16 highest() { return bfloat16_impl::raw_uint16_to_bfloat16(0x7F7F); }
    constexpr static inline Eigen::bfloat16 lowest() { return bfloat16_impl::raw_uint16_to_bfloat16(0xFF7F); }
    constexpr static inline Eigen::bfloat16 infinity() { return bfloat16_impl::raw_uint16_to_bfloat16(0x7f80); }
    constexpr static inline Eigen::bfloat16 quiet_NaN() { return bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0); }
  };
}  // namespace Eigen
namespace Eigen {
  namespace numext {
    template <>
    __attribute__((always_inline)) inline bool(isnan)(const Eigen::bfloat16& h) {
      return (bfloat16_impl::isnan)(h);
    }
    template <>
    __attribute__((always_inline)) inline bool(isinf)(const Eigen::bfloat16& h) {
      return (bfloat16_impl::isinf)(h);
    }
    template <>
    __attribute__((always_inline)) inline bool(isfinite)(const Eigen::bfloat16& h) {
      return (bfloat16_impl::isfinite)(h);
    }
    template <>
    inline Eigen::bfloat16 bit_cast<Eigen::bfloat16, uint16_t>(const uint16_t& src) {
      return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(src);
    }
    template <>
    inline uint16_t bit_cast<uint16_t, Eigen::bfloat16>(const Eigen::bfloat16& src) {
      return Eigen::bfloat16_impl::raw_bfloat16_as_uint16(src);
    }
  }  // namespace numext
}  // namespace Eigen
namespace std {
  template <>
  struct hash<Eigen::bfloat16> {
    inline std::size_t operator()(const Eigen::bfloat16& a) const {
      return static_cast<std::size_t>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(a));
    }
  };
}  // namespace std

namespace Eigen {
  namespace internal {
    template <>
    struct scalar_cast_op<float, Eigen::half> {
      typedef Eigen::half result_type;
      inline Eigen::half operator()(const float& a) const { return Eigen::half(a); }
    };
    template <>
    struct functor_traits<scalar_cast_op<float, Eigen::half>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
    template <>
    struct scalar_cast_op<int, Eigen::half> {
      typedef Eigen::half result_type;
      inline Eigen::half operator()(const int& a) const { return Eigen::half(static_cast<float>(a)); }
    };
    template <>
    struct functor_traits<scalar_cast_op<int, Eigen::half>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
    template <>
    struct scalar_cast_op<Eigen::half, float> {
      typedef float result_type;
      inline float operator()(const Eigen::half& a) const { return static_cast<float>(a); }
    };
    template <>
    struct functor_traits<scalar_cast_op<Eigen::half, float>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
    template <>
    struct scalar_cast_op<float, Eigen::bfloat16> {
      typedef Eigen::bfloat16 result_type;
      inline Eigen::bfloat16 operator()(const float& a) const { return Eigen::bfloat16(a); }
    };
    template <>
    struct functor_traits<scalar_cast_op<float, Eigen::bfloat16>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
    template <>
    struct scalar_cast_op<int, Eigen::bfloat16> {
      typedef Eigen::bfloat16 result_type;
      inline Eigen::bfloat16 operator()(const int& a) const { return Eigen::bfloat16(static_cast<float>(a)); }
    };
    template <>
    struct functor_traits<scalar_cast_op<int, Eigen::bfloat16>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
    template <>
    struct scalar_cast_op<Eigen::bfloat16, float> {
      typedef float result_type;
      inline float operator()(const Eigen::bfloat16& a) const { return static_cast<float>(a); }
    };
    template <>
    struct functor_traits<scalar_cast_op<Eigen::bfloat16, float>> {
      enum { Cost = NumTraits<float>::AddCost, PacketAccess = false };
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Packet>
    inline Packet pfrexp_generic(const Packet& a, Packet& exponent);
    template <typename Packet>
    inline Packet pfrexp_generic_get_biased_exponent(const Packet& p);
    template <typename Packet>
    inline Packet pldexp_generic(const Packet& a, const Packet& exponent);
    template <typename Packet>
    inline Packet plog_float(const Packet _x);
    template <typename Packet>
    inline Packet plog2_float(const Packet _x);
    template <typename Packet>
    inline Packet plog_double(const Packet _x);
    template <typename Packet>
    inline Packet plog2_double(const Packet _x);
    template <typename Packet>
    Packet generic_plog1p(const Packet& x);
    template <typename Packet>
    Packet generic_expm1(const Packet& x);
    template <typename Packet>
    inline Packet pexp_float(const Packet _x);
    template <typename Packet>
    inline Packet pexp_double(const Packet _x);
    template <typename Packet>
    inline Packet psin_float(const Packet& x);
    template <typename Packet>
    inline Packet pcos_float(const Packet& x);
    template <typename Packet>
    inline Packet pasin_float(const Packet& x);
    template <typename Packet>
    inline Packet pacos_float(const Packet& x);
    template <typename Packet>
    inline Packet patan_float(const Packet& x);
    template <typename Packet>
    inline Packet patan_double(const Packet& x);
    template <typename Packet>
    inline Packet psqrt_complex(const Packet& a);
    template <typename Packet>
    inline Packet pdiv_complex(const Packet& x, const Packet& y);
    template <typename Packet, int N>
    struct ppolevl;
  }  // namespace internal
}  // namespace Eigen
#include <csignal> /* clang -E -fkeep-system-includes */

namespace Eigen {
  namespace internal {
    typedef __m128 Packet4f;
    typedef __m128d Packet2d;
    typedef eigen_packet_wrapper<__m128i, 0> Packet4i;
    typedef eigen_packet_wrapper<__m128i, 1> Packet16b;
    template <>
    struct is_arithmetic<__m128> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<__m128i> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<__m128d> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<Packet4i> {
      enum { value = true };
    };
    template <>
    struct is_arithmetic<Packet16b> {
      enum { value = true };
    };
    template <int p, int q, int r, int s>
    struct shuffle_mask {
      enum { mask = (s) << 6 | (r) << 4 | (q) << 2 | (p) };
    };
    inline Packet4f vec4f_movelh(const Packet4f& a, const Packet4f& b) { return Packet4f(_mm_movelh_ps(a, b)); }
    inline Packet4f vec4f_movehl(const Packet4f& a, const Packet4f& b) { return Packet4f(_mm_movehl_ps(a, b)); }
    inline Packet4f vec4f_unpacklo(const Packet4f& a, const Packet4f& b) { return Packet4f(_mm_unpacklo_ps(a, b)); }
    inline Packet4f vec4f_unpackhi(const Packet4f& a, const Packet4f& b) { return Packet4f(_mm_unpackhi_ps(a, b)); }
    inline Packet2d vec2d_unpacklo(const Packet2d& a, const Packet2d& b) { return Packet2d(_mm_unpacklo_pd(a, b)); }
    inline Packet2d vec2d_unpackhi(const Packet2d& a, const Packet2d& b) { return Packet2d(_mm_unpackhi_pd(a, b)); }
    template <>
    struct packet_traits<float> : default_packet_traits {
      typedef Packet4f type;
      typedef Packet4f half;
      enum {
        Vectorizable = 1,
        AlignedOnScalar = 1,
        size = 4,
        HasHalfPacket = 0,
        HasCmp = 1,
        HasDiv = 1,
        HasReciprocal = 1,
        HasSin = 1,
        HasCos = 1,
        HasACos = 1,
        HasASin = 1,
        HasATan = 1,
        HasLog = 1,
        HasLog1p = 1,
        HasExpm1 = 1,
        HasNdtri = 1,
        HasExp = 1,
        HasBessel = 1,
        HasSqrt = 1,
        HasRsqrt = 1,
        HasTanh = 1,
        HasErf = 1,
        HasBlend = 1,
        HasCeil = 1,
        HasFloor = 1,
        HasRound = 1,
        HasRint = 1,
        HasSign = 0
      };
    };
    template <>
    struct packet_traits<double> : default_packet_traits {
      typedef Packet2d type;
      typedef Packet2d half;
      enum {
        Vectorizable = 1,
        AlignedOnScalar = 1,
        size = 2,
        HasHalfPacket = 0,
        HasCmp = 1,
        HasDiv = 1,
        HasLog = 1,
        HasExp = 1,
        HasSqrt = 1,
        HasRsqrt = 1,
        HasATan = 1,
        HasBlend = 1,
        HasFloor = 1,
        HasCeil = 1,
        HasRound = 1,
        HasRint = 1
      };
    };
    template <>
    struct packet_traits<int> : default_packet_traits {
      typedef Packet4i type;
      typedef Packet4i half;
      enum { Vectorizable = 1, AlignedOnScalar = 1, HasCmp = 1, HasDiv = 1, size = 4, HasShift = 1, HasBlend = 1 };
    };
    template <>
    struct packet_traits<bool> : default_packet_traits {
      typedef Packet16b type;
      typedef Packet16b half;
      enum {
        Vectorizable = 1,
        AlignedOnScalar = 1,
        HasHalfPacket = 0,
        size = 16,
        HasAdd = 1,
        HasSub = 1,
        HasShift = 0,
        HasMul = 1,
        HasNegate = 1,
        HasAbs = 0,
        HasAbs2 = 0,
        HasMin = 0,
        HasMax = 0,
        HasConj = 0,
        HasSqrt = 1,
        HasSign = 0
      };
    };
    template <>
    struct unpacket_traits<Packet4f> {
      typedef float type;
      typedef Packet4f half;
      typedef Packet4i integer_packet;
      enum {
        size = 4,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    struct unpacket_traits<Packet2d> {
      typedef double type;
      typedef Packet2d half;
      enum {
        size = 2,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    struct unpacket_traits<Packet4i> {
      typedef int type;
      typedef Packet4i half;
      enum {
        size = 4,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    struct unpacket_traits<Packet16b> {
      typedef bool type;
      typedef Packet16b half;
      enum {
        size = 16,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    struct scalar_div_cost<float, true> {
      enum { value = 7 };
    };
    template <>
    struct scalar_div_cost<double, true> {
      enum { value = 8 };
    };
    template <>
    inline Packet4f pset1<Packet4f>(const float& from) {
      return _mm_set_ps1(from);
    }
    template <>
    inline Packet2d pset1<Packet2d>(const double& from) {
      return _mm_set1_pd(from);
    }
    template <>
    inline Packet4i pset1<Packet4i>(const int& from) {
      return _mm_set1_epi32(from);
    }
    template <>
    inline Packet16b pset1<Packet16b>(const bool& from) {
      return _mm_set1_epi8(static_cast<char>(from));
    }
    template <>
    inline Packet4f pset1frombits<Packet4f>(unsigned int from) {
      return _mm_castsi128_ps(pset1<Packet4i>(from));
    }
    template <>
    inline Packet2d pset1frombits<Packet2d>(uint64_t from) {
      return _mm_castsi128_pd(_mm_set1_epi64x(from));
    }
    template <>
    inline Packet4f peven_mask(const Packet4f&) {
      return _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1));
    }
    template <>
    inline Packet4i peven_mask(const Packet4i&) {
      return _mm_set_epi32(0, -1, 0, -1);
    }
    template <>
    inline Packet2d peven_mask(const Packet2d&) {
      return _mm_castsi128_pd(_mm_set_epi32(0, 0, -1, -1));
    }
    template <>
    inline Packet4f pzero(const Packet4f&) {
      return _mm_setzero_ps();
    }
    template <>
    inline Packet2d pzero(const Packet2d&) {
      return _mm_setzero_pd();
    }
    template <>
    inline Packet4i pzero(const Packet4i&) {
      return _mm_setzero_si128();
    }
    template <>
    inline Packet4f plset<Packet4f>(const float& a) {
      return _mm_add_ps(pset1<Packet4f>(a), _mm_set_ps(3, 2, 1, 0));
    }
    template <>
    inline Packet2d plset<Packet2d>(const double& a) {
      return _mm_add_pd(pset1<Packet2d>(a), _mm_set_pd(1, 0));
    }
    template <>
    inline Packet4i plset<Packet4i>(const int& a) {
      return _mm_add_epi32(pset1<Packet4i>(a), _mm_set_epi32(3, 2, 1, 0));
    }
    template <>
    inline Packet4f padd<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_add_ps(a, b);
    }
    template <>
    inline Packet2d padd<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_add_pd(a, b);
    }
    template <>
    inline Packet4i padd<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_add_epi32(a, b);
    }
    template <>
    inline Packet16b padd<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_or_si128(a, b);
    }
    template <typename Packet>
    inline Packet padds(const Packet& a, const Packet& b);
    template <>
    inline Packet4f padds<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_add_ss(a, b);
    }
    template <>
    inline Packet2d padds<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_add_sd(a, b);
    }
    template <>
    inline Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_sub_ps(a, b);
    }
    template <>
    inline Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_sub_pd(a, b);
    }
    template <>
    inline Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_sub_epi32(a, b);
    }
    template <>
    inline Packet16b psub<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_xor_si128(a, b);
    }
    template <>
    inline Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b);
    template <>
    inline Packet4f paddsub<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_addsub_ps(a, b);
    }
    template <>
    inline Packet2d pxor<Packet2d>(const Packet2d&, const Packet2d&);
    template <>
    inline Packet2d paddsub<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_addsub_pd(a, b);
    }
    template <>
    inline Packet4f pnegate(const Packet4f& a) {
      const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x80000000, 0x80000000, 0x80000000));
      return _mm_xor_ps(a, mask);
    }
    template <>
    inline Packet2d pnegate(const Packet2d& a) {
      const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0, 0x80000000, 0x0, 0x80000000));
      return _mm_xor_pd(a, mask);
    }
    template <>
    inline Packet4i pnegate(const Packet4i& a) {
      return psub(Packet4i(_mm_setr_epi32(0, 0, 0, 0)), a);
    }
    template <>
    inline Packet16b pnegate(const Packet16b& a) {
      return psub(pset1<Packet16b>(false), a);
    }
    template <>
    inline Packet4f pconj(const Packet4f& a) {
      return a;
    }
    template <>
    inline Packet2d pconj(const Packet2d& a) {
      return a;
    }
    template <>
    inline Packet4i pconj(const Packet4i& a) {
      return a;
    }
    template <>
    inline Packet4f pmul<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_mul_ps(a, b);
    }
    template <>
    inline Packet2d pmul<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_mul_pd(a, b);
    }
    template <>
    inline Packet4i pmul<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_mullo_epi32(a, b);
    }
    template <>
    inline Packet16b pmul<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_and_si128(a, b);
    }
    template <>
    inline Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_div_ps(a, b);
    }
    template <>
    inline Packet2d pdiv<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_div_pd(a, b);
    }
    template <>
    inline Packet4i pdiv<Packet4i>(const Packet4i& a, const Packet4i& b) {
      __m128i q_lo = _mm_cvttpd_epi32(_mm_div_pd(_mm_cvtepi32_pd(a), _mm_cvtepi32_pd(b)));
      __m128i q_hi = _mm_cvttpd_epi32(_mm_div_pd(
          _mm_cvtepi32_pd(Packet4i(
              ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(a), (int)((shuffle_mask<2, 3, 0, 1>::mask)))))),
          _mm_cvtepi32_pd(Packet4i(
              ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(b), (int)((shuffle_mask<2, 3, 0, 1>::mask))))))));
      return Packet4i(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_unpacklo_epi32(q_lo, q_hi)),
                                                      (int)((shuffle_mask<0, 2, 1, 3>::mask)))));
    }
    template <>
    inline Packet4i pmadd(const Packet4i& a, const Packet4i& b, const Packet4i& c) {
      return padd(pmul(a, b), c);
    }
    template <>
    inline Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b) {
      return _mm_blendv_ps(b, a, mask);
    }
    template <>
    inline Packet4i pselect(const Packet4i& mask, const Packet4i& a, const Packet4i& b) {
      return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b), _mm_castsi128_ps(a), _mm_castsi128_ps(mask)));
    }
    template <>
    inline Packet2d pselect(const Packet2d& mask, const Packet2d& a, const Packet2d& b) {
      return _mm_blendv_pd(b, a, mask);
    }
    template <>
    inline Packet16b pselect(const Packet16b& mask, const Packet16b& a, const Packet16b& b) {
      return _mm_blendv_epi8(b, a, mask);
    }
    template <>
    inline Packet4i ptrue<Packet4i>(const Packet4i& a) {
      return _mm_cmpeq_epi32(a, a);
    }
    template <>
    inline Packet16b ptrue<Packet16b>(const Packet16b& a) {
      return _mm_cmpeq_epi8(a, a);
    }
    template <>
    inline Packet4f ptrue<Packet4f>(const Packet4f& a) {
      Packet4i b = _mm_castps_si128(a);
      return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
    }
    template <>
    inline Packet2d ptrue<Packet2d>(const Packet2d& a) {
      Packet4i b = _mm_castpd_si128(a);
      return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
    }
    template <>
    inline Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_and_ps(a, b);
    }
    template <>
    inline Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_and_pd(a, b);
    }
    template <>
    inline Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_and_si128(a, b);
    }
    template <>
    inline Packet16b pand<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_and_si128(a, b);
    }
    template <>
    inline Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_or_ps(a, b);
    }
    template <>
    inline Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_or_pd(a, b);
    }
    template <>
    inline Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_or_si128(a, b);
    }
    template <>
    inline Packet16b por<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_or_si128(a, b);
    }
    template <>
    inline Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_xor_ps(a, b);
    }
    template <>
    inline Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_xor_pd(a, b);
    }
    template <>
    inline Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_xor_si128(a, b);
    }
    template <>
    inline Packet16b pxor<Packet16b>(const Packet16b& a, const Packet16b& b) {
      return _mm_xor_si128(a, b);
    }
    template <>
    inline Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_andnot_ps(b, a);
    }
    template <>
    inline Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_andnot_pd(b, a);
    }
    template <>
    inline Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_andnot_si128(b, a);
    }
    template <>
    inline Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) {
      return _mm_cmple_ps(a, b);
    }
    template <>
    inline Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) {
      return _mm_cmplt_ps(a, b);
    }
    template <>
    inline Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) {
      return _mm_cmpnge_ps(a, b);
    }
    template <>
    inline Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) {
      return _mm_cmpeq_ps(a, b);
    }
    template <>
    inline Packet2d pcmp_le(const Packet2d& a, const Packet2d& b) {
      return _mm_cmple_pd(a, b);
    }
    template <>
    inline Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b) {
      return _mm_cmplt_pd(a, b);
    }
    template <>
    inline Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b) {
      return _mm_cmpnge_pd(a, b);
    }
    template <>
    inline Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) {
      return _mm_cmpeq_pd(a, b);
    }
    template <>
    inline Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) {
      return _mm_cmplt_epi32(a, b);
    }
    template <>
    inline Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) {
      return _mm_cmpeq_epi32(a, b);
    }
    template <>
    inline Packet16b pcmp_eq(const Packet16b& a, const Packet16b& b) {
      return _mm_cmpeq_epi8(a, b);
    }
    template <>
    inline Packet4i pcmp_le(const Packet4i& a, const Packet4i& b) {
      return por(pcmp_lt(a, b), pcmp_eq(a, b));
    }
    template <>
    inline Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_min_ps(b, a);
    }
    template <>
    inline Packet2d pmin<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_min_pd(b, a);
    }
    template <>
    inline Packet4i pmin<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_min_epi32(a, b);
    }
    template <>
    inline Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b) {
      return _mm_max_ps(b, a);
    }
    template <>
    inline Packet2d pmax<Packet2d>(const Packet2d& a, const Packet2d& b) {
      return _mm_max_pd(b, a);
    }
    template <>
    inline Packet4i pmax<Packet4i>(const Packet4i& a, const Packet4i& b) {
      return _mm_max_epi32(a, b);
    }
    template <typename Packet, typename Op>
    inline Packet pminmax_propagate_numbers(const Packet& a, const Packet& b, Op op) {
      Packet not_nan_mask_a = pcmp_eq(a, a);
      Packet m = op(a, b);
      return pselect<Packet>(not_nan_mask_a, m, b);
    }
    template <typename Packet, typename Op>
    inline Packet pminmax_propagate_nan(const Packet& a, const Packet& b, Op op) {
      Packet not_nan_mask_a = pcmp_eq(a, a);
      Packet m = op(b, a);
      return pselect<Packet>(not_nan_mask_a, m, a);
    }
    template <>
    inline Packet4f pmin<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
      return pminmax_propagate_numbers(a, b, pmin<Packet4f>);
    }
    template <>
    inline Packet2d pmin<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
      return pminmax_propagate_numbers(a, b, pmin<Packet2d>);
    }
    template <>
    inline Packet4f pmax<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
      return pminmax_propagate_numbers(a, b, pmax<Packet4f>);
    }
    template <>
    inline Packet2d pmax<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
      return pminmax_propagate_numbers(a, b, pmax<Packet2d>);
    }
    template <>
    inline Packet4f pmin<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
      return pminmax_propagate_nan(a, b, pmin<Packet4f>);
    }
    template <>
    inline Packet2d pmin<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
      return pminmax_propagate_nan(a, b, pmin<Packet2d>);
    }
    template <>
    inline Packet4f pmax<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
      return pminmax_propagate_nan(a, b, pmax<Packet4f>);
    }
    template <>
    inline Packet2d pmax<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
      return pminmax_propagate_nan(a, b, pmax<Packet2d>);
    }
    template <int N>
    inline Packet4i parithmetic_shift_right(const Packet4i& a) {
      return _mm_srai_epi32(a, N);
    }
    template <int N>
    inline Packet4i plogical_shift_right(const Packet4i& a) {
      return _mm_srli_epi32(a, N);
    }
    template <int N>
    inline Packet4i plogical_shift_left(const Packet4i& a) {
      return _mm_slli_epi32(a, N);
    }
    template <>
    inline Packet4f pabs(const Packet4f& a) {
      const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF));
      return _mm_and_ps(a, mask);
    }
    template <>
    inline Packet2d pabs(const Packet2d& a) {
      const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF));
      return _mm_and_pd(a, mask);
    }
    template <>
    inline Packet4i pabs(const Packet4i& a) {
      return _mm_abs_epi32(a);
    }
    template <>
    inline Packet4f pround<Packet4f>(const Packet4f& a) {
      const Packet4f mask = pset1frombits<Packet4f>(0x80000000u);
      const Packet4f prev0dot5 = pset1frombits<Packet4f>(0x3EFFFFFFu);
      return ((__m128)__builtin_ia32_roundps((__v4sf)(__m128)(padd(por(pand(a, mask), prev0dot5), a)), (0x03)));
    }
    template <>
    inline Packet2d pround<Packet2d>(const Packet2d& a) {
      const Packet2d mask = _mm_castsi128_pd(_mm_set_epi64x(0x8000000000000000ull, 0x8000000000000000ull));
      const Packet2d prev0dot5 = _mm_castsi128_pd(_mm_set_epi64x(0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull));
      return ((__m128d)__builtin_ia32_roundpd((__v2df)(__m128d)(padd(por(pand(a, mask), prev0dot5), a)), (0x03)));
    }
    template <>
    inline Packet4f print<Packet4f>(const Packet4f& a) {
      return ((__m128)__builtin_ia32_roundps((__v4sf)(__m128)(a), (0x04)));
    }
    template <>
    inline Packet2d print<Packet2d>(const Packet2d& a) {
      return ((__m128d)__builtin_ia32_roundpd((__v2df)(__m128d)(a), (0x04)));
    }
    template <>
    inline Packet4f pceil<Packet4f>(const Packet4f& a) {
      return ((__m128)__builtin_ia32_roundps((__v4sf)(__m128)((a)), ((0x00 | 0x02))));
    }
    template <>
    inline Packet2d pceil<Packet2d>(const Packet2d& a) {
      return ((__m128d)__builtin_ia32_roundpd((__v2df)(__m128d)((a)), ((0x00 | 0x02))));
    }
    template <>
    inline Packet4f pfloor<Packet4f>(const Packet4f& a) {
      return ((__m128)__builtin_ia32_roundps((__v4sf)(__m128)((a)), ((0x00 | 0x01))));
    }
    template <>
    inline Packet2d pfloor<Packet2d>(const Packet2d& a) {
      return ((__m128d)__builtin_ia32_roundpd((__v2df)(__m128d)((a)), ((0x00 | 0x01))));
    }
    template <>
    inline Packet4f pload<Packet4f>(const float* from) {
      return _mm_load_ps(from);
    }
    template <>
    inline Packet2d pload<Packet2d>(const double* from) {
      return _mm_load_pd(from);
    }
    template <>
    inline Packet4i pload<Packet4i>(const int* from) {
      return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
    }
    template <>
    inline Packet16b pload<Packet16b>(const bool* from) {
      return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
    }
    template <>
    inline Packet4f ploadu<Packet4f>(const float* from) {
      return _mm_loadu_ps(from);
    }
    template <>
    inline Packet2d ploadu<Packet2d>(const double* from) {
      return _mm_loadu_pd(from);
    }
    template <>
    inline Packet4i ploadu<Packet4i>(const int* from) {
      return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
    }
    template <>
    inline Packet16b ploadu<Packet16b>(const bool* from) {
      return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
    }
    template <typename Packet>
    inline Packet ploadl(const typename unpacket_traits<Packet>::type* from);
    template <>
    inline Packet4f ploadl<Packet4f>(const float* from) {
      return _mm_castpd_ps(_mm_load_sd(reinterpret_cast<const double*>(from)));
    }
    template <>
    inline Packet2d ploadl<Packet2d>(const double* from) {
      return _mm_load_sd(from);
    }
    template <typename Packet>
    inline Packet ploads(const typename unpacket_traits<Packet>::type* from);
    template <>
    inline Packet4f ploads<Packet4f>(const float* from) {
      return _mm_load_ss(from);
    }
    template <>
    inline Packet2d ploads<Packet2d>(const double* from) {
      return _mm_load_sd(from);
    }
    template <>
    inline Packet4f ploaddup<Packet4f>(const float* from) {
      return Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
          (__v4si)(__m128i)(_mm_castps_si128(_mm_castpd_ps(_mm_load_sd(reinterpret_cast<const double*>(from))))),
          (int)((shuffle_mask<0, 0, 1, 1>::mask))))));
    }
    template <>
    inline Packet2d ploaddup<Packet2d>(const double* from) {
      return pset1<Packet2d>(from[0]);
    }
    template <>
    inline Packet4i ploaddup<Packet4i>(const int* from) {
      Packet4i tmp;
      tmp = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(from));
      return Packet4i(
          ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(tmp), (int)((shuffle_mask<0, 0, 1, 1>::mask)))));
    }
    template <>
    inline Packet16b ploaddup<Packet16b>(const bool* from) {
      __m128i tmp = _mm_castpd_si128(pload1<Packet2d>(reinterpret_cast<const double*>(from)));
      return _mm_unpacklo_epi8(tmp, tmp);
    }
    template <>
    inline Packet16b ploadquad<Packet16b>(const bool* from) {
      __m128i tmp = _mm_castps_si128(pload1<Packet4f>(reinterpret_cast<const float*>(from)));
      tmp = _mm_unpacklo_epi8(tmp, tmp);
      return _mm_unpacklo_epi16(tmp, tmp);
    }
    template <>
    inline void pstore<float>(float* to, const Packet4f& from) {
      _mm_store_ps(to, from);
    }
    template <>
    inline void pstore<double>(double* to, const Packet2d& from) {
      _mm_store_pd(to, from);
    }
    template <>
    inline void pstore<int>(int* to, const Packet4i& from) {
      _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
    }
    template <>
    inline void pstore<bool>(bool* to, const Packet16b& from) {
      _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
    }
    template <>
    inline void pstoreu<double>(double* to, const Packet2d& from) {
      _mm_storeu_pd(to, from);
    }
    template <>
    inline void pstoreu<float>(float* to, const Packet4f& from) {
      _mm_storeu_ps(to, from);
    }
    template <>
    inline void pstoreu<int>(int* to, const Packet4i& from) {
      _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
    }
    template <>
    inline void pstoreu<bool>(bool* to, const Packet16b& from) {
      _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
    }
    template <typename Scalar, typename Packet>
    inline void pstorel(Scalar* to, const Packet& from);
    template <>
    inline void pstorel(float* to, const Packet4f& from) {
      _mm_storel_pi(reinterpret_cast<__m64*>(to), from);
    }
    template <>
    inline void pstorel(double* to, const Packet2d& from) {
      _mm_storel_pd(to, from);
    }
    template <typename Scalar, typename Packet>
    inline void pstores(Scalar* to, const Packet& from);
    template <>
    inline void pstores(float* to, const Packet4f& from) {
      _mm_store_ss(to, from);
    }
    template <>
    inline void pstores(double* to, const Packet2d& from) {
      _mm_store_sd(to, from);
    }
    template <>
    inline Packet4f pgather<float, Packet4f>(const float* from, Index stride) {
      return _mm_set_ps(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);
    }
    template <>
    inline Packet2d pgather<double, Packet2d>(const double* from, Index stride) {
      return _mm_set_pd(from[1 * stride], from[0 * stride]);
    }
    template <>
    inline Packet4i pgather<int, Packet4i>(const int* from, Index stride) {
      return _mm_set_epi32(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);
    }
    template <>
    inline Packet16b pgather<bool, Packet16b>(const bool* from, Index stride) {
      return _mm_set_epi8(from[15 * stride],
                          from[14 * stride],
                          from[13 * stride],
                          from[12 * stride],
                          from[11 * stride],
                          from[10 * stride],
                          from[9 * stride],
                          from[8 * stride],
                          from[7 * stride],
                          from[6 * stride],
                          from[5 * stride],
                          from[4 * stride],
                          from[3 * stride],
                          from[2 * stride],
                          from[1 * stride],
                          from[0 * stride]);
    }
    template <>
    inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride) {
      to[stride * 0] = _mm_cvtss_f32(from);
      to[stride * 1] =
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from), (__v4sf)(__m128)(from), (int)(1))));
      to[stride * 2] =
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from), (__v4sf)(__m128)(from), (int)(2))));
      to[stride * 3] =
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from), (__v4sf)(__m128)(from), (int)(3))));
    }
    template <>
    inline void pscatter<double, Packet2d>(double* to, const Packet2d& from, Index stride) {
      to[stride * 0] = _mm_cvtsd_f64(from);
      to[stride * 1] =
          _mm_cvtsd_f64(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(from), (__v2df)(__m128d)(from), (int)(1))));
    }
    template <>
    inline void pscatter<int, Packet4i>(int* to, const Packet4i& from, Index stride) {
      to[stride * 0] = _mm_cvtsi128_si32(from);
      to[stride * 1] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(1))));
      to[stride * 2] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(2))));
      to[stride * 3] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(3))));
    }
    template <>
    inline void pscatter<bool, Packet16b>(bool* to, const Packet16b& from, Index stride) {
      to[4 * stride * 0] = _mm_cvtsi128_si32(from);
      to[4 * stride * 1] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(1))));
      to[4 * stride * 2] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(2))));
      to[4 * stride * 3] = _mm_cvtsi128_si32(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(from), (int)(3))));
    }
    template <>
    inline void pstore1<Packet4f>(float* to, const float& a) {
      Packet4f pa = _mm_set_ss(a);
      pstore(to,
             Packet4f(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                 (__v4si)(__m128i)(_mm_castps_si128(pa)), (int)((shuffle_mask<0, 0, 0, 0>::mask))))))));
    }
    template <>
    inline void pstore1<Packet2d>(double* to, const double& a) {
      Packet2d pa = _mm_set_sd(a);
      pstore(to,
             Packet2d(Packet2d(_mm_castsi128_pd(
                 ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castpd_si128(pa)),
                                                 (int)((shuffle_mask<2 * 0, 2 * 0 + 1, 2 * 0, 2 * 0 + 1>::mask))))))));
    }
    typedef const char* SsePrefetchPtrType;
    template <>
    inline void prefetch<float>(const float* addr) {
      (__builtin_prefetch((const void*)((SsePrefetchPtrType)(addr)), ((3) >> 2) & 1, (3) & 0x3));
    }
    template <>
    inline void prefetch<double>(const double* addr) {
      (__builtin_prefetch((const void*)((SsePrefetchPtrType)(addr)), ((3) >> 2) & 1, (3) & 0x3));
    }
    template <>
    inline void prefetch<int>(const int* addr) {
      (__builtin_prefetch((const void*)((SsePrefetchPtrType)(addr)), ((3) >> 2) & 1, (3) & 0x3));
    }
    template <>
    inline float pfirst<Packet4f>(const Packet4f& a) {
      return _mm_cvtss_f32(a);
    }
    template <>
    inline double pfirst<Packet2d>(const Packet2d& a) {
      return _mm_cvtsd_f64(a);
    }
    template <>
    inline int pfirst<Packet4i>(const Packet4i& a) {
      return _mm_cvtsi128_si32(a);
    }
    template <>
    inline bool pfirst<Packet16b>(const Packet16b& a) {
      int x = _mm_cvtsi128_si32(a);
      return static_cast<bool>(x & 1);
    }
    template <>
    inline Packet4f preverse(const Packet4f& a) {
      return ((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(a), (__v4sf)(__m128)(a), (int)(0x1B)));
    }
    template <>
    inline Packet2d preverse(const Packet2d& a) {
      return ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(a), (__v2df)(__m128d)(a), (int)(0x1)));
    }
    template <>
    inline Packet4i preverse(const Packet4i& a) {
      return ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(a), (int)(0x1B)));
    }
    template <>
    inline Packet16b preverse(const Packet16b& a) {
      __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);
      return _mm_shuffle_epi8(a, mask);
    }
    template <>
    inline Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
      return pfrexp_generic(a, exponent);
    }
    template <>
    inline Packet2d pfrexp_generic_get_biased_exponent(const Packet2d& a) {
      const Packet2d cst_exp_mask = pset1frombits<Packet2d>(static_cast<uint64_t>(0x7ff0000000000000ull));
      __m128i a_expo = _mm_srli_epi64(_mm_castpd_si128(pand(a, cst_exp_mask)), 52);
      return _mm_cvtepi32_pd(Packet4i(
          ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(a_expo), (int)((shuffle_mask<0, 2, 1, 3>::mask))))));
    }
    template <>
    inline Packet2d pfrexp<Packet2d>(const Packet2d& a, Packet2d& exponent) {
      return pfrexp_generic(a, exponent);
    }
    template <>
    inline Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
      return pldexp_generic(a, exponent);
    }
    template <>
    inline Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
      const Packet2d max_exponent = pset1<Packet2d>(2099.0);
      const Packet2d e = pmin(pmax(exponent, pnegate(max_exponent)), max_exponent);
      const Packet4i ei = Packet4i(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_cvtpd_epi32(e)),
                                                                   (int)((shuffle_mask<0, 3, 1, 3>::mask)))));
      const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);
      Packet4i b = parithmetic_shift_right<2>(ei);
      Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));
      Packet2d out = pmul(pmul(pmul(a, c), c), c);
      b = psub(psub(psub(ei, b), b), b);
      c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));
      out = pmul(out, c);
      return out;
    }
    template <>
    inline void pbroadcast4<Packet4f>(const float* a, Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3) {
      a3 = pload<Packet4f>(a);
      a0 = Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(a3)),
                                                                     (int)((shuffle_mask<0, 0, 0, 0>::mask))))));
      a1 = Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(a3)),
                                                                     (int)((shuffle_mask<1, 1, 1, 1>::mask))))));
      a2 = Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(a3)),
                                                                     (int)((shuffle_mask<2, 2, 2, 2>::mask))))));
      a3 = Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(a3)),
                                                                     (int)((shuffle_mask<3, 3, 3, 3>::mask))))));
    }
    template <>
    inline void pbroadcast4<Packet2d>(const double* a, Packet2d& a0, Packet2d& a1, Packet2d& a2, Packet2d& a3) {
      a0 = _mm_load1_pd(a + 0);
      a1 = _mm_load1_pd(a + 1);
      a2 = _mm_load1_pd(a + 2);
      a3 = _mm_load1_pd(a + 3);
    }
    inline void punpackp(Packet4f* vecs) {
      vecs[1] =
          _mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(vecs[0])), (int)(0x55))));
      vecs[2] =
          _mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(vecs[0])), (int)(0xAA))));
      vecs[3] =
          _mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(vecs[0])), (int)(0xFF))));
      vecs[0] =
          _mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(_mm_castps_si128(vecs[0])), (int)(0x00))));
    }
    template <>
    inline float predux<Packet4f>(const Packet4f& a) {
      Packet4f tmp = _mm_add_ps(a, _mm_movehl_ps(a, a));
      return pfirst<Packet4f>(
          _mm_add_ss(tmp, ((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(tmp), (__v4sf)(__m128)(tmp), (int)(1)))));
    }
    template <>
    inline double predux<Packet2d>(const Packet2d& a) {
      return pfirst<Packet2d>(_mm_add_sd(a, _mm_unpackhi_pd(a, a)));
    }
    template <>
    inline int predux<Packet4i>(const Packet4i& a) {
      Packet4i tmp0 = _mm_hadd_epi32(a, a);
      return pfirst<Packet4i>(_mm_hadd_epi32(tmp0, tmp0));
    }
    template <>
    inline bool predux<Packet16b>(const Packet16b& a) {
      Packet4i tmp = _mm_or_si128(a, _mm_unpackhi_epi64(a, a));
      return (pfirst(tmp) != 0) ||
             (pfirst<Packet4i>(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(tmp), (int)(1)))) != 0);
    }
    template <>
    inline float predux_mul<Packet4f>(const Packet4f& a) {
      Packet4f tmp = _mm_mul_ps(a, _mm_movehl_ps(a, a));
      return pfirst<Packet4f>(
          _mm_mul_ss(tmp, ((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(tmp), (__v4sf)(__m128)(tmp), (int)(1)))));
    }
    template <>
    inline double predux_mul<Packet2d>(const Packet2d& a) {
      return pfirst<Packet2d>(_mm_mul_sd(a, _mm_unpackhi_pd(a, a)));
    }
    template <>
    inline int predux_mul<Packet4i>(const Packet4i& a) {
      alignas(16) int aux[4];
      pstore(aux, a);
      return (aux[0] * aux[1]) * (aux[2] * aux[3]);
    }
    template <>
    inline bool predux_mul<Packet16b>(const Packet16b& a) {
      Packet4i tmp = _mm_and_si128(a, _mm_unpackhi_epi64(a, a));
      return ((pfirst<Packet4i>(tmp) == 0x01010101) &&
              (pfirst<Packet4i>(((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(tmp), (int)(1)))) == 0x01010101));
    }
    template <>
    inline float predux_min<Packet4f>(const Packet4f& a) {
      Packet4f tmp = _mm_min_ps(a, _mm_movehl_ps(a, a));
      return pfirst<Packet4f>(
          _mm_min_ss(tmp, ((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(tmp), (__v4sf)(__m128)(tmp), (int)(1)))));
    }
    template <>
    inline double predux_min<Packet2d>(const Packet2d& a) {
      return pfirst<Packet2d>(_mm_min_sd(a, _mm_unpackhi_pd(a, a)));
    }
    template <>
    inline int predux_min<Packet4i>(const Packet4i& a) {
      Packet4i tmp = _mm_min_epi32(
          a,
          ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(a), (int)((((0) << 6) | ((0) << 4) | ((3) << 2) | (2))))));
      return pfirst<Packet4i>(_mm_min_epi32(tmp, ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(tmp), (int)(1)))));
    }
    template <>
    inline float predux_max<Packet4f>(const Packet4f& a) {
      Packet4f tmp = _mm_max_ps(a, _mm_movehl_ps(a, a));
      return pfirst<Packet4f>(
          _mm_max_ss(tmp, ((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(tmp), (__v4sf)(__m128)(tmp), (int)(1)))));
    }
    template <>
    inline double predux_max<Packet2d>(const Packet2d& a) {
      return pfirst<Packet2d>(_mm_max_sd(a, _mm_unpackhi_pd(a, a)));
    }
    template <>
    inline int predux_max<Packet4i>(const Packet4i& a) {
      Packet4i tmp = _mm_max_epi32(
          a,
          ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(a), (int)((((0) << 6) | ((0) << 4) | ((3) << 2) | (2))))));
      return pfirst<Packet4i>(_mm_max_epi32(tmp, ((__m128i)__builtin_ia32_pshufd((__v4si)(__m128i)(tmp), (int)(1)))));
    }
    template <>
    inline bool predux_any(const Packet4f& x) {
      return _mm_movemask_ps(x) != 0x0;
    }
    template <>
    inline bool predux_any(const Packet4i& x) {
      return _mm_movemask_ps(_mm_castsi128_ps(x)) != 0x0;
    }
    inline void ptranspose(PacketBlock<Packet4f, 4>& kernel) {
      do {
        __m128 tmp3, tmp2, tmp1, tmp0;
        tmp0 = _mm_unpacklo_ps((kernel.packet[0]), (kernel.packet[1]));
        tmp2 = _mm_unpacklo_ps((kernel.packet[2]), (kernel.packet[3]));
        tmp1 = _mm_unpackhi_ps((kernel.packet[0]), (kernel.packet[1]));
        tmp3 = _mm_unpackhi_ps((kernel.packet[2]), (kernel.packet[3]));
        (kernel.packet[0]) = _mm_movelh_ps(tmp0, tmp2);
        (kernel.packet[1]) = _mm_movehl_ps(tmp2, tmp0);
        (kernel.packet[2]) = _mm_movelh_ps(tmp1, tmp3);
        (kernel.packet[3]) = _mm_movehl_ps(tmp3, tmp1);
      } while (0);
    }
    inline void ptranspose(PacketBlock<Packet2d, 2>& kernel) {
      __m128d tmp = _mm_unpackhi_pd(kernel.packet[0], kernel.packet[1]);
      kernel.packet[0] = _mm_unpacklo_pd(kernel.packet[0], kernel.packet[1]);
      kernel.packet[1] = tmp;
    }
    inline void ptranspose(PacketBlock<Packet4i, 4>& kernel) {
      __m128i T0 = _mm_unpacklo_epi32(kernel.packet[0], kernel.packet[1]);
      __m128i T1 = _mm_unpacklo_epi32(kernel.packet[2], kernel.packet[3]);
      __m128i T2 = _mm_unpackhi_epi32(kernel.packet[0], kernel.packet[1]);
      __m128i T3 = _mm_unpackhi_epi32(kernel.packet[2], kernel.packet[3]);
      kernel.packet[0] = _mm_unpacklo_epi64(T0, T1);
      kernel.packet[1] = _mm_unpackhi_epi64(T0, T1);
      kernel.packet[2] = _mm_unpacklo_epi64(T2, T3);
      kernel.packet[3] = _mm_unpackhi_epi64(T2, T3);
    }
    inline void ptranspose(PacketBlock<Packet16b, 4>& kernel) {
      __m128i T0 = _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);
      __m128i T1 = _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);
      __m128i T2 = _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);
      __m128i T3 = _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);
      kernel.packet[0] = _mm_unpacklo_epi16(T0, T2);
      kernel.packet[1] = _mm_unpackhi_epi16(T0, T2);
      kernel.packet[2] = _mm_unpacklo_epi16(T1, T3);
      kernel.packet[3] = _mm_unpackhi_epi16(T1, T3);
    }
    inline void ptranspose(PacketBlock<Packet16b, 16>& kernel) {
      __m128i t0 = _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);
      __m128i t1 = _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);
      __m128i t2 = _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);
      __m128i t3 = _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);
      __m128i t4 = _mm_unpacklo_epi8(kernel.packet[4], kernel.packet[5]);
      __m128i t5 = _mm_unpackhi_epi8(kernel.packet[4], kernel.packet[5]);
      __m128i t6 = _mm_unpacklo_epi8(kernel.packet[6], kernel.packet[7]);
      __m128i t7 = _mm_unpackhi_epi8(kernel.packet[6], kernel.packet[7]);
      __m128i t8 = _mm_unpacklo_epi8(kernel.packet[8], kernel.packet[9]);
      __m128i t9 = _mm_unpackhi_epi8(kernel.packet[8], kernel.packet[9]);
      __m128i ta = _mm_unpacklo_epi8(kernel.packet[10], kernel.packet[11]);
      __m128i tb = _mm_unpackhi_epi8(kernel.packet[10], kernel.packet[11]);
      __m128i tc = _mm_unpacklo_epi8(kernel.packet[12], kernel.packet[13]);
      __m128i td = _mm_unpackhi_epi8(kernel.packet[12], kernel.packet[13]);
      __m128i te = _mm_unpacklo_epi8(kernel.packet[14], kernel.packet[15]);
      __m128i tf = _mm_unpackhi_epi8(kernel.packet[14], kernel.packet[15]);
      __m128i s0 = _mm_unpacklo_epi16(t0, t2);
      __m128i s1 = _mm_unpackhi_epi16(t0, t2);
      __m128i s2 = _mm_unpacklo_epi16(t1, t3);
      __m128i s3 = _mm_unpackhi_epi16(t1, t3);
      __m128i s4 = _mm_unpacklo_epi16(t4, t6);
      __m128i s5 = _mm_unpackhi_epi16(t4, t6);
      __m128i s6 = _mm_unpacklo_epi16(t5, t7);
      __m128i s7 = _mm_unpackhi_epi16(t5, t7);
      __m128i s8 = _mm_unpacklo_epi16(t8, ta);
      __m128i s9 = _mm_unpackhi_epi16(t8, ta);
      __m128i sa = _mm_unpacklo_epi16(t9, tb);
      __m128i sb = _mm_unpackhi_epi16(t9, tb);
      __m128i sc = _mm_unpacklo_epi16(tc, te);
      __m128i sd = _mm_unpackhi_epi16(tc, te);
      __m128i se = _mm_unpacklo_epi16(td, tf);
      __m128i sf = _mm_unpackhi_epi16(td, tf);
      __m128i u0 = _mm_unpacklo_epi32(s0, s4);
      __m128i u1 = _mm_unpackhi_epi32(s0, s4);
      __m128i u2 = _mm_unpacklo_epi32(s1, s5);
      __m128i u3 = _mm_unpackhi_epi32(s1, s5);
      __m128i u4 = _mm_unpacklo_epi32(s2, s6);
      __m128i u5 = _mm_unpackhi_epi32(s2, s6);
      __m128i u6 = _mm_unpacklo_epi32(s3, s7);
      __m128i u7 = _mm_unpackhi_epi32(s3, s7);
      __m128i u8 = _mm_unpacklo_epi32(s8, sc);
      __m128i u9 = _mm_unpackhi_epi32(s8, sc);
      __m128i ua = _mm_unpacklo_epi32(s9, sd);
      __m128i ub = _mm_unpackhi_epi32(s9, sd);
      __m128i uc = _mm_unpacklo_epi32(sa, se);
      __m128i ud = _mm_unpackhi_epi32(sa, se);
      __m128i ue = _mm_unpacklo_epi32(sb, sf);
      __m128i uf = _mm_unpackhi_epi32(sb, sf);
      kernel.packet[0] = _mm_unpacklo_epi64(u0, u8);
      kernel.packet[1] = _mm_unpackhi_epi64(u0, u8);
      kernel.packet[2] = _mm_unpacklo_epi64(u1, u9);
      kernel.packet[3] = _mm_unpackhi_epi64(u1, u9);
      kernel.packet[4] = _mm_unpacklo_epi64(u2, ua);
      kernel.packet[5] = _mm_unpackhi_epi64(u2, ua);
      kernel.packet[6] = _mm_unpacklo_epi64(u3, ub);
      kernel.packet[7] = _mm_unpackhi_epi64(u3, ub);
      kernel.packet[8] = _mm_unpacklo_epi64(u4, uc);
      kernel.packet[9] = _mm_unpackhi_epi64(u4, uc);
      kernel.packet[10] = _mm_unpacklo_epi64(u5, ud);
      kernel.packet[11] = _mm_unpackhi_epi64(u5, ud);
      kernel.packet[12] = _mm_unpacklo_epi64(u6, ue);
      kernel.packet[13] = _mm_unpackhi_epi64(u6, ue);
      kernel.packet[14] = _mm_unpacklo_epi64(u7, uf);
      kernel.packet[15] = _mm_unpackhi_epi64(u7, uf);
    }
    template <>
    inline Packet4i pblend(const Selector<4>& ifPacket, const Packet4i& thenPacket, const Packet4i& elsePacket) {
      const __m128i zero = _mm_setzero_si128();
      const __m128i select =
          _mm_set_epi32(ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
      __m128i false_mask = _mm_cmpeq_epi32(select, zero);
      return _mm_blendv_epi8(thenPacket, elsePacket, false_mask);
    }
    template <>
    inline Packet4f pblend(const Selector<4>& ifPacket, const Packet4f& thenPacket, const Packet4f& elsePacket) {
      const __m128 zero = _mm_setzero_ps();
      const __m128 select = _mm_set_ps(ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
      __m128 false_mask = _mm_cmpeq_ps(select, zero);
      return _mm_blendv_ps(thenPacket, elsePacket, false_mask);
    }
    template <>
    inline Packet2d pblend(const Selector<2>& ifPacket, const Packet2d& thenPacket, const Packet2d& elsePacket) {
      const __m128d zero = _mm_setzero_pd();
      const __m128d select = _mm_set_pd(ifPacket.select[1], ifPacket.select[0]);
      __m128d false_mask = _mm_cmpeq_pd(select, zero);
      return _mm_blendv_pd(thenPacket, elsePacket, false_mask);
    }
    inline __m128i half2floatsse(__m128i h) {
      __m128i input = _mm_cvtepu16_epi32(h);
      __m128i shifted_exp = _mm_set1_epi32(0x7c00 << 13);
      __m128i ou = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x7fff)), 13);
      __m128i exp = _mm_and_si128(ou, shifted_exp);
      ou = _mm_add_epi32(ou, _mm_set1_epi32((127 - 15) << 23));
      __m128i naninf_mask = _mm_cmpeq_epi32(exp, shifted_exp);
      __m128i naninf_adj = _mm_and_si128(_mm_set1_epi32((128 - 16) << 23), naninf_mask);
      ou = _mm_add_epi32(ou, naninf_adj);
      __m128i zeroden_mask = _mm_cmpeq_epi32(exp, _mm_setzero_si128());
      __m128i zeroden_adj = _mm_and_si128(zeroden_mask, _mm_set1_epi32(1 << 23));
      ou = _mm_add_epi32(ou, zeroden_adj);
      __m128i magic = _mm_and_si128(zeroden_mask, _mm_set1_epi32(113 << 23));
      ou = _mm_castps_si128(_mm_sub_ps(_mm_castsi128_ps(ou), _mm_castsi128_ps(magic)));
      __m128i sign = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x8000)), 16);
      ou = _mm_or_si128(ou, sign);
      return ou;
    }
    inline __m128i float2half(__m128 f) {
      __m128i o = _mm_setzero_si128();
      __m128i sign = _mm_set1_epi32(0x80000000u);
      sign = _mm_and_si128(sign, _mm_castps_si128(f));
      f = _mm_xor_ps(f, _mm_castsi128_ps(sign));
      __m128i fu = _mm_castps_si128(f);
      __m128i f16max = _mm_set1_epi32((127 + 16) << 23);
      __m128i f32infty = _mm_set1_epi32(255 << 23);
      __m128i infnan_mask = _mm_cmplt_epi32(f16max, _mm_castps_si128(f));
      __m128i inf_mask = _mm_cmpgt_epi32(_mm_castps_si128(f), f32infty);
      __m128i nan_mask = _mm_andnot_si128(inf_mask, infnan_mask);
      __m128i inf_value = _mm_and_si128(inf_mask, _mm_set1_epi32(0x7e00));
      __m128i nan_value = _mm_and_si128(nan_mask, _mm_set1_epi32(0x7c00));
      __m128i naninf_value = _mm_or_si128(inf_value, nan_value);
      __m128i denorm_magic = _mm_set1_epi32(((127 - 15) + (23 - 10) + 1) << 23);
      __m128i subnorm_mask = _mm_cmplt_epi32(_mm_castps_si128(f), _mm_set1_epi32(113 << 23));
      f = _mm_add_ps(f, _mm_castsi128_ps(denorm_magic));
      o = _mm_sub_epi32(_mm_castps_si128(f), denorm_magic);
      o = _mm_and_si128(o, subnorm_mask);
      o = _mm_or_si128(o, naninf_value);
      __m128i mask = _mm_or_si128(infnan_mask, subnorm_mask);
      o = _mm_and_si128(o, mask);
      __m128i mand_odd = _mm_and_si128(_mm_srli_epi32(fu, 13), _mm_set1_epi32(0x1));
      fu = _mm_add_epi32(fu, _mm_set1_epi32(0xc8000fffU));
      fu = _mm_add_epi32(fu, mand_odd);
      fu = _mm_andnot_si128(mask, fu);
      fu = _mm_srli_epi32(fu, 13);
      o = _mm_or_si128(fu, o);
      o = _mm_or_si128(o, _mm_srli_epi32(sign, 16));
      return _mm_and_si128(o, _mm_set1_epi32(0xffff));
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <>
    struct type_casting_traits<float, int> {
      enum { VectorizedCast = 1, SrcCoeffRatio = 1, TgtCoeffRatio = 1 };
    };
    template <>
    struct type_casting_traits<int, float> {
      enum { VectorizedCast = 1, SrcCoeffRatio = 1, TgtCoeffRatio = 1 };
    };
    template <>
    struct type_casting_traits<double, float> {
      enum { VectorizedCast = 1, SrcCoeffRatio = 2, TgtCoeffRatio = 1 };
    };
    template <>
    struct type_casting_traits<float, double> {
      enum { VectorizedCast = 1, SrcCoeffRatio = 1, TgtCoeffRatio = 2 };
    };
    template <>
    inline Packet4i pcast<Packet4f, Packet4i>(const Packet4f& a) {
      return _mm_cvttps_epi32(a);
    }
    template <>
    inline Packet4f pcast<Packet4i, Packet4f>(const Packet4i& a) {
      return _mm_cvtepi32_ps(a);
    }
    template <>
    inline Packet4f pcast<Packet2d, Packet4f>(const Packet2d& a, const Packet2d& b) {
      return ((__m128)__builtin_ia32_shufps(
          (__v4sf)(__m128)(_mm_cvtpd_ps(a)), (__v4sf)(__m128)(_mm_cvtpd_ps(b)), (int)((1 << 2) | (1 << 6))));
    }
    template <>
    inline Packet2d pcast<Packet4f, Packet2d>(const Packet4f& a) {
      return _mm_cvtps_pd(a);
    }
    template <>
    inline Packet2d preinterpret<Packet2d, Packet4f>(const Packet4f& a) {
      return _mm_castps_pd(a);
    }
    template <>
    inline Packet4f preinterpret<Packet4f, Packet2d>(const Packet2d& a) {
      return _mm_castpd_ps(a);
    }
    template <>
    inline Packet4i preinterpret<Packet4i, Packet4f>(const Packet4f& a) {
      return _mm_castps_si128(a);
    }
    template <>
    inline Packet4f preinterpret<Packet4f, Packet4i>(const Packet4i& a) {
      return _mm_castsi128_ps(a);
    }
    template <>
    inline Packet2d preinterpret<Packet2d, Packet4i>(const Packet4i& a) {
      return _mm_castsi128_pd(a);
    }
    template <>
    inline Packet4i preinterpret<Packet4i, Packet2d>(const Packet2d& a) {
      return _mm_castpd_si128(a);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <>
    inline Packet4f plog<Packet4f>(const Packet4f& _x) {
      return plog_float(_x);
    }
    template <>
    inline Packet2d plog<Packet2d>(const Packet2d& _x) {
      return plog_double(_x);
    }
    template <>
    inline Packet4f plog2<Packet4f>(const Packet4f& _x) {
      return plog2_float(_x);
    }
    template <>
    inline Packet2d plog2<Packet2d>(const Packet2d& _x) {
      return plog2_double(_x);
    }
    template <>
    inline Packet4f plog1p<Packet4f>(const Packet4f& _x) {
      return generic_plog1p(_x);
    }
    template <>
    inline Packet4f pexpm1<Packet4f>(const Packet4f& _x) {
      return generic_expm1(_x);
    }
    template <>
    inline Packet4f pexp<Packet4f>(const Packet4f& _x) {
      return pexp_float(_x);
    }
    template <>
    inline Packet2d pexp<Packet2d>(const Packet2d& x) {
      return pexp_double(x);
    }
    template <>
    inline Packet4f psin<Packet4f>(const Packet4f& _x) {
      return psin_float(_x);
    }
    template <>
    inline Packet4f pcos<Packet4f>(const Packet4f& _x) {
      return pcos_float(_x);
    }
    template <>
    inline Packet4f pacos<Packet4f>(const Packet4f& _x) {
      return pacos_float(_x);
    }
    template <>
    inline Packet2d patan<Packet2d>(const Packet2d& _x) {
      return patan_double(_x);
    }
    template <>
    inline Packet4f pasin<Packet4f>(const Packet4f& _x) {
      return pasin_float(_x);
    }
    template <>
    inline Packet4f patan<Packet4f>(const Packet4f& _x) {
      return patan_float(_x);
    }
    template <>
    inline Packet4f psqrt<Packet4f>(const Packet4f& x) {
      return _mm_sqrt_ps(x);
    }
    template <>
    inline Packet2d psqrt<Packet2d>(const Packet2d& x) {
      return _mm_sqrt_pd(x);
    }
    template <>
    inline Packet16b psqrt<Packet16b>(const Packet16b& x) {
      return x;
    }
    template <>
    inline __attribute__((unused)) Packet4f prsqrt<Packet4f>(const Packet4f& x) {
      return generic_rsqrt_newton_step<Packet4f, 1>::run(x, _mm_rsqrt_ps(x));
    }
    template <>
    inline Packet4f ptanh<Packet4f>(const Packet4f& x) {
      return internal::generic_fast_tanh_float(x);
    }
  }  // namespace internal
  namespace numext {
    template <>
    __attribute__((always_inline)) inline float sqrt(const float& x) {
      return internal::pfirst(internal::Packet4f(_mm_sqrt_ss(_mm_set_ss(x))));
    }
    template <>
    __attribute__((always_inline)) inline double sqrt(const double& x) {
      return internal::pfirst(internal::Packet2d(_mm_sqrt_pd(_mm_set_sd(x))));
    }
  }  // namespace numext
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    struct Packet2cf {
      inline Packet2cf() {}
      inline explicit Packet2cf(const __m128& a) : v(a) {}
      Packet4f v;
    };
    template <>
    struct packet_traits<std::complex<float>> : default_packet_traits {
      typedef Packet2cf type;
      typedef Packet2cf half;
      enum {
        Vectorizable = 1,
        AlignedOnScalar = 1,
        size = 2,
        HasHalfPacket = 0,
        HasAdd = 1,
        HasSub = 1,
        HasMul = 1,
        HasDiv = 1,
        HasNegate = 1,
        HasSqrt = 1,
        HasAbs = 0,
        HasAbs2 = 0,
        HasMin = 0,
        HasMax = 0,
        HasSetLinear = 0,
        HasBlend = 1
      };
    };
    template <>
    struct unpacket_traits<Packet2cf> {
      typedef std::complex<float> type;
      typedef Packet2cf half;
      typedef Packet4f as_real;
      enum {
        size = 2,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    inline Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_add_ps(a.v, b.v));
    }
    template <>
    inline Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_sub_ps(a.v, b.v));
    }
    template <>
    inline Packet2cf pnegate(const Packet2cf& a) {
      const __m128 mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x80000000, 0x80000000, 0x80000000));
      return Packet2cf(_mm_xor_ps(a.v, mask));
    }
    template <>
    inline Packet2cf pconj(const Packet2cf& a) {
      const __m128 mask = _mm_castsi128_ps(_mm_setr_epi32(0x00000000, 0x80000000, 0x00000000, 0x80000000));
      return Packet2cf(_mm_xor_ps(a.v, mask));
    }
    template <>
    inline Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_addsub_ps(
          _mm_mul_ps(_mm_moveldup_ps(a.v), b.v),
          _mm_mul_ps(_mm_movehdup_ps(a.v),
                     Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                         (__v4si)(__m128i)(_mm_castps_si128(b.v)), (int)((shuffle_mask<1, 0, 3, 2>::mask)))))))));
    }
    template <>
    inline Packet2cf ptrue<Packet2cf>(const Packet2cf& a) {
      return Packet2cf(ptrue(Packet4f(a.v)));
    }
    template <>
    inline Packet2cf pand<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_and_ps(a.v, b.v));
    }
    template <>
    inline Packet2cf por<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_or_ps(a.v, b.v));
    }
    template <>
    inline Packet2cf pxor<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_xor_ps(a.v, b.v));
    }
    template <>
    inline Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return Packet2cf(_mm_andnot_ps(b.v, a.v));
    }
    template <>
    inline Packet2cf pload<Packet2cf>(const std::complex<float>* from) {
      return Packet2cf(pload<Packet4f>(&numext::real_ref(*from)));
    }
    template <>
    inline Packet2cf ploadu<Packet2cf>(const std::complex<float>* from) {
      return Packet2cf(ploadu<Packet4f>(&numext::real_ref(*from)));
    }
    template <>
    inline Packet2cf pset1<Packet2cf>(const std::complex<float>& from) {
      const float re = std::real(from);
      const float im = std::imag(from);
      return Packet2cf(_mm_set_ps(im, re, im, re));
    }
    template <>
    inline Packet2cf ploaddup<Packet2cf>(const std::complex<float>* from) {
      return pset1<Packet2cf>(*from);
    }
    template <>
    inline void pstore<std::complex<float>>(std::complex<float>* to, const Packet2cf& from) {
      pstore(&numext::real_ref(*to), Packet4f(from.v));
    }
    template <>
    inline void pstoreu<std::complex<float>>(std::complex<float>* to, const Packet2cf& from) {
      pstoreu(&numext::real_ref(*to), Packet4f(from.v));
    }
    template <>
    inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride) {
      return Packet2cf(_mm_set_ps(std::imag(from[1 * stride]),
                                  std::real(from[1 * stride]),
                                  std::imag(from[0 * stride]),
                                  std::real(from[0 * stride])));
    }
    template <>
    inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from, Index stride) {
      to[stride * 0] = std::complex<float>(
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from.v), (__v4sf)(__m128)(from.v), (int)(0)))),
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from.v), (__v4sf)(__m128)(from.v), (int)(1)))));
      to[stride * 1] = std::complex<float>(
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from.v), (__v4sf)(__m128)(from.v), (int)(2)))),
          _mm_cvtss_f32(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)(from.v), (__v4sf)(__m128)(from.v), (int)(3)))));
    }
    template <>
    inline void prefetch<std::complex<float>>(const std::complex<float>* addr) {
      (__builtin_prefetch((const void*)((SsePrefetchPtrType)(addr)), ((3) >> 2) & 1, (3) & 0x3));
    }
    template <>
    inline std::complex<float> pfirst<Packet2cf>(const Packet2cf& a) {
      alignas(alignof(__m64)) std::complex<float> res;
      _mm_storel_pi((__m64*)&res, a.v);
      return res;
    }
    template <>
    inline Packet2cf preverse(const Packet2cf& a) {
      return Packet2cf(_mm_castpd_ps(preverse(Packet2d(_mm_castps_pd(a.v)))));
    }
    template <>
    inline std::complex<float> predux<Packet2cf>(const Packet2cf& a) {
      return pfirst(Packet2cf(_mm_add_ps(a.v, _mm_movehl_ps(a.v, a.v))));
    }
    template <>
    inline std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a) {
      return pfirst(pmul(a, Packet2cf(_mm_movehl_ps(a.v, a.v))));
    }
    inline Packet2cf pcplxflip(const Packet2cf& x) {
      return Packet2cf(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
          (__v4si)(__m128i)(_mm_castps_si128(x.v)), (int)((shuffle_mask<1, 0, 3, 2>::mask)))))));
    }
    template <>
    struct conj_helper<Packet4f, Packet2cf, false, false> {
      inline Packet2cf pmadd(const Packet4f& x, const Packet2cf& y, const Packet2cf& c) const {
        return padd(c, this->pmul(x, y));
      }
      inline Packet2cf pmul(const Packet4f& x, const Packet2cf& y) const {
        return Packet2cf(Eigen::internal::pmul<Packet4f>(x, y.v));
      }
    };
    template <>
    struct conj_helper<Packet2cf, Packet4f, false, false> {
      inline Packet2cf pmadd(const Packet2cf& x, const Packet4f& y, const Packet2cf& c) const {
        return padd(c, this->pmul(x, y));
      }
      inline Packet2cf pmul(const Packet2cf& x, const Packet4f& y) const {
        return Packet2cf(Eigen::internal::pmul<Packet4f>(x.v, y));
      }
    };
    template <>
    inline Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
      return pdiv_complex(a, b);
    }
    struct Packet1cd {
      inline Packet1cd() {}
      inline explicit Packet1cd(const __m128d& a) : v(a) {}
      Packet2d v;
    };
    template <>
    struct packet_traits<std::complex<double>> : default_packet_traits {
      typedef Packet1cd type;
      typedef Packet1cd half;
      enum {
        Vectorizable = 1,
        AlignedOnScalar = 0,
        size = 1,
        HasHalfPacket = 0,
        HasAdd = 1,
        HasSub = 1,
        HasMul = 1,
        HasDiv = 1,
        HasNegate = 1,
        HasSqrt = 1,
        HasAbs = 0,
        HasAbs2 = 0,
        HasMin = 0,
        HasMax = 0,
        HasSetLinear = 0
      };
    };
    template <>
    struct unpacket_traits<Packet1cd> {
      typedef std::complex<double> type;
      typedef Packet1cd half;
      typedef Packet2d as_real;
      enum {
        size = 1,
        alignment = Aligned16,
        vectorizable = true,
        masked_load_available = false,
        masked_store_available = false
      };
    };
    template <>
    inline Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_add_pd(a.v, b.v));
    }
    template <>
    inline Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_sub_pd(a.v, b.v));
    }
    template <>
    inline Packet1cd pnegate(const Packet1cd& a) {
      return Packet1cd(pnegate(Packet2d(a.v)));
    }
    template <>
    inline Packet1cd pconj(const Packet1cd& a) {
      const __m128d mask = _mm_castsi128_pd(_mm_set_epi32(0x80000000, 0x0, 0x0, 0x0));
      return Packet1cd(_mm_xor_pd(a.v, mask));
    }
    template <>
    inline Packet1cd pmul<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(
          _mm_addsub_pd(_mm_mul_pd(_mm_movedup_pd(a.v), b.v),
                        _mm_mul_pd(Packet2d(_mm_castsi128_pd(((__m128i)__builtin_ia32_pshufd(
                                       (__v4si)(__m128i)(_mm_castpd_si128(a.v)),
                                       (int)((shuffle_mask<2 * 1, 2 * 1 + 1, 2 * 1, 2 * 1 + 1>::mask)))))),
                                   Packet2d(_mm_castsi128_pd(((__m128i)__builtin_ia32_pshufd(
                                       (__v4si)(__m128i)(_mm_castpd_si128(b.v)),
                                       (int)((shuffle_mask<2 * 1, 2 * 1 + 1, 2 * 0, 2 * 0 + 1>::mask)))))))));
    }
    template <>
    inline Packet1cd ptrue<Packet1cd>(const Packet1cd& a) {
      return Packet1cd(ptrue(Packet2d(a.v)));
    }
    template <>
    inline Packet1cd pand<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_and_pd(a.v, b.v));
    }
    template <>
    inline Packet1cd por<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_or_pd(a.v, b.v));
    }
    template <>
    inline Packet1cd pxor<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_xor_pd(a.v, b.v));
    }
    template <>
    inline Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return Packet1cd(_mm_andnot_pd(b.v, a.v));
    }
    template <>
    inline Packet1cd pload<Packet1cd>(const std::complex<double>* from) {
      return Packet1cd(pload<Packet2d>((const double*)from));
    }
    template <>
    inline Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) {
      return Packet1cd(ploadu<Packet2d>((const double*)from));
    }
    template <>
    inline Packet1cd pset1<Packet1cd>(const std::complex<double>& from) {
      return ploadu<Packet1cd>(&from);
    }
    template <>
    inline Packet1cd ploaddup<Packet1cd>(const std::complex<double>* from) {
      return pset1<Packet1cd>(*from);
    }
    template <>
    inline void pstore<std::complex<double>>(std::complex<double>* to, const Packet1cd& from) {
      pstore((double*)to, Packet2d(from.v));
    }
    template <>
    inline void pstoreu<std::complex<double>>(std::complex<double>* to, const Packet1cd& from) {
      pstoreu((double*)to, Packet2d(from.v));
    }
    template <>
    inline void prefetch<std::complex<double>>(const std::complex<double>* addr) {
      (__builtin_prefetch((const void*)((SsePrefetchPtrType)(addr)), ((3) >> 2) & 1, (3) & 0x3));
    }
    template <>
    inline std::complex<double> pfirst<Packet1cd>(const Packet1cd& a) {
      alignas(16) double res[2];
      _mm_store_pd(res, a.v);
      return std::complex<double>(res[0], res[1]);
    }
    template <>
    inline Packet1cd preverse(const Packet1cd& a) {
      return a;
    }
    template <>
    inline std::complex<double> predux<Packet1cd>(const Packet1cd& a) {
      return pfirst(a);
    }
    template <>
    inline std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) {
      return pfirst(a);
    }
    template <>
    struct conj_helper<Packet2d, Packet1cd, false, false> {
      inline Packet1cd pmadd(const Packet2d& x, const Packet1cd& y, const Packet1cd& c) const {
        return padd(c, this->pmul(x, y));
      }
      inline Packet1cd pmul(const Packet2d& x, const Packet1cd& y) const {
        return Packet1cd(Eigen::internal::pmul<Packet2d>(x, y.v));
      }
    };
    template <>
    struct conj_helper<Packet1cd, Packet2d, false, false> {
      inline Packet1cd pmadd(const Packet1cd& x, const Packet2d& y, const Packet1cd& c) const {
        return padd(c, this->pmul(x, y));
      }
      inline Packet1cd pmul(const Packet1cd& x, const Packet2d& y) const {
        return Packet1cd(Eigen::internal::pmul<Packet2d>(x.v, y));
      }
    };
    template <>
    inline Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
      return pdiv_complex(a, b);
    }
    inline Packet1cd pcplxflip(const Packet1cd& x) { return Packet1cd(preverse(Packet2d(x.v))); }
    inline void ptranspose(PacketBlock<Packet2cf, 2>& kernel) {
      __m128d w1 = _mm_castps_pd(kernel.packet[0].v);
      __m128d w2 = _mm_castps_pd(kernel.packet[1].v);
      __m128 tmp = _mm_castpd_ps(_mm_unpackhi_pd(w1, w2));
      kernel.packet[0].v = _mm_castpd_ps(_mm_unpacklo_pd(w1, w2));
      kernel.packet[1].v = tmp;
    }
    template <>
    inline Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
      __m128 eq = _mm_cmpeq_ps(a.v, b.v);
      return Packet2cf(
          pand<Packet4f>(eq,
                         Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                             (__v4si)(__m128i)(_mm_castps_si128(eq)), (int)((shuffle_mask<1, 0, 3, 2>::mask))))))));
    }
    template <>
    inline Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
      __m128d eq = _mm_cmpeq_pd(a.v, b.v);
      return Packet1cd(pand<Packet2d>(eq,
                                      Packet2d(_mm_castsi128_pd(((__m128i)__builtin_ia32_pshufd(
                                          (__v4si)(__m128i)(_mm_castpd_si128(eq)),
                                          (int)((shuffle_mask<2 * 1, 2 * 1 + 1, 2 * 0, 2 * 0 + 1>::mask))))))));
    }
    template <>
    inline Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
      __m128d result = pblend<Packet2d>(ifPacket, _mm_castps_pd(thenPacket.v), _mm_castps_pd(elsePacket.v));
      return Packet2cf(_mm_castpd_ps(result));
    }
    template <>
    inline Packet1cd psqrt<Packet1cd>(const Packet1cd& a) {
      return psqrt_complex<Packet1cd>(a);
    }
    template <>
    inline Packet2cf psqrt<Packet2cf>(const Packet2cf& a) {
      return psqrt_complex<Packet2cf>(a);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T>
    struct make_integer;
    template <>
    struct make_integer<float> {
      typedef numext::int32_t type;
    };
    template <>
    struct make_integer<double> {
      typedef numext::int64_t type;
    };
    template <>
    struct make_integer<half> {
      typedef numext::int16_t type;
    };
    template <>
    struct make_integer<bfloat16> {
      typedef numext::int16_t type;
    };
    template <typename Packet>
    inline Packet pfrexp_generic_get_biased_exponent(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      typedef typename unpacket_traits<Packet>::integer_packet PacketI;
      static constexpr int mantissa_bits = numext::numeric_limits<Scalar>::digits - 1;
      return pcast<PacketI, Packet>(plogical_shift_right<mantissa_bits>(preinterpret<PacketI>(pabs(a))));
    }
    template <typename Packet>
    inline Packet pfrexp_generic(const Packet& a, Packet& exponent) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      typedef typename make_unsigned<typename make_integer<Scalar>::type>::type ScalarUI;
      static constexpr int TotalBits = sizeof(Scalar) * 8, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
                           ExponentBits = TotalBits - MantissaBits - 1;
      constexpr ScalarUI scalar_sign_mantissa_mask = ~(((ScalarUI(1) << ExponentBits) - ScalarUI(1)) << MantissaBits);
      const Packet sign_mantissa_mask = pset1frombits<Packet>(static_cast<ScalarUI>(scalar_sign_mantissa_mask));
      const Packet half = pset1<Packet>(Scalar(0.5));
      const Packet zero = pzero(a);
      const Packet normal_min = pset1<Packet>((numext::numeric_limits<Scalar>::min)());
      const Packet is_denormal = pcmp_lt(pabs(a), normal_min);
      constexpr ScalarUI scalar_normalization_offset = ScalarUI(MantissaBits + 1);
      const Scalar scalar_normalization_factor = Scalar(ScalarUI(1) << int(scalar_normalization_offset));
      const Packet normalization_factor = pset1<Packet>(scalar_normalization_factor);
      const Packet normalized_a = pselect(is_denormal, pmul(a, normalization_factor), a);
      const Scalar scalar_exponent_offset = -Scalar((ScalarUI(1) << (ExponentBits - 1)) - ScalarUI(2));
      Packet exponent_offset = pset1<Packet>(scalar_exponent_offset);
      const Packet normalization_offset = pset1<Packet>(-Scalar(scalar_normalization_offset));
      exponent_offset = pselect(is_denormal, padd(exponent_offset, normalization_offset), exponent_offset);
      exponent = pfrexp_generic_get_biased_exponent(normalized_a);
      const Scalar scalar_non_finite_exponent = Scalar((ScalarUI(1) << ExponentBits) - ScalarUI(1));
      const Packet non_finite_exponent = pset1<Packet>(scalar_non_finite_exponent);
      const Packet is_zero_or_not_finite = por(pcmp_eq(a, zero), pcmp_eq(exponent, non_finite_exponent));
      const Packet m = pselect(is_zero_or_not_finite, a, por(pand(normalized_a, sign_mantissa_mask), half));
      exponent = pselect(is_zero_or_not_finite, zero, padd(exponent, exponent_offset));
      return m;
    }
    template <typename Packet>
    inline Packet pldexp_generic(const Packet& a, const Packet& exponent) {
      typedef typename unpacket_traits<Packet>::integer_packet PacketI;
      typedef typename unpacket_traits<Packet>::type Scalar;
      typedef typename unpacket_traits<PacketI>::type ScalarI;
      static constexpr int TotalBits = sizeof(Scalar) * 8, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
                           ExponentBits = TotalBits - MantissaBits - 1;
      const Packet max_exponent = pset1<Packet>(Scalar((ScalarI(1) << ExponentBits) + ScalarI(MantissaBits - 1)));
      const PacketI bias = pset1<PacketI>((ScalarI(1) << (ExponentBits - 1)) - ScalarI(1));
      const PacketI e = pcast<Packet, PacketI>(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
      PacketI b = parithmetic_shift_right<2>(e);
      Packet c = preinterpret<Packet>(plogical_shift_left<MantissaBits>(padd(b, bias)));
      Packet out = pmul(pmul(pmul(a, c), c), c);
      b = psub(psub(psub(e, b), b), b);
      c = preinterpret<Packet>(plogical_shift_left<MantissaBits>(padd(b, bias)));
      out = pmul(out, c);
      return out;
    }
    template <typename Packet>
    struct pldexp_fast_impl {
      typedef typename unpacket_traits<Packet>::integer_packet PacketI;
      typedef typename unpacket_traits<Packet>::type Scalar;
      typedef typename unpacket_traits<PacketI>::type ScalarI;
      static constexpr int TotalBits = sizeof(Scalar) * 8, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
                           ExponentBits = TotalBits - MantissaBits - 1;
      static inline Packet run(const Packet& a, const Packet& exponent) {
        const Packet bias = pset1<Packet>(Scalar((ScalarI(1) << (ExponentBits - 1)) - ScalarI(1)));
        const Packet limit = pset1<Packet>(Scalar((ScalarI(1) << ExponentBits) - ScalarI(1)));
        const PacketI e = pcast<Packet, PacketI>(pmin(pmax(padd(exponent, bias), pzero(limit)), limit));
        return pmul(a, preinterpret<Packet>(plogical_shift_left<MantissaBits>(e)));
      }
    };
    template <typename Packet, bool base2>
    inline Packet plog_impl_float(const Packet _x) {
      const Packet cst_1 = pset1<Packet>(1.0f);
      const Packet cst_minus_inf = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0xff800000u));
      const Packet cst_pos_inf = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0x7f800000u));
      const Packet cst_cephes_SQRTHF = pset1<Packet>(0.707106781186547524f);
      Packet e, x;
      x = pfrexp(_x, e);
      Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);
      Packet tmp = pand(x, mask);
      x = psub(x, cst_1);
      e = psub(e, pand(cst_1, mask));
      x = padd(x, tmp);
      const Packet cst_p1 = pset1<Packet>(1.0000000190281136f);
      const Packet cst_p2 = pset1<Packet>(1.0000000190281063f);
      const Packet cst_p3 = pset1<Packet>(0.18256296349849254f);
      const Packet cst_q1 = pset1<Packet>(1.4999999999999927f);
      const Packet cst_q2 = pset1<Packet>(0.59923249590823520f);
      const Packet cst_q3 = pset1<Packet>(0.049616247954120038f);
      Packet p = pmadd(x, cst_p3, cst_p2);
      p = pmadd(x, p, cst_p1);
      p = pmul(x, p);
      Packet q = pmadd(x, cst_q3, cst_q2);
      q = pmadd(x, q, cst_q1);
      q = pmadd(x, q, cst_1);
      x = pdiv(p, q);
      if (base2) {
        const Packet cst_log2e = pset1<Packet>(
            static_cast<float>(1.442695040888963407359924681001892137426645954152985934135449406931109219L));
        x = pmadd(x, cst_log2e, e);
      } else {
        const Packet cst_ln2 = pset1<Packet>(
            static_cast<float>(0.693147180559945309417232121458176568075500134360255254120680009493393621L));
        x = pmadd(e, cst_ln2, x);
      }
      Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));
      Packet iszero_mask = pcmp_eq(_x, pzero(_x));
      Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);
      return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));
    }
    template <typename Packet>
    inline Packet plog_float(const Packet _x) {
      return plog_impl_float<Packet, false>(_x);
    }
    template <typename Packet>
    inline Packet plog2_float(const Packet _x) {
      return plog_impl_float<Packet, true>(_x);
    }
    template <typename Packet, bool base2>
    inline Packet plog_impl_double(const Packet _x) {
      Packet x = _x;
      const Packet cst_1 = pset1<Packet>(1.0);
      const Packet cst_neg_half = pset1<Packet>(-0.5);
      const Packet cst_minus_inf = pset1frombits<Packet>(static_cast<uint64_t>(0xfff0000000000000ull));
      const Packet cst_pos_inf = pset1frombits<Packet>(static_cast<uint64_t>(0x7ff0000000000000ull));
      const Packet cst_cephes_SQRTHF = pset1<Packet>(0.70710678118654752440E0);
      const Packet cst_cephes_log_p0 = pset1<Packet>(1.01875663804580931796E-4);
      const Packet cst_cephes_log_p1 = pset1<Packet>(4.97494994976747001425E-1);
      const Packet cst_cephes_log_p2 = pset1<Packet>(4.70579119878881725854E0);
      const Packet cst_cephes_log_p3 = pset1<Packet>(1.44989225341610930846E1);
      const Packet cst_cephes_log_p4 = pset1<Packet>(1.79368678507819816313E1);
      const Packet cst_cephes_log_p5 = pset1<Packet>(7.70838733755885391666E0);
      const Packet cst_cephes_log_q0 = pset1<Packet>(1.0);
      const Packet cst_cephes_log_q1 = pset1<Packet>(1.12873587189167450590E1);
      const Packet cst_cephes_log_q2 = pset1<Packet>(4.52279145837532221105E1);
      const Packet cst_cephes_log_q3 = pset1<Packet>(8.29875266912776603211E1);
      const Packet cst_cephes_log_q4 = pset1<Packet>(7.11544750618563894466E1);
      const Packet cst_cephes_log_q5 = pset1<Packet>(2.31251620126765340583E1);
      Packet e;
      x = pfrexp(x, e);
      Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);
      Packet tmp = pand(x, mask);
      x = psub(x, cst_1);
      e = psub(e, pand(cst_1, mask));
      x = padd(x, tmp);
      Packet x2 = pmul(x, x);
      Packet x3 = pmul(x2, x);
      Packet y, y1, y_;
      y = pmadd(cst_cephes_log_p0, x, cst_cephes_log_p1);
      y1 = pmadd(cst_cephes_log_p3, x, cst_cephes_log_p4);
      y = pmadd(y, x, cst_cephes_log_p2);
      y1 = pmadd(y1, x, cst_cephes_log_p5);
      y_ = pmadd(y, x3, y1);
      y = pmadd(cst_cephes_log_q0, x, cst_cephes_log_q1);
      y1 = pmadd(cst_cephes_log_q3, x, cst_cephes_log_q4);
      y = pmadd(y, x, cst_cephes_log_q2);
      y1 = pmadd(y1, x, cst_cephes_log_q5);
      y = pmadd(y, x3, y1);
      y_ = pmul(y_, x3);
      y = pdiv(y_, y);
      y = pmadd(cst_neg_half, x2, y);
      x = padd(x, y);
      if (base2) {
        const Packet cst_log2e = pset1<Packet>(
            static_cast<double>(1.442695040888963407359924681001892137426645954152985934135449406931109219L));
        x = pmadd(x, cst_log2e, e);
      } else {
        const Packet cst_ln2 = pset1<Packet>(
            static_cast<double>(0.693147180559945309417232121458176568075500134360255254120680009493393621L));
        x = pmadd(e, cst_ln2, x);
      }
      Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));
      Packet iszero_mask = pcmp_eq(_x, pzero(_x));
      Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);
      return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));
    }
    template <typename Packet>
    inline Packet plog_double(const Packet _x) {
      return plog_impl_double<Packet, false>(_x);
    }
    template <typename Packet>
    inline Packet plog2_double(const Packet _x) {
      return plog_impl_double<Packet, true>(_x);
    }
    template <typename Packet>
    Packet generic_plog1p(const Packet& x) {
      typedef typename unpacket_traits<Packet>::type ScalarType;
      const Packet one = pset1<Packet>(ScalarType(1));
      Packet xp1 = padd(x, one);
      Packet small_mask = pcmp_eq(xp1, one);
      Packet log1 = plog(xp1);
      Packet inf_mask = pcmp_eq(xp1, log1);
      Packet log_large = pmul(x, pdiv(log1, psub(xp1, one)));
      return pselect(por(small_mask, inf_mask), x, log_large);
    }
    template <typename Packet>
    Packet generic_expm1(const Packet& x) {
      typedef typename unpacket_traits<Packet>::type ScalarType;
      const Packet one = pset1<Packet>(ScalarType(1));
      const Packet neg_one = pset1<Packet>(ScalarType(-1));
      Packet u = pexp(x);
      Packet one_mask = pcmp_eq(u, one);
      Packet u_minus_one = psub(u, one);
      Packet neg_one_mask = pcmp_eq(u_minus_one, neg_one);
      Packet logu = plog(u);
      Packet pos_inf_mask = pcmp_eq(logu, u);
      Packet expm1 = pmul(u_minus_one, pdiv(x, logu));
      expm1 = pselect(pos_inf_mask, u, expm1);
      return pselect(one_mask, x, pselect(neg_one_mask, neg_one, expm1));
    }
    template <typename Packet>
    inline Packet pexp_float(const Packet _x) {
      const Packet cst_zero = pset1<Packet>(0.0f);
      const Packet cst_one = pset1<Packet>(1.0f);
      const Packet cst_half = pset1<Packet>(0.5f);
      const Packet cst_exp_hi = pset1<Packet>(88.723f);
      const Packet cst_exp_lo = pset1<Packet>(-104.f);
      const Packet cst_cephes_LOG2EF = pset1<Packet>(1.44269504088896341f);
      const Packet cst_p2 = pset1<Packet>(0.49999988079071044921875f);
      const Packet cst_p3 = pset1<Packet>(0.16666518151760101318359375f);
      const Packet cst_p4 = pset1<Packet>(4.166965186595916748046875e-2f);
      const Packet cst_p5 = pset1<Packet>(8.36894474923610687255859375e-3f);
      const Packet cst_p6 = pset1<Packet>(1.37449637986719608306884765625e-3f);
      Packet zero_mask = pcmp_lt(_x, cst_exp_lo);
      Packet x = pmin(_x, cst_exp_hi);
      Packet m = pfloor(pmadd(x, cst_cephes_LOG2EF, cst_half));
      const Packet cst_cephes_exp_C1 = pset1<Packet>(-0.693359375f);
      const Packet cst_cephes_exp_C2 = pset1<Packet>(2.12194440e-4f);
      Packet r = pmadd(m, cst_cephes_exp_C1, x);
      r = pmadd(m, cst_cephes_exp_C2, r);
      const Packet r2 = pmul(r, r);
      Packet p_even = pmadd(r2, cst_p6, cst_p4);
      const Packet p_odd = pmadd(r2, cst_p5, cst_p3);
      p_even = pmadd(r2, p_even, cst_p2);
      const Packet p_low = padd(r, cst_one);
      Packet y = pmadd(r, p_odd, p_even);
      y = pmadd(r2, y, p_low);
      return pselect(zero_mask, cst_zero, pmax(pldexp(y, m), _x));
    }
    template <typename Packet>
    inline Packet pexp_double(const Packet _x) {
      Packet x = _x;
      const Packet cst_zero = pset1<Packet>(0.0);
      const Packet cst_1 = pset1<Packet>(1.0);
      const Packet cst_2 = pset1<Packet>(2.0);
      const Packet cst_half = pset1<Packet>(0.5);
      const Packet cst_exp_hi = pset1<Packet>(709.784);
      const Packet cst_exp_lo = pset1<Packet>(-709.784);
      const Packet cst_cephes_LOG2EF = pset1<Packet>(1.4426950408889634073599);
      const Packet cst_cephes_exp_p0 = pset1<Packet>(1.26177193074810590878e-4);
      const Packet cst_cephes_exp_p1 = pset1<Packet>(3.02994407707441961300e-2);
      const Packet cst_cephes_exp_p2 = pset1<Packet>(9.99999999999999999910e-1);
      const Packet cst_cephes_exp_q0 = pset1<Packet>(3.00198505138664455042e-6);
      const Packet cst_cephes_exp_q1 = pset1<Packet>(2.52448340349684104192e-3);
      const Packet cst_cephes_exp_q2 = pset1<Packet>(2.27265548208155028766e-1);
      const Packet cst_cephes_exp_q3 = pset1<Packet>(2.00000000000000000009e0);
      const Packet cst_cephes_exp_C1 = pset1<Packet>(0.693145751953125);
      const Packet cst_cephes_exp_C2 = pset1<Packet>(1.42860682030941723212e-6);
      Packet tmp, fx;
      Packet zero_mask = pcmp_lt(_x, cst_exp_lo);
      x = pmin(x, cst_exp_hi);
      fx = pmadd(cst_cephes_LOG2EF, x, cst_half);
      fx = pfloor(fx);
      tmp = pmul(fx, cst_cephes_exp_C1);
      Packet z = pmul(fx, cst_cephes_exp_C2);
      x = psub(x, tmp);
      x = psub(x, z);
      Packet x2 = pmul(x, x);
      Packet px = cst_cephes_exp_p0;
      px = pmadd(px, x2, cst_cephes_exp_p1);
      px = pmadd(px, x2, cst_cephes_exp_p2);
      px = pmul(px, x);
      Packet qx = cst_cephes_exp_q0;
      qx = pmadd(qx, x2, cst_cephes_exp_q1);
      qx = pmadd(qx, x2, cst_cephes_exp_q2);
      qx = pmadd(qx, x2, cst_cephes_exp_q3);
      x = pdiv(px, psub(qx, px));
      x = pmadd(cst_2, x, cst_1);
      return pselect(zero_mask, cst_zero, pmax(pldexp(x, fx), _x));
    }
    inline float trig_reduce_huge(float xf, Eigen::numext::int32_t* quadrant) {
      using Eigen::numext::int32_t;
      using Eigen::numext::int64_t;
      using Eigen::numext::uint32_t;
      using Eigen::numext::uint64_t;
      const double pio2_62 = 3.4061215800865545e-19;
      const uint64_t zero_dot_five = uint64_t(1) << 61;
      static const uint32_t two_over_pi[] = {
          0x00000028, 0x000028be, 0x0028be60, 0x28be60db, 0xbe60db93, 0x60db9391, 0xdb939105, 0x9391054a, 0x91054a7f,
          0x054a7f09, 0x4a7f09d5, 0x7f09d5f4, 0x09d5f47d, 0xd5f47d4d, 0xf47d4d37, 0x7d4d3770, 0x4d377036, 0x377036d8,
          0x7036d8a5, 0x36d8a566, 0xd8a5664f, 0xa5664f10, 0x664f10e4, 0x4f10e410, 0x10e41000, 0xe4100000};
      uint32_t xi = numext::bit_cast<uint32_t>(xf);
      uint32_t e = (xi >> 23) - 118;
      xi = ((xi & 0x007fffffu) | 0x00800000u) << (e & 0x7);
      uint32_t i = e >> 3;
      uint32_t twoopi_1 = two_over_pi[i - 1];
      uint32_t twoopi_2 = two_over_pi[i + 3];
      uint32_t twoopi_3 = two_over_pi[i + 7];
      uint64_t p;
      p = uint64_t(xi) * twoopi_3;
      p = uint64_t(xi) * twoopi_2 + (p >> 32);
      p = (uint64_t(xi * twoopi_1) << 32) + p;
      uint64_t q = (p + zero_dot_five) >> 62;
      *quadrant = int(q);
      p -= q << 62;
      return float(double(int64_t(p)) * pio2_62);
    }
    template <bool ComputeSine, typename Packet>
    inline Packet psincos_float(const Packet& _x) {
      typedef typename unpacket_traits<Packet>::integer_packet PacketI;
      const Packet cst_2oPI = pset1<Packet>(0.636619746685028076171875f);
      const Packet cst_rounding_magic = pset1<Packet>(12582912);
      const PacketI csti_1 = pset1<PacketI>(1);
      const Packet cst_sign_mask = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0x80000000u));
      Packet x = pabs(_x);
      Packet y = pmul(x, cst_2oPI);
      Packet y_round = padd(y, cst_rounding_magic);
      __asm__("" : "+g,x"(y_round));
      PacketI y_int = preinterpret<PacketI>(y_round);
      y = psub(y_round, cst_rounding_magic);
      const float huge_th = ComputeSine ? 25966.f : 18838.f;
      x = pmadd(y, pset1<Packet>(-1.5703125), x);
      __asm__("" : "+g,x"(x));
      x = pmadd(y, pset1<Packet>(-0.000483989715576171875), x);
      __asm__("" : "+g,x"(x));
      x = pmadd(y, pset1<Packet>(1.62865035235881805419921875e-07), x);
      x = pmadd(y, pset1<Packet>(5.5644315544167710640977020375430583953857421875e-11), x);
      if (predux_any(pcmp_le(pset1<Packet>(huge_th), pabs(_x)))) {
        const int PacketSize = unpacket_traits<Packet>::size;
        alignas(sizeof(Packet)) float vals[PacketSize];
        alignas(sizeof(Packet)) float x_cpy[PacketSize];
        alignas(sizeof(Packet)) Eigen::numext::int32_t y_int2[PacketSize];
        pstoreu(vals, pabs(_x));
        pstoreu(x_cpy, x);
        pstoreu(y_int2, y_int);
        for (int k = 0; k < PacketSize; ++k) {
          float val = vals[k];
          if (val >= huge_th && (numext::isfinite)(val))
            x_cpy[k] = trig_reduce_huge(val, &y_int2[k]);
        }
        x = ploadu<Packet>(x_cpy);
        y_int = ploadu<PacketI>(y_int2);
      }
      Packet sign_bit = ComputeSine ? pxor(_x, preinterpret<Packet>(plogical_shift_left<30>(y_int)))
                                    : preinterpret<Packet>(plogical_shift_left<30>(padd(y_int, csti_1)));
      sign_bit = pand(sign_bit, cst_sign_mask);
      Packet poly_mask = preinterpret<Packet>(pcmp_eq(pand(y_int, csti_1), pzero(y_int)));
      Packet x2 = pmul(x, x);
      Packet y1 = pset1<Packet>(2.4372266125283204019069671630859375e-05f);
      y1 = pmadd(y1, x2, pset1<Packet>(-0.00138865201734006404876708984375f));
      y1 = pmadd(y1, x2, pset1<Packet>(0.041666619479656219482421875f));
      y1 = pmadd(y1, x2, pset1<Packet>(-0.5f));
      y1 = pmadd(y1, x2, pset1<Packet>(1.f));
      Packet y2 = pset1<Packet>(-0.0001959234114083702898469196984621021329076029360294342041015625f);
      y2 = pmadd(y2, x2, pset1<Packet>(0.0083326873655616851693794799871284340042620897293090820312500000f));
      y2 = pmadd(y2, x2, pset1<Packet>(-0.1666666203982298255503735617821803316473960876464843750000000000f));
      y2 = pmul(y2, x2);
      y2 = pmadd(y2, x, x);
      y = ComputeSine ? pselect(poly_mask, y2, y1) : pselect(poly_mask, y1, y2);
      return pxor(y, sign_bit);
    }
    template <typename Packet>
    inline Packet psin_float(const Packet& x) {
      return psincos_float<true>(x);
    }
    template <typename Packet>
    inline Packet pcos_float(const Packet& x) {
      return psincos_float<false>(x);
    }
    template <typename Packet>
    inline Packet pacos_float(const Packet& x_in) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
      const Packet cst_one = pset1<Packet>(Scalar(1));
      const Packet cst_pi =
          pset1<Packet>(Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L));
      const Packet p6 = pset1<Packet>(Scalar(2.26911413483321666717529296875e-3));
      const Packet p5 = pset1<Packet>(Scalar(-1.1063250713050365447998046875e-2));
      const Packet p4 = pset1<Packet>(Scalar(2.680264413356781005859375e-2));
      const Packet p3 = pset1<Packet>(Scalar(-4.87488098442554473876953125e-2));
      const Packet p2 = pset1<Packet>(Scalar(8.874166011810302734375e-2));
      const Packet p1 = pset1<Packet>(Scalar(-0.2145837843418121337890625));
      const Packet p0 = pset1<Packet>(Scalar(1.57079613208770751953125));
      const Packet neg_mask = pcmp_lt(x_in, pzero(x_in));
      Packet x = pabs(x_in);
      const Packet invalid_mask = pcmp_lt(pset1<Packet>(1.0f), x);
      Packet x2 = pmul(x_in, x_in);
      Packet p_even = pmadd(p6, x2, p4);
      Packet p_odd = pmadd(p5, x2, p3);
      p_even = pmadd(p_even, x2, p2);
      p_odd = pmadd(p_odd, x2, p1);
      p_even = pmadd(p_even, x2, p0);
      Packet p = pmadd(p_odd, x, p_even);
      Packet denom = psqrt(psub(cst_one, x));
      Packet result = pmul(denom, p);
      result = pselect(neg_mask, psub(cst_pi, result), result);
      return pselect(invalid_mask, pset1<Packet>(std::numeric_limits<float>::quiet_NaN()), result);
    }
    template <typename Packet>
    inline Packet pasin_float(const Packet& x_in) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
      const Packet p9 = pset1<Packet>(Scalar(5.08838854730129241943359375e-2f));
      const Packet p7 = pset1<Packet>(Scalar(3.95139865577220916748046875e-2f));
      const Packet p5 = pset1<Packet>(Scalar(7.550220191478729248046875e-2f));
      const Packet p3 = pset1<Packet>(Scalar(0.16664917767047882080078125f));
      const Packet p1 = pset1<Packet>(Scalar(1.00000011920928955078125f));
      const Packet neg_mask = pcmp_lt(x_in, pzero(x_in));
      Packet x = pabs(x_in);
      const Packet invalid_mask = pcmp_lt(pset1<Packet>(1.0f), x);
      const Packet cst_half = pset1<Packet>(Scalar(0.5f));
      const Packet cst_two = pset1<Packet>(Scalar(2));
      Packet x_large = psqrt(pnmadd(cst_half, x, cst_half));
      const Packet large_mask = pcmp_lt(cst_half, x);
      x = pselect(large_mask, x_large, x);
      Packet x2 = pmul(x, x);
      Packet p = pmadd(p9, x2, p7);
      p = pmadd(p, x2, p5);
      p = pmadd(p, x2, p3);
      p = pmadd(p, x2, p1);
      p = pmul(p, x);
      constexpr float kPiOverTwo =
          static_cast<float>(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 2);
      Packet p_large = pnmadd(cst_two, p, pset1<Packet>(kPiOverTwo));
      p = pselect(large_mask, p_large, p);
      p = pselect(neg_mask, pnegate(p), p);
      return pselect(invalid_mask, pset1<Packet>(std::numeric_limits<float>::quiet_NaN()), p);
    }
    template <typename Packet>
    inline Packet patan_reduced_float(const Packet& x) {
      const Packet q0 = pset1<Packet>(-0.3333314359188079833984375f);
      const Packet q2 = pset1<Packet>(0.19993579387664794921875f);
      const Packet q4 = pset1<Packet>(-0.14209578931331634521484375f);
      const Packet q6 = pset1<Packet>(0.1066047251224517822265625f);
      const Packet q8 = pset1<Packet>(-7.5408883392810821533203125e-2f);
      const Packet q10 = pset1<Packet>(4.3082617223262786865234375e-2f);
      const Packet q12 = pset1<Packet>(-1.62907354533672332763671875e-2f);
      const Packet q14 = pset1<Packet>(2.90188402868807315826416015625e-3f);
      const Packet x2 = pmul(x, x);
      const Packet x4 = pmul(x2, x2);
      Packet q_odd = pmadd(q14, x4, q10);
      Packet q_even = pmadd(q12, x4, q8);
      q_odd = pmadd(q_odd, x4, q6);
      q_even = pmadd(q_even, x4, q4);
      q_odd = pmadd(q_odd, x4, q2);
      q_even = pmadd(q_even, x4, q0);
      const Packet q = pmadd(q_odd, x2, q_even);
      return pmadd(q, pmul(x, x2), x);
    }
    template <typename Packet>
    inline Packet patan_float(const Packet& x_in) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
      const Packet cst_one = pset1<Packet>(1.0f);
      constexpr float kPiOverTwo =
          static_cast<float>(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 2);
      const Packet neg_mask = pcmp_lt(x_in, pzero(x_in));
      const Packet large_mask = pcmp_lt(cst_one, pabs(x_in));
      const Packet large_shift = pselect(neg_mask, pset1<Packet>(-kPiOverTwo), pset1<Packet>(kPiOverTwo));
      const Packet x = pselect(large_mask, preciprocal(x_in), x_in);
      const Packet p = patan_reduced_float(x);
      return pselect(large_mask, psub(large_shift, p), p);
    }
    template <typename Packet>
    inline Packet patan_reduced_double(const Packet& x) {
      const Packet q0 = pset1<Packet>(-0.33333333333330028569463365784031338989734649658203);
      const Packet q2 = pset1<Packet>(0.199999999990664090177006073645316064357757568359375);
      const Packet q4 = pset1<Packet>(-0.142857141937123677255527809393242932856082916259766);
      const Packet q6 = pset1<Packet>(0.111111065991039953404495577160560060292482376098633);
      const Packet q8 = pset1<Packet>(-9.0907812986129224452902519715280504897236824035645e-2);
      const Packet q10 = pset1<Packet>(7.6900542950704739442180368769186316058039665222168e-2);
      const Packet q12 = pset1<Packet>(-6.6410112986494976294871150912513257935643196105957e-2);
      const Packet q14 = pset1<Packet>(5.6920144995467943094258345126945641823112964630127e-2);
      const Packet q16 = pset1<Packet>(-4.3577020814990513608577771265117917209863662719727e-2);
      const Packet q18 = pset1<Packet>(2.1244050233624342527427586446719942614436149597168e-2);
      const Packet x2 = pmul(x, x);
      const Packet x4 = pmul(x2, x2);
      Packet q_odd = pmadd(q18, x4, q14);
      Packet q_even = pmadd(q16, x4, q12);
      q_odd = pmadd(q_odd, x4, q10);
      q_even = pmadd(q_even, x4, q8);
      q_odd = pmadd(q_odd, x4, q6);
      q_even = pmadd(q_even, x4, q4);
      q_odd = pmadd(q_odd, x4, q2);
      q_even = pmadd(q_even, x4, q0);
      const Packet p = pmadd(q_odd, x2, q_even);
      return pmadd(p, pmul(x, x2), x);
    }
    template <typename Packet>
    inline Packet patan_double(const Packet& x_in) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static_assert(std::is_same<Scalar, double>::value, "Scalar type must be double");
      const Packet cst_one = pset1<Packet>(1.0);
      constexpr double kPiOverTwo =
          static_cast<double>(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 2);
      const Packet cst_pi_over_two = pset1<Packet>(kPiOverTwo);
      constexpr double kPiOverFour =
          static_cast<double>(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 4);
      const Packet cst_pi_over_four = pset1<Packet>(kPiOverFour);
      const Packet cst_large = pset1<Packet>(2.4142135623730950488016887);
      const Packet cst_medium = pset1<Packet>(0.4142135623730950488016887);
      const Packet neg_mask = pcmp_lt(x_in, pzero(x_in));
      Packet x = pabs(x_in);
      const Packet large_mask = pcmp_lt(cst_large, x);
      x = pselect(large_mask, preciprocal(x), x);
      const Packet medium_mask = pandnot(pcmp_lt(cst_medium, x), large_mask);
      x = pselect(medium_mask, pdiv(psub(x, cst_one), padd(x, cst_one)), x);
      Packet p = patan_reduced_double(x);
      p = pselect(large_mask, psub(cst_pi_over_two, p), p);
      p = pselect(medium_mask, padd(cst_pi_over_four, p), p);
      return pselect(neg_mask, pnegate(p), p);
    }
    template <typename Packet>
    inline Packet pdiv_complex(const Packet& x, const Packet& y) {
      typedef typename unpacket_traits<Packet>::as_real RealPacket;
      const RealPacket y_abs = pabs(y.v);
      const RealPacket y_abs_flip = pcplxflip(Packet(y_abs)).v;
      const RealPacket y_max = pmax(y_abs, y_abs_flip);
      const RealPacket y_scaled = pdiv(y.v, y_max);
      const RealPacket y_scaled_sq = pmul(y_scaled, y_scaled);
      const RealPacket denom = padd(y_scaled_sq, pcplxflip(Packet(y_scaled_sq)).v);
      Packet result_scaled = pmul(x, pconj(Packet(y_scaled)));
      result_scaled = Packet(pdiv(result_scaled.v, denom));
      return Packet(pdiv(result_scaled.v, y_max));
    }
    template <typename Packet>
    inline Packet psqrt_complex(const Packet& a) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      typedef typename Scalar::value_type RealScalar;
      typedef typename unpacket_traits<Packet>::as_real RealPacket;
      RealPacket a_abs = pabs(a.v);
      RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;
      RealPacket a_max = pmax(a_abs, a_abs_flip);
      RealPacket a_min = pmin(a_abs, a_abs_flip);
      RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));
      RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));
      RealPacket r = pdiv(a_min, a_max);
      const RealPacket cst_one = pset1<RealPacket>(RealScalar(1));
      RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));
      l = pselect(a_min_zero_mask, a_max, l);
      const RealPacket cst_half = pset1<RealPacket>(RealScalar(0.5));
      Packet rho;
      rho.v = psqrt(pmul(cst_half, padd(a_abs, l)));
      RealPacket eta = pandnot(pmul(cst_half, pdiv(a.v, pcplxflip(rho).v)), a_max_zero_mask);
      RealPacket real_mask = peven_mask(a.v);
      Packet positive_real_result;
      positive_real_result.v = pselect(real_mask, rho.v, eta);
      const RealPacket cst_imag_sign_mask = pset1<Packet>(Scalar(RealScalar(0.0), RealScalar(-0.0))).v;
      RealPacket imag_signs = pand(a.v, cst_imag_sign_mask);
      Packet negative_real_result;
      negative_real_result.v = por(pabs(pcplxflip(positive_real_result).v), imag_signs);
      Packet negative_real_mask;
      negative_real_mask.v = pcmp_lt(pand(real_mask, a.v), pzero(a.v));
      negative_real_mask.v = por(negative_real_mask.v, pcplxflip(negative_real_mask).v);
      Packet result = pselect(negative_real_mask, negative_real_result, positive_real_result);
      const RealPacket cst_pos_inf = pset1<RealPacket>(NumTraits<RealScalar>::infinity());
      Packet is_inf;
      is_inf.v = pcmp_eq(a_abs, cst_pos_inf);
      Packet is_real_inf;
      is_real_inf.v = pand(is_inf.v, real_mask);
      is_real_inf = por(is_real_inf, pcplxflip(is_real_inf));
      Packet real_inf_result;
      real_inf_result.v = pmul(a_abs, pset1<Packet>(Scalar(RealScalar(1.0), RealScalar(0.0))).v);
      real_inf_result.v = pselect(negative_real_mask.v, pcplxflip(real_inf_result).v, real_inf_result.v);
      Packet is_imag_inf;
      is_imag_inf.v = pandnot(is_inf.v, real_mask);
      is_imag_inf = por(is_imag_inf, pcplxflip(is_imag_inf));
      Packet imag_inf_result;
      imag_inf_result.v = por(pand(cst_pos_inf, real_mask), pandnot(a.v, real_mask));
      return pselect(is_imag_inf, imag_inf_result, pselect(is_real_inf, real_inf_result, result));
    }
    template <typename Packet>
    struct psign_impl<Packet,
                      std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
                                       !NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
      static inline Packet run(const Packet& a) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet cst_one = pset1<Packet>(Scalar(1));
        const Packet cst_minus_one = pset1<Packet>(Scalar(-1));
        const Packet cst_zero = pzero(a);
        const Packet not_nan_mask = pcmp_eq(a, a);
        const Packet positive_mask = pcmp_lt(cst_zero, a);
        const Packet positive = pand(positive_mask, cst_one);
        const Packet negative_mask = pcmp_lt(a, cst_zero);
        const Packet negative = pand(negative_mask, cst_minus_one);
        return pselect(not_nan_mask, por(positive, negative), a);
      }
    };
    template <typename Packet>
    struct psign_impl<Packet,
                      std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
                                       NumTraits<typename unpacket_traits<Packet>::type>::IsSigned &&
                                       NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
      static inline Packet run(const Packet& a) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet cst_one = pset1<Packet>(Scalar(1));
        const Packet cst_minus_one = pset1<Packet>(Scalar(-1));
        const Packet cst_zero = pzero(a);
        const Packet positive_mask = pcmp_lt(cst_zero, a);
        const Packet positive = pand(positive_mask, cst_one);
        const Packet negative_mask = pcmp_lt(a, cst_zero);
        const Packet negative = pand(negative_mask, cst_minus_one);
        return por(positive, negative);
      }
    };
    template <typename Packet>
    struct psign_impl<Packet,
                      std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
                                       !NumTraits<typename unpacket_traits<Packet>::type>::IsSigned &&
                                       NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
      static inline Packet run(const Packet& a) {
        using Scalar = typename unpacket_traits<Packet>::type;
        const Packet cst_one = pset1<Packet>(Scalar(1));
        const Packet cst_zero = pzero(a);
        const Packet zero_mask = pcmp_eq(cst_zero, a);
        return pandnot(cst_one, zero_mask);
      }
    };
    template <typename Packet>
    struct psign_impl<Packet,
                      std::enable_if_t<NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
                                       unpacket_traits<Packet>::vectorizable>> {
      static inline Packet run(const Packet& a) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        typedef typename Scalar::value_type RealScalar;
        typedef typename unpacket_traits<Packet>::as_real RealPacket;
        RealPacket a_abs = pabs(a.v);
        RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;
        RealPacket a_max = pmax(a_abs, a_abs_flip);
        RealPacket a_min = pmin(a_abs, a_abs_flip);
        RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));
        RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));
        RealPacket r = pdiv(a_min, a_max);
        const RealPacket cst_one = pset1<RealPacket>(RealScalar(1));
        RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));
        l = pselect(a_min_zero_mask, a_max, l);
        RealPacket sign_as_real = pandnot(pdiv(a.v, l), a_max_zero_mask);
        Packet sign;
        sign.v = sign_as_real;
        return sign;
      }
    };
    template <typename Packet>
    inline void absolute_split(const Packet& x, Packet& n, Packet& r) {
      n = pround(x);
      r = psub(x, n);
    }
    template <typename Packet>
    inline void fast_twosum(const Packet& x, const Packet& y, Packet& s_hi, Packet& s_lo) {
      s_hi = padd(x, y);
      const Packet t = psub(s_hi, x);
      s_lo = psub(y, t);
    }
    template <typename Packet>
    inline void veltkamp_splitting(const Packet& x, Packet& x_hi, Packet& x_lo) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      constexpr int shift = (NumTraits<Scalar>::digits() + 1) / 2;
      const Scalar shift_scale = Scalar(uint64_t(1) << shift);
      const Packet gamma = pmul(pset1<Packet>(shift_scale + Scalar(1)), x);
      Packet rho = psub(x, gamma);
      x_hi = padd(rho, gamma);
      x_lo = psub(x, x_hi);
    }
    template <typename Packet>
    inline void twoprod(const Packet& x, const Packet& y, Packet& p_hi, Packet& p_lo) {
      Packet x_hi, x_lo, y_hi, y_lo;
      veltkamp_splitting(x, x_hi, x_lo);
      veltkamp_splitting(y, y_hi, y_lo);
      p_hi = pmul(x, y);
      p_lo = pmadd(x_hi, y_hi, pnegate(p_hi));
      p_lo = pmadd(x_hi, y_lo, p_lo);
      p_lo = pmadd(x_lo, y_hi, p_lo);
      p_lo = pmadd(x_lo, y_lo, p_lo);
    }
    template <typename Packet>
    inline void twosum(
        const Packet& x_hi, const Packet& x_lo, const Packet& y_hi, const Packet& y_lo, Packet& s_hi, Packet& s_lo) {
      const Packet x_greater_mask = pcmp_lt(pabs(y_hi), pabs(x_hi));
      Packet r_hi_1, r_lo_1;
      fast_twosum(x_hi, y_hi, r_hi_1, r_lo_1);
      Packet r_hi_2, r_lo_2;
      fast_twosum(y_hi, x_hi, r_hi_2, r_lo_2);
      const Packet r_hi = pselect(x_greater_mask, r_hi_1, r_hi_2);
      const Packet s1 = padd(padd(y_lo, r_lo_1), x_lo);
      const Packet s2 = padd(padd(x_lo, r_lo_2), y_lo);
      const Packet s = pselect(x_greater_mask, s1, s2);
      fast_twosum(r_hi, s, s_hi, s_lo);
    }
    template <typename Packet>
    inline void fast_twosum(
        const Packet& x_hi, const Packet& x_lo, const Packet& y_hi, const Packet& y_lo, Packet& s_hi, Packet& s_lo) {
      Packet r_hi, r_lo;
      fast_twosum(x_hi, y_hi, r_hi, r_lo);
      const Packet s = padd(padd(y_lo, r_lo), x_lo);
      fast_twosum(r_hi, s, s_hi, s_lo);
    }
    template <typename Packet>
    inline void fast_twosum(const Packet& x, const Packet& y_hi, const Packet& y_lo, Packet& s_hi, Packet& s_lo) {
      Packet r_hi, r_lo;
      fast_twosum(x, y_hi, r_hi, r_lo);
      const Packet s = padd(y_lo, r_lo);
      fast_twosum(r_hi, s, s_hi, s_lo);
    }
    template <typename Packet>
    inline void twoprod(const Packet& x_hi, const Packet& x_lo, const Packet& y, Packet& p_hi, Packet& p_lo) {
      Packet c_hi, c_lo1;
      twoprod(x_hi, y, c_hi, c_lo1);
      const Packet c_lo2 = pmul(x_lo, y);
      Packet t_hi, t_lo1;
      fast_twosum(c_hi, c_lo2, t_hi, t_lo1);
      const Packet t_lo2 = padd(t_lo1, c_lo1);
      fast_twosum(t_hi, t_lo2, p_hi, p_lo);
    }
    template <typename Packet>
    inline void twoprod(
        const Packet& x_hi, const Packet& x_lo, const Packet& y_hi, const Packet& y_lo, Packet& p_hi, Packet& p_lo) {
      Packet p_hi_hi, p_hi_lo;
      twoprod(x_hi, x_lo, y_hi, p_hi_hi, p_hi_lo);
      Packet p_lo_hi, p_lo_lo;
      twoprod(x_hi, x_lo, y_lo, p_lo_hi, p_lo_lo);
      fast_twosum(p_hi_hi, p_hi_lo, p_lo_hi, p_lo_lo, p_hi, p_lo);
    }
    template <typename Packet>
    void doubleword_div_fp(const Packet& x_hi, const Packet& x_lo, const Packet& y, Packet& z_hi, Packet& z_lo) {
      const Packet t_hi = pdiv(x_hi, y);
      Packet pi_hi, pi_lo;
      twoprod(t_hi, y, pi_hi, pi_lo);
      const Packet delta_hi = psub(x_hi, pi_hi);
      const Packet delta_t = psub(delta_hi, pi_lo);
      const Packet delta = padd(delta_t, x_lo);
      const Packet t_lo = pdiv(delta, y);
      fast_twosum(t_hi, t_lo, z_hi, z_lo);
    }
    template <typename Scalar>
    struct accurate_log2 {
      template <typename Packet>
      inline void operator()(const Packet& x, Packet& log2_x_hi, Packet& log2_x_lo) {
        log2_x_hi = plog2(x);
        log2_x_lo = pzero(x);
      }
    };
    template <>
    struct accurate_log2<float> {
      template <typename Packet>
      inline void operator()(const Packet& z, Packet& log2_x_hi, Packet& log2_x_lo) {
        const Packet p6 = pset1<Packet>(9.703654795885e-2f);
        const Packet p5 = pset1<Packet>(-0.1690667718648f);
        const Packet p4 = pset1<Packet>(0.1720575392246f);
        const Packet p3 = pset1<Packet>(-0.1789081543684f);
        const Packet p2 = pset1<Packet>(0.2050433009862f);
        const Packet p1 = pset1<Packet>(-0.2404672354459f);
        const Packet p0 = pset1<Packet>(0.2885761857032f);
        const Packet C3_hi = pset1<Packet>(-0.360674142838f);
        const Packet C3_lo = pset1<Packet>(-6.13283912543e-09f);
        const Packet C2_hi = pset1<Packet>(0.480897903442f);
        const Packet C2_lo = pset1<Packet>(-1.44861207474e-08f);
        const Packet C1_hi = pset1<Packet>(-0.721347510815f);
        const Packet C1_lo = pset1<Packet>(-4.84483164698e-09f);
        const Packet C0_hi = pset1<Packet>(1.44269502163f);
        const Packet C0_lo = pset1<Packet>(2.01711713999e-08f);
        const Packet one = pset1<Packet>(1.0f);
        const Packet x = psub(z, one);
        Packet x2 = pmul(x, x);
        Packet p_even = pmadd(p6, x2, p4);
        p_even = pmadd(p_even, x2, p2);
        p_even = pmadd(p_even, x2, p0);
        Packet p_odd = pmadd(p5, x2, p3);
        p_odd = pmadd(p_odd, x2, p1);
        Packet p = pmadd(p_odd, x, p_even);
        Packet q_hi, q_lo;
        Packet t_hi, t_lo;
        twoprod(p, x, t_hi, t_lo);
        fast_twosum(C3_hi, C3_lo, t_hi, t_lo, q_hi, q_lo);
        twoprod(q_hi, q_lo, x, t_hi, t_lo);
        fast_twosum(C2_hi, C2_lo, t_hi, t_lo, q_hi, q_lo);
        twoprod(q_hi, q_lo, x, t_hi, t_lo);
        fast_twosum(C1_hi, C1_lo, t_hi, t_lo, q_hi, q_lo);
        twoprod(q_hi, q_lo, x, t_hi, t_lo);
        fast_twosum(C0_hi, C0_lo, t_hi, t_lo, q_hi, q_lo);
        twoprod(q_hi, q_lo, x, log2_x_hi, log2_x_lo);
      }
    };
    template <>
    struct accurate_log2<double> {
      template <typename Packet>
      inline void operator()(const Packet& x, Packet& log2_x_hi, Packet& log2_x_lo) {
        const Packet q12 = pset1<Packet>(2.87074255468000586e-9);
        const Packet q10 = pset1<Packet>(2.38957980901884082e-8);
        const Packet q8 = pset1<Packet>(2.31032094540014656e-7);
        const Packet q6 = pset1<Packet>(2.27279857398537278e-6);
        const Packet q4 = pset1<Packet>(2.31271023278625638e-5);
        const Packet q2 = pset1<Packet>(2.47556738444535513e-4);
        const Packet q0 = pset1<Packet>(2.88543873228900172e-3);
        const Packet C_hi = pset1<Packet>(0.0400377511598501157);
        const Packet C_lo = pset1<Packet>(-4.77726582251425391e-19);
        const Packet one = pset1<Packet>(1.0);
        const Packet cst_2_log2e_hi = pset1<Packet>(2.88539008177792677);
        const Packet cst_2_log2e_lo = pset1<Packet>(4.07660016854549667e-17);
        Packet t_hi, t_lo;
        twoprod(cst_2_log2e_hi, cst_2_log2e_lo, psub(x, one), t_hi, t_lo);
        Packet r_hi, r_lo;
        doubleword_div_fp(t_hi, t_lo, padd(x, one), r_hi, r_lo);
        Packet r2_hi, r2_lo;
        twoprod(r_hi, r_lo, r_hi, r_lo, r2_hi, r2_lo);
        Packet r4_hi, r4_lo;
        twoprod(r2_hi, r2_lo, r2_hi, r2_lo, r4_hi, r4_lo);
        Packet q_even = pmadd(q12, r4_hi, q8);
        Packet q_odd = pmadd(q10, r4_hi, q6);
        q_even = pmadd(q_even, r4_hi, q4);
        q_odd = pmadd(q_odd, r4_hi, q2);
        q_even = pmadd(q_even, r4_hi, q0);
        Packet q = pmadd(q_odd, r2_hi, q_even);
        Packet p_hi, p_lo;
        twoprod(r2_hi, r2_lo, q, p_hi, p_lo);
        Packet p1_hi, p1_lo;
        fast_twosum(C_hi, C_lo, p_hi, p_lo, p1_hi, p1_lo);
        Packet p2_hi, p2_lo;
        twoprod(r2_hi, r2_lo, p1_hi, p1_lo, p2_hi, p2_lo);
        Packet p3_hi, p3_lo;
        fast_twosum(one, p2_hi, p2_lo, p3_hi, p3_lo);
        twoprod(p3_hi, p3_lo, r_hi, r_lo, log2_x_hi, log2_x_lo);
      }
    };
    template <typename Scalar>
    struct fast_accurate_exp2 {
      template <typename Packet>
      inline Packet operator()(const Packet& x) {
        return pexp(pmul(
            pset1<Packet>(Scalar(0.693147180559945309417232121458176568075500134360255254120680009493393621L)), x));
      }
    };
    template <>
    struct fast_accurate_exp2<float> {
      template <typename Packet>
      inline Packet operator()(const Packet& x) {
        const Packet p4 = pset1<Packet>(1.539513905e-4f);
        const Packet p3 = pset1<Packet>(1.340007293e-3f);
        const Packet p2 = pset1<Packet>(9.618283249e-3f);
        const Packet p1 = pset1<Packet>(5.550328270e-2f);
        const Packet p0 = pset1<Packet>(0.2402264923f);
        const Packet C_hi = pset1<Packet>(0.6931471825f);
        const Packet C_lo = pset1<Packet>(2.36836577e-08f);
        const Packet one = pset1<Packet>(1.0f);
        Packet x2 = pmul(x, x);
        Packet p_even = pmadd(p4, x2, p2);
        Packet p_odd = pmadd(p3, x2, p1);
        p_even = pmadd(p_even, x2, p0);
        Packet p = pmadd(p_odd, x, p_even);
        Packet p_hi, p_lo;
        twoprod(p, x, p_hi, p_lo);
        Packet q1_hi, q1_lo;
        twosum(p_hi, p_lo, C_hi, C_lo, q1_hi, q1_lo);
        Packet q2_hi, q2_lo;
        twoprod(q1_hi, q1_lo, x, q2_hi, q2_lo);
        Packet q3_hi, q3_lo;
        fast_twosum(one, q2_hi, q3_hi, q3_lo);
        return padd(q3_hi, padd(q2_lo, q3_lo));
      }
    };
    template <>
    struct fast_accurate_exp2<double> {
      template <typename Packet>
      inline Packet operator()(const Packet& x) {
        const Packet p9 = pset1<Packet>(4.431642109085495276e-10);
        const Packet p8 = pset1<Packet>(7.073829923303358410e-9);
        const Packet p7 = pset1<Packet>(1.017822306737031311e-7);
        const Packet p6 = pset1<Packet>(1.321543498017646657e-6);
        const Packet p5 = pset1<Packet>(1.525273342728892877e-5);
        const Packet p4 = pset1<Packet>(1.540353045780084423e-4);
        const Packet p3 = pset1<Packet>(1.333355814685869807e-3);
        const Packet p2 = pset1<Packet>(9.618129107593478832e-3);
        const Packet p1 = pset1<Packet>(5.550410866481961247e-2);
        const Packet p0 = pset1<Packet>(0.240226506959101332);
        const Packet C_hi = pset1<Packet>(0.693147180559945286);
        const Packet C_lo = pset1<Packet>(4.81927865669806721e-17);
        const Packet one = pset1<Packet>(1.0);
        Packet x2 = pmul(x, x);
        Packet p_even = pmadd(p8, x2, p6);
        Packet p_odd = pmadd(p9, x2, p7);
        p_even = pmadd(p_even, x2, p4);
        p_odd = pmadd(p_odd, x2, p5);
        p_even = pmadd(p_even, x2, p2);
        p_odd = pmadd(p_odd, x2, p3);
        p_even = pmadd(p_even, x2, p0);
        p_odd = pmadd(p_odd, x2, p1);
        Packet p = pmadd(p_odd, x, p_even);
        Packet p_hi, p_lo;
        twoprod(p, x, p_hi, p_lo);
        Packet q1_hi, q1_lo;
        twosum(p_hi, p_lo, C_hi, C_lo, q1_hi, q1_lo);
        Packet q2_hi, q2_lo;
        twoprod(q1_hi, q1_lo, x, q2_hi, q2_lo);
        Packet q3_hi, q3_lo;
        fast_twosum(one, q2_hi, q3_hi, q3_lo);
        return padd(q3_hi, padd(q2_lo, q3_lo));
      }
    };
    template <typename Packet>
    inline Packet generic_pow_impl(const Packet& x, const Packet& y) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      Packet e_x;
      Packet m_x = pfrexp(x, e_x);
      constexpr Scalar sqrt_half = Scalar(0.70710678118654752440);
      const Packet m_x_scale_mask = pcmp_lt(m_x, pset1<Packet>(sqrt_half));
      m_x = pselect(m_x_scale_mask, pmul(pset1<Packet>(Scalar(2)), m_x), m_x);
      e_x = pselect(m_x_scale_mask, psub(e_x, pset1<Packet>(Scalar(1))), e_x);
      Packet rx_hi, rx_lo;
      accurate_log2<Scalar>()(m_x, rx_hi, rx_lo);
      Packet f1_hi, f1_lo, f2_hi, f2_lo;
      twoprod(e_x, y, f1_hi, f1_lo);
      twoprod(rx_hi, rx_lo, y, f2_hi, f2_lo);
      Packet f_hi, f_lo;
      fast_twosum(f1_hi, f1_lo, f2_hi, f2_lo, f_hi, f_lo);
      Packet n_z, r_z;
      absolute_split(f_hi, n_z, r_z);
      r_z = padd(r_z, f_lo);
      Packet n_r;
      absolute_split(r_z, n_r, r_z);
      n_z = padd(n_z, n_r);
      const Packet e_r = fast_accurate_exp2<Scalar>()(r_z);
      return pldexp(e_r, n_z);
    }
    template <typename Packet>
    inline Packet generic_pow(const Packet& x, const Packet& y) {
      typedef typename unpacket_traits<Packet>::type Scalar;
      const Packet cst_pos_inf = pset1<Packet>(NumTraits<Scalar>::infinity());
      const Packet cst_neg_inf = pset1<Packet>(-NumTraits<Scalar>::infinity());
      const Packet cst_zero = pset1<Packet>(Scalar(0));
      const Packet cst_one = pset1<Packet>(Scalar(1));
      const Packet cst_nan = pset1<Packet>(NumTraits<Scalar>::quiet_NaN());
      const Packet abs_x = pabs(x);
      const Packet abs_x_is_zero = pcmp_eq(abs_x, cst_zero);
      const Packet x_has_signbit = pcmp_eq(por(pand(x, cst_neg_inf), cst_pos_inf), cst_neg_inf);
      const Packet x_is_neg = pandnot(x_has_signbit, abs_x_is_zero);
      const Packet x_is_neg_zero = pand(x_has_signbit, abs_x_is_zero);
      const Packet abs_x_is_inf = pcmp_eq(abs_x, cst_pos_inf);
      const Packet abs_x_is_one = pcmp_eq(abs_x, cst_one);
      const Packet abs_x_is_gt_one = pcmp_lt(cst_one, abs_x);
      const Packet abs_x_is_lt_one = pcmp_lt(abs_x, cst_one);
      const Packet x_is_one = pandnot(abs_x_is_one, x_is_neg);
      const Packet x_is_neg_one = pand(abs_x_is_one, x_is_neg);
      const Packet x_is_nan = pandnot(ptrue(x), pcmp_eq(x, x));
      const Packet abs_y = pabs(y);
      const Packet y_is_one = pcmp_eq(y, cst_one);
      const Packet abs_y_is_zero = pcmp_eq(abs_y, cst_zero);
      const Packet y_is_neg = pcmp_lt(y, cst_zero);
      const Packet y_is_pos = pandnot(ptrue(y), por(abs_y_is_zero, y_is_neg));
      const Packet y_is_nan = pandnot(ptrue(y), pcmp_eq(y, y));
      const Packet abs_y_is_inf = pcmp_eq(abs_y, cst_pos_inf);
      constexpr Scalar huge_exponent =
          (NumTraits<Scalar>::max_exponent() *
           Scalar(0.693147180559945309417232121458176568075500134360255254120680009493393621L)) /
          NumTraits<Scalar>::epsilon();
      const Packet abs_y_is_huge = pcmp_le(pset1<Packet>(huge_exponent), pabs(y));
      const Packet y_is_int = pcmp_eq(pfloor(y), y);
      const Packet y_div_2 = pmul(y, pset1<Packet>(Scalar(0.5)));
      const Packet y_is_even = pcmp_eq(pround(y_div_2), y_div_2);
      const Packet invalid_negative_x = pandnot(pandnot(pandnot(x_is_neg, abs_x_is_inf), y_is_int), abs_y_is_inf);
      const Packet pow_is_nan = por(invalid_negative_x, por(x_is_nan, y_is_nan));
      const Packet pow_is_one = por(por(x_is_one, abs_y_is_zero),
                                    pand(x_is_neg_one, por(abs_y_is_inf, pandnot(y_is_even, invalid_negative_x))));
      const Packet pow_is_zero = por(por(por(pand(abs_x_is_zero, y_is_pos), pand(abs_x_is_inf, y_is_neg)),
                                         pand(pand(abs_x_is_lt_one, abs_y_is_huge), y_is_pos)),
                                     pand(pand(abs_x_is_gt_one, abs_y_is_huge), y_is_neg));
      const Packet pow_is_inf = por(por(por(pand(abs_x_is_zero, y_is_neg), pand(abs_x_is_inf, y_is_pos)),
                                        pand(pand(abs_x_is_lt_one, abs_y_is_huge), y_is_neg)),
                                    pand(pand(abs_x_is_gt_one, abs_y_is_huge), y_is_pos));
      const Packet inf_val =
          pselect(pandnot(pand(por(pand(abs_x_is_inf, x_is_neg), pand(x_is_neg_zero, y_is_neg)), y_is_int), y_is_even),
                  cst_neg_inf,
                  cst_pos_inf);
      const Packet negate_pow_abs = pandnot(x_is_neg, y_is_even);
      const Packet pow_abs = generic_pow_impl(abs_x, y);
      return pselect(
          y_is_one,
          x,
          pselect(
              pow_is_one,
              cst_one,
              pselect(pow_is_nan,
                      cst_nan,
                      pselect(pow_is_inf,
                              inf_val,
                              pselect(pow_is_zero, cst_zero, pselect(negate_pow_abs, pnegate(pow_abs), pow_abs))))));
    }
    template <typename Packet, int N>
    struct ppolevl {
      static inline Packet run(const Packet& x, const typename unpacket_traits<Packet>::type coeff[]) {
        static_assert((N > 0), "YOU_MADE_A_PROGRAMMING_MISTAKE");
        ;
        return pmadd(ppolevl<Packet, N - 1>::run(x, coeff), x, pset1<Packet>(coeff[N]));
      }
    };
    template <typename Packet>
    struct ppolevl<Packet, 0> {
      static inline Packet run(const Packet& x, const typename unpacket_traits<Packet>::type coeff[]) {
        Eigen::internal::ignore_unused_variable(x);
        ;
        return pset1<Packet>(coeff[0]);
      }
    };
    template <typename Packet, int N>
    struct pchebevl {
      static inline Packet run(Packet x, const typename unpacket_traits<Packet>::type coef[]) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        Packet b0 = pset1<Packet>(coef[0]);
        Packet b1 = pset1<Packet>(static_cast<Scalar>(0.f));
        Packet b2;
        for (int i = 1; i < N; i++) {
          b2 = b1;
          b1 = b0;
          b0 = psub(pmadd(x, b1, pset1<Packet>(coef[i])), b2);
        }
        return pmul(pset1<Packet>(static_cast<Scalar>(0.5f)), psub(b0, b2));
      }
    };
    namespace unary_pow {
      template <typename ScalarExponent, bool IsIntegerAtCompileTime = NumTraits<ScalarExponent>::IsInteger>
      struct is_odd {
        static inline ScalarExponent run(const ScalarExponent& x) {
          ScalarExponent xdiv2 = x / ScalarExponent(2);
          ScalarExponent floorxdiv2 = numext::floor(xdiv2);
          return xdiv2 != floorxdiv2;
        }
      };
      template <typename ScalarExponent>
      struct is_odd<ScalarExponent, true> {
        static inline ScalarExponent run(const ScalarExponent& x) { return x % ScalarExponent(2); }
      };
      template <typename Packet,
                typename ScalarExponent,
                bool BaseIsIntegerType = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>
      struct do_div {
        static inline Packet run(const Packet& x, const ScalarExponent& exponent) {
          typedef typename unpacket_traits<Packet>::type Scalar;
          const Packet cst_pos_one = pset1<Packet>(Scalar(1));
          return exponent < 0 ? pdiv(cst_pos_one, x) : x;
        }
      };
      template <typename Packet, typename ScalarExponent>
      struct do_div<Packet, ScalarExponent, true> {
        static inline Packet run(const Packet& x, const ScalarExponent& exponent) {
          Eigen::internal::ignore_unused_variable(exponent);
          ;
          return x;
        }
      };
      template <typename Packet, typename ScalarExponent>
      static inline Packet int_pow(const Packet& x, const ScalarExponent& exponent) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        const Packet cst_pos_one = pset1<Packet>(Scalar(1));
        if (exponent == 0)
          return cst_pos_one;
        Packet result = x;
        Packet y = cst_pos_one;
        ScalarExponent m = numext::abs(exponent);
        while (m > 1) {
          bool odd = is_odd<ScalarExponent>::run(m);
          if (odd)
            y = pmul(y, result);
          result = pmul(result, result);
          m = numext::floor(m / ScalarExponent(2));
        }
        result = pmul(y, result);
        result = do_div<Packet, ScalarExponent>::run(result, exponent);
        return result;
      }
      template <typename Packet>
      static inline Packet gen_pow(const Packet& x, const typename unpacket_traits<Packet>::type& exponent) {
        const Packet exponent_packet = pset1<Packet>(exponent);
        return generic_pow_impl(x, exponent_packet);
      }
      template <typename Packet, typename ScalarExponent>
      static inline Packet handle_nonint_int_errors(const Packet& x,
                                                    const Packet& powx,
                                                    const ScalarExponent& exponent) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        const bool exponent_is_odd = is_odd<ScalarExponent>::run(exponent);
        const bool exponent_is_neg = exponent < 0;
        const Packet exp_is_odd = exponent_is_odd ? ptrue(x) : pzero(x);
        const Packet exp_is_neg = exponent_is_neg ? ptrue(x) : pzero(x);
        const Scalar pos_zero = Scalar(0);
        const Scalar neg_zero = -Scalar(0);
        const Scalar pos_one = Scalar(1);
        const Scalar pos_inf = NumTraits<Scalar>::infinity();
        const Scalar neg_inf = -NumTraits<Scalar>::infinity();
        const Packet cst_pos_zero = pset1<Packet>(pos_zero);
        const Packet cst_neg_zero = pset1<Packet>(neg_zero);
        const Packet cst_pos_one = pset1<Packet>(pos_one);
        const Packet cst_pos_inf = pset1<Packet>(pos_inf);
        const Packet cst_neg_inf = pset1<Packet>(neg_inf);
        const Packet abs_x = pabs(x);
        const Packet abs_x_is_zero = pcmp_eq(abs_x, cst_pos_zero);
        const Packet abs_x_is_one = pcmp_eq(abs_x, cst_pos_one);
        const Packet abs_x_is_inf = pcmp_eq(abs_x, cst_pos_inf);
        const Packet x_has_signbit = pcmp_eq(por(pand(x, cst_neg_inf), cst_pos_inf), cst_neg_inf);
        const Packet x_is_neg = pandnot(x_has_signbit, abs_x_is_zero);
        const Packet x_is_neg_zero = pand(x_has_signbit, abs_x_is_zero);
        if (exponent == 0) {
          return cst_pos_one;
        }
        Packet pow_is_pos_inf = pand(pandnot(abs_x_is_zero, x_is_neg_zero), pand(exp_is_odd, exp_is_neg));
        pow_is_pos_inf = por(pow_is_pos_inf, pand(abs_x_is_zero, pandnot(exp_is_neg, exp_is_odd)));
        pow_is_pos_inf = por(pow_is_pos_inf, pand(pand(abs_x_is_inf, x_is_neg), pandnot(pnot(exp_is_neg), exp_is_odd)));
        pow_is_pos_inf = por(pow_is_pos_inf, pandnot(pandnot(abs_x_is_inf, x_is_neg), exp_is_neg));
        Packet pow_is_neg_inf = pand(x_is_neg_zero, pand(exp_is_neg, exp_is_odd));
        pow_is_neg_inf = por(pow_is_neg_inf, pand(pand(abs_x_is_inf, x_is_neg), pandnot(exp_is_odd, exp_is_neg)));
        Packet pow_is_pos_zero = pandnot(abs_x_is_zero, exp_is_neg);
        pow_is_pos_zero = por(pow_is_pos_zero, pand(pand(abs_x_is_inf, x_is_neg), pandnot(exp_is_neg, exp_is_odd)));
        pow_is_pos_zero = por(pow_is_pos_zero, pand(pandnot(abs_x_is_inf, x_is_neg), exp_is_neg));
        Packet pow_is_neg_zero = pand(x_is_neg_zero, pandnot(exp_is_odd, exp_is_neg));
        pow_is_neg_zero = por(pow_is_neg_zero, pand(pand(abs_x_is_inf, x_is_neg), pand(exp_is_odd, exp_is_neg)));
        Packet result = pselect(pow_is_neg_inf, cst_neg_inf, powx);
        result = pselect(pow_is_neg_zero, cst_neg_zero, result);
        result = pselect(pow_is_pos_zero, cst_pos_zero, result);
        result = pselect(pow_is_pos_inf, cst_pos_inf, result);
        result = pselect(pandnot(abs_x_is_one, x_is_neg), cst_pos_one, result);
        return result;
      }
      template <typename Packet, typename ScalarExponent>
      static inline Packet handle_nonint_nonint_errors(const Packet& x,
                                                       const Packet& powx,
                                                       const ScalarExponent& exponent) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        const bool exponent_is_fin = (numext::isfinite)(exponent);
        const bool exponent_is_nan = (numext::isnan)(exponent);
        const bool exponent_is_neg = exponent < 0;
        const bool exponent_is_inf = !exponent_is_fin && !exponent_is_nan;
        const Packet exp_is_neg = exponent_is_neg ? ptrue(x) : pzero(x);
        const Packet exp_is_inf = exponent_is_inf ? ptrue(x) : pzero(x);
        const Scalar pos_zero = Scalar(0);
        const Scalar pos_one = Scalar(1);
        const Scalar pos_inf = NumTraits<Scalar>::infinity();
        const Scalar neg_inf = -NumTraits<Scalar>::infinity();
        const Scalar nan = NumTraits<Scalar>::quiet_NaN();
        const Packet cst_pos_zero = pset1<Packet>(pos_zero);
        const Packet cst_pos_one = pset1<Packet>(pos_one);
        const Packet cst_pos_inf = pset1<Packet>(pos_inf);
        const Packet cst_neg_inf = pset1<Packet>(neg_inf);
        const Packet cst_nan = pset1<Packet>(nan);
        const Packet abs_x = pabs(x);
        const Packet abs_x_is_zero = pcmp_eq(abs_x, cst_pos_zero);
        const Packet abs_x_is_lt_one = pcmp_lt(abs_x, cst_pos_one);
        const Packet abs_x_is_gt_one = pcmp_lt(cst_pos_one, abs_x);
        const Packet abs_x_is_one = pcmp_eq(abs_x, cst_pos_one);
        const Packet abs_x_is_inf = pcmp_eq(abs_x, cst_pos_inf);
        const Packet x_has_signbit = pcmp_eq(por(pand(x, cst_neg_inf), cst_pos_inf), cst_neg_inf);
        const Packet x_is_neg = pandnot(x_has_signbit, abs_x_is_zero);
        if (exponent_is_nan) {
          return pselect(pandnot(abs_x_is_one, x_is_neg), cst_pos_one, cst_nan);
        }
        Packet pow_is_pos_zero = pandnot(abs_x_is_zero, exp_is_neg);
        pow_is_pos_zero = por(pow_is_pos_zero, pand(abs_x_is_gt_one, pand(exp_is_inf, exp_is_neg)));
        pow_is_pos_zero = por(pow_is_pos_zero, pand(abs_x_is_lt_one, pandnot(exp_is_inf, exp_is_neg)));
        pow_is_pos_zero = por(pow_is_pos_zero, pand(abs_x_is_inf, exp_is_neg));
        const Packet pow_is_pos_one = pand(abs_x_is_one, exp_is_inf);
        Packet pow_is_pos_inf = pand(abs_x_is_zero, exp_is_neg);
        pow_is_pos_inf = por(pow_is_pos_inf, pand(abs_x_is_lt_one, pand(exp_is_inf, exp_is_neg)));
        pow_is_pos_inf = por(pow_is_pos_inf, pand(abs_x_is_gt_one, pandnot(exp_is_inf, exp_is_neg)));
        pow_is_pos_inf = por(pow_is_pos_inf, pandnot(abs_x_is_inf, exp_is_neg));
        const Packet pow_is_nan = pandnot(pandnot(x_is_neg, abs_x_is_inf), exp_is_inf);
        Packet result = pselect(pow_is_pos_inf, cst_pos_inf, powx);
        result = pselect(pow_is_pos_one, cst_pos_one, result);
        result = pselect(pow_is_pos_zero, cst_pos_zero, result);
        result = pselect(pow_is_nan, cst_nan, result);
        result = pselect(pandnot(abs_x_is_one, x_is_neg), cst_pos_one, result);
        return result;
      }
      template <typename Packet, typename ScalarExponent>
      static inline Packet handle_int_int(const Packet& x, const ScalarExponent& exponent) {
        typedef typename unpacket_traits<Packet>::type Scalar;
        const bool exponent_is_odd = unary_pow::is_odd<ScalarExponent>::run(exponent);
        const Scalar zero = Scalar(0);
        const Scalar pos_one = Scalar(1);
        const Packet cst_zero = pset1<Packet>(zero);
        const Packet cst_pos_one = pset1<Packet>(pos_one);
        const Packet abs_x = pabs(x);
        const Packet pow_is_zero = exponent < 0 ? pcmp_lt(cst_pos_one, abs_x) : pzero(x);
        const Packet pow_is_one = pcmp_eq(cst_pos_one, abs_x);
        const Packet pow_is_neg = exponent_is_odd ? pcmp_lt(x, cst_zero) : pzero(x);
        Packet result = pselect(pow_is_zero, cst_zero, x);
        result = pselect(pandnot(pow_is_one, pow_is_neg), cst_pos_one, result);
        result = pselect(pand(pow_is_one, pow_is_neg), pnegate(cst_pos_one), result);
        return result;
      }
    }  // namespace unary_pow
    template <typename Packet,
              typename ScalarExponent,
              bool BaseIsIntegerType = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger,
              bool ExponentIsIntegerType = NumTraits<ScalarExponent>::IsInteger>
    struct unary_pow_impl;
    template <typename Packet, typename ScalarExponent>
    struct unary_pow_impl<Packet, ScalarExponent, false, false> {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static inline Packet run(const Packet& x, const ScalarExponent& exponent) {
        const bool exponent_is_integer = (numext::isfinite)(exponent) && numext::round(exponent) == exponent;
        if (exponent_is_integer) {
          Packet result = unary_pow::int_pow(x, exponent);
          result = unary_pow::handle_nonint_int_errors(x, result, exponent);
          return result;
        } else {
          Packet result = unary_pow::gen_pow(x, exponent);
          result = unary_pow::handle_nonint_nonint_errors(x, result, exponent);
          return result;
        }
      }
    };
    template <typename Packet, typename ScalarExponent>
    struct unary_pow_impl<Packet, ScalarExponent, false, true> {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static inline Packet run(const Packet& x, const ScalarExponent& exponent) {
        Packet result = unary_pow::int_pow(x, exponent);
        result = unary_pow::handle_nonint_int_errors(x, result, exponent);
        return result;
      }
    };
    template <typename Packet, typename ScalarExponent>
    struct unary_pow_impl<Packet, ScalarExponent, true, true> {
      typedef typename unpacket_traits<Packet>::type Scalar;
      static inline Packet run(const Packet& x, const ScalarExponent& exponent) {
        if (exponent < 0 || exponent > NumTraits<Scalar>::digits()) {
          return unary_pow::handle_int_int(x, exponent);
        } else {
          return unary_pow::int_pow(x, exponent);
        }
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {}
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Arg1, typename Arg2>
    struct binary_op_base {
      typedef Arg1 first_argument_type;
      typedef Arg2 second_argument_type;
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_sum_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_sum_op>::ReturnType result_type;
      inline result_type operator()(const LhsScalar& a, const RhsScalar& b) const { return a + b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::padd(a, b);
      }
      template <typename Packet>
      inline result_type predux(const Packet& a) const {
        return internal::predux(a);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_sum_op<LhsScalar, RhsScalar>> {
      enum {
        Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2,
        PacketAccess =
            is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasAdd && packet_traits<RhsScalar>::HasAdd
      };
    };
    template <>
    inline bool scalar_sum_op<bool, bool>::operator()(const bool& a, const bool& b) const {
      return a || b;
    }
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_product_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_product_op>::ReturnType result_type;
      inline result_type operator()(const LhsScalar& a, const RhsScalar& b) const { return a * b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pmul(a, b);
      }
      template <typename Packet>
      inline result_type predux(const Packet& a) const {
        return internal::predux_mul(a);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_product_op<LhsScalar, RhsScalar>> {
      enum {
        Cost = (int(NumTraits<LhsScalar>::MulCost) + int(NumTraits<RhsScalar>::MulCost)) / 2,
        PacketAccess =
            is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMul && packet_traits<RhsScalar>::HasMul
      };
    };
    template <>
    inline bool scalar_product_op<bool, bool>::operator()(const bool& a, const bool& b) const {
      return a && b;
    }
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_conj_product_op : binary_op_base<LhsScalar, RhsScalar> {
      enum { Conj = NumTraits<LhsScalar>::IsComplex };
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_conj_product_op>::ReturnType result_type;
      inline result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
        return conj_helper<LhsScalar, RhsScalar, Conj, false>().pmul(a, b);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return conj_helper<Packet, Packet, Conj, false>().pmul(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_conj_product_op<LhsScalar, RhsScalar>> {
      enum {
        Cost = NumTraits<LhsScalar>::MulCost,
        PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMul
      };
    };
    template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
    struct scalar_min_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_min_op>::ReturnType result_type;
      inline result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
        return internal::pmin<NaNPropagation>(a, b);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pmin<NaNPropagation>(a, b);
      }
      template <typename Packet>
      inline result_type predux(const Packet& a) const {
        return internal::predux_min<NaNPropagation>(a);
      }
    };
    template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
    struct functor_traits<scalar_min_op<LhsScalar, RhsScalar, NaNPropagation>> {
      enum {
        Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
        PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMin
      };
    };
    template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
    struct scalar_max_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_max_op>::ReturnType result_type;
      inline result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
        return internal::pmax<NaNPropagation>(a, b);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pmax<NaNPropagation>(a, b);
      }
      template <typename Packet>
      inline result_type predux(const Packet& a) const {
        return internal::predux_max<NaNPropagation>(a);
      }
    };
    template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
    struct functor_traits<scalar_max_op<LhsScalar, RhsScalar, NaNPropagation>> {
      enum {
        Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
        PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMax
      };
    };
    template <typename LhsScalar, typename RhsScalar, ComparisonName cmp>
    struct scalar_cmp_op;
    template <typename LhsScalar, typename RhsScalar, ComparisonName cmp>
    struct functor_traits<scalar_cmp_op<LhsScalar, RhsScalar, cmp>> {
      enum {
        Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
        PacketAccess =
            is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasCmp && is_same<LhsScalar, bool>::value
      };
    };
    template <ComparisonName Cmp, typename LhsScalar, typename RhsScalar>
    struct result_of<scalar_cmp_op<LhsScalar, RhsScalar, Cmp>(LhsScalar, RhsScalar)> {
      typedef bool type;
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_EQ> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a == b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_eq(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_LT> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a < b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_lt(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_LE> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a <= b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_le(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_GT> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a > b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_lt(b, a);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_GE> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a >= b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_le(b, a);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_UNORD> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return !(a <= b || b <= a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_eq(internal::por(internal::pcmp_le(a, b), internal::pcmp_le(b, a)), internal::pzero(a));
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_NEQ> : binary_op_base<LhsScalar, RhsScalar> {
      typedef bool result_type;
      inline bool operator()(const LhsScalar& a, const RhsScalar& b) const { return a != b; }
      template <typename Packet>
      inline Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pcmp_eq(internal::pcmp_eq(a, b), internal::pzero(a));
      }
    };
    template <typename Scalar>
    struct scalar_hypot_op<Scalar, Scalar> : binary_op_base<Scalar, Scalar> {
      inline const Scalar operator()(const Scalar& x, const Scalar& y) const {
        return internal::positive_real_hypot(x, y);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_hypot_op<Scalar, Scalar>> {
      enum {
        Cost =
            3 * NumTraits<Scalar>::AddCost + 2 * NumTraits<Scalar>::MulCost + 2 * scalar_div_cost<Scalar, false>::value,
        PacketAccess = false
      };
    };
    template <typename Scalar, typename Exponent>
    struct scalar_pow_op : binary_op_base<Scalar, Exponent> {
      typedef typename ScalarBinaryOpTraits<Scalar, Exponent, scalar_pow_op>::ReturnType result_type;
      inline result_type operator()(const Scalar& a, const Exponent& b) const { return numext::pow(a, b); }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return generic_pow(a, b);
      }
    };
    template <typename Scalar, typename Exponent>
    struct functor_traits<scalar_pow_op<Scalar, Exponent>> {
      enum {
        Cost = 5 * NumTraits<Scalar>::MulCost,
        PacketAccess =
            (!NumTraits<Scalar>::IsComplex && !NumTraits<Scalar>::IsInteger && packet_traits<Scalar>::HasExp &&
             packet_traits<Scalar>::HasLog && packet_traits<Scalar>::HasRound && packet_traits<Scalar>::HasCmp &&
             !is_same<Scalar, half>::value && !is_same<Scalar, bfloat16>::value)
      };
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_difference_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_difference_op>::ReturnType result_type;
      inline const result_type operator()(const LhsScalar& a, const RhsScalar& b) const { return a - b; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::psub(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_difference_op<LhsScalar, RhsScalar>> {
      enum {
        Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2,
        PacketAccess =
            is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasSub && packet_traits<RhsScalar>::HasSub
      };
    };
    template <typename Packet, bool IsInteger = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>
    struct maybe_raise_div_by_zero {
      static inline void run(Packet x) {
        Eigen::internal::ignore_unused_variable(x);
        ;
      }
    };
    template <typename Packet>
    struct maybe_raise_div_by_zero<Packet, true> {
      static inline void run(Packet x) {
        if ((__builtin_expect(predux_any(pcmp_eq(x, pzero(x))), false))) {
          std::raise(8);
        }
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_quotient_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_quotient_op>::ReturnType result_type;
      inline const result_type operator()(const LhsScalar& a, const RhsScalar& b) const { return a / b; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        maybe_raise_div_by_zero<Packet>::run(b);
        return internal::pdiv(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_quotient_op<LhsScalar, RhsScalar>> {
      typedef typename scalar_quotient_op<LhsScalar, RhsScalar>::result_type result_type;
      enum {
        PacketAccess = is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasDiv &&
                       packet_traits<RhsScalar>::HasDiv,
        Cost = scalar_div_cost<result_type, PacketAccess>::value
      };
    };
    struct scalar_boolean_and_op {
      inline bool operator()(const bool& a, const bool& b) const { return a && b; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pand(a, b);
      }
    };
    template <>
    struct functor_traits<scalar_boolean_and_op> {
      enum { Cost = NumTraits<bool>::AddCost, PacketAccess = true };
    };
    struct scalar_boolean_or_op {
      inline bool operator()(const bool& a, const bool& b) const { return a || b; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::por(a, b);
      }
    };
    template <>
    struct functor_traits<scalar_boolean_or_op> {
      enum { Cost = NumTraits<bool>::AddCost, PacketAccess = true };
    };
    struct scalar_boolean_xor_op {
      inline bool operator()(const bool& a, const bool& b) const { return a ^ b; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pxor(a, b);
      }
    };
    template <>
    struct functor_traits<scalar_boolean_xor_op> {
      enum { Cost = NumTraits<bool>::AddCost, PacketAccess = true };
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_absolute_difference_op : binary_op_base<LhsScalar, RhsScalar> {
      typedef
          typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_absolute_difference_op>::ReturnType result_type;
      inline const result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
        return numext::absdiff(a, b);
      }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a, const Packet& b) const {
        return internal::pabsdiff(a, b);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_absolute_difference_op<LhsScalar, RhsScalar>> {
      enum {
        Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
        PacketAccess = is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasAbsDiff
      };
    };
    template <typename LhsScalar, typename RhsScalar>
    struct scalar_atan2_op {
      using Scalar = LhsScalar;
      inline std::enable_if_t<is_same<LhsScalar, RhsScalar>::value, Scalar> operator()(const Scalar& y,
                                                                                       const Scalar& x) const {
        using std::atan2;
        ;
        return static_cast<Scalar>(atan2(y, x));
      }
      template <typename Packet>
      inline std::enable_if_t<is_same<LhsScalar, RhsScalar>::value, Packet> packetOp(const Packet& y,
                                                                                     const Packet& x) const {
        const Packet kSignMask = pset1<Packet>(-Scalar(0));
        const Packet kPi =
            pset1<Packet>(Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L));
        const Packet kPiO2 =
            pset1<Packet>(Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 2));
        const Packet kPiO4 =
            pset1<Packet>(Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L / 4));
        const Packet k3PiO4 = pset1<Packet>(
            Scalar(3.0 * (3.141592653589793238462643383279502884197169399375105820974944592307816406L / 4)));
        Packet x_signbit = pand(x, kSignMask);
        Packet x_has_signbit = pcmp_lt(por(x_signbit, kPi), pzero(x));
        Packet x_is_zero = pcmp_eq(x, pzero(x));
        Packet x_neg = pandnot(x_has_signbit, x_is_zero);
        Packet y_signbit = pand(y, kSignMask);
        Packet y_is_zero = pcmp_eq(y, pzero(y));
        Packet x_is_not_nan = pcmp_eq(x, x);
        Packet y_is_not_nan = pcmp_eq(y, y);
        Packet result = patan(pdiv(y, x));
        Packet shift = pselect(x_neg, por(kPi, y_signbit), pzero(x));
        Packet is_not_nan = pcmp_eq(result, result);
        result =
            pselect(is_not_nan, padd(shift, result), pselect(x_neg, por(k3PiO4, y_signbit), por(kPiO4, y_signbit)));
        result = pselect(x_is_zero, pselect(y_is_zero, pzero(y), por(y_signbit, kPiO2)), result);
        result = pselect(y_is_zero, pselect(x_has_signbit, por(y_signbit, kPi), por(y_signbit, pzero(y))), result);
        Packet kQNaN = pset1<Packet>(NumTraits<Scalar>::quiet_NaN());
        return pselect(pand(x_is_not_nan, y_is_not_nan), result, kQNaN);
      }
    };
    template <typename LhsScalar, typename RhsScalar>
    struct functor_traits<scalar_atan2_op<LhsScalar, RhsScalar>> {
      enum {
        PacketAccess = is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasATan &&
                       packet_traits<LhsScalar>::HasDiv && !NumTraits<LhsScalar>::IsInteger &&
                       !NumTraits<LhsScalar>::IsComplex,
        Cost = scalar_div_cost<LhsScalar, PacketAccess>::value + 5 * NumTraits<LhsScalar>::MulCost +
               5 * NumTraits<LhsScalar>::AddCost
      };
    };
    template <typename BinaryOp>
    struct bind1st_op : BinaryOp {
      typedef typename BinaryOp::first_argument_type first_argument_type;
      typedef typename BinaryOp::second_argument_type second_argument_type;
      typedef typename BinaryOp::result_type result_type;
      explicit bind1st_op(const first_argument_type& val) : m_value(val) {}
      inline const result_type operator()(const second_argument_type& b) const {
        return BinaryOp::operator()(m_value, b);
      }
      template <typename Packet>
      inline const Packet packetOp(const Packet& b) const {
        return BinaryOp::packetOp(internal::pset1<Packet>(m_value), b);
      }
      first_argument_type m_value;
    };
    template <typename BinaryOp>
    struct functor_traits<bind1st_op<BinaryOp>> : functor_traits<BinaryOp> {};
    template <typename BinaryOp>
    struct bind2nd_op : BinaryOp {
      typedef typename BinaryOp::first_argument_type first_argument_type;
      typedef typename BinaryOp::second_argument_type second_argument_type;
      typedef typename BinaryOp::result_type result_type;
      explicit bind2nd_op(const second_argument_type& val) : m_value(val) {}
      inline const result_type operator()(const first_argument_type& a) const {
        return BinaryOp::operator()(a, m_value);
      }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return BinaryOp::packetOp(a, internal::pset1<Packet>(m_value));
      }
      second_argument_type m_value;
    };
    template <typename BinaryOp>
    struct functor_traits<bind2nd_op<BinaryOp>> : functor_traits<BinaryOp> {};
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar>
    struct scalar_opposite_op {
      inline const Scalar operator()(const Scalar& a) const { return -a; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pnegate(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_opposite_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasNegate };
    };
    template <typename Scalar>
    struct scalar_abs_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline const result_type operator()(const Scalar& a) const { return numext::abs(a); }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pabs(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_abs_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasAbs };
    };
    template <typename Scalar>
    struct scalar_score_coeff_op : scalar_abs_op<Scalar> {
      typedef void Score_is_abs;
    };
    template <typename Scalar>
    struct functor_traits<scalar_score_coeff_op<Scalar>> : functor_traits<scalar_abs_op<Scalar>> {};
    template <typename Scalar, typename = void>
    struct abs_knowing_score {
      typedef typename NumTraits<Scalar>::Real result_type;
      template <typename Score>
      inline const result_type operator()(const Scalar& a, const Score&) const {
        return numext::abs(a);
      }
    };
    template <typename Scalar>
    struct abs_knowing_score<Scalar, typename scalar_score_coeff_op<Scalar>::Score_is_abs> {
      typedef typename NumTraits<Scalar>::Real result_type;
      template <typename Scal>
      inline const result_type operator()(const Scal&, const result_type& a) const {
        return a;
      }
    };
    template <typename Scalar>
    struct scalar_abs2_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline const result_type operator()(const Scalar& a) const { return numext::abs2(a); }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pmul(a, a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_abs2_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasAbs2 };
    };
    template <typename Scalar>
    struct scalar_conjugate_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::conj(a); }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pconj(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_conjugate_op<Scalar>> {
      enum { Cost = 0, PacketAccess = packet_traits<Scalar>::HasConj };
    };
    template <typename Scalar>
    struct scalar_arg_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline const result_type operator()(const Scalar& a) const { return numext::arg(a); }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::parg(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_arg_op<Scalar>> {
      enum {
        Cost = NumTraits<Scalar>::IsComplex ? 5 * NumTraits<Scalar>::MulCost : NumTraits<Scalar>::AddCost,
        PacketAccess = packet_traits<Scalar>::HasArg
      };
    };
    template <typename Scalar, typename NewType>
    struct scalar_cast_op {
      typedef NewType result_type;
      inline const NewType operator()(const Scalar& a) const { return cast<Scalar, NewType>(a); }
    };
    template <typename Scalar, typename NewType>
    struct functor_traits<scalar_cast_op<Scalar, NewType>> {
      enum { Cost = is_same<Scalar, NewType>::value ? 0 : NumTraits<NewType>::AddCost, PacketAccess = false };
    };
    template <typename Scalar, int N>
    struct scalar_shift_right_op {
      inline const Scalar operator()(const Scalar& a) const { return a >> N; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::parithmetic_shift_right<N>(a);
      }
    };
    template <typename Scalar, int N>
    struct functor_traits<scalar_shift_right_op<Scalar, N>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift };
    };
    template <typename Scalar, int N>
    struct scalar_shift_left_op {
      inline const Scalar operator()(const Scalar& a) const { return a << N; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::plogical_shift_left<N>(a);
      }
    };
    template <typename Scalar, int N>
    struct functor_traits<scalar_shift_left_op<Scalar, N>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift };
    };
    template <typename Scalar>
    struct scalar_real_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline result_type operator()(const Scalar& a) const { return numext::real(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_real_op<Scalar>> {
      enum { Cost = 0, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_imag_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline result_type operator()(const Scalar& a) const { return numext::imag(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_imag_op<Scalar>> {
      enum { Cost = 0, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_real_ref_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline result_type& operator()(const Scalar& a) const { return numext::real_ref(*const_cast<Scalar*>(&a)); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_real_ref_op<Scalar>> {
      enum { Cost = 0, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_imag_ref_op {
      typedef typename NumTraits<Scalar>::Real result_type;
      inline result_type& operator()(const Scalar& a) const { return numext::imag_ref(*const_cast<Scalar*>(&a)); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_imag_ref_op<Scalar>> {
      enum { Cost = 0, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_exp_op {
      inline const Scalar operator()(const Scalar& a) const { return internal::pexp(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pexp(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_exp_op<Scalar>> {
      enum {
        PacketAccess = packet_traits<Scalar>::HasExp,
        Cost = (sizeof(Scalar) == 4 ? (21 * NumTraits<Scalar>::AddCost + 13 * NumTraits<Scalar>::MulCost)
                                    : (23 * NumTraits<Scalar>::AddCost + 12 * NumTraits<Scalar>::MulCost +
                                       scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value))
      };
    };
    template <typename Scalar>
    struct scalar_expm1_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::expm1(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pexpm1(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_expm1_op<Scalar>> {
      enum { PacketAccess = packet_traits<Scalar>::HasExpm1, Cost = functor_traits<scalar_exp_op<Scalar>>::Cost };
    };
    template <typename Scalar>
    struct scalar_log_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::log(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::plog(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_log_op<Scalar>> {
      enum {
        PacketAccess = packet_traits<Scalar>::HasLog,
        Cost = (PacketAccess          ? (36 * NumTraits<Scalar>::AddCost + 14 * NumTraits<Scalar>::MulCost)
                : sizeof(Scalar) == 4 ? 40
                                      : 85)
      };
    };
    template <typename Scalar>
    struct scalar_log1p_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::log1p(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::plog1p(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_log1p_op<Scalar>> {
      enum { PacketAccess = packet_traits<Scalar>::HasLog1p, Cost = functor_traits<scalar_log_op<Scalar>>::Cost };
    };
    template <typename Scalar>
    struct scalar_log10_op {
      inline const Scalar operator()(const Scalar& a) const {
        using std::log10;
        return log10(a);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::plog10(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_log10_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog10 };
    };
    template <typename Scalar>
    struct scalar_log2_op {
      inline const Scalar operator()(const Scalar& a) const {
        return Scalar(1.442695040888963407359924681001892137426645954152985934135449406931109219L) * numext::log(a);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::plog2(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_log2_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog };
    };
    template <typename Scalar>
    struct scalar_sqrt_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::sqrt(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::psqrt(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_sqrt_op<Scalar>> {
      enum {
        Cost = (sizeof(Scalar) == 8 ? 28 : (3 * NumTraits<Scalar>::AddCost + 5 * NumTraits<Scalar>::MulCost)),
        PacketAccess = packet_traits<Scalar>::HasSqrt
      };
    };
    template <>
    struct scalar_sqrt_op<bool> {
      __attribute__((deprecated)) inline bool operator()(const bool& a) const { return a; }
      template <typename Packet>
      __attribute__((deprecated)) inline Packet packetOp(const Packet& a) const {
        return a;
      }
    };
    template <>
    struct functor_traits<scalar_sqrt_op<bool>> {
      enum { Cost = 1, PacketAccess = packet_traits<bool>::Vectorizable };
    };
    template <typename Scalar>
    struct scalar_rsqrt_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::rsqrt(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::prsqrt(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_rsqrt_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasRsqrt };
    };
    template <typename Scalar>
    struct scalar_cos_op {
      inline Scalar operator()(const Scalar& a) const { return numext::cos(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pcos(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_cos_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCos };
    };
    template <typename Scalar>
    struct scalar_sin_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::sin(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::psin(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_sin_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasSin };
    };
    template <typename Scalar>
    struct scalar_tan_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::tan(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::ptan(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_tan_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasTan };
    };
    template <typename Scalar>
    struct scalar_acos_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::acos(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pacos(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_acos_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasACos };
    };
    template <typename Scalar>
    struct scalar_asin_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::asin(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pasin(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_asin_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasASin };
    };
    template <typename Scalar>
    struct scalar_atan_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::atan(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::patan(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_atan_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasATan };
    };
    template <typename Scalar>
    struct scalar_tanh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::tanh(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& x) const {
        return ptanh(x);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_tanh_op<Scalar>> {
      enum {
        PacketAccess = packet_traits<Scalar>::HasTanh,
        Cost =
            ((1 && is_same<Scalar, float>::value) ? (11 * NumTraits<Scalar>::AddCost + 11 * NumTraits<Scalar>::MulCost +
                                                     scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value)
                                                  : (6 * NumTraits<Scalar>::AddCost + 3 * NumTraits<Scalar>::MulCost +
                                                     2 * scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value +
                                                     functor_traits<scalar_exp_op<Scalar>>::Cost))
      };
    };
    template <typename Scalar>
    struct scalar_atanh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::atanh(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_atanh_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_sinh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::sinh(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::psinh(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_sinh_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasSinh };
    };
    template <typename Scalar>
    struct scalar_asinh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::asinh(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_asinh_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_cosh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::cosh(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pcosh(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_cosh_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCosh };
    };
    template <typename Scalar>
    struct scalar_acosh_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::acosh(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_acosh_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_inverse_op {
      inline Scalar operator()(const Scalar& a) const { return Scalar(1) / a; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::preciprocal(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_inverse_op<Scalar>> {
      enum {
        PacketAccess = packet_traits<Scalar>::HasDiv,
        Cost = (packet_traits<Scalar>::HasReciprocal ? 4 * NumTraits<Scalar>::MulCost
                                                     : scalar_div_cost<Scalar, PacketAccess>::value)
      };
    };
    template <typename Scalar>
    struct scalar_square_op {
      inline Scalar operator()(const Scalar& a) const { return a * a; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pmul(a, a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_square_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul };
    };
    template <>
    struct scalar_square_op<bool> {
      __attribute__((deprecated)) inline bool operator()(const bool& a) const { return a; }
      template <typename Packet>
      __attribute__((deprecated)) inline const Packet packetOp(const Packet& a) const {
        return a;
      }
    };
    template <>
    struct functor_traits<scalar_square_op<bool>> {
      enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable };
    };
    template <typename Scalar>
    struct scalar_cube_op {
      inline Scalar operator()(const Scalar& a) const { return a * a * a; }
      template <typename Packet>
      inline const Packet packetOp(const Packet& a) const {
        return internal::pmul(a, pmul(a, a));
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_cube_op<Scalar>> {
      enum { Cost = 2 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul };
    };
    template <>
    struct scalar_cube_op<bool> {
      __attribute__((deprecated)) inline bool operator()(const bool& a) const { return a; }
      template <typename Packet>
      __attribute__((deprecated)) inline const Packet packetOp(const Packet& a) const {
        return a;
      }
    };
    template <>
    struct functor_traits<scalar_cube_op<bool>> {
      enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable };
    };
    template <typename Scalar>
    struct scalar_round_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::round(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pround(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_round_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasRound };
    };
    template <typename Scalar>
    struct scalar_floor_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::floor(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pfloor(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_floor_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasFloor };
    };
    template <typename Scalar>
    struct scalar_rint_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::rint(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::print(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_rint_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasRint };
    };
    template <typename Scalar>
    struct scalar_ceil_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::ceil(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::pceil(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_ceil_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCeil };
    };
    template <typename Scalar>
    struct scalar_isnan_op {
      typedef bool result_type;
      inline result_type operator()(const Scalar& a) const { return (numext::isnan)(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_isnan_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_isinf_op {
      typedef bool result_type;
      inline result_type operator()(const Scalar& a) const { return (numext::isinf)(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_isinf_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_isfinite_op {
      typedef bool result_type;
      inline result_type operator()(const Scalar& a) const { return (numext::isfinite)(a); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_isfinite_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_boolean_not_op {
      inline bool operator()(const bool& a) const { return !a; }
    };
    template <typename Scalar>
    struct functor_traits<scalar_boolean_not_op<Scalar>> {
      enum { Cost = NumTraits<bool>::AddCost, PacketAccess = false };
    };
    template <typename Scalar>
    struct scalar_sign_op {
      inline const Scalar operator()(const Scalar& a) const { return numext::sign(a); }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return internal::psign(a);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_sign_op<Scalar>> {
      enum {
        Cost = NumTraits<Scalar>::IsComplex ? (8 * NumTraits<Scalar>::MulCost) : (3 * NumTraits<Scalar>::AddCost),
        PacketAccess = packet_traits<Scalar>::HasSign && packet_traits<Scalar>::Vectorizable
      };
    };
    template <typename T>
    struct scalar_logistic_op {
      inline T operator()(const T& x) const { return packetOp(x); }
      template <typename Packet>
      inline Packet packetOp(const Packet& x) const {
        const Packet one = pset1<Packet>(T(1));
        const Packet inf = pset1<Packet>(NumTraits<T>::infinity());
        const Packet e = pexp(x);
        const Packet inf_mask = pcmp_eq(e, inf);
        return pselect(inf_mask, one, pdiv(e, padd(one, e)));
      }
    };
    template <typename T>
    struct functor_traits<scalar_logistic_op<T>> {
      enum {
        Cost =
            scalar_div_cost<T, packet_traits<T>::HasDiv>::value +
            (internal::is_same<T, float>::value ? NumTraits<T>::AddCost * 15 + NumTraits<T>::MulCost * 11
                                                : NumTraits<T>::AddCost * 2 + functor_traits<scalar_exp_op<T>>::Cost),
        PacketAccess = packet_traits<T>::HasAdd && packet_traits<T>::HasDiv &&
                       (internal::is_same<T, float>::value
                            ? packet_traits<T>::HasMul && packet_traits<T>::HasMax && packet_traits<T>::HasMin
                            : packet_traits<T>::HasNegate && packet_traits<T>::HasExp)
      };
    };
    template <typename Scalar,
              typename ExponentScalar,
              bool IsBaseInteger = NumTraits<Scalar>::IsInteger,
              bool IsExponentInteger = NumTraits<ExponentScalar>::IsInteger,
              bool IsBaseComplex = NumTraits<Scalar>::IsComplex,
              bool IsExponentComplex = NumTraits<ExponentScalar>::IsComplex>
    struct scalar_unary_pow_op {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          ExponentScalar,
          internal::has_ReturnType<ScalarBinaryOpTraits<Scalar, ExponentScalar, scalar_unary_pow_op>>::value>::type
          PromotedExponent;
      typedef typename ScalarBinaryOpTraits<Scalar, PromotedExponent, scalar_unary_pow_op>::ReturnType result_type;
      inline scalar_unary_pow_op(const ExponentScalar& exponent) : m_exponent(exponent) {}
      inline result_type operator()(const Scalar& a) const {
        using std::pow;
        ;
        return static_cast<result_type>(pow(a, m_exponent));
      }

    private:
      const ExponentScalar m_exponent;
      scalar_unary_pow_op() {}
    };
    template <typename T>
    constexpr int exponent_digits() {
      return 8 * sizeof(T) - NumTraits<T>::digits() - NumTraits<T>::IsSigned;
    }
    template <typename From, typename To>
    struct is_floating_exactly_representable {
      static constexpr bool value =
          (exponent_digits<To>() >= exponent_digits<From>() && NumTraits<To>::digits() >= NumTraits<From>::digits());
    };
    template <typename Scalar, typename ExponentScalar>
    struct scalar_unary_pow_op<Scalar, ExponentScalar, false, false, false, false> {
      template <bool IsExactlyRepresentable = is_floating_exactly_representable<ExponentScalar, Scalar>::value>
      std::enable_if_t<IsExactlyRepresentable, void> check_is_representable() const {}
      template <bool IsExactlyRepresentable = is_floating_exactly_representable<ExponentScalar, Scalar>::value>
      __attribute__((deprecated)) std::enable_if_t<!IsExactlyRepresentable, void> check_is_representable() const {}
      inline scalar_unary_pow_op(const ExponentScalar& exponent) : m_exponent(static_cast<Scalar>(exponent)) {
        check_is_representable();
      }
      inline Scalar operator()(const Scalar& a) const {
        using std::pow;
        ;
        return static_cast<Scalar>(pow(a, m_exponent));
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return unary_pow_impl<Packet, Scalar>::run(a, m_exponent);
      }

    private:
      const Scalar m_exponent;
      scalar_unary_pow_op() {}
    };
    template <typename Scalar, typename ExponentScalar, bool BaseIsInteger>
    struct scalar_unary_pow_op<Scalar, ExponentScalar, BaseIsInteger, true, false, false> {
      inline scalar_unary_pow_op(const ExponentScalar& exponent) : m_exponent(exponent) {}
      inline Scalar operator()(const Scalar& a) const {
        return unary_pow_impl<Scalar, ExponentScalar>::run(a, m_exponent);
      }
      template <typename Packet>
      inline Packet packetOp(const Packet& a) const {
        return unary_pow_impl<Packet, ExponentScalar>::run(a, m_exponent);
      }

    private:
      const ExponentScalar m_exponent;
      scalar_unary_pow_op() {}
    };
    template <typename Scalar, typename ExponentScalar>
    struct functor_traits<scalar_unary_pow_op<Scalar, ExponentScalar>> {
      enum {
        GenPacketAccess = functor_traits<scalar_pow_op<Scalar, ExponentScalar>>::PacketAccess,
        IntPacketAccess = !NumTraits<Scalar>::IsComplex && packet_traits<Scalar>::HasMul &&
                          (packet_traits<Scalar>::HasDiv || NumTraits<Scalar>::IsInteger) &&
                          packet_traits<Scalar>::HasCmp,
        PacketAccess = NumTraits<ExponentScalar>::IsInteger ? IntPacketAccess : (IntPacketAccess && GenPacketAccess),
        Cost = functor_traits<scalar_pow_op<Scalar, ExponentScalar>>::Cost
      };
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar>
    struct scalar_constant_op {
      inline scalar_constant_op(const scalar_constant_op& other) : m_other(other.m_other) {}
      inline scalar_constant_op(const Scalar& other) : m_other(other) {}
      inline const Scalar operator()() const { return m_other; }
      template <typename PacketType>
      inline const PacketType packetOp() const {
        return internal::pset1<PacketType>(m_other);
      }
      const Scalar m_other;
    };
    template <typename Scalar>
    struct functor_traits<scalar_constant_op<Scalar>> {
      enum { Cost = 0, PacketAccess = packet_traits<Scalar>::Vectorizable, IsRepeatable = true };
    };
    template <typename Scalar>
    struct scalar_identity_op {
      template <typename IndexType>
      inline const Scalar operator()(IndexType row, IndexType col) const {
        return row == col ? Scalar(1) : Scalar(0);
      }
    };
    template <typename Scalar>
    struct functor_traits<scalar_identity_op<Scalar>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = false, IsRepeatable = true };
    };
    template <typename Scalar, bool IsInteger>
    struct linspaced_op_impl;
    template <typename Scalar>
    struct linspaced_op_impl<Scalar, false> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps)
          : m_low(low),
            m_high(high),
            m_size1(num_steps == 1 ? 1 : num_steps - 1),
            m_step(num_steps == 1 ? Scalar() : Scalar((high - low) / RealScalar(num_steps - 1))),
            m_flip(numext::abs(high) < numext::abs(low)) {}
      template <typename IndexType>
      inline const Scalar operator()(IndexType i) const {
        if (m_flip)
          return (i == 0) ? m_low : Scalar(m_high - RealScalar(m_size1 - i) * m_step);
        else
          return (i == m_size1) ? m_high : Scalar(m_low + RealScalar(i) * m_step);
      }
      template <typename Packet, typename IndexType>
      inline const Packet packetOp(IndexType i) const {
        if (m_flip) {
          Packet pi = plset<Packet>(Scalar(i - m_size1));
          Packet res = padd(pset1<Packet>(m_high), pmul(pset1<Packet>(m_step), pi));
          if ((__builtin_expect(false || (i != 0), true)))
            return res;
          Packet mask = pcmp_lt(pset1<Packet>(0), plset<Packet>(0));
          return pselect<Packet>(mask, res, pset1<Packet>(m_low));
        } else {
          Packet pi = plset<Packet>(Scalar(i));
          Packet res = padd(pset1<Packet>(m_low), pmul(pset1<Packet>(m_step), pi));
          if ((__builtin_expect(false || (i != m_size1 - unpacket_traits<Packet>::size + 1), true)))
            return res;
          Packet mask = pcmp_lt(plset<Packet>(0), pset1<Packet>(unpacket_traits<Packet>::size - 1));
          return pselect<Packet>(mask, res, pset1<Packet>(m_high));
        }
      }
      const Scalar m_low;
      const Scalar m_high;
      const Index m_size1;
      const Scalar m_step;
      const bool m_flip;
    };
    template <typename Scalar>
    struct linspaced_op_impl<Scalar, true> {
      linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps)
          : m_low(low),
            m_multiplier((high - low) / convert_index<Scalar>(num_steps <= 1 ? 1 : num_steps - 1)),
            m_divisor(convert_index<Scalar>((high >= low ? num_steps : -num_steps) + (high - low)) /
                      ((numext::abs(high - low) + 1) == 0 ? 1 : (numext::abs(high - low) + 1))),
            m_use_divisor(num_steps > 1 && (numext::abs(high - low) + 1) < num_steps) {}
      template <typename IndexType>
      inline const Scalar operator()(IndexType i) const {
        if (m_use_divisor)
          return m_low + convert_index<Scalar>(i) / m_divisor;
        else
          return m_low + convert_index<Scalar>(i) * m_multiplier;
      }
      const Scalar m_low;
      const Scalar m_multiplier;
      const Scalar m_divisor;
      const bool m_use_divisor;
    };
    template <typename Scalar>
    struct linspaced_op;
    template <typename Scalar>
    struct functor_traits<linspaced_op<Scalar>> {
      enum {
        Cost = 1,
        PacketAccess =
            (!NumTraits<Scalar>::IsInteger) && packet_traits<Scalar>::HasSetLinear && packet_traits<Scalar>::HasBlend,
        IsRepeatable = true
      };
    };
    template <typename Scalar>
    struct linspaced_op {
      linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
          : impl((num_steps == 1 ? high : low), high, num_steps) {}
      template <typename IndexType>
      inline const Scalar operator()(IndexType i) const {
        return impl(i);
      }
      template <typename Packet, typename IndexType>
      inline const Packet packetOp(IndexType i) const {
        return impl.template packetOp<Packet>(i);
      }
      const linspaced_op_impl<Scalar, NumTraits<Scalar>::IsInteger> impl;
    };
    template <typename Functor>
    struct functor_has_linear_access {
      enum { ret = !has_binary_operator<Functor>::value };
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace numext {
    template <typename T = void>
    struct equal_to {
      typedef bool result_type;
      bool operator()(const T& lhs, const T& rhs) const { return lhs == rhs; }
    };
    template <typename T = void>
    struct not_equal_to {
      typedef bool result_type;
      bool operator()(const T& lhs, const T& rhs) const { return lhs != rhs; }
    };
  }  // namespace numext
  namespace internal {
    template <typename T>
    struct functor_traits<std::multiplies<T>> {
      enum { Cost = NumTraits<T>::MulCost, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::divides<T>> {
      enum { Cost = NumTraits<T>::MulCost, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::plus<T>> {
      enum { Cost = NumTraits<T>::AddCost, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::minus<T>> {
      enum { Cost = NumTraits<T>::AddCost, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::negate<T>> {
      enum { Cost = NumTraits<T>::AddCost, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::logical_or<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::logical_and<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::logical_not<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::greater<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::less<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::greater_equal<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::less_equal<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<std::equal_to<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<numext::equal_to<T>> : functor_traits<std::equal_to<T>> {};
    template <typename T>
    struct functor_traits<std::not_equal_to<T>> {
      enum { Cost = 1, PacketAccess = false };
    };
    template <typename T>
    struct functor_traits<numext::not_equal_to<T>> : functor_traits<std::not_equal_to<T>> {};
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename DstScalar, typename SrcScalar>
    struct assign_op {
      inline void assignCoeff(DstScalar& a, const SrcScalar& b) const { a = b; }
      template <int Alignment, typename Packet>
      inline void assignPacket(DstScalar* a, const Packet& b) const {
        internal::pstoret<DstScalar, Packet, Alignment>(a, b);
      }
    };
    template <typename DstScalar>
    struct assign_op<DstScalar, void> {};
    template <typename DstScalar, typename SrcScalar>
    struct functor_traits<assign_op<DstScalar, SrcScalar>> {
      enum {
        Cost = NumTraits<DstScalar>::ReadCost,
        PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::Vectorizable &&
                       packet_traits<SrcScalar>::Vectorizable
      };
    };
    template <typename DstScalar, typename SrcScalar>
    struct add_assign_op {
      inline void assignCoeff(DstScalar& a, const SrcScalar& b) const { a += b; }
      template <int Alignment, typename Packet>
      inline void assignPacket(DstScalar* a, const Packet& b) const {
        internal::pstoret<DstScalar, Packet, Alignment>(a, internal::padd(internal::ploadt<Packet, Alignment>(a), b));
      }
    };
    template <typename DstScalar, typename SrcScalar>
    struct functor_traits<add_assign_op<DstScalar, SrcScalar>> {
      enum {
        Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::AddCost,
        PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasAdd
      };
    };
    template <typename DstScalar, typename SrcScalar>
    struct sub_assign_op {
      inline void assignCoeff(DstScalar& a, const SrcScalar& b) const { a -= b; }
      template <int Alignment, typename Packet>
      inline void assignPacket(DstScalar* a, const Packet& b) const {
        internal::pstoret<DstScalar, Packet, Alignment>(a, internal::psub(internal::ploadt<Packet, Alignment>(a), b));
      }
    };
    template <typename DstScalar, typename SrcScalar>
    struct functor_traits<sub_assign_op<DstScalar, SrcScalar>> {
      enum {
        Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::AddCost,
        PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasSub
      };
    };
    template <typename DstScalar, typename SrcScalar = DstScalar>
    struct mul_assign_op {
      inline void assignCoeff(DstScalar& a, const SrcScalar& b) const { a *= b; }
      template <int Alignment, typename Packet>
      inline void assignPacket(DstScalar* a, const Packet& b) const {
        internal::pstoret<DstScalar, Packet, Alignment>(a, internal::pmul(internal::ploadt<Packet, Alignment>(a), b));
      }
    };
    template <typename DstScalar, typename SrcScalar>
    struct functor_traits<mul_assign_op<DstScalar, SrcScalar>> {
      enum {
        Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::MulCost,
        PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasMul
      };
    };
    template <typename DstScalar, typename SrcScalar = DstScalar>
    struct div_assign_op {
      inline void assignCoeff(DstScalar& a, const SrcScalar& b) const { a /= b; }
      template <int Alignment, typename Packet>
      inline void assignPacket(DstScalar* a, const Packet& b) const {
        internal::pstoret<DstScalar, Packet, Alignment>(a, internal::pdiv(internal::ploadt<Packet, Alignment>(a), b));
      }
    };
    template <typename DstScalar, typename SrcScalar>
    struct functor_traits<div_assign_op<DstScalar, SrcScalar>> {
      enum {
        Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::MulCost,
        PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasDiv
      };
    };
    template <typename Scalar>
    struct swap_assign_op {
      inline void assignCoeff(Scalar& a, const Scalar& b) const {
        using std::swap;
        swap(a, const_cast<Scalar&>(b));
      }
    };
    template <typename Scalar>
    struct functor_traits<swap_assign_op<Scalar>> {
      enum { Cost = 3 * NumTraits<Scalar>::ReadCost, PacketAccess = packet_traits<Scalar>::Vectorizable };
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    struct symbolic_last_tag {};
  }  // namespace internal
  namespace placeholders {
    typedef symbolic::SymbolExpr<internal::symbolic_last_tag> last_t;
    static const last_t last;
  }  // namespace placeholders
  namespace internal {
    inline Index eval_expr_given_size(Index x, Index) { return x; }
    template <int N>
    FixedInt<N> eval_expr_given_size(FixedInt<N> x, Index) {
      return x;
    }
    template <typename Derived>
    Index eval_expr_given_size(const symbolic::BaseExpr<Derived>& x, Index size) {
      return x.derived().eval(Eigen::placeholders::last = size - 1);
    }
    template <typename T, typename EnableIf = void>
    struct get_compile_time_incr {
      enum { value = UndefinedIncr };
    };
    template <typename T>
    constexpr Index first(const T& x) noexcept {
      return x.first();
    }
    template <typename T, int XprSize, typename EnableIf = void>
    struct IndexedViewCompatibleType {
      typedef T type;
    };
    template <typename T, typename Q>
    const T& makeIndexedViewCompatible(const T& x, Index, Q) {
      return x;
    }
    struct SingleRange {
      enum { SizeAtCompileTime = 1 };
      SingleRange(Index val) : m_value(val) {}
      Index operator[](Index) const { return m_value; }
      static constexpr Index size() noexcept { return 1; }
      Index first() const noexcept { return m_value; }
      Index m_value;
    };
    template <>
    struct get_compile_time_incr<SingleRange> {
      enum { value = 1 };
    };
    template <typename T, int XprSize>
    struct IndexedViewCompatibleType<T, XprSize, std::enable_if_t<internal::is_integral<T>::value>> {
      typedef SingleRange type;
    };
    template <typename T, int XprSize>
    struct IndexedViewCompatibleType<T, XprSize, std::enable_if_t<symbolic::is_symbolic<T>::value>> {
      typedef SingleRange type;
    };
    template <typename T>
    std::enable_if_t<symbolic::is_symbolic<T>::value, SingleRange> makeIndexedViewCompatible(const T& id,
                                                                                             Index size,
                                                                                             SpecializedType) {
      return eval_expr_given_size(id, size);
    }
    struct all_t {
      all_t() {}
    };
    template <int XprSize>
    struct AllRange {
      enum { SizeAtCompileTime = XprSize };
      AllRange(Index size = XprSize) : m_size(size) {}
      constexpr Index operator[](Index i) const noexcept { return i; }
      constexpr Index size() const noexcept { return m_size.value(); }
      constexpr Index first() const noexcept { return 0; }
      variable_if_dynamic<Index, XprSize> m_size;
    };
    template <int XprSize>
    struct IndexedViewCompatibleType<all_t, XprSize> {
      typedef AllRange<XprSize> type;
    };
    template <typename XprSizeType>
    inline AllRange<get_fixed_value<XprSizeType>::value> makeIndexedViewCompatible(all_t,
                                                                                   XprSizeType size,
                                                                                   SpecializedType) {
      return AllRange<get_fixed_value<XprSizeType>::value>(size);
    }
    template <int Size>
    struct get_compile_time_incr<AllRange<Size>> {
      enum { value = 1 };
    };
  }  // namespace internal
  namespace placeholders {
    typedef symbolic::AddExpr<symbolic::SymbolExpr<internal::symbolic_last_tag>,
                              symbolic::ValueExpr<Eigen::internal::FixedInt<1>>>
        lastp1_t;
    typedef Eigen::internal::all_t all_t;
    static const lastp1_t lastp1(last + fix<1>());
    static const lastp1_t end = lastp1;
    static const Eigen::internal::all_t all;
  }  // namespace placeholders
}  // namespace Eigen

namespace Eigen {
  enum AutoSize_t { AutoSize };
  const int AutoOrder = 2;
  namespace internal {
    template <typename SizeType, typename OtherSize, int TotalSize>
    struct get_compiletime_reshape_size {
      enum { value = get_fixed_value<SizeType>::value };
    };
    template <typename SizeType>
    Index get_runtime_reshape_size(SizeType size, Index, Index) {
      return internal::get_runtime_value(size);
    }
    template <typename OtherSize, int TotalSize>
    struct get_compiletime_reshape_size<AutoSize_t, OtherSize, TotalSize> {
      enum {
        other_size = get_fixed_value<OtherSize>::value,
        value = (TotalSize == Dynamic || other_size == Dynamic) ? Dynamic : TotalSize / other_size
      };
    };
    inline Index get_runtime_reshape_size(AutoSize_t, Index other, Index total) { return total / other; }
    constexpr inline int get_compiletime_reshape_order(int flags, int order) {
      return order == AutoOrder ? flags & RowMajorBit : order;
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T>
    struct cleanup_seq_incr {
      typedef typename cleanup_index_type<T, DynamicIndex>::type type;
    };
  }  // namespace internal
  template <typename FirstType = Index, typename SizeType = Index, typename IncrType = internal::FixedInt<1>>
  class ArithmeticSequence;
  template <typename FirstType, typename SizeType, typename IncrType>
  ArithmeticSequence<typename internal::cleanup_index_type<FirstType>::type,
                     typename internal::cleanup_index_type<SizeType>::type,
                     typename internal::cleanup_seq_incr<IncrType>::type>
  seqN(FirstType first, SizeType size, IncrType incr);
  template <typename FirstType, typename SizeType, typename IncrType>
  class ArithmeticSequence {
  public:
    ArithmeticSequence(FirstType first, SizeType size) : m_first(first), m_size(size) {}
    ArithmeticSequence(FirstType first, SizeType size, IncrType incr) : m_first(first), m_size(size), m_incr(incr) {}
    enum {
      SizeAtCompileTime = internal::get_fixed_value<SizeType>::value,
      IncrAtCompileTime = internal::get_fixed_value<IncrType, DynamicIndex>::value
    };
    Index size() const { return m_size; }
    Index first() const { return m_first; }
    Index operator[](Index i) const { return m_first + i * m_incr; }
    const FirstType& firstObject() const { return m_first; }
    const SizeType& sizeObject() const { return m_size; }
    const IncrType& incrObject() const { return m_incr; }

  protected:
    FirstType m_first;
    SizeType m_size;
    IncrType m_incr;

  public:
    auto reverse() const -> decltype(Eigen::seqN(m_first + (m_size + fix<-1>()) * m_incr, m_size, -m_incr)) {
      return seqN(m_first + (m_size + fix<-1>()) * m_incr, m_size, -m_incr);
    }
  };
  template <typename FirstType, typename SizeType, typename IncrType>
  ArithmeticSequence<typename internal::cleanup_index_type<FirstType>::type,
                     typename internal::cleanup_index_type<SizeType>::type,
                     typename internal::cleanup_seq_incr<IncrType>::type>
  seqN(FirstType first, SizeType size, IncrType incr) {
    return ArithmeticSequence<typename internal::cleanup_index_type<FirstType>::type,
                              typename internal::cleanup_index_type<SizeType>::type,
                              typename internal::cleanup_seq_incr<IncrType>::type>(first, size, incr);
  }
  template <typename FirstType, typename SizeType>
  ArithmeticSequence<typename internal::cleanup_index_type<FirstType>::type,
                     typename internal::cleanup_index_type<SizeType>::type>
  seqN(FirstType first, SizeType size) {
    return ArithmeticSequence<typename internal::cleanup_index_type<FirstType>::type,
                              typename internal::cleanup_index_type<SizeType>::type>(first, size);
  }
  template <typename FirstType, typename LastType>
  auto seq(FirstType f,
           LastType l) -> decltype(seqN(typename internal::cleanup_index_type<FirstType>::type(f),
                                        (typename internal::cleanup_index_type<LastType>::type(l) -
                                         typename internal::cleanup_index_type<FirstType>::type(f) + fix<1>()))) {
    return seqN(typename internal::cleanup_index_type<FirstType>::type(f),
                (typename internal::cleanup_index_type<LastType>::type(l) -
                 typename internal::cleanup_index_type<FirstType>::type(f) + fix<1>()));
  }
  template <typename FirstType, typename LastType, typename IncrType>
  auto seq(FirstType f,
           LastType l,
           IncrType incr) -> decltype(seqN(typename internal::cleanup_index_type<FirstType>::type(f),
                                           (typename internal::cleanup_index_type<LastType>::type(l) -
                                            typename internal::cleanup_index_type<FirstType>::type(f) +
                                            typename internal::cleanup_seq_incr<IncrType>::type(incr)) /
                                               typename internal::cleanup_seq_incr<IncrType>::type(incr),
                                           typename internal::cleanup_seq_incr<IncrType>::type(incr))) {
    typedef typename internal::cleanup_seq_incr<IncrType>::type CleanedIncrType;
    return seqN(typename internal::cleanup_index_type<FirstType>::type(f),
                (typename internal::cleanup_index_type<LastType>::type(l) -
                 typename internal::cleanup_index_type<FirstType>::type(f) + CleanedIncrType(incr)) /
                    CleanedIncrType(incr),
                CleanedIncrType(incr));
  }
  namespace placeholders {
    template <typename SizeType, typename IncrType>
    auto lastN(SizeType size,
               IncrType incr) -> decltype(seqN(Eigen::placeholders::last - (size - fix<1>()) * incr, size, incr)) {
      return seqN(Eigen::placeholders::last - (size - fix<1>()) * incr, size, incr);
    }
    template <typename SizeType>
    auto lastN(SizeType size) -> decltype(seqN(Eigen::placeholders::last + fix<1>() - size, size)) {
      return seqN(Eigen::placeholders::last + fix<1>() - size, size);
    }
  }  // namespace placeholders
  namespace internal {
    template <typename T>
    struct make_size_type {
      typedef std::conditional_t<symbolic::is_symbolic<T>::value, Index, T> type;
    };
    template <typename FirstType, typename SizeType, typename IncrType, int XprSize>
    struct IndexedViewCompatibleType<ArithmeticSequence<FirstType, SizeType, IncrType>, XprSize> {
      typedef ArithmeticSequence<Index, typename make_size_type<SizeType>::type, IncrType> type;
    };
    template <typename FirstType, typename SizeType, typename IncrType>
    ArithmeticSequence<Index, typename make_size_type<SizeType>::type, IncrType> makeIndexedViewCompatible(
        const ArithmeticSequence<FirstType, SizeType, IncrType>& ids, Index size, SpecializedType) {
      return ArithmeticSequence<Index, typename make_size_type<SizeType>::type, IncrType>(
          eval_expr_given_size(ids.firstObject(), size),
          eval_expr_given_size(ids.sizeObject(), size),
          ids.incrObject());
    }
    template <typename FirstType, typename SizeType, typename IncrType>
    struct get_compile_time_incr<ArithmeticSequence<FirstType, SizeType, IncrType>> {
      enum { value = get_fixed_value<IncrType, DynamicIndex>::value };
    };
  }  // namespace internal
  namespace indexing {
    using Eigen::fix;
    using Eigen::seq;
    using Eigen::seqN;
    using Eigen::placeholders::all;
    using Eigen::placeholders::last;
    using Eigen::placeholders::lastN;
    using Eigen::placeholders::lastp1;
  }  // namespace indexing
}  // namespace Eigen

namespace Eigen {
  enum { DontAlignCols = 1 };
  enum { StreamPrecision = -1, FullPrecision = -2 };
  namespace internal {
    template <typename Derived>
    std::ostream& print_matrix(std::ostream& s, const Derived& _m, const IOFormat& fmt);
  }
  struct IOFormat {
    IOFormat(int _precision = StreamPrecision,
             int _flags = 0,
             const std::string& _coeffSeparator = " ",
             const std::string& _rowSeparator = "\n",
             const std::string& _rowPrefix = "",
             const std::string& _rowSuffix = "",
             const std::string& _matPrefix = "",
             const std::string& _matSuffix = "",
             const char _fill = ' ')
        : matPrefix(_matPrefix),
          matSuffix(_matSuffix),
          rowPrefix(_rowPrefix),
          rowSuffix(_rowSuffix),
          rowSeparator(_rowSeparator),
          rowSpacer(""),
          coeffSeparator(_coeffSeparator),
          fill(_fill),
          precision(_precision),
          flags(_flags) {
      if ((flags & DontAlignCols))
        return;
      int i = int(matSuffix.length()) - 1;
      while (i >= 0 && matSuffix[i] != '\n') {
        rowSpacer += ' ';
        i--;
      }
    }
    std::string matPrefix, matSuffix;
    std::string rowPrefix, rowSuffix, rowSeparator, rowSpacer;
    std::string coeffSeparator;
    char fill;
    int precision;
    int flags;
  };
  template <typename ExpressionType>
  class WithFormat {
  public:
    WithFormat(const ExpressionType& matrix, const IOFormat& format) : m_matrix(matrix), m_format(format) {}
    friend std::ostream& operator<<(std::ostream& s, const WithFormat& wf) {
      return internal::print_matrix(s, wf.m_matrix.eval(), wf.m_format);
    }

  protected:
    typename ExpressionType::Nested m_matrix;
    IOFormat m_format;
  };
  namespace internal {
    template <typename Scalar>
    struct significant_decimals_impl {
      static inline int run() { return NumTraits<Scalar>::digits10(); }
    };
    template <typename Derived>
    std::ostream& print_matrix(std::ostream& s, const Derived& _m, const IOFormat& fmt) {
      using internal::is_same;
      if (_m.size() == 0) {
        s << fmt.matPrefix << fmt.matSuffix;
        return s;
      }
      typename Derived::Nested m = _m;
      typedef typename Derived::Scalar Scalar;
      typedef std::conditional_t<is_same<Scalar, char>::value || is_same<Scalar, unsigned char>::value ||
                                     is_same<Scalar, numext::int8_t>::value || is_same<Scalar, numext::uint8_t>::value,
                                 int,
                                 std::conditional_t<is_same<Scalar, std::complex<char>>::value ||
                                                        is_same<Scalar, std::complex<unsigned char>>::value ||
                                                        is_same<Scalar, std::complex<numext::int8_t>>::value ||
                                                        is_same<Scalar, std::complex<numext::uint8_t>>::value,
                                                    std::complex<int>,
                                                    const Scalar&>>
          PrintType;
      Index width = 0;
      std::streamsize explicit_precision;
      if (fmt.precision == StreamPrecision) {
        explicit_precision = 0;
      } else if (fmt.precision == FullPrecision) {
        if (NumTraits<Scalar>::IsInteger) {
          explicit_precision = 0;
        } else {
          explicit_precision = significant_decimals_impl<Scalar>::run();
        }
      } else {
        explicit_precision = fmt.precision;
      }
      std::streamsize old_precision = 0;
      if (explicit_precision)
        old_precision = s.precision(explicit_precision);
      bool align_cols = !(fmt.flags & DontAlignCols);
      if (align_cols) {
        for (Index j = 0; j < m.cols(); ++j)
          for (Index i = 0; i < m.rows(); ++i) {
            std::stringstream sstr;
            sstr.copyfmt(s);
            sstr << static_cast<PrintType>(m.coeff(i, j));
            width = std::max<Index>(width, Index(sstr.str().length()));
          }
      }
      std::streamsize old_width = s.width();
      char old_fill_character = s.fill();
      s << fmt.matPrefix;
      for (Index i = 0; i < m.rows(); ++i) {
        if (i)
          s << fmt.rowSpacer;
        s << fmt.rowPrefix;
        if (width) {
          s.fill(fmt.fill);
          s.width(width);
        }
        s << static_cast<PrintType>(m.coeff(i, 0));
        for (Index j = 1; j < m.cols(); ++j) {
          s << fmt.coeffSeparator;
          if (width) {
            s.fill(fmt.fill);
            s.width(width);
          }
          s << static_cast<PrintType>(m.coeff(i, j));
        }
        s << fmt.rowSuffix;
        if (i < m.rows() - 1)
          s << fmt.rowSeparator;
      }
      s << fmt.matSuffix;
      if (explicit_precision)
        s.precision(old_precision);
      if (width) {
        s.fill(old_fill_character);
        s.width(old_width);
      }
      return s;
    }
  }  // namespace internal
  template <typename Derived>
  std::ostream& operator<<(std::ostream& s, const DenseBase<Derived>& m) {
    return internal::print_matrix(s, m.eval(), Eigen::IOFormat());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T>
    struct add_const_on_value_type_if_arithmetic {
      typedef std::conditional_t<is_arithmetic<T>::value, T, add_const_on_value_type_t<T>> type;
    };
  }  // namespace internal
  template <typename Derived>
  class DenseCoeffsBase<Derived, ReadOnlyAccessors> : public EigenBase<Derived> {
  public:
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef std::conditional_t<bool(internal::traits<Derived>::Flags& LvalueBit),
                               const Scalar&,
                               std::conditional_t<internal::is_arithmetic<Scalar>::value, Scalar, const Scalar>>
        CoeffReturnType;
    typedef
        typename internal::add_const_on_value_type_if_arithmetic<typename internal::packet_traits<Scalar>::type>::type
            PacketReturnType;
    typedef EigenBase<Derived> Base;
    using Base::cols;
    using Base::derived;
    using Base::rows;
    using Base::size;
    inline Index rowIndexByOuterInner(Index outer, Index inner) const {
      return int(Derived::RowsAtCompileTime) == 1   ? 0
             : int(Derived::ColsAtCompileTime) == 1 ? inner
             : int(Derived::Flags) & RowMajorBit    ? outer
                                                    : inner;
    }
    inline Index colIndexByOuterInner(Index outer, Index inner) const {
      return int(Derived::ColsAtCompileTime) == 1   ? 0
             : int(Derived::RowsAtCompileTime) == 1 ? inner
             : int(Derived::Flags) & RowMajorBit    ? inner
                                                    : outer;
    }
    inline CoeffReturnType coeff(Index row, Index col) const {
      ;
      return internal::evaluator<Derived>(derived()).coeff(row, col);
    }
    inline CoeffReturnType coeffByOuterInner(Index outer, Index inner) const {
      return coeff(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
    }
    inline CoeffReturnType operator()(Index row, Index col) const {
      (static_cast<bool>(row >= 0 && row < rows() && col >= 0 && col < cols())
           ? void(0)
           : __assert_fail("row >= 0 && row < rows() && col >= 0 && col < cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           121,
                           __extension__ __PRETTY_FUNCTION__));
      return coeff(row, col);
    }
    inline CoeffReturnType coeff(Index index) const {
      static_assert(internal::evaluator<Derived>::Flags & LinearAccessBit,
                    "THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS");
      ;
      return internal::evaluator<Derived>(derived()).coeff(index);
    }
    inline CoeffReturnType operator[](Index index) const {
      static_assert(Derived::IsVectorAtCompileTime,
                    "THE_BRACKET_OPERATOR_IS_ONLY_FOR_VECTORS__USE_THE_PARENTHESIS_OPERATOR_INSTEAD");
      (static_cast<bool>(index >= 0 && index < size())
           ? void(0)
           : __assert_fail("index >= 0 && index < size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           165,
                           __extension__ __PRETTY_FUNCTION__));
      return coeff(index);
    }
    inline CoeffReturnType operator()(Index index) const {
      (static_cast<bool>(index >= 0 && index < size())
           ? void(0)
           : __assert_fail("index >= 0 && index < size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           183,
                           __extension__ __PRETTY_FUNCTION__));
      return coeff(index);
    }
    inline CoeffReturnType x() const { return (*this)[0]; }
    inline CoeffReturnType y() const {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 2, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[1];
    }
    inline CoeffReturnType z() const {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 3, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[2];
    }
    inline CoeffReturnType w() const {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 4, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[3];
    }
    template <int LoadMode>
    inline PacketReturnType packet(Index row, Index col) const {
      typedef typename internal::packet_traits<Scalar>::type DefaultPacketType;
      ;
      return internal::evaluator<Derived>(derived()).template packet<LoadMode, DefaultPacketType>(row, col);
    }
    template <int LoadMode>
    inline PacketReturnType packetByOuterInner(Index outer, Index inner) const {
      return packet<LoadMode>(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
    }
    template <int LoadMode>
    inline PacketReturnType packet(Index index) const {
      static_assert(internal::evaluator<Derived>::Flags & LinearAccessBit,
                    "THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS");
      typedef typename internal::packet_traits<Scalar>::type DefaultPacketType;
      ;
      return internal::evaluator<Derived>(derived()).template packet<LoadMode, DefaultPacketType>(index);
    }

  protected:
    void coeffRef();
    void coeffRefByOuterInner();
    void writePacket();
    void writePacketByOuterInner();
    void copyCoeff();
    void copyCoeffByOuterInner();
    void copyPacket();
    void copyPacketByOuterInner();
    void stride();
    void innerStride();
    void outerStride();
    void rowStride();
    void colStride();
  };
  template <typename Derived>
  class DenseCoeffsBase<Derived, WriteAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors> {
  public:
    typedef DenseCoeffsBase<Derived, ReadOnlyAccessors> Base;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    using Base::coeff;
    using Base::colIndexByOuterInner;
    using Base::cols;
    using Base::derived;
    using Base::rowIndexByOuterInner;
    using Base::rows;
    using Base::size;
    using Base::operator[];
    using Base::operator();
    using Base::w;
    using Base::x;
    using Base::y;
    using Base::z;
    inline Scalar& coeffRef(Index row, Index col) {
      ;
      return internal::evaluator<Derived>(derived()).coeffRef(row, col);
    }
    inline Scalar& coeffRefByOuterInner(Index outer, Index inner) {
      return coeffRef(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
    }
    inline Scalar& operator()(Index row, Index col) {
      (static_cast<bool>(row >= 0 && row < rows() && col >= 0 && col < cols())
           ? void(0)
           : __assert_fail("row >= 0 && row < rows() && col >= 0 && col < cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           369,
                           __extension__ __PRETTY_FUNCTION__));
      return coeffRef(row, col);
    }
    inline Scalar& coeffRef(Index index) {
      static_assert(internal::evaluator<Derived>::Flags & LinearAccessBit,
                    "THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS");
      ;
      return internal::evaluator<Derived>(derived()).coeffRef(index);
    }
    inline Scalar& operator[](Index index) {
      static_assert(Derived::IsVectorAtCompileTime,
                    "THE_BRACKET_OPERATOR_IS_ONLY_FOR_VECTORS__USE_THE_PARENTHESIS_OPERATOR_INSTEAD");
      (static_cast<bool>(index >= 0 && index < size())
           ? void(0)
           : __assert_fail("index >= 0 && index < size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           412,
                           __extension__ __PRETTY_FUNCTION__));
      return coeffRef(index);
    }
    inline Scalar& operator()(Index index) {
      (static_cast<bool>(index >= 0 && index < size())
           ? void(0)
           : __assert_fail("index >= 0 && index < size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseCoeffsBase.h",
                           429,
                           __extension__ __PRETTY_FUNCTION__));
      return coeffRef(index);
    }
    inline Scalar& x() { return (*this)[0]; }
    inline Scalar& y() {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 2, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[1];
    }
    inline Scalar& z() {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 3, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[2];
    }
    inline Scalar& w() {
      static_assert(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 4, "OUT_OF_RANGE_ACCESS");
      ;
      return (*this)[3];
    }
  };
  template <typename Derived>
  class DenseCoeffsBase<Derived, DirectAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors> {
  public:
    typedef DenseCoeffsBase<Derived, ReadOnlyAccessors> Base;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    using Base::cols;
    using Base::derived;
    using Base::rows;
    using Base::size;
    constexpr inline Index innerStride() const { return derived().innerStride(); }
    constexpr inline Index outerStride() const { return derived().outerStride(); }
    constexpr inline Index stride() const { return Derived::IsVectorAtCompileTime ? innerStride() : outerStride(); }
    constexpr inline Index rowStride() const { return Derived::IsRowMajor ? outerStride() : innerStride(); }
    constexpr inline Index colStride() const { return Derived::IsRowMajor ? innerStride() : outerStride(); }
  };
  template <typename Derived>
  class DenseCoeffsBase<Derived, DirectWriteAccessors> : public DenseCoeffsBase<Derived, WriteAccessors> {
  public:
    typedef DenseCoeffsBase<Derived, WriteAccessors> Base;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    using Base::cols;
    using Base::derived;
    using Base::rows;
    using Base::size;
    constexpr inline Index innerStride() const noexcept { return derived().innerStride(); }
    constexpr inline Index outerStride() const noexcept { return derived().outerStride(); }
    constexpr inline Index stride() const noexcept {
      return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
    }
    constexpr inline Index rowStride() const noexcept { return Derived::IsRowMajor ? outerStride() : innerStride(); }
    constexpr inline Index colStride() const noexcept { return Derived::IsRowMajor ? innerStride() : outerStride(); }
  };
  namespace internal {
    template <int Alignment, typename Derived, bool JustReturnZero>
    struct first_aligned_impl {
      static constexpr inline Index run(const Derived&) noexcept { return 0; }
    };
    template <int Alignment, typename Derived>
    struct first_aligned_impl<Alignment, Derived, false> {
      static inline Index run(const Derived& m) { return internal::first_aligned<Alignment>(m.data(), m.size()); }
    };
    template <int Alignment, typename Derived>
    static inline Index first_aligned(const DenseBase<Derived>& m) {
      enum { ReturnZero = (int(evaluator<Derived>::Alignment) >= Alignment) || !(Derived::Flags & DirectAccessBit) };
      return first_aligned_impl<Alignment, Derived, ReturnZero>::run(m.derived());
    }
    template <typename Derived>
    static inline Index first_default_aligned(const DenseBase<Derived>& m) {
      typedef typename Derived::Scalar Scalar;
      typedef typename packet_traits<Scalar>::type DefaultPacketType;
      return internal::first_aligned<int(unpacket_traits<DefaultPacketType>::alignment), Derived>(m);
    }
    template <typename Derived, bool HasDirectAccess = has_direct_access<Derived>::ret>
    struct inner_stride_at_compile_time {
      enum { ret = traits<Derived>::InnerStrideAtCompileTime };
    };
    template <typename Derived>
    struct inner_stride_at_compile_time<Derived, false> {
      enum { ret = 0 };
    };
    template <typename Derived, bool HasDirectAccess = has_direct_access<Derived>::ret>
    struct outer_stride_at_compile_time {
      enum { ret = traits<Derived>::OuterStrideAtCompileTime };
    };
    template <typename Derived>
    struct outer_stride_at_compile_time<Derived, false> {
      enum { ret = 0 };
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  static_assert(NumTraits<DenseIndex>::IsSigned, "THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE");
  template <typename Derived>
  class DenseBase : public DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value> {
  public:
    typedef Eigen::InnerIterator<Derived> InnerIterator;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef Scalar value_type;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value> Base;
    using Base::coeff;
    using Base::coeffByOuterInner;
    using Base::colIndexByOuterInner;
    using Base::cols;
    using Base::const_cast_derived;
    using Base::derived;
    using Base::rowIndexByOuterInner;
    using Base::rows;
    using Base::size;
    using Base::operator();
    using Base::operator[];
    using Base::colStride;
    using Base::innerStride;
    using Base::outerStride;
    using Base::rowStride;
    using Base::stride;
    using Base::w;
    using Base::x;
    using Base::y;
    using Base::z;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    enum {
      RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
      SizeAtCompileTime = (internal::size_of_xpr_at_compile_time<Derived>::ret),
      MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
      MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits<Derived>::MaxRowsAtCompileTime,
                                                            internal::traits<Derived>::MaxColsAtCompileTime),
      IsVectorAtCompileTime =
          internal::traits<Derived>::RowsAtCompileTime == 1 || internal::traits<Derived>::ColsAtCompileTime == 1,
      NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0
                      : bool(IsVectorAtCompileTime)  ? 1
                                                     : 2,
      Flags = internal::traits<Derived>::Flags,
      IsRowMajor = int(Flags) & RowMajorBit,
      InnerSizeAtCompileTime = int(IsVectorAtCompileTime) ? int(SizeAtCompileTime)
                               : int(IsRowMajor)          ? int(ColsAtCompileTime)
                                                          : int(RowsAtCompileTime),
      InnerStrideAtCompileTime = internal::inner_stride_at_compile_time<Derived>::ret,
      OuterStrideAtCompileTime = internal::outer_stride_at_compile_time<Derived>::ret
    };
    typedef typename internal::find_best_packet<Scalar, SizeAtCompileTime>::type PacketScalar;
    enum { IsPlainObjectBase = 0 };
    typedef Matrix<typename internal::traits<Derived>::Scalar,
                   internal::traits<Derived>::RowsAtCompileTime,
                   internal::traits<Derived>::ColsAtCompileTime,
                   AutoAlign | (internal::traits<Derived>::Flags & RowMajorBit ? RowMajor : ColMajor),
                   internal::traits<Derived>::MaxRowsAtCompileTime,
                   internal::traits<Derived>::MaxColsAtCompileTime>
        PlainMatrix;
    typedef Array<typename internal::traits<Derived>::Scalar,
                  internal::traits<Derived>::RowsAtCompileTime,
                  internal::traits<Derived>::ColsAtCompileTime,
                  AutoAlign | (internal::traits<Derived>::Flags & RowMajorBit ? RowMajor : ColMajor),
                  internal::traits<Derived>::MaxRowsAtCompileTime,
                  internal::traits<Derived>::MaxColsAtCompileTime>
        PlainArray;
    typedef std::conditional_t<internal::is_same<typename internal::traits<Derived>::XprKind, MatrixXpr>::value,
                               PlainMatrix,
                               PlainArray>
        PlainObject;
    constexpr Index outerSize() const {
      return IsVectorAtCompileTime ? 1 : int(IsRowMajor) ? this->rows() : this->cols();
    }
    constexpr Index innerSize() const {
      return IsVectorAtCompileTime ? this->size() : int(IsRowMajor) ? this->cols() : this->rows();
    }
    void resize(Index newSize) {
      ;
      (static_cast<bool>(newSize == this->size() && "DenseBase::resize() does not actually allow to resize.")
           ? void(0)
           : __assert_fail("newSize == this->size() && \"DenseBase::resize() does not actually allow to resize.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseBase.h",
                           239,
                           __extension__ __PRETTY_FUNCTION__));
    }
    void resize(Index rows, Index cols) {
      ;
      ;
      (static_cast<bool>(rows == this->rows() && cols == this->cols() &&
                         "DenseBase::resize() does not actually allow to resize.")
           ? void(0)
           : __assert_fail("rows == this->rows() && cols == this->cols() && \"DenseBase::resize() does not actually "
                           "allow to resize.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseBase.h",
                           251,
                           __extension__ __PRETTY_FUNCTION__));
    }
    typedef CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> ConstantReturnType;
    __attribute__((deprecated)) typedef CwiseNullaryOp<internal::linspaced_op<Scalar>, PlainObject>
        SequentialLinSpacedReturnType;
    typedef CwiseNullaryOp<internal::linspaced_op<Scalar>, PlainObject> RandomAccessLinSpacedReturnType;
    typedef Matrix<typename NumTraits<typename internal::traits<Derived>::Scalar>::Real,
                   internal::traits<Derived>::ColsAtCompileTime,
                   1>
        EigenvaluesReturnType;
    template <typename OtherDerived>
    inline Derived& operator=(const DenseBase<OtherDerived>& other);
    inline Derived& operator=(const DenseBase& other);
    template <typename OtherDerived>
    Derived& operator=(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    Derived& operator+=(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    Derived& operator-=(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    Derived& operator=(const ReturnByValue<OtherDerived>& func);
    template <typename OtherDerived>
    __attribute__((deprecated)) Derived& lazyAssign(const DenseBase<OtherDerived>& other);
    CommaInitializer<Derived> operator<<(const Scalar& s);
    template <unsigned int Added, unsigned int Removed>
    __attribute__((deprecated)) const Derived& flagged() const {
      return derived();
    }
    template <typename OtherDerived>
    CommaInitializer<Derived> operator<<(const DenseBase<OtherDerived>& other);
    typedef Transpose<Derived> TransposeReturnType;
    TransposeReturnType transpose();
    typedef Transpose<const Derived> ConstTransposeReturnType;
    const ConstTransposeReturnType transpose() const;
    void transposeInPlace();
    static const ConstantReturnType Constant(Index rows, Index cols, const Scalar& value);
    static const ConstantReturnType Constant(Index size, const Scalar& value);
    static const ConstantReturnType Constant(const Scalar& value);
    __attribute__((deprecated)) static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t,
                                                                                       Index size,
                                                                                       const Scalar& low,
                                                                                       const Scalar& high);
    __attribute__((deprecated)) static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t,
                                                                                       const Scalar& low,
                                                                                       const Scalar& high);
    static const RandomAccessLinSpacedReturnType LinSpaced(Index size, const Scalar& low, const Scalar& high);
    static const RandomAccessLinSpacedReturnType LinSpaced(const Scalar& low, const Scalar& high);
    template <typename CustomNullaryOp>
    static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(Index rows,
                                                                          Index cols,
                                                                          const CustomNullaryOp& func);
    template <typename CustomNullaryOp>
    static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(Index size, const CustomNullaryOp& func);
    template <typename CustomNullaryOp>
    static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(const CustomNullaryOp& func);
    static const ConstantReturnType Zero(Index rows, Index cols);
    static const ConstantReturnType Zero(Index size);
    static const ConstantReturnType Zero();
    static const ConstantReturnType Ones(Index rows, Index cols);
    static const ConstantReturnType Ones(Index size);
    static const ConstantReturnType Ones();
    void fill(const Scalar& value);
    Derived& setConstant(const Scalar& value);
    Derived& setLinSpaced(Index size, const Scalar& low, const Scalar& high);
    Derived& setLinSpaced(const Scalar& low, const Scalar& high);
    Derived& setZero();
    Derived& setOnes();
    Derived& setRandom();
    template <typename OtherDerived>
    bool isApprox(const DenseBase<OtherDerived>& other,
                  const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isMuchSmallerThan(const RealScalar& other,
                           const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    template <typename OtherDerived>
    bool isMuchSmallerThan(const DenseBase<OtherDerived>& other,
                           const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isApproxToConstant(const Scalar& value, const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isConstant(const Scalar& value, const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isZero(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isOnes(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    inline bool hasNaN() const;
    inline bool allFinite() const;
    inline Derived& operator*=(const Scalar& other);
    inline Derived& operator/=(const Scalar& other);
    typedef internal::add_const_on_value_type_t<typename internal::eval<Derived>::type> EvalReturnType;
    inline EvalReturnType eval() const { return typename internal::eval<Derived>::type(derived()); }
    template <typename OtherDerived>
    inline void swap(const DenseBase<OtherDerived>& other) {
      static_assert(!OtherDerived::IsPlainObjectBase, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      (static_cast<bool>(rows() == other.rows() && cols() == other.cols())
           ? void(0)
           : __assert_fail("rows()==other.rows() && cols()==other.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseBase.h",
                           412,
                           __extension__ __PRETTY_FUNCTION__));
      call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op<Scalar>());
    }
    template <typename OtherDerived>
    inline void swap(PlainObjectBase<OtherDerived>& other) {
      (static_cast<bool>(rows() == other.rows() && cols() == other.cols())
           ? void(0)
           : __assert_fail("rows()==other.rows() && cols()==other.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseBase.h",
                           423,
                           __extension__ __PRETTY_FUNCTION__));
      call_assignment(derived(), other.derived(), internal::swap_assign_op<Scalar>());
    }
    inline const NestByValue<Derived> nestByValue() const;
    inline const ForceAlignedAccess<Derived> forceAlignedAccess() const;
    inline ForceAlignedAccess<Derived> forceAlignedAccess();
    template <bool Enable>
    inline const std::conditional_t<Enable, ForceAlignedAccess<Derived>, Derived&> forceAlignedAccessIf() const;
    template <bool Enable>
    inline std::conditional_t<Enable, ForceAlignedAccess<Derived>, Derived&> forceAlignedAccessIf();
    Scalar sum() const;
    Scalar mean() const;
    Scalar trace() const;
    Scalar prod() const;
    template <int NaNPropagation>
    typename internal::traits<Derived>::Scalar minCoeff() const;
    template <int NaNPropagation>
    typename internal::traits<Derived>::Scalar maxCoeff() const;
    inline typename internal::traits<Derived>::Scalar minCoeff() const { return minCoeff<PropagateFast>(); }
    inline typename internal::traits<Derived>::Scalar maxCoeff() const { return maxCoeff<PropagateFast>(); }
    template <int NaNPropagation, typename IndexType>
    typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const;
    template <int NaNPropagation, typename IndexType>
    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const;
    template <int NaNPropagation, typename IndexType>
    typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const;
    template <int NaNPropagation, typename IndexType>
    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const;
    template <typename IndexType>
    inline typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const {
      return minCoeff<PropagateFast>(row, col);
    }
    template <typename IndexType>
    inline typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const {
      return maxCoeff<PropagateFast>(row, col);
    }
    template <typename IndexType>
    inline typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const {
      return minCoeff<PropagateFast>(index);
    }
    template <typename IndexType>
    inline typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const {
      return maxCoeff<PropagateFast>(index);
    }
    template <typename BinaryOp>
    Scalar redux(const BinaryOp& func) const;
    template <typename Visitor>
    void visit(Visitor& func) const;
    inline const WithFormat<Derived> format(const IOFormat& fmt) const { return WithFormat<Derived>(derived(), fmt); }
    CoeffReturnType value() const {
      static_assert((Derived::RowsAtCompileTime == 1 || Derived::RowsAtCompileTime == Eigen::Dynamic) &&
                        (Derived::ColsAtCompileTime == 1 || Derived::ColsAtCompileTime == Eigen::Dynamic),
                    "THIS_METHOD_IS_ONLY_FOR_1x1_EXPRESSIONS");
      (static_cast<bool>(this->rows() == 1 && this->cols() == 1)
           ? void(0)
           : __assert_fail("this->rows() == 1 && this->cols() == 1",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/DenseBase.h",
                           518,
                           __extension__ __PRETTY_FUNCTION__));
      return derived().coeff(0, 0);
    }
    bool all() const;
    bool any() const;
    Index count() const;
    typedef VectorwiseOp<Derived, Horizontal> RowwiseReturnType;
    typedef const VectorwiseOp<const Derived, Horizontal> ConstRowwiseReturnType;
    typedef VectorwiseOp<Derived, Vertical> ColwiseReturnType;
    typedef const VectorwiseOp<const Derived, Vertical> ConstColwiseReturnType;
    inline ConstRowwiseReturnType rowwise() const { return ConstRowwiseReturnType(derived()); }
    RowwiseReturnType rowwise();
    inline ConstColwiseReturnType colwise() const { return ConstColwiseReturnType(derived()); }
    ColwiseReturnType colwise();
    typedef CwiseNullaryOp<internal::scalar_random_op<Scalar>, PlainObject> RandomReturnType;
    static const RandomReturnType Random(Index rows, Index cols);
    static const RandomReturnType Random(Index size);
    static const RandomReturnType Random();
    template <typename ThenDerived, typename ElseDerived>
    inline const Select<Derived, ThenDerived, ElseDerived> select(const DenseBase<ThenDerived>& thenMatrix,
                                                                  const DenseBase<ElseDerived>& elseMatrix) const;
    template <typename ThenDerived>
    inline const Select<Derived, ThenDerived, typename ThenDerived::ConstantReturnType> select(
        const DenseBase<ThenDerived>& thenMatrix, const typename ThenDerived::Scalar& elseScalar) const;
    template <typename ElseDerived>
    inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived> select(
        const typename ElseDerived::Scalar& thenScalar, const DenseBase<ElseDerived>& elseMatrix) const;
    template <int p>
    RealScalar lpNorm() const;
    template <int RowFactor, int ColFactor>
    const Replicate<Derived, RowFactor, ColFactor> replicate() const;
    const Replicate<Derived, Dynamic, Dynamic> replicate(Index rowFactor, Index colFactor) const {
      return Replicate<Derived, Dynamic, Dynamic>(derived(), rowFactor, colFactor);
    }
    typedef Reverse<Derived, BothDirections> ReverseReturnType;
    typedef const Reverse<const Derived, BothDirections> ConstReverseReturnType;
    ReverseReturnType reverse();
    ConstReverseReturnType reverse() const { return ConstReverseReturnType(derived()); }
    void reverseInPlace();
    typedef std::conditional_t<(Flags & DirectAccessBit) == DirectAccessBit,
                               internal::pointer_based_stl_iterator<Derived>,
                               internal::generic_randaccess_stl_iterator<Derived>>
        iterator_type;
    typedef std::conditional_t<(Flags & DirectAccessBit) == DirectAccessBit,
                               internal::pointer_based_stl_iterator<const Derived>,
                               internal::generic_randaccess_stl_iterator<const Derived>>
        const_iterator_type;
    typedef std::conditional_t<IsVectorAtCompileTime, iterator_type, void> iterator;
    typedef std::conditional_t<IsVectorAtCompileTime, const_iterator_type, void> const_iterator;
    inline iterator begin();
    inline const_iterator begin() const;
    inline const_iterator cbegin() const;
    inline iterator end();
    inline const_iterator end() const;
    inline const_iterator cend() const;
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               const CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, const Derived>,
                               const Derived&>
        ConjugateReturnType;
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               const CwiseUnaryOp<internal::scalar_real_op<Scalar>, const Derived>,
                               const Derived&>
        RealReturnType;
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               CwiseUnaryView<internal::scalar_real_ref_op<Scalar>, Derived>,
                               Derived&>
        NonConstRealReturnType;
    typedef CwiseUnaryOp<internal::scalar_imag_op<Scalar>, const Derived> ImagReturnType;
    typedef CwiseUnaryView<internal::scalar_imag_ref_op<Scalar>, Derived> NonConstImagReturnType;
    typedef CwiseUnaryOp<internal::scalar_opposite_op<Scalar>, const Derived> NegativeReturnType;
    inline const NegativeReturnType operator-() const { return NegativeReturnType(derived()); }
    template <class NewType>
    struct CastXpr {
      typedef typename internal::cast_return_type<
          Derived,
          const CwiseUnaryOp<internal::scalar_cast_op<Scalar, NewType>, const Derived>>::type Type;
    };
    template <typename NewType>
    typename CastXpr<NewType>::Type cast() const {
      return typename CastXpr<NewType>::Type(derived());
    }
    inline ConjugateReturnType conjugate() const { return ConjugateReturnType(derived()); }
    template <bool Cond>
    inline std::conditional_t<Cond, ConjugateReturnType, const Derived&> conjugateIf() const {
      typedef std::conditional_t<Cond, ConjugateReturnType, const Derived&> ReturnType;
      return ReturnType(derived());
    }
    inline RealReturnType real() const { return RealReturnType(derived()); }
    inline const ImagReturnType imag() const { return ImagReturnType(derived()); }
    template <typename CustomUnaryOp>
    inline const CwiseUnaryOp<CustomUnaryOp, const Derived> unaryExpr(
        const CustomUnaryOp& func = CustomUnaryOp()) const {
      return CwiseUnaryOp<CustomUnaryOp, const Derived>(derived(), func);
    }
    template <typename CustomViewOp>
    inline const CwiseUnaryView<CustomViewOp, const Derived> unaryViewExpr(
        const CustomViewOp& func = CustomViewOp()) const {
      return CwiseUnaryView<CustomViewOp, const Derived>(derived(), func);
    }
    inline NonConstRealReturnType real() { return NonConstRealReturnType(derived()); }
    inline NonConstImagReturnType imag() { return NonConstImagReturnType(derived()); }
    typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, 1, !IsRowMajor> ColXpr;
    typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, 1, !IsRowMajor> ConstColXpr;
    typedef Block<Derived, 1, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> RowXpr;
    typedef const Block<const Derived, 1, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> ConstRowXpr;
    typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, Dynamic, !IsRowMajor> ColsBlockXpr;
    typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, Dynamic, !IsRowMajor>
        ConstColsBlockXpr;
    typedef Block<Derived, Dynamic, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> RowsBlockXpr;
    typedef const Block<const Derived, Dynamic, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor>
        ConstRowsBlockXpr;
    template <int N>
    struct NColsBlockXpr {
      typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, N, !IsRowMajor> Type;
    };
    template <int N>
    struct ConstNColsBlockXpr {
      typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, N, !IsRowMajor> Type;
    };
    template <int N>
    struct NRowsBlockXpr {
      typedef Block<Derived, N, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> Type;
    };
    template <int N>
    struct ConstNRowsBlockXpr {
      typedef const Block<const Derived, N, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> Type;
    };
    typedef Block<Derived> BlockXpr;
    typedef const Block<const Derived> ConstBlockXpr;
    template <int Rows, int Cols>
    struct FixedBlockXpr {
      typedef Block<Derived, Rows, Cols> Type;
    };
    template <int Rows, int Cols>
    struct ConstFixedBlockXpr {
      typedef Block<const Derived, Rows, Cols> Type;
    };
    typedef VectorBlock<Derived> SegmentReturnType;
    typedef const VectorBlock<const Derived> ConstSegmentReturnType;
    template <int Size>
    struct FixedSegmentReturnType {
      typedef VectorBlock<Derived, Size> Type;
    };
    template <int Size>
    struct ConstFixedSegmentReturnType {
      typedef const VectorBlock<const Derived, Size> Type;
    };
    typedef Block<Derived, IsRowMajor ? 1 : Dynamic, IsRowMajor ? Dynamic : 1, true> InnerVectorReturnType;
    typedef Block<const Derived, IsRowMajor ? 1 : Dynamic, IsRowMajor ? Dynamic : 1, true> ConstInnerVectorReturnType;
    typedef Block<Derived, Dynamic, Dynamic, true> InnerVectorsReturnType;
    typedef Block<const Derived, Dynamic, Dynamic, true> ConstInnerVectorsReturnType;
    template <typename NRowsType, typename NColsType>
    inline typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                  internal::get_fixed_value<NColsType>::value>::Type
    block(Index startRow, Index startCol, NRowsType blockRows, NColsType blockCols) {
      return typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                    internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                       startRow,
                                                                                       startCol,
                                                                                       internal::get_runtime_value(
                                                                                           blockRows),
                                                                                       internal::get_runtime_value(
                                                                                           blockCols));
    }
    template <typename NRowsType, typename NColsType>
    inline const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                             internal::get_fixed_value<NColsType>::value>::Type
    block(Index startRow, Index startCol, NRowsType blockRows, NColsType blockCols) const {
      return typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                         internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                            startRow,
                                                                                            startCol,
                                                                                            internal::get_runtime_value(
                                                                                                blockRows),
                                                                                            internal::get_runtime_value(
                                                                                                blockCols));
    }
    template <typename NRowsType, typename NColsType>
    inline typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                  internal::get_fixed_value<NColsType>::value>::Type
    topRightCorner(NRowsType cRows, NColsType cCols) {
      return
          typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                 internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                    0,
                                                                                    cols() -
                                                                                        internal::get_runtime_value(
                                                                                            cCols),
                                                                                    internal::get_runtime_value(cRows),
                                                                                    internal::get_runtime_value(cCols));
    }
    template <typename NRowsType, typename NColsType>
    inline const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                             internal::get_fixed_value<NColsType>::value>::Type
    topRightCorner(NRowsType cRows, NColsType cCols) const {
      return typename ConstFixedBlockXpr<
          internal::get_fixed_value<NRowsType>::value,
          internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                             0,
                                                             cols() - internal::get_runtime_value(cCols),
                                                             internal::get_runtime_value(cRows),
                                                             internal::get_runtime_value(cCols));
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type topRightCorner() {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - CCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type topRightCorner() const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - CCols);
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type topRightCorner(Index cRows, Index cCols) {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - cCols, cRows, cCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type topRightCorner(Index cRows, Index cCols) const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - cCols, cRows, cCols);
    }
    template <typename NRowsType, typename NColsType>
    inline typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                  internal::get_fixed_value<NColsType>::value>::Type
    topLeftCorner(NRowsType cRows, NColsType cCols) {
      return
          typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                 internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                    0,
                                                                                    0,
                                                                                    internal::get_runtime_value(cRows),
                                                                                    internal::get_runtime_value(cCols));
    }
    template <typename NRowsType, typename NColsType>
    inline const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                             internal::get_fixed_value<NColsType>::value>::Type
    topLeftCorner(NRowsType cRows, NColsType cCols) const {
      return typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                         internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                            0,
                                                                                            0,
                                                                                            internal::get_runtime_value(
                                                                                                cRows),
                                                                                            internal::get_runtime_value(
                                                                                                cCols));
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type topLeftCorner() {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type topLeftCorner() const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0);
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type topLeftCorner(Index cRows, Index cCols) {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0, cRows, cCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type topLeftCorner(Index cRows, Index cCols) const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0, cRows, cCols);
    }
    template <typename NRowsType, typename NColsType>
    inline typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                  internal::get_fixed_value<NColsType>::value>::Type
    bottomRightCorner(NRowsType cRows, NColsType cCols) {
      return
          typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                 internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                    rows() -
                                                                                        internal::get_runtime_value(
                                                                                            cRows),
                                                                                    cols() -
                                                                                        internal::get_runtime_value(
                                                                                            cCols),
                                                                                    internal::get_runtime_value(cRows),
                                                                                    internal::get_runtime_value(cCols));
    }
    template <typename NRowsType, typename NColsType>
    inline const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                             internal::get_fixed_value<NColsType>::value>::Type
    bottomRightCorner(NRowsType cRows, NColsType cCols) const {
      return typename ConstFixedBlockXpr<
          internal::get_fixed_value<NRowsType>::value,
          internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                             rows() - internal::get_runtime_value(cRows),
                                                             cols() - internal::get_runtime_value(cCols),
                                                             internal::get_runtime_value(cRows),
                                                             internal::get_runtime_value(cCols));
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type bottomRightCorner() {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, cols() - CCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomRightCorner() const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, cols() - CCols);
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type bottomRightCorner(Index cRows, Index cCols) {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, cols() - cCols, cRows, cCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomRightCorner(Index cRows, Index cCols) const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, cols() - cCols, cRows, cCols);
    }
    template <typename NRowsType, typename NColsType>
    inline typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                  internal::get_fixed_value<NColsType>::value>::Type
    bottomLeftCorner(NRowsType cRows, NColsType cCols) {
      return
          typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                 internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                                                    rows() -
                                                                                        internal::get_runtime_value(
                                                                                            cRows),
                                                                                    0,
                                                                                    internal::get_runtime_value(cRows),
                                                                                    internal::get_runtime_value(cCols));
    }
    template <typename NRowsType, typename NColsType>
    inline typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
                                       internal::get_fixed_value<NColsType>::value>::Type
    bottomLeftCorner(NRowsType cRows, NColsType cCols) const {
      return typename ConstFixedBlockXpr<
          internal::get_fixed_value<NRowsType>::value,
          internal::get_fixed_value<NColsType>::value>::Type(derived(),
                                                             rows() - internal::get_runtime_value(cRows),
                                                             0,
                                                             internal::get_runtime_value(cRows),
                                                             internal::get_runtime_value(cCols));
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type bottomLeftCorner() {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, 0);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomLeftCorner() const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, 0);
    }
    template <int CRows, int CCols>
    inline typename FixedBlockXpr<CRows, CCols>::Type bottomLeftCorner(Index cRows, Index cCols) {
      return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, 0, cRows, cCols);
    }
    template <int CRows, int CCols>
    inline const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomLeftCorner(Index cRows, Index cCols) const {
      return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, 0, cRows, cCols);
    }
    template <typename NRowsType>
    inline typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type topRows(NRowsType n) {
      return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), 0, 0, internal::get_runtime_value(n), cols());
    }
    template <typename NRowsType>
    inline const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type topRows(
        NRowsType n) const {
      return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), 0, 0, internal::get_runtime_value(n), cols());
    }
    template <int N>
    inline typename NRowsBlockXpr<N>::Type topRows(Index n = N) {
      return typename NRowsBlockXpr<N>::Type(derived(), 0, 0, n, cols());
    }
    template <int N>
    inline typename ConstNRowsBlockXpr<N>::Type topRows(Index n = N) const {
      return typename ConstNRowsBlockXpr<N>::Type(derived(), 0, 0, n, cols());
    }
    template <typename NRowsType>
    inline typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type bottomRows(NRowsType n) {
      return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), rows() - internal::get_runtime_value(n), 0, internal::get_runtime_value(n), cols());
    }
    template <typename NRowsType>
    inline const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type bottomRows(
        NRowsType n) const {
      return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), rows() - internal::get_runtime_value(n), 0, internal::get_runtime_value(n), cols());
    }
    template <int N>
    inline typename NRowsBlockXpr<N>::Type bottomRows(Index n = N) {
      return typename NRowsBlockXpr<N>::Type(derived(), rows() - n, 0, n, cols());
    }
    template <int N>
    inline typename ConstNRowsBlockXpr<N>::Type bottomRows(Index n = N) const {
      return typename ConstNRowsBlockXpr<N>::Type(derived(), rows() - n, 0, n, cols());
    }
    template <typename NRowsType>
    inline typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type middleRows(Index startRow,
                                                                                                NRowsType n) {
      return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), startRow, 0, internal::get_runtime_value(n), cols());
    }
    template <typename NRowsType>
    inline const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type middleRows(
        Index startRow, NRowsType n) const {
      return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
          derived(), startRow, 0, internal::get_runtime_value(n), cols());
    }
    template <int N>
    inline typename NRowsBlockXpr<N>::Type middleRows(Index startRow, Index n = N) {
      return typename NRowsBlockXpr<N>::Type(derived(), startRow, 0, n, cols());
    }
    template <int N>
    inline typename ConstNRowsBlockXpr<N>::Type middleRows(Index startRow, Index n = N) const {
      return typename ConstNRowsBlockXpr<N>::Type(derived(), startRow, 0, n, cols());
    }
    template <typename NColsType>
    inline typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type leftCols(NColsType n) {
      return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, 0, rows(), internal::get_runtime_value(n));
    }
    template <typename NColsType>
    inline const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type leftCols(
        NColsType n) const {
      return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, 0, rows(), internal::get_runtime_value(n));
    }
    template <int N>
    inline typename NColsBlockXpr<N>::Type leftCols(Index n = N) {
      return typename NColsBlockXpr<N>::Type(derived(), 0, 0, rows(), n);
    }
    template <int N>
    inline typename ConstNColsBlockXpr<N>::Type leftCols(Index n = N) const {
      return typename ConstNColsBlockXpr<N>::Type(derived(), 0, 0, rows(), n);
    }
    template <typename NColsType>
    inline typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type rightCols(NColsType n) {
      return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, cols() - internal::get_runtime_value(n), rows(), internal::get_runtime_value(n));
    }
    template <typename NColsType>
    inline const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type rightCols(
        NColsType n) const {
      return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, cols() - internal::get_runtime_value(n), rows(), internal::get_runtime_value(n));
    }
    template <int N>
    inline typename NColsBlockXpr<N>::Type rightCols(Index n = N) {
      return typename NColsBlockXpr<N>::Type(derived(), 0, cols() - n, rows(), n);
    }
    template <int N>
    inline typename ConstNColsBlockXpr<N>::Type rightCols(Index n = N) const {
      return typename ConstNColsBlockXpr<N>::Type(derived(), 0, cols() - n, rows(), n);
    }
    template <typename NColsType>
    inline typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type middleCols(Index startCol,
                                                                                                NColsType numCols) {
      return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, startCol, rows(), internal::get_runtime_value(numCols));
    }
    template <typename NColsType>
    inline const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type middleCols(
        Index startCol, NColsType numCols) const {
      return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
          derived(), 0, startCol, rows(), internal::get_runtime_value(numCols));
    }
    template <int N>
    inline typename NColsBlockXpr<N>::Type middleCols(Index startCol, Index n = N) {
      return typename NColsBlockXpr<N>::Type(derived(), 0, startCol, rows(), n);
    }
    template <int N>
    inline typename ConstNColsBlockXpr<N>::Type middleCols(Index startCol, Index n = N) const {
      return typename ConstNColsBlockXpr<N>::Type(derived(), 0, startCol, rows(), n);
    }
    template <int NRows, int NCols>
    inline typename FixedBlockXpr<NRows, NCols>::Type block(Index startRow, Index startCol) {
      return typename FixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol);
    }
    template <int NRows, int NCols>
    inline const typename ConstFixedBlockXpr<NRows, NCols>::Type block(Index startRow, Index startCol) const {
      return typename ConstFixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol);
    }
    template <int NRows, int NCols>
    inline typename FixedBlockXpr<NRows, NCols>::Type block(Index startRow,
                                                            Index startCol,
                                                            Index blockRows,
                                                            Index blockCols) {
      return typename FixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol, blockRows, blockCols);
    }
    template <int NRows, int NCols>
    inline const typename ConstFixedBlockXpr<NRows, NCols>::Type block(Index startRow,
                                                                       Index startCol,
                                                                       Index blockRows,
                                                                       Index blockCols) const {
      return typename ConstFixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol, blockRows, blockCols);
    }
    inline ColXpr col(Index i) { return ColXpr(derived(), i); }
    inline ConstColXpr col(Index i) const { return ConstColXpr(derived(), i); }
    inline RowXpr row(Index i) { return RowXpr(derived(), i); }
    inline ConstRowXpr row(Index i) const { return ConstRowXpr(derived(), i); }
    template <typename NType>
    inline typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type segment(Index start,
                                                                                                  NType n) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), start, internal::get_runtime_value(n));
    }
    template <typename NType>
    inline const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type segment(
        Index start, NType n) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), start, internal::get_runtime_value(n));
    }
    template <typename NType>
    inline typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type head(NType n) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), 0, internal::get_runtime_value(n));
    }
    template <typename NType>
    inline const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type head(
        NType n) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), 0, internal::get_runtime_value(n));
    }
    template <typename NType>
    inline typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type tail(NType n) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), this->size() - internal::get_runtime_value(n), internal::get_runtime_value(n));
    }
    template <typename NType>
    inline const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type tail(
        NType n) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
          derived(), this->size() - internal::get_runtime_value(n), internal::get_runtime_value(n));
    }
    template <int N>
    inline typename FixedSegmentReturnType<N>::Type segment(Index start, Index n = N) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<N>::Type(derived(), start, n);
    }
    template <int N>
    inline typename ConstFixedSegmentReturnType<N>::Type segment(Index start, Index n = N) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<N>::Type(derived(), start, n);
    }
    template <int N>
    inline typename FixedSegmentReturnType<N>::Type head(Index n = N) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<N>::Type(derived(), 0, n);
    }
    template <int N>
    inline typename ConstFixedSegmentReturnType<N>::Type head(Index n = N) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<N>::Type(derived(), 0, n);
    }
    template <int N>
    inline typename FixedSegmentReturnType<N>::Type tail(Index n = N) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename FixedSegmentReturnType<N>::Type(derived(), size() - n);
    }
    template <int N>
    inline typename ConstFixedSegmentReturnType<N>::Type tail(Index n = N) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return typename ConstFixedSegmentReturnType<N>::Type(derived(), size() - n);
    }
    inline InnerVectorReturnType innerVector(Index outer) { return InnerVectorReturnType(derived(), outer); }
    inline const ConstInnerVectorReturnType innerVector(Index outer) const {
      return ConstInnerVectorReturnType(derived(), outer);
    }
    inline InnerVectorsReturnType innerVectors(Index outerStart, Index outerSize) {
      return Block<Derived, Dynamic, Dynamic, true>(derived(),
                                                    IsRowMajor ? outerStart : 0,
                                                    IsRowMajor ? 0 : outerStart,
                                                    IsRowMajor ? outerSize : rows(),
                                                    IsRowMajor ? cols() : outerSize);
    }
    inline const ConstInnerVectorsReturnType innerVectors(Index outerStart, Index outerSize) const {
      return Block<const Derived, Dynamic, Dynamic, true>(derived(),
                                                          IsRowMajor ? outerStart : 0,
                                                          IsRowMajor ? 0 : outerStart,
                                                          IsRowMajor ? outerSize : rows(),
                                                          IsRowMajor ? cols() : outerSize);
    }
    template <DirectionType Direction>
    inline std::conditional_t<Direction == Vertical, ColXpr, RowXpr> subVector(Index i) {
      return std::conditional_t<Direction == Vertical, ColXpr, RowXpr>(derived(), i);
    }
    template <DirectionType Direction>
    inline std::conditional_t<Direction == Vertical, ConstColXpr, ConstRowXpr> subVector(Index i) const {
      return std::conditional_t<Direction == Vertical, ConstColXpr, ConstRowXpr>(derived(), i);
    }
    template <DirectionType Direction>
    inline constexpr Index subVectors() const {
      return (Direction == Vertical) ? cols() : rows();
    }

  protected:
    template <typename Indices>
    struct IvcRowType : public internal::IndexedViewCompatibleType<Indices, RowsAtCompileTime> {};
    template <typename Indices>
    struct IvcColType : public internal::IndexedViewCompatibleType<Indices, ColsAtCompileTime> {};
    template <typename Indices>
    struct IvcType : public internal::IndexedViewCompatibleType<Indices, SizeAtCompileTime> {};
    typedef typename internal::IndexedViewCompatibleType<Index, 1>::type IvcIndex;
    template <typename Indices>
    typename IvcRowType<Indices>::type ivcRow(const Indices& indices) const {
      return internal::makeIndexedViewCompatible(
          indices, internal::variable_if_dynamic<Index, RowsAtCompileTime>(derived().rows()), Specialized);
    }
    template <typename Indices>
    typename IvcColType<Indices>::type ivcCol(const Indices& indices) const {
      return internal::makeIndexedViewCompatible(
          indices, internal::variable_if_dynamic<Index, ColsAtCompileTime>(derived().cols()), Specialized);
    }
    template <typename Indices>
    typename IvcColType<Indices>::type ivcSize(const Indices& indices) const {
      return internal::makeIndexedViewCompatible(
          indices, internal::variable_if_dynamic<Index, SizeAtCompileTime>(derived().size()), Specialized);
    }

  public:
    template <typename RowIndices, typename ColIndices>
    struct ConstIndexedViewType {
      typedef IndexedView<const Derived, typename IvcRowType<RowIndices>::type, typename IvcColType<ColIndices>::type>
          type;
    };
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<
        internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
            internal::traits<typename ConstIndexedViewType<RowIndices, ColIndices>::type>::ReturnAsIndexedView,
        typename ConstIndexedViewType<RowIndices, ColIndices>::type>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) const {
      return typename ConstIndexedViewType<RowIndices, ColIndices>::type(
          derived(), ivcRow(rowIndices), ivcCol(colIndices));
    }
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
                         internal::traits<typename ConstIndexedViewType<RowIndices, ColIndices>::type>::ReturnAsBlock,
                     typename internal::traits<typename ConstIndexedViewType<RowIndices, ColIndices>::type>::BlockType>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) const {
      typedef
          typename internal::traits<typename ConstIndexedViewType<RowIndices, ColIndices>::type>::BlockType BlockType;
      typename IvcRowType<RowIndices>::type actualRowIndices = ivcRow(rowIndices);
      typename IvcColType<ColIndices>::type actualColIndices = ivcCol(colIndices);
      return BlockType(derived(),
                       internal::first(actualRowIndices),
                       internal::first(actualColIndices),
                       internal::index_list_size(actualRowIndices),
                       internal::index_list_size(actualColIndices));
    }
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
                         internal::traits<typename ConstIndexedViewType<RowIndices, ColIndices>::type>::ReturnAsScalar,
                     CoeffReturnType>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) const {
      return Base::operator()(internal::eval_expr_given_size(rowIndices, rows()),
                              internal::eval_expr_given_size(colIndices, cols()));
    }
    template <typename RowIndicesT, std::size_t RowIndicesN, typename ColIndices>
    IndexedView<const Derived, const RowIndicesT (&)[RowIndicesN], typename IvcColType<ColIndices>::type> operator()(
        const RowIndicesT (&rowIndices)[RowIndicesN], const ColIndices& colIndices) const {
      return IndexedView<const Derived, const RowIndicesT(&)[RowIndicesN], typename IvcColType<ColIndices>::type>(
          derived(), rowIndices, ivcCol(colIndices));
    }
    template <typename RowIndices, typename ColIndicesT, std::size_t ColIndicesN>
    IndexedView<const Derived, typename IvcRowType<RowIndices>::type, const ColIndicesT (&)[ColIndicesN]> operator()(
        const RowIndices& rowIndices, const ColIndicesT (&colIndices)[ColIndicesN]) const {
      return IndexedView<const Derived, typename IvcRowType<RowIndices>::type, const ColIndicesT(&)[ColIndicesN]>(
          derived(), ivcRow(rowIndices), colIndices);
    }
    template <typename RowIndicesT, std::size_t RowIndicesN, typename ColIndicesT, std::size_t ColIndicesN>
    IndexedView<const Derived, const RowIndicesT (&)[RowIndicesN], const ColIndicesT (&)[ColIndicesN]> operator()(
        const RowIndicesT (&rowIndices)[RowIndicesN], const ColIndicesT (&colIndices)[ColIndicesN]) const {
      return IndexedView<const Derived, const RowIndicesT(&)[RowIndicesN], const ColIndicesT(&)[ColIndicesN]>(
          derived(), rowIndices, colIndices);
    }
    template <typename Indices>
    std::enable_if_t<IsRowMajor && (!(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1 ||
                                      internal::is_valid_index_type<Indices>::value)),
                     IndexedView<const Derived, IvcIndex, typename IvcType<Indices>::type>>
    operator()(const Indices& indices) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<const Derived, IvcIndex, typename IvcType<Indices>::type>(
          derived(), IvcIndex(0), ivcCol(indices));
    }
    template <typename Indices>
    std::enable_if_t<(!IsRowMajor) && (!(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1 ||
                                         internal::is_valid_index_type<Indices>::value)),
                     IndexedView<const Derived, typename IvcType<Indices>::type, IvcIndex>>
    operator()(const Indices& indices) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<const Derived, typename IvcType<Indices>::type, IvcIndex>(
          derived(), ivcRow(indices), IvcIndex(0));
    }
    template <typename Indices>
    std::enable_if_t<(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1) &&
                         (!internal::is_valid_index_type<Indices>::value) && (!symbolic::is_symbolic<Indices>::value),
                     VectorBlock<const Derived, internal::array_size<Indices>::value>>
    operator()(const Indices& indices) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      typename IvcType<Indices>::type actualIndices = ivcSize(indices);
      return VectorBlock<const Derived, internal::array_size<Indices>::value>(
          derived(), internal::first(actualIndices), internal::index_list_size(actualIndices));
    }
    template <typename IndexType>
    std::enable_if_t<symbolic::is_symbolic<IndexType>::value, CoeffReturnType> operator()(const IndexType& id) const {
      return Base::operator()(internal::eval_expr_given_size(id, size()));
    }
    template <typename IndicesT, std::size_t IndicesN>
    std::enable_if_t<IsRowMajor, IndexedView<const Derived, IvcIndex, const IndicesT (&)[IndicesN]>> operator()(
        const IndicesT (&indices)[IndicesN]) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<const Derived, IvcIndex, const IndicesT(&)[IndicesN]>(derived(), IvcIndex(0), indices);
    }
    template <typename IndicesT, std::size_t IndicesN>
    std::enable_if_t<!IsRowMajor, IndexedView<const Derived, const IndicesT (&)[IndicesN], IvcIndex>> operator()(
        const IndicesT (&indices)[IndicesN]) const {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<const Derived, const IndicesT(&)[IndicesN], IvcIndex>(derived(), indices, IvcIndex(0));
    }
    template <typename RowIndices, typename ColIndices>
    struct IndexedViewType {
      typedef IndexedView<Derived, typename IvcRowType<RowIndices>::type, typename IvcColType<ColIndices>::type> type;
    };
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
                         internal::traits<typename IndexedViewType<RowIndices, ColIndices>::type>::ReturnAsIndexedView,
                     typename IndexedViewType<RowIndices, ColIndices>::type>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) {
      return typename IndexedViewType<RowIndices, ColIndices>::type(derived(), ivcRow(rowIndices), ivcCol(colIndices));
    }
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
                         internal::traits<typename IndexedViewType<RowIndices, ColIndices>::type>::ReturnAsBlock,
                     typename internal::traits<typename IndexedViewType<RowIndices, ColIndices>::type>::BlockType>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) {
      typedef typename internal::traits<typename IndexedViewType<RowIndices, ColIndices>::type>::BlockType BlockType;
      typename IvcRowType<RowIndices>::type actualRowIndices = ivcRow(rowIndices);
      typename IvcColType<ColIndices>::type actualColIndices = ivcCol(colIndices);
      return BlockType(derived(),
                       internal::first(actualRowIndices),
                       internal::first(actualColIndices),
                       internal::index_list_size(actualRowIndices),
                       internal::index_list_size(actualColIndices));
    }
    template <typename RowIndices, typename ColIndices>
    std::enable_if_t<internal::valid_indexed_view_overload<RowIndices, ColIndices>::value &&
                         internal::traits<typename IndexedViewType<RowIndices, ColIndices>::type>::ReturnAsScalar,
                     CoeffReturnType>
    operator()(const RowIndices& rowIndices, const ColIndices& colIndices) {
      return Base::operator()(internal::eval_expr_given_size(rowIndices, rows()),
                              internal::eval_expr_given_size(colIndices, cols()));
    }
    template <typename RowIndicesT, std::size_t RowIndicesN, typename ColIndices>
    IndexedView<Derived, const RowIndicesT (&)[RowIndicesN], typename IvcColType<ColIndices>::type> operator()(
        const RowIndicesT (&rowIndices)[RowIndicesN], const ColIndices& colIndices) {
      return IndexedView<Derived, const RowIndicesT(&)[RowIndicesN], typename IvcColType<ColIndices>::type>(
          derived(), rowIndices, ivcCol(colIndices));
    }
    template <typename RowIndices, typename ColIndicesT, std::size_t ColIndicesN>
    IndexedView<Derived, typename IvcRowType<RowIndices>::type, const ColIndicesT (&)[ColIndicesN]> operator()(
        const RowIndices& rowIndices, const ColIndicesT (&colIndices)[ColIndicesN]) {
      return IndexedView<Derived, typename IvcRowType<RowIndices>::type, const ColIndicesT(&)[ColIndicesN]>(
          derived(), ivcRow(rowIndices), colIndices);
    }
    template <typename RowIndicesT, std::size_t RowIndicesN, typename ColIndicesT, std::size_t ColIndicesN>
    IndexedView<Derived, const RowIndicesT (&)[RowIndicesN], const ColIndicesT (&)[ColIndicesN]> operator()(
        const RowIndicesT (&rowIndices)[RowIndicesN], const ColIndicesT (&colIndices)[ColIndicesN]) {
      return IndexedView<Derived, const RowIndicesT(&)[RowIndicesN], const ColIndicesT(&)[ColIndicesN]>(
          derived(), rowIndices, colIndices);
    }
    template <typename Indices>
    std::enable_if_t<IsRowMajor && (!(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1 ||
                                      internal::is_valid_index_type<Indices>::value)),
                     IndexedView<Derived, IvcIndex, typename IvcType<Indices>::type>>
    operator()(const Indices& indices) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<Derived, IvcIndex, typename IvcType<Indices>::type>(derived(), IvcIndex(0), ivcCol(indices));
    }
    template <typename Indices>
    std::enable_if_t<(!IsRowMajor) && (!(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1 ||
                                         internal::is_valid_index_type<Indices>::value)),
                     IndexedView<Derived, typename IvcType<Indices>::type, IvcIndex>>
    operator()(const Indices& indices) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<Derived, typename IvcType<Indices>::type, IvcIndex>(derived(), ivcRow(indices), IvcIndex(0));
    }
    template <typename Indices>
    std::enable_if_t<(internal::get_compile_time_incr<typename IvcType<Indices>::type>::value == 1) &&
                         (!internal::is_valid_index_type<Indices>::value) && (!symbolic::is_symbolic<Indices>::value),
                     VectorBlock<Derived, internal::array_size<Indices>::value>>
    operator()(const Indices& indices) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      typename IvcType<Indices>::type actualIndices = ivcSize(indices);
      return VectorBlock<Derived, internal::array_size<Indices>::value>(
          derived(), internal::first(actualIndices), internal::index_list_size(actualIndices));
    }
    template <typename IndexType>
    std::enable_if_t<symbolic::is_symbolic<IndexType>::value, CoeffReturnType> operator()(const IndexType& id) {
      return Base::operator()(internal::eval_expr_given_size(id, size()));
    }
    template <typename IndicesT, std::size_t IndicesN>
    std::enable_if_t<IsRowMajor, IndexedView<Derived, IvcIndex, const IndicesT (&)[IndicesN]>> operator()(
        const IndicesT (&indices)[IndicesN]) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<Derived, IvcIndex, const IndicesT(&)[IndicesN]>(derived(), IvcIndex(0), indices);
    }
    template <typename IndicesT, std::size_t IndicesN>
    std::enable_if_t<!IsRowMajor, IndexedView<Derived, const IndicesT (&)[IndicesN], IvcIndex>> operator()(
        const IndicesT (&indices)[IndicesN]) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      return IndexedView<Derived, const IndicesT(&)[IndicesN], IvcIndex>(derived(), indices, IvcIndex(0));
    }
    template <typename NRowsType, typename NColsType>
    inline Reshaped<const Derived,
                    internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value>
    reshaped(NRowsType nRows, NColsType nCols) const {
      return Reshaped<const Derived,
                      internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value>(
          derived(),
          internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),
          internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));
    }
    template <int Order, typename NRowsType, typename NColsType>
    inline Reshaped<const Derived,
                    internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_order(Flags, Order)>
    reshaped(NRowsType nRows, NColsType nCols) const {
      return Reshaped<const Derived,
                      internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_order(Flags, Order)>(
          derived(),
          internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),
          internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));
    }
    inline Reshaped<const Derived, SizeAtCompileTime, 1> reshaped() const {
      return Reshaped<const Derived, SizeAtCompileTime, 1>(derived(), size(), 1);
    }
    template <int Order>
    inline Reshaped<const Derived, SizeAtCompileTime, 1, internal::get_compiletime_reshape_order(Flags, Order)>
    reshaped() const {
      static_assert(Order == RowMajor || Order == ColMajor || Order == AutoOrder, "INVALID_TEMPLATE_PARAMETER");
      ;
      return Reshaped<const Derived, SizeAtCompileTime, 1, internal::get_compiletime_reshape_order(Flags, Order)>(
          derived(), size(), 1);
    }
    template <typename NRowsType, typename NColsType>
    inline Reshaped<Derived,
                    internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value>
    reshaped(NRowsType nRows, NColsType nCols) {
      return Reshaped<Derived,
                      internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value>(
          derived(),
          internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),
          internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));
    }
    template <int Order, typename NRowsType, typename NColsType>
    inline Reshaped<Derived,
                    internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value,
                    internal::get_compiletime_reshape_order(Flags, Order)>
    reshaped(NRowsType nRows, NColsType nCols) {
      return Reshaped<Derived,
                      internal::get_compiletime_reshape_size<NRowsType, NColsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_size<NColsType, NRowsType, SizeAtCompileTime>::value,
                      internal::get_compiletime_reshape_order(Flags, Order)>(
          derived(),
          internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),
          internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));
    }
    inline Reshaped<Derived, SizeAtCompileTime, 1> reshaped() {
      return Reshaped<Derived, SizeAtCompileTime, 1>(derived(), size(), 1);
    }
    template <int Order>
    inline Reshaped<Derived, SizeAtCompileTime, 1, internal::get_compiletime_reshape_order(Flags, Order)> reshaped() {
      static_assert(Order == RowMajor || Order == ColMajor || Order == AutoOrder, "INVALID_TEMPLATE_PARAMETER");
      ;
      return Reshaped<Derived, SizeAtCompileTime, 1, internal::get_compiletime_reshape_order(Flags, Order)>(
          derived(), size(), 1);
    }
    template <typename Dest>
    inline void evalTo(Dest&) const {
      static_assert((internal::is_same<Dest, void>::value),
                    "THE_EVAL_EVALTO_FUNCTION_SHOULD_NEVER_BE_CALLED_FOR_DENSE_OBJECTS");
      ;
    }

  protected:
    DenseBase(const DenseBase&) = default;
    DenseBase() {}

  private:
    explicit DenseBase(int);
    DenseBase(int, int);
    template <typename OtherDerived>
    explicit DenseBase(const DenseBase<OtherDerived>&);
  };
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  class MatrixBase : public DenseBase<Derived> {
  public:
    typedef MatrixBase StorageBaseType;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef DenseBase<Derived> Base;
    using Base::coeff;
    using Base::coeffRef;
    using Base::cols;
    using Base::ColsAtCompileTime;
    using Base::const_cast_derived;
    using Base::derived;
    using Base::eval;
    using Base::Flags;
    using Base::IsVectorAtCompileTime;
    using Base::lazyAssign;
    using Base::MaxColsAtCompileTime;
    using Base::MaxRowsAtCompileTime;
    using Base::MaxSizeAtCompileTime;
    using Base::rows;
    using Base::RowsAtCompileTime;
    using Base::size;
    using Base::SizeAtCompileTime;
    using Base::operator-;
    using Base::operator+=;
    using Base::operator-=;
    using Base::operator*=;
    using Base::operator/=;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Base::ConstTransposeReturnType ConstTransposeReturnType;
    typedef typename Base::RowXpr RowXpr;
    typedef typename Base::ColXpr ColXpr;
    typedef Matrix<Scalar,
                   internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime),
                   internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime)>
        SquareMatrixType;
    inline Index diagonalSize() const { return (numext::mini)(rows(), cols()); }
    typedef typename Base::PlainObject PlainObject;
    typedef CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> ConstantReturnType;
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, ConstTransposeReturnType>,
                               ConstTransposeReturnType>
        AdjointReturnType;
    typedef Matrix<std::complex<RealScalar>, internal::traits<Derived>::ColsAtCompileTime, 1, ColMajor>
        EigenvaluesReturnType;
    typedef CwiseNullaryOp<internal::scalar_identity_op<Scalar>, PlainObject> IdentityReturnType;
    typedef Block<const CwiseNullaryOp<internal::scalar_identity_op<Scalar>, SquareMatrixType>,
                  internal::traits<Derived>::RowsAtCompileTime,
                  internal::traits<Derived>::ColsAtCompileTime>
        BasisReturnType;
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_difference_op<typename internal::traits<Derived>::Scalar,
                                                              typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(operator-)(const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_difference_op<typename internal::traits<Derived>::Scalar,
                                                          typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_sum_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(operator+)(const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_sum_op<typename internal::traits<Derived>::Scalar,
                                                   typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename CustomBinaryOp, typename OtherDerived>
    inline const CwiseBinaryOp<CustomBinaryOp, const Derived, const OtherDerived> binaryExpr(
        const Eigen::MatrixBase<OtherDerived>& other, const CustomBinaryOp& func = CustomBinaryOp()) const {
      return CwiseBinaryOp<CustomBinaryOp, const Derived, const OtherDerived>(derived(), other.derived(), func);
    }
    template <typename T>
    inline friend const CwiseBinaryOp<
        internal::scalar_product_op<
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::type,
            typename internal::traits<Derived>::Scalar>,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::
                type>::type,
        const Derived>(operator*)(const T& scalar, const StorageBaseType& matrix) {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_product_op<PromotedT, typename internal::traits<Derived>::Scalar>,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type,
                           const Derived>(
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),
          matrix.derived());
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_product_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::
                type>::type>(operator*)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_quotient_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::
                type>::type>(operator/)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_boolean_and_op, const Derived, const OtherDerived> operator&&(
        const Eigen::MatrixBase<OtherDerived>& other) const {
      static_assert(
          (internal::is_same<bool, Scalar>::value && internal::is_same<bool, typename OtherDerived::Scalar>::value),
          "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return CwiseBinaryOp<internal::scalar_boolean_and_op, const Derived, const OtherDerived>(derived(),
                                                                                               other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_boolean_or_op, const Derived, const OtherDerived> operator||(
        const Eigen::MatrixBase<OtherDerived>& other) const {
      static_assert(
          (internal::is_same<bool, Scalar>::value && internal::is_same<bool, typename OtherDerived::Scalar>::value),
          "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return CwiseBinaryOp<internal::scalar_boolean_or_op, const Derived, const OtherDerived>(derived(),
                                                                                              other.derived());
    }
    typedef CwiseUnaryOp<internal::scalar_abs_op<Scalar>, const Derived> CwiseAbsReturnType;
    typedef CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const Derived> CwiseAbs2ReturnType;
    typedef CwiseUnaryOp<internal::scalar_arg_op<Scalar>, const Derived> CwiseArgReturnType;
    typedef CwiseUnaryOp<internal::scalar_sqrt_op<Scalar>, const Derived> CwiseSqrtReturnType;
    typedef CwiseUnaryOp<internal::scalar_sign_op<Scalar>, const Derived> CwiseSignReturnType;
    typedef CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const Derived> CwiseInverseReturnType;
    inline const CwiseAbsReturnType cwiseAbs() const { return CwiseAbsReturnType(derived()); }
    inline const CwiseAbs2ReturnType cwiseAbs2() const { return CwiseAbs2ReturnType(derived()); }
    inline const CwiseSqrtReturnType cwiseSqrt() const { return CwiseSqrtReturnType(derived()); }
    inline const CwiseSignReturnType cwiseSign() const { return CwiseSignReturnType(derived()); }
    inline const CwiseInverseReturnType cwiseInverse() const { return CwiseInverseReturnType(derived()); }
    inline const CwiseArgReturnType cwiseArg() const { return CwiseArgReturnType(derived()); }
    template <typename ScalarExponent>
    using CwisePowReturnType =
        std::enable_if_t<internal::is_arithmetic<typename NumTraits<ScalarExponent>::Real>::value,
                         CwiseUnaryOp<internal::scalar_unary_pow_op<Scalar, ScalarExponent>, const Derived>>;
    template <typename ScalarExponent>
    inline const CwisePowReturnType<ScalarExponent> cwisePow(const ScalarExponent& exponent) const {
      return CwisePowReturnType<ScalarExponent>(derived(),
                                                internal::scalar_unary_pow_op<Scalar, ScalarExponent>(exponent));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                           typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>
    cwiseProduct(const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived> cwiseEqual(
        const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived> cwiseNotEqual(
        const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
    cwiseMin(const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const ConstantReturnType>
    cwiseMin(const Scalar& other) const {
      return cwiseMin<NaNPropagation>(Derived::Constant(rows(), cols(), other));
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
    cwiseMax(const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const ConstantReturnType>
    cwiseMax(const Scalar& other) const {
      return cwiseMax<NaNPropagation>(Derived::Constant(rows(), cols(), other));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived> cwiseQuotient(
        const Eigen::MatrixBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived>(derived(),
                                                                                                    other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>,
                          const Derived,
                          const ConstantReturnType>
        CwiseScalarEqualReturnType;
    inline const CwiseScalarEqualReturnType cwiseEqual(const Scalar& s) const {
      return CwiseScalarEqualReturnType(
          derived(), Derived::Constant(rows(), cols(), s), internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>());
    }
    inline Derived& operator=(const MatrixBase& other);
    template <typename OtherDerived>
    inline Derived& operator=(const DenseBase<OtherDerived>& other);
    template <typename OtherDerived>
    Derived& operator=(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    Derived& operator=(const ReturnByValue<OtherDerived>& other);
    template <typename OtherDerived>
    inline Derived& operator+=(const MatrixBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Derived& operator-=(const MatrixBase<OtherDerived>& other);
    template <typename OtherDerived>
    const Product<Derived, OtherDerived> operator*(const MatrixBase<OtherDerived>& other) const;
    template <typename OtherDerived>
    const Product<Derived, OtherDerived, LazyProduct> lazyProduct(const MatrixBase<OtherDerived>& other) const;
    template <typename OtherDerived>
    Derived& operator*=(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    void applyOnTheLeft(const EigenBase<OtherDerived>& other);
    template <typename OtherDerived>
    void applyOnTheRight(const EigenBase<OtherDerived>& other);
    template <typename DiagonalDerived>
    const Product<Derived, DiagonalDerived, LazyProduct> operator*(const DiagonalBase<DiagonalDerived>& diagonal) const;
    template <typename SkewDerived>
    const Product<Derived, SkewDerived, LazyProduct> operator*(const SkewSymmetricBase<SkewDerived>& skew) const;
    template <typename OtherDerived>
    typename ScalarBinaryOpTraits<typename internal::traits<Derived>::Scalar,
                                  typename internal::traits<OtherDerived>::Scalar>::ReturnType
    dot(const MatrixBase<OtherDerived>& other) const;
    RealScalar squaredNorm() const;
    RealScalar norm() const;
    RealScalar stableNorm() const;
    RealScalar blueNorm() const;
    RealScalar hypotNorm() const;
    const PlainObject normalized() const;
    const PlainObject stableNormalized() const;
    void normalize();
    void stableNormalize();
    const AdjointReturnType adjoint() const;
    void adjointInPlace();
    typedef Diagonal<Derived> DiagonalReturnType;
    DiagonalReturnType diagonal();
    typedef Diagonal<const Derived> ConstDiagonalReturnType;
    const ConstDiagonalReturnType diagonal() const;
    template <int Index>
    Diagonal<Derived, Index> diagonal();
    template <int Index>
    const Diagonal<const Derived, Index> diagonal() const;
    Diagonal<Derived, DynamicIndex> diagonal(Index index);
    const Diagonal<const Derived, DynamicIndex> diagonal(Index index) const;
    template <unsigned int Mode>
    struct TriangularViewReturnType {
      typedef TriangularView<Derived, Mode> Type;
    };
    template <unsigned int Mode>
    struct ConstTriangularViewReturnType {
      typedef const TriangularView<const Derived, Mode> Type;
    };
    template <unsigned int Mode>
    typename TriangularViewReturnType<Mode>::Type triangularView();
    template <unsigned int Mode>
    typename ConstTriangularViewReturnType<Mode>::Type triangularView() const;
    template <unsigned int UpLo>
    struct SelfAdjointViewReturnType {
      typedef SelfAdjointView<Derived, UpLo> Type;
    };
    template <unsigned int UpLo>
    struct ConstSelfAdjointViewReturnType {
      typedef const SelfAdjointView<const Derived, UpLo> Type;
    };
    template <unsigned int UpLo>
    typename SelfAdjointViewReturnType<UpLo>::Type selfadjointView();
    template <unsigned int UpLo>
    typename ConstSelfAdjointViewReturnType<UpLo>::Type selfadjointView() const;
    const SparseView<Derived> sparseView(
        const Scalar& m_reference = Scalar(0),
        const typename NumTraits<Scalar>::Real& m_epsilon = NumTraits<Scalar>::dummy_precision()) const;
    static const IdentityReturnType Identity();
    static const IdentityReturnType Identity(Index rows, Index cols);
    static const BasisReturnType Unit(Index size, Index i);
    static const BasisReturnType Unit(Index i);
    static const BasisReturnType UnitX();
    static const BasisReturnType UnitY();
    static const BasisReturnType UnitZ();
    static const BasisReturnType UnitW();
    const DiagonalWrapper<const Derived> asDiagonal() const;
    const PermutationWrapper<const Derived> asPermutation() const;
    const SkewSymmetricWrapper<const Derived> asSkewSymmetric() const;
    Derived& setIdentity();
    Derived& setIdentity(Index rows, Index cols);
    Derived& setUnit(Index i);
    Derived& setUnit(Index newSize, Index i);
    bool isIdentity(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isDiagonal(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isUpperTriangular(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isLowerTriangular(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isSkewSymmetric(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    template <typename OtherDerived>
    bool isOrthogonal(const MatrixBase<OtherDerived>& other,
                      const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    bool isUnitary(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
    template <typename OtherDerived>
    inline bool operator==(const MatrixBase<OtherDerived>& other) const {
      return cwiseEqual(other).all();
    }
    template <typename OtherDerived>
    inline bool operator!=(const MatrixBase<OtherDerived>& other) const {
      return cwiseNotEqual(other).any();
    }
    NoAlias<Derived, Eigen::MatrixBase> noalias();
    inline const Derived& forceAlignedAccess() const { return derived(); }
    inline Derived& forceAlignedAccess() { return derived(); }
    template <bool Enable>
    inline const Derived& forceAlignedAccessIf() const {
      return derived();
    }
    template <bool Enable>
    inline Derived& forceAlignedAccessIf() {
      return derived();
    }
    Scalar trace() const;
    template <int p>
    RealScalar lpNorm() const;
    MatrixBase<Derived>& matrix() { return *this; }
    const MatrixBase<Derived>& matrix() const { return *this; }
    inline ArrayWrapper<Derived> array() { return ArrayWrapper<Derived>(derived()); }
    inline const ArrayWrapper<const Derived> array() const { return ArrayWrapper<const Derived>(derived()); }
    inline const FullPivLU<PlainObject> fullPivLu() const;
    inline const PartialPivLU<PlainObject> partialPivLu() const;
    inline const PartialPivLU<PlainObject> lu() const;
    inline const Inverse<Derived> inverse() const;
    template <typename ResultType>
    inline void computeInverseAndDetWithCheck(
        ResultType& inverse,
        typename ResultType::Scalar& determinant,
        bool& invertible,
        const RealScalar& absDeterminantThreshold = NumTraits<Scalar>::dummy_precision()) const;
    template <typename ResultType>
    inline void computeInverseWithCheck(
        ResultType& inverse,
        bool& invertible,
        const RealScalar& absDeterminantThreshold = NumTraits<Scalar>::dummy_precision()) const;
    Scalar determinant() const;
    inline const LLT<PlainObject> llt() const;
    inline const LDLT<PlainObject> ldlt() const;
    inline const HouseholderQR<PlainObject> householderQr() const;
    inline const ColPivHouseholderQR<PlainObject> colPivHouseholderQr() const;
    inline const FullPivHouseholderQR<PlainObject> fullPivHouseholderQr() const;
    inline const CompleteOrthogonalDecomposition<PlainObject> completeOrthogonalDecomposition() const;
    inline EigenvaluesReturnType eigenvalues() const;
    inline RealScalar operatorNorm() const;
    template <int Options = 0>
    inline JacobiSVD<PlainObject, Options> jacobiSvd() const;
    template <int Options = 0>
    __attribute__((deprecated)) inline JacobiSVD<PlainObject, Options> jacobiSvd(unsigned int computationOptions) const;
    template <int Options = 0>
    inline BDCSVD<PlainObject, Options> bdcSvd() const;
    template <int Options = 0>
    __attribute__((deprecated)) inline BDCSVD<PlainObject, Options> bdcSvd(unsigned int computationOptions) const;
    template <typename OtherDerived>
    struct cross_product_return_type {
      typedef typename ScalarBinaryOpTraits<typename internal::traits<Derived>::Scalar,
                                            typename internal::traits<OtherDerived>::Scalar>::ReturnType Scalar;
      typedef Matrix<Scalar, MatrixBase::RowsAtCompileTime, MatrixBase::ColsAtCompileTime> type;
    };
    template <typename OtherDerived>
    inline typename cross_product_return_type<OtherDerived>::type cross(const MatrixBase<OtherDerived>& other) const;
    template <typename OtherDerived>
    inline PlainObject cross3(const MatrixBase<OtherDerived>& other) const;
    inline PlainObject unitOrthogonal(void) const;
    inline Matrix<Scalar, 3, 1> eulerAngles(Index a0, Index a1, Index a2) const;
    enum {
      HomogeneousReturnTypeDirection =
          ColsAtCompileTime == 1 && RowsAtCompileTime == 1
              ? ((internal::traits<Derived>::Flags & RowMajorBit) == RowMajorBit ? Horizontal : Vertical)
          : ColsAtCompileTime == 1 ? Vertical
                                   : Horizontal
    };
    typedef Homogeneous<Derived, HomogeneousReturnTypeDirection> HomogeneousReturnType;
    inline HomogeneousReturnType homogeneous() const;
    enum { SizeMinusOne = SizeAtCompileTime == Dynamic ? Dynamic : SizeAtCompileTime - 1 };
    typedef Block<const Derived,
                  internal::traits<Derived>::ColsAtCompileTime == 1 ? SizeMinusOne : 1,
                  internal::traits<Derived>::ColsAtCompileTime == 1 ? 1 : SizeMinusOne>
        ConstStartMinusOne;
    typedef CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<ConstStartMinusOne>::Scalar, Scalar>,
                          const ConstStartMinusOne,
                          const typename internal::plain_constant_type<ConstStartMinusOne, Scalar>::type>
        HNormalizedReturnType;
    inline const HNormalizedReturnType hnormalized() const;
    void makeHouseholderInPlace(Scalar& tau, RealScalar& beta);
    template <typename EssentialPart>
    void makeHouseholder(EssentialPart& essential, Scalar& tau, RealScalar& beta) const;
    template <typename EssentialPart>
    void applyHouseholderOnTheLeft(const EssentialPart& essential, const Scalar& tau, Scalar* workspace);
    template <typename EssentialPart>
    void applyHouseholderOnTheRight(const EssentialPart& essential, const Scalar& tau, Scalar* workspace);
    template <typename OtherScalar>
    void applyOnTheLeft(Index p, Index q, const JacobiRotation<OtherScalar>& j);
    template <typename OtherScalar>
    void applyOnTheRight(Index p, Index q, const JacobiRotation<OtherScalar>& j);
    template <typename OtherDerived>
    inline const typename SparseMatrixBase<OtherDerived>::template CwiseProductDenseReturnType<Derived>::Type
    cwiseProduct(const SparseMatrixBase<OtherDerived>& other) const {
      return other.cwiseProduct(derived());
    }
    typedef typename internal::stem_function<Scalar>::type StemFunction;
    const MatrixExponentialReturnValue<Derived> exp() const;
    const MatrixFunctionReturnValue<Derived> matrixFunction(StemFunction f) const;
    const MatrixFunctionReturnValue<Derived> cosh() const;
    const MatrixFunctionReturnValue<Derived> sinh() const;
    const MatrixFunctionReturnValue<Derived> atanh() const;
    const MatrixFunctionReturnValue<Derived> acosh() const;
    const MatrixFunctionReturnValue<Derived> asinh() const;
    const MatrixFunctionReturnValue<Derived> cos() const;
    const MatrixFunctionReturnValue<Derived> sin() const;
    const MatrixSquareRootReturnValue<Derived> sqrt() const;
    const MatrixLogarithmReturnValue<Derived> log() const;
    const MatrixPowerReturnValue<Derived> pow(const RealScalar& p) const;
    const MatrixComplexPowerReturnValue<Derived> pow(const std::complex<RealScalar>& p) const;

  protected:
    MatrixBase(const MatrixBase&) = default;
    MatrixBase() = default;
    ~MatrixBase() = default;

  private:
    explicit MatrixBase(int);
    MatrixBase(int, int);
    template <typename OtherDerived>
    explicit MatrixBase(const MatrixBase<OtherDerived>&);

  protected:
    template <typename OtherDerived>
    Derived& operator+=(const ArrayBase<OtherDerived>&) {
      static_assert(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1, "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      ;
      return *this;
    }
    template <typename OtherDerived>
    Derived& operator-=(const ArrayBase<OtherDerived>&) {
      static_assert(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1, "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      ;
      return *this;
    }
  };
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator*=(const EigenBase<OtherDerived>& other) {
    other.derived().applyThisOnTheRight(derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline void MatrixBase<Derived>::applyOnTheRight(const EigenBase<OtherDerived>& other) {
    other.derived().applyThisOnTheRight(derived());
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline void MatrixBase<Derived>::applyOnTheLeft(const EigenBase<OtherDerived>& other) {
    other.derived().applyThisOnTheLeft(derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  struct EigenBase {
    typedef Eigen::Index Index;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    Derived& derived() { return *static_cast<Derived*>(this); }
    const Derived& derived() const { return *static_cast<const Derived*>(this); }
    inline Derived& const_cast_derived() const { return *static_cast<Derived*>(const_cast<EigenBase*>(this)); }
    inline const Derived& const_derived() const { return *static_cast<const Derived*>(this); }
    constexpr inline Index rows() const noexcept { return derived().rows(); }
    constexpr inline Index cols() const noexcept { return derived().cols(); }
    constexpr inline Index size() const noexcept { return rows() * cols(); }
    template <typename Dest>
    inline void evalTo(Dest& dst) const {
      derived().evalTo(dst);
    }
    template <typename Dest>
    inline void addTo(Dest& dst) const {
      typename Dest::PlainObject res(rows(), cols());
      evalTo(res);
      dst += res;
    }
    template <typename Dest>
    inline void subTo(Dest& dst) const {
      typename Dest::PlainObject res(rows(), cols());
      evalTo(res);
      dst -= res;
    }
    template <typename Dest>
    inline void applyThisOnTheRight(Dest& dst) const {
      dst = dst * this->derived();
    }
    template <typename Dest>
    inline void applyThisOnTheLeft(Dest& dst) const {
      dst = this->derived() * dst;
    }
  };
  template <typename Derived>
  template <typename OtherDerived>
  Derived& DenseBase<Derived>::operator=(const EigenBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  Derived& DenseBase<Derived>::operator+=(const EigenBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  Derived& DenseBase<Derived>::operator-=(const EigenBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Lhs, typename Rhs, int Option, typename StorageKind>
  class ProductImpl;
  namespace internal {
    template <typename Lhs, typename Rhs, int Option>
    struct traits<Product<Lhs, Rhs, Option>> {
      typedef remove_all_t<Lhs> LhsCleaned;
      typedef remove_all_t<Rhs> RhsCleaned;
      typedef traits<LhsCleaned> LhsTraits;
      typedef traits<RhsCleaned> RhsTraits;
      typedef MatrixXpr XprKind;
      typedef typename ScalarBinaryOpTraits<typename traits<LhsCleaned>::Scalar,
                                            typename traits<RhsCleaned>::Scalar>::ReturnType Scalar;
      typedef typename product_promote_storage_type<typename LhsTraits::StorageKind,
                                                    typename RhsTraits::StorageKind,
                                                    internal::product_type<Lhs, Rhs>::ret>::ret StorageKind;
      typedef typename promote_index_type<typename LhsTraits::StorageIndex, typename RhsTraits::StorageIndex>::type
          StorageIndex;
      enum {
        RowsAtCompileTime = LhsTraits::RowsAtCompileTime,
        ColsAtCompileTime = RhsTraits::ColsAtCompileTime,
        MaxRowsAtCompileTime = LhsTraits::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = RhsTraits::MaxColsAtCompileTime,
        InnerSize = min_size_prefer_fixed(LhsTraits::ColsAtCompileTime, RhsTraits::RowsAtCompileTime),
        Flags = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? RowMajorBit
                : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
                : (((LhsTraits::Flags & NoPreferredStorageOrderBit) && (RhsTraits::Flags & RowMajorBit)) ||
                   ((RhsTraits::Flags & NoPreferredStorageOrderBit) && (LhsTraits::Flags & RowMajorBit)))
                    ? RowMajorBit
                    : NoPreferredStorageOrderBit
      };
    };
  }  // namespace internal
  template <typename Lhs_, typename Rhs_, int Option>
  class Product : public ProductImpl<
                      Lhs_,
                      Rhs_,
                      Option,
                      typename internal::product_promote_storage_type<typename internal::traits<Lhs_>::StorageKind,
                                                                      typename internal::traits<Rhs_>::StorageKind,
                                                                      internal::product_type<Lhs_, Rhs_>::ret>::ret> {
  public:
    typedef Lhs_ Lhs;
    typedef Rhs_ Rhs;
    typedef typename ProductImpl<
        Lhs,
        Rhs,
        Option,
        typename internal::product_promote_storage_type<typename internal::traits<Lhs>::StorageKind,
                                                        typename internal::traits<Rhs>::StorageKind,
                                                        internal::product_type<Lhs, Rhs>::ret>::ret>::Base Base;
    typedef typename Eigen::internal::traits<Product>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Product>::type Nested;
    typedef typename Eigen::internal::traits<Product>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Product>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Product>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Product>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Product>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename internal::ref_selector<Lhs>::type LhsNested;
    typedef typename internal::ref_selector<Rhs>::type RhsNested;
    typedef internal::remove_all_t<LhsNested> LhsNestedCleaned;
    typedef internal::remove_all_t<RhsNested> RhsNestedCleaned;
    inline Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {
      (static_cast<bool>(lhs.cols() == rhs.rows() && "invalid matrix product" &&
                         "if you wanted a coeff-wise or a dot product use the respective explicit functions")
           ? void(0)
           : __assert_fail("lhs.cols() == rhs.rows() && \"invalid matrix product\" && \"if you wanted a coeff-wise or "
                           "a dot product use the respective explicit functions\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Product.h",
                           100,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline constexpr Index rows() const noexcept { return m_lhs.rows(); }
    inline constexpr Index cols() const noexcept { return m_rhs.cols(); }
    inline const LhsNestedCleaned& lhs() const { return m_lhs; }
    inline const RhsNestedCleaned& rhs() const { return m_rhs; }

  protected:
    LhsNested m_lhs;
    RhsNested m_rhs;
  };
  namespace internal {
    template <typename Lhs, typename Rhs, int Option, int ProductTag = internal::product_type<Lhs, Rhs>::ret>
    class dense_product_base : public internal::dense_xpr_base<Product<Lhs, Rhs, Option>>::type {};
    template <typename Lhs, typename Rhs, int Option>
    class dense_product_base<Lhs, Rhs, Option, InnerProduct>
        : public internal::dense_xpr_base<Product<Lhs, Rhs, Option>>::type {
      typedef Product<Lhs, Rhs, Option> ProductXpr;
      typedef typename internal::dense_xpr_base<ProductXpr>::type Base;

    public:
      using Base::derived;
      typedef typename Base::Scalar Scalar;
      inline operator const Scalar() const { return internal::evaluator<ProductXpr>(derived()).coeff(0, 0); }
    };
  }  // namespace internal
  template <typename Lhs, typename Rhs, int Option, typename StorageKind>
  class ProductImpl : public internal::generic_xpr_base<Product<Lhs, Rhs, Option>, MatrixXpr, StorageKind>::type {
  public:
    typedef typename internal::generic_xpr_base<Product<Lhs, Rhs, Option>, MatrixXpr, StorageKind>::type Base;
  };
  template <typename Lhs, typename Rhs, int Option>
  class ProductImpl<Lhs, Rhs, Option, Dense> : public internal::dense_product_base<Lhs, Rhs, Option> {
    typedef Product<Lhs, Rhs, Option> Derived;

  public:
    typedef typename internal::dense_product_base<Lhs, Rhs, Option> Base;
    typedef typename Eigen::internal::traits<Derived>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Derived>::type Nested;
    typedef typename Eigen::internal::traits<Derived>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Derived>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Derived>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Derived>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;

  protected:
    enum {
      IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) &&
                   (ColsAtCompileTime == 1 || ColsAtCompileTime == Dynamic),
      EnableCoeff = IsOneByOne || Option == LazyProduct
    };

  public:
    inline Scalar coeff(Index row, Index col) const {
      static_assert(EnableCoeff, "THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS");
      ;
      (static_cast<bool>((Option == LazyProduct) || (this->rows() == 1 && this->cols() == 1))
           ? void(0)
           : __assert_fail("(Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Product.h",
                           175,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::evaluator<Derived>(derived()).coeff(row, col);
    }
    inline Scalar coeff(Index i) const {
      static_assert(EnableCoeff, "THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS");
      ;
      (static_cast<bool>((Option == LazyProduct) || (this->rows() == 1 && this->cols() == 1))
           ? void(0)
           : __assert_fail("(Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Product.h",
                           183,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::evaluator<Derived>(derived()).coeff(i);
    }
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename StorageKind>
    struct storage_kind_to_evaluator_kind {
      typedef IndexBased Kind;
    };
    template <typename StorageKind>
    struct storage_kind_to_shape;
    template <>
    struct storage_kind_to_shape<Dense> {
      typedef DenseShape Shape;
    };
    template <>
    struct storage_kind_to_shape<SolverStorage> {
      typedef SolverShape Shape;
    };
    template <>
    struct storage_kind_to_shape<PermutationStorage> {
      typedef PermutationShape Shape;
    };
    template <>
    struct storage_kind_to_shape<TranspositionsStorage> {
      typedef TranspositionsShape Shape;
    };
    template <typename T,
              typename Arg1Kind = typename evaluator_traits<typename T::Arg1>::Kind,
              typename Arg2Kind = typename evaluator_traits<typename T::Arg2>::Kind,
              typename Arg3Kind = typename evaluator_traits<typename T::Arg3>::Kind,
              typename Arg1Scalar = typename traits<typename T::Arg1>::Scalar,
              typename Arg2Scalar = typename traits<typename T::Arg2>::Scalar,
              typename Arg3Scalar = typename traits<typename T::Arg3>::Scalar>
    struct ternary_evaluator;
    template <typename T,
              typename LhsKind = typename evaluator_traits<typename T::Lhs>::Kind,
              typename RhsKind = typename evaluator_traits<typename T::Rhs>::Kind,
              typename LhsScalar = typename traits<typename T::Lhs>::Scalar,
              typename RhsScalar = typename traits<typename T::Rhs>::Scalar>
    struct binary_evaluator;
    template <typename T,
              typename Kind = typename evaluator_traits<typename T::NestedExpression>::Kind,
              typename Scalar = typename T::Scalar>
    struct unary_evaluator;
    template <typename T>
    struct evaluator_traits_base {
      typedef typename storage_kind_to_evaluator_kind<typename traits<T>::StorageKind>::Kind Kind;
      typedef typename storage_kind_to_shape<typename traits<T>::StorageKind>::Shape Shape;
    };
    template <typename T>
    struct evaluator_traits : public evaluator_traits_base<T> {};
    template <typename T, typename Shape = typename evaluator_traits<T>::Shape>
    struct evaluator_assume_aliasing {
      static const bool value = false;
    };
    template <typename T>
    struct evaluator : public unary_evaluator<T> {
      typedef unary_evaluator<T> Base;
      inline explicit evaluator(const T& xpr) : Base(xpr) {}
    };
    template <typename T>
    struct evaluator<const T> : evaluator<T> {
      inline explicit evaluator(const T& xpr) : evaluator<T>(xpr) {}
    };
    template <typename ExpressionType>
    struct evaluator_base {
      typedef traits<ExpressionType> ExpressionTraits;
      enum { Alignment = 0 };
      inline evaluator_base() {}
      inline ~evaluator_base() {}

    private:
      evaluator_base(const evaluator_base&);
      const evaluator_base& operator=(const evaluator_base&);
    };
    template <typename Scalar, int OuterStride>
    class plainobjectbase_evaluator_data {
    public:
      inline plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride) : data(ptr) {
        Eigen::internal::ignore_unused_variable(outerStride);
        ;
        ;
      }
      inline constexpr Index outerStride() const noexcept { return OuterStride; }
      const Scalar* data;
    };
    template <typename Scalar>
    class plainobjectbase_evaluator_data<Scalar, Dynamic> {
    public:
      inline plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride)
          : data(ptr), m_outerStride(outerStride) {}
      inline Index outerStride() const { return m_outerStride; }
      const Scalar* data;

    protected:
      Index m_outerStride;
    };
    template <typename Derived>
    struct evaluator<PlainObjectBase<Derived>> : evaluator_base<Derived> {
      typedef PlainObjectBase<Derived> PlainObjectType;
      typedef typename PlainObjectType::Scalar Scalar;
      typedef typename PlainObjectType::CoeffReturnType CoeffReturnType;
      enum {
        IsRowMajor = PlainObjectType::IsRowMajor,
        IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime,
        RowsAtCompileTime = PlainObjectType::RowsAtCompileTime,
        ColsAtCompileTime = PlainObjectType::ColsAtCompileTime,
        CoeffReadCost = NumTraits<Scalar>::ReadCost,
        Flags = traits<Derived>::EvaluatorFlags,
        Alignment = traits<Derived>::Alignment
      };
      enum {
        OuterStrideAtCompileTime = IsVectorAtCompileTime ? 0
                                   : int(IsRowMajor)     ? ColsAtCompileTime
                                                         : RowsAtCompileTime
      };
      inline evaluator() : m_d(0, OuterStrideAtCompileTime) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      inline explicit evaluator(const PlainObjectType& m) : m_d(m.data(), IsVectorAtCompileTime ? 0 : m.outerStride()) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      inline CoeffReturnType coeff(Index row, Index col) const {
        if (IsRowMajor)
          return m_d.data[row * m_d.outerStride() + col];
        else
          return m_d.data[row + col * m_d.outerStride()];
      }
      inline CoeffReturnType coeff(Index index) const { return m_d.data[index]; }
      inline Scalar& coeffRef(Index row, Index col) {
        if (IsRowMajor)
          return const_cast<Scalar*>(m_d.data)[row * m_d.outerStride() + col];
        else
          return const_cast<Scalar*>(m_d.data)[row + col * m_d.outerStride()];
      }
      inline Scalar& coeffRef(Index index) { return const_cast<Scalar*>(m_d.data)[index]; }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        if (IsRowMajor)
          return ploadt<PacketType, LoadMode>(m_d.data + row * m_d.outerStride() + col);
        else
          return ploadt<PacketType, LoadMode>(m_d.data + row + col * m_d.outerStride());
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return ploadt<PacketType, LoadMode>(m_d.data + index);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        if (IsRowMajor)
          return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + row * m_d.outerStride() + col,
                                                        x);
        else
          return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + row + col * m_d.outerStride(),
                                                        x);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + index, x);
      }

    protected:
      plainobjectbase_evaluator_data<Scalar, OuterStrideAtCompileTime> m_d;
    };
    template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
    struct evaluator<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
        : evaluator<PlainObjectBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {
      typedef Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
      inline evaluator() {}
      inline explicit evaluator(const XprType& m) : evaluator<PlainObjectBase<XprType>>(m) {}
    };
    template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
    struct evaluator<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
        : evaluator<PlainObjectBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {
      typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
      inline evaluator() {}
      inline explicit evaluator(const XprType& m) : evaluator<PlainObjectBase<XprType>>(m) {}
    };
    template <typename ArgType>
    struct unary_evaluator<Transpose<ArgType>, IndexBased> : evaluator_base<Transpose<ArgType>> {
      typedef Transpose<ArgType> XprType;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        Flags = evaluator<ArgType>::Flags ^ RowMajorBit,
        Alignment = evaluator<ArgType>::Alignment
      };
      inline explicit unary_evaluator(const XprType& t) : m_argImpl(t.nestedExpression()) {}
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const { return m_argImpl.coeff(col, row); }
      inline CoeffReturnType coeff(Index index) const { return m_argImpl.coeff(index); }
      inline Scalar& coeffRef(Index row, Index col) { return m_argImpl.coeffRef(col, row); }
      inline typename XprType::Scalar& coeffRef(Index index) { return m_argImpl.coeffRef(index); }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_argImpl.template packet<LoadMode, PacketType>(col, row);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return m_argImpl.template packet<LoadMode, PacketType>(index);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        m_argImpl.template writePacket<StoreMode, PacketType>(col, row, x);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        m_argImpl.template writePacket<StoreMode, PacketType>(index, x);
      }

    protected:
      evaluator<ArgType> m_argImpl;
    };
    template <typename Scalar,
              typename NullaryOp,
              bool has_nullary = has_nullary_operator<NullaryOp>::value,
              bool has_unary = has_unary_operator<NullaryOp>::value,
              bool has_binary = has_binary_operator<NullaryOp>::value>
    struct nullary_wrapper {
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType i, IndexType j) const {
        return op(i, j);
      }
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType i) const {
        return op(i);
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType i, IndexType j) const {
        return op.template packetOp<T>(i, j);
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType i) const {
        return op.template packetOp<T>(i);
      }
    };
    template <typename Scalar, typename NullaryOp>
    struct nullary_wrapper<Scalar, NullaryOp, true, false, false> {
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType = 0, IndexType = 0) const {
        return op();
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType = 0, IndexType = 0) const {
        return op.template packetOp<T>();
      }
    };
    template <typename Scalar, typename NullaryOp>
    struct nullary_wrapper<Scalar, NullaryOp, false, false, true> {
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType i, IndexType j = 0) const {
        return op(i, j);
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType i, IndexType j = 0) const {
        return op.template packetOp<T>(i, j);
      }
    };
    template <typename Scalar, typename NullaryOp>
    struct nullary_wrapper<Scalar, NullaryOp, false, true, false> {
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType i, IndexType j) const {
        (static_cast<bool>(i == 0 || j == 0)
             ? void(0)
             : __assert_fail("i==0 || j==0",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/CoreEvaluators.h",
                             423,
                             __extension__ __PRETTY_FUNCTION__));
        return op(i + j);
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType i, IndexType j) const {
        (static_cast<bool>(i == 0 || j == 0)
             ? void(0)
             : __assert_fail("i==0 || j==0",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/CoreEvaluators.h",
                             427,
                             __extension__ __PRETTY_FUNCTION__));
        return op.template packetOp<T>(i + j);
      }
      template <typename IndexType>
      inline Scalar operator()(const NullaryOp& op, IndexType i) const {
        return op(i);
      }
      template <typename T, typename IndexType>
      inline T packetOp(const NullaryOp& op, IndexType i) const {
        return op.template packetOp<T>(i);
      }
    };
    template <typename Scalar, typename NullaryOp>
    struct nullary_wrapper<Scalar, NullaryOp, false, false, false> {};
    template <typename NullaryOp, typename PlainObjectType>
    struct evaluator<CwiseNullaryOp<NullaryOp, PlainObjectType>>
        : evaluator_base<CwiseNullaryOp<NullaryOp, PlainObjectType>> {
      typedef CwiseNullaryOp<NullaryOp, PlainObjectType> XprType;
      typedef internal::remove_all_t<PlainObjectType> PlainObjectTypeCleaned;
      enum {
        CoeffReadCost = internal::functor_traits<NullaryOp>::Cost,
        Flags = (evaluator<PlainObjectTypeCleaned>::Flags &
                 (HereditaryBits | (functor_has_linear_access<NullaryOp>::ret ? LinearAccessBit : 0) |
                  (functor_traits<NullaryOp>::PacketAccess ? PacketAccessBit : 0))) |
                (functor_traits<NullaryOp>::IsRepeatable ? 0 : EvalBeforeNestingBit),
        Alignment = AlignedMax
      };
      explicit evaluator(const XprType& n) : m_functor(n.functor()), m_wrapper() {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      template <typename IndexType>
      inline CoeffReturnType coeff(IndexType row, IndexType col) const {
        return m_wrapper(m_functor, row, col);
      }
      template <typename IndexType>
      inline CoeffReturnType coeff(IndexType index) const {
        return m_wrapper(m_functor, index);
      }
      template <int LoadMode, typename PacketType, typename IndexType>
      inline PacketType packet(IndexType row, IndexType col) const {
        return m_wrapper.template packetOp<PacketType>(m_functor, row, col);
      }
      template <int LoadMode, typename PacketType, typename IndexType>
      inline PacketType packet(IndexType index) const {
        return m_wrapper.template packetOp<PacketType>(m_functor, index);
      }

    protected:
      const NullaryOp m_functor;
      const internal::nullary_wrapper<CoeffReturnType, NullaryOp> m_wrapper;
    };
    template <typename UnaryOp, typename ArgType>
    struct unary_evaluator<CwiseUnaryOp<UnaryOp, ArgType>, IndexBased>
        : evaluator_base<CwiseUnaryOp<UnaryOp, ArgType>> {
      typedef CwiseUnaryOp<UnaryOp, ArgType> XprType;
      enum {
        CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
        Flags = evaluator<ArgType>::Flags &
                (HereditaryBits | LinearAccessBit | (functor_traits<UnaryOp>::PacketAccess ? PacketAccessBit : 0)),
        Alignment = evaluator<ArgType>::Alignment
      };
      inline explicit unary_evaluator(const XprType& op) : m_d(op) {
        static_assert((functor_traits<UnaryOp>::Cost) >= 0 && (functor_traits<UnaryOp>::Cost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const { return m_d.func()(m_d.argImpl.coeff(row, col)); }
      inline CoeffReturnType coeff(Index index) const { return m_d.func()(m_d.argImpl.coeff(index)); }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(row, col));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(index));
      }

    protected:
      struct Data {
        inline Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
        inline const UnaryOp& func() const { return op; }
        UnaryOp op;
        evaluator<ArgType> argImpl;
      };
      Data m_d;
    };
    template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
    struct evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>>
        : public ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> {
      typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
      typedef ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> Base;
      explicit evaluator(const XprType& xpr) : Base(xpr) {}
    };
    template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
    struct ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>, IndexBased, IndexBased>
        : evaluator_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> {
      typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
      enum {
        CoeffReadCost = int(evaluator<Arg1>::CoeffReadCost) + int(evaluator<Arg2>::CoeffReadCost) +
                        int(evaluator<Arg3>::CoeffReadCost) + int(functor_traits<TernaryOp>::Cost),
        Arg1Flags = evaluator<Arg1>::Flags,
        Arg2Flags = evaluator<Arg2>::Flags,
        Arg3Flags = evaluator<Arg3>::Flags,
        SameType = is_same<typename Arg1::Scalar, typename Arg2::Scalar>::value &&
                   is_same<typename Arg1::Scalar, typename Arg3::Scalar>::value,
        StorageOrdersAgree = (int(Arg1Flags) & RowMajorBit) == (int(Arg2Flags) & RowMajorBit) &&
                             (int(Arg1Flags) & RowMajorBit) == (int(Arg3Flags) & RowMajorBit),
        Flags0 =
            (int(Arg1Flags) | int(Arg2Flags) | int(Arg3Flags)) &
            (HereditaryBits |
             (int(Arg1Flags) & int(Arg2Flags) & int(Arg3Flags) &
              ((StorageOrdersAgree ? LinearAccessBit : 0) |
               (functor_traits<TernaryOp>::PacketAccess && StorageOrdersAgree && SameType ? PacketAccessBit : 0)))),
        Flags = (Flags0 & ~RowMajorBit) | (Arg1Flags & RowMajorBit),
        Alignment = plain_enum_min(plain_enum_min(evaluator<Arg1>::Alignment, evaluator<Arg2>::Alignment),
                                   evaluator<Arg3>::Alignment)
      };
      explicit ternary_evaluator(const XprType& xpr) : m_d(xpr) {
        static_assert(
            (functor_traits<TernaryOp>::Cost) >= 0 && (functor_traits<TernaryOp>::Cost) <= HugeCost * HugeCost,
            "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const {
        return m_d.func()(m_d.arg1Impl.coeff(row, col), m_d.arg2Impl.coeff(row, col), m_d.arg3Impl.coeff(row, col));
      }
      inline CoeffReturnType coeff(Index index) const {
        return m_d.func()(m_d.arg1Impl.coeff(index), m_d.arg2Impl.coeff(index), m_d.arg3Impl.coeff(index));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode, PacketType>(row, col),
                                   m_d.arg2Impl.template packet<LoadMode, PacketType>(row, col),
                                   m_d.arg3Impl.template packet<LoadMode, PacketType>(row, col));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode, PacketType>(index),
                                   m_d.arg2Impl.template packet<LoadMode, PacketType>(index),
                                   m_d.arg3Impl.template packet<LoadMode, PacketType>(index));
      }

    protected:
      struct Data {
        inline Data(const XprType& xpr)
            : op(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
        inline const TernaryOp& func() const { return op; }
        TernaryOp op;
        evaluator<Arg1> arg1Impl;
        evaluator<Arg2> arg2Impl;
        evaluator<Arg3> arg3Impl;
      };
      Data m_d;
    };
    template <typename BinaryOp, typename Lhs, typename Rhs>
    struct evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> : public binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
      typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
      typedef binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> Base;
      inline explicit evaluator(const XprType& xpr) : Base(xpr) {}
    };
    template <typename BinaryOp, typename Lhs, typename Rhs>
    struct binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>, IndexBased, IndexBased>
        : evaluator_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
      typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
      enum {
        CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) +
                        int(functor_traits<BinaryOp>::Cost),
        LhsFlags = evaluator<Lhs>::Flags,
        RhsFlags = evaluator<Rhs>::Flags,
        SameType = is_same<typename Lhs::Scalar, typename Rhs::Scalar>::value,
        StorageOrdersAgree = (int(LhsFlags) & RowMajorBit) == (int(RhsFlags) & RowMajorBit),
        Flags0 = (int(LhsFlags) | int(RhsFlags)) &
                 (HereditaryBits |
                  (int(LhsFlags) & int(RhsFlags) &
                   ((StorageOrdersAgree ? LinearAccessBit : 0) |
                    (functor_traits<BinaryOp>::PacketAccess && StorageOrdersAgree && SameType ? PacketAccessBit : 0)))),
        Flags = (Flags0 & ~RowMajorBit) | (LhsFlags & RowMajorBit),
        Alignment = plain_enum_min(evaluator<Lhs>::Alignment, evaluator<Rhs>::Alignment)
      };
      inline explicit binary_evaluator(const XprType& xpr) : m_d(xpr) {
        static_assert((functor_traits<BinaryOp>::Cost) >= 0 && (functor_traits<BinaryOp>::Cost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const {
        return m_d.func()(m_d.lhsImpl.coeff(row, col), m_d.rhsImpl.coeff(row, col));
      }
      inline CoeffReturnType coeff(Index index) const {
        return m_d.func()(m_d.lhsImpl.coeff(index), m_d.rhsImpl.coeff(index));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode, PacketType>(row, col),
                                   m_d.rhsImpl.template packet<LoadMode, PacketType>(row, col));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode, PacketType>(index),
                                   m_d.rhsImpl.template packet<LoadMode, PacketType>(index));
      }

    protected:
      struct Data {
        inline Data(const XprType& xpr) : op(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
        inline const BinaryOp& func() const { return op; }
        BinaryOp op;
        evaluator<Lhs> lhsImpl;
        evaluator<Rhs> rhsImpl;
      };
      Data m_d;
    };
    template <typename UnaryOp, typename ArgType, typename StrideType>
    struct unary_evaluator<CwiseUnaryView<UnaryOp, ArgType, StrideType>, IndexBased>
        : evaluator_base<CwiseUnaryView<UnaryOp, ArgType, StrideType>> {
      typedef CwiseUnaryView<UnaryOp, ArgType, StrideType> XprType;
      enum {
        CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
        Flags = (evaluator<ArgType>::Flags & (HereditaryBits | LinearAccessBit | DirectAccessBit)),
        Alignment = 0
      };
      explicit unary_evaluator(const XprType& op) : m_d(op) {
        static_assert((functor_traits<UnaryOp>::Cost) >= 0 && (functor_traits<UnaryOp>::Cost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const { return m_d.func()(m_d.argImpl.coeff(row, col)); }
      inline CoeffReturnType coeff(Index index) const { return m_d.func()(m_d.argImpl.coeff(index)); }
      inline Scalar& coeffRef(Index row, Index col) { return m_d.func()(m_d.argImpl.coeffRef(row, col)); }
      inline Scalar& coeffRef(Index index) { return m_d.func()(m_d.argImpl.coeffRef(index)); }

    protected:
      struct Data {
        inline Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
        inline const UnaryOp& func() const { return op; }
        UnaryOp op;
        evaluator<ArgType> argImpl;
      };
      Data m_d;
    };
    template <typename Derived, typename PlainObjectType>
    struct mapbase_evaluator;
    template <typename Derived, typename PlainObjectType>
    struct mapbase_evaluator : evaluator_base<Derived> {
      typedef Derived XprType;
      typedef typename XprType::PointerType PointerType;
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      enum {
        IsRowMajor = XprType::RowsAtCompileTime,
        ColsAtCompileTime = XprType::ColsAtCompileTime,
        CoeffReadCost = NumTraits<Scalar>::ReadCost
      };
      inline explicit mapbase_evaluator(const XprType& map)
          : m_data(const_cast<PointerType>(map.data())),
            m_innerStride(map.innerStride()),
            m_outerStride(map.outerStride()) {
        static_assert(check_implication((evaluator<Derived>::Flags & PacketAccessBit) != 0,
                                        internal::inner_stride_at_compile_time<Derived>::ret == 1),
                      "PACKET_ACCESS_REQUIRES_TO_HAVE_INNER_STRIDE_FIXED_TO_1");
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      inline CoeffReturnType coeff(Index row, Index col) const { return m_data[col * colStride() + row * rowStride()]; }
      inline CoeffReturnType coeff(Index index) const { return m_data[index * m_innerStride.value()]; }
      inline Scalar& coeffRef(Index row, Index col) { return m_data[col * colStride() + row * rowStride()]; }
      inline Scalar& coeffRef(Index index) { return m_data[index * m_innerStride.value()]; }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        PointerType ptr = m_data + row * rowStride() + col * colStride();
        return internal::ploadt<PacketType, LoadMode>(ptr);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return internal::ploadt<PacketType, LoadMode>(m_data + index * m_innerStride.value());
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        PointerType ptr = m_data + row * rowStride() + col * colStride();
        return internal::pstoret<Scalar, PacketType, StoreMode>(ptr, x);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        internal::pstoret<Scalar, PacketType, StoreMode>(m_data + index * m_innerStride.value(), x);
      }

    protected:
      inline constexpr Index rowStride() const noexcept {
        return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value();
      }
      inline constexpr Index colStride() const noexcept {
        return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value();
      }
      PointerType m_data;
      const internal::variable_if_dynamic<Index, XprType::InnerStrideAtCompileTime> m_innerStride;
      const internal::variable_if_dynamic<Index, XprType::OuterStrideAtCompileTime> m_outerStride;
    };
    template <typename PlainObjectType, int MapOptions, typename StrideType>
    struct evaluator<Map<PlainObjectType, MapOptions, StrideType>>
        : public mapbase_evaluator<Map<PlainObjectType, MapOptions, StrideType>, PlainObjectType> {
      typedef Map<PlainObjectType, MapOptions, StrideType> XprType;
      typedef typename XprType::Scalar Scalar;
      typedef typename packet_traits<Scalar>::type PacketScalar;
      enum {
        InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
                                       ? int(PlainObjectType::InnerStrideAtCompileTime)
                                       : int(StrideType::InnerStrideAtCompileTime),
        OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
                                       ? int(PlainObjectType::OuterStrideAtCompileTime)
                                       : int(StrideType::OuterStrideAtCompileTime),
        HasNoInnerStride = InnerStrideAtCompileTime == 1,
        HasNoOuterStride = StrideType::OuterStrideAtCompileTime == 0,
        HasNoStride = HasNoInnerStride && HasNoOuterStride,
        IsDynamicSize = PlainObjectType::SizeAtCompileTime == Dynamic,
        PacketAccessMask = bool(HasNoInnerStride) ? ~int(0) : ~int(PacketAccessBit),
        LinearAccessMask =
            bool(HasNoStride) || bool(PlainObjectType::IsVectorAtCompileTime) ? ~int(0) : ~int(LinearAccessBit),
        Flags = int(evaluator<PlainObjectType>::Flags) & (LinearAccessMask & PacketAccessMask),
        Alignment = int(MapOptions) & int(AlignedMask)
      };
      explicit evaluator(const XprType& map) : mapbase_evaluator<XprType, PlainObjectType>(map) {}
    };
    template <typename PlainObjectType, int RefOptions, typename StrideType>
    struct evaluator<Ref<PlainObjectType, RefOptions, StrideType>>
        : public mapbase_evaluator<Ref<PlainObjectType, RefOptions, StrideType>, PlainObjectType> {
      typedef Ref<PlainObjectType, RefOptions, StrideType> XprType;
      enum {
        Flags = evaluator<Map<PlainObjectType, RefOptions, StrideType>>::Flags,
        Alignment = evaluator<Map<PlainObjectType, RefOptions, StrideType>>::Alignment
      };
      inline explicit evaluator(const XprType& ref) : mapbase_evaluator<XprType, PlainObjectType>(ref) {}
    };
    template <typename ArgType,
              int BlockRows,
              int BlockCols,
              bool InnerPanel,
              bool HasDirectAccess = internal::has_direct_access<ArgType>::ret>
    struct block_evaluator;
    template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
    struct evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>>
        : block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> {
      typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
      typedef typename XprType::Scalar Scalar;
      typedef typename packet_traits<Scalar>::type PacketScalar;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        RowsAtCompileTime = traits<XprType>::RowsAtCompileTime,
        ColsAtCompileTime = traits<XprType>::ColsAtCompileTime,
        MaxRowsAtCompileTime = traits<XprType>::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = traits<XprType>::MaxColsAtCompileTime,
        ArgTypeIsRowMajor = (int(evaluator<ArgType>::Flags) & RowMajorBit) != 0,
        IsRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? 1
                     : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
                                                                                : ArgTypeIsRowMajor,
        HasSameStorageOrderAsArgType = (IsRowMajor == ArgTypeIsRowMajor),
        InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
        InnerStrideAtCompileTime = HasSameStorageOrderAsArgType ? int(inner_stride_at_compile_time<ArgType>::ret)
                                                                : int(outer_stride_at_compile_time<ArgType>::ret),
        OuterStrideAtCompileTime = HasSameStorageOrderAsArgType ? int(outer_stride_at_compile_time<ArgType>::ret)
                                                                : int(inner_stride_at_compile_time<ArgType>::ret),
        MaskPacketAccessBit = (InnerStrideAtCompileTime == 1 || HasSameStorageOrderAsArgType) ? PacketAccessBit : 0,
        FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 ||
                                (InnerPanel && (evaluator<ArgType>::Flags & LinearAccessBit)))
                                   ? LinearAccessBit
                                   : 0,
        FlagsRowMajorBit = XprType::Flags & RowMajorBit,
        Flags0 = evaluator<ArgType>::Flags & ((HereditaryBits & ~RowMajorBit) | DirectAccessBit | MaskPacketAccessBit),
        Flags = Flags0 | FlagsLinearAccessBit | FlagsRowMajorBit,
        PacketAlignment = unpacket_traits<PacketScalar>::alignment,
        Alignment0 = (InnerPanel && (OuterStrideAtCompileTime != Dynamic) && (OuterStrideAtCompileTime != 0) &&
                      (((OuterStrideAtCompileTime * int(sizeof(Scalar))) % int(PacketAlignment)) == 0))
                         ? int(PacketAlignment)
                         : 0,
        Alignment = plain_enum_min(evaluator<ArgType>::Alignment, Alignment0)
      };
      typedef block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> block_evaluator_type;
      inline explicit evaluator(const XprType& block) : block_evaluator_type(block) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
    };
    template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
    struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, false>
        : unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>> {
      typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
      inline explicit block_evaluator(const XprType& block) : unary_evaluator<XprType>(block) {}
    };
    template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
    struct unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>, IndexBased>
        : evaluator_base<Block<ArgType, BlockRows, BlockCols, InnerPanel>> {
      typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
      inline explicit unary_evaluator(const XprType& block)
          : m_argImpl(block.nestedExpression()),
            m_startRow(block.startRow()),
            m_startCol(block.startCol()),
            m_linear_offset(ForwardLinearAccess
                                ? (ArgType::IsRowMajor
                                       ? block.startRow() * block.nestedExpression().cols() + block.startCol()
                                       : block.startCol() * block.nestedExpression().rows() + block.startRow())
                                : 0) {}
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      enum {
        RowsAtCompileTime = XprType::RowsAtCompileTime,
        ForwardLinearAccess = (InnerPanel || int(XprType::IsRowMajor) == int(ArgType::IsRowMajor)) &&
                              bool(evaluator<ArgType>::Flags & LinearAccessBit)
      };
      inline CoeffReturnType coeff(Index row, Index col) const {
        return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col);
      }
      inline CoeffReturnType coeff(Index index) const {
        return linear_coeff_impl(index, bool_constant<ForwardLinearAccess>());
      }
      inline Scalar& coeffRef(Index row, Index col) {
        return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col);
      }
      inline Scalar& coeffRef(Index index) { return linear_coeffRef_impl(index, bool_constant<ForwardLinearAccess>()); }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_argImpl.template packet<LoadMode, PacketType>(m_startRow.value() + row, m_startCol.value() + col);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        if (ForwardLinearAccess)
          return m_argImpl.template packet<LoadMode, PacketType>(m_linear_offset.value() + index);
        else
          return packet<LoadMode, PacketType>(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        return m_argImpl.template writePacket<StoreMode, PacketType>(
            m_startRow.value() + row, m_startCol.value() + col, x);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        if (ForwardLinearAccess)
          return m_argImpl.template writePacket<StoreMode, PacketType>(m_linear_offset.value() + index, x);
        else
          return writePacket<StoreMode, PacketType>(
              RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0, x);
      }

    protected:
      inline CoeffReturnType linear_coeff_impl(Index index, internal::true_type) const {
        return m_argImpl.coeff(m_linear_offset.value() + index);
      }
      inline CoeffReturnType linear_coeff_impl(Index index, internal::false_type) const {
        return coeff(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
      }
      inline Scalar& linear_coeffRef_impl(Index index, internal::true_type) {
        return m_argImpl.coeffRef(m_linear_offset.value() + index);
      }
      inline Scalar& linear_coeffRef_impl(Index index, internal::false_type) {
        return coeffRef(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
      }
      evaluator<ArgType> m_argImpl;
      const variable_if_dynamic<Index, (ArgType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic> m_startRow;
      const variable_if_dynamic<Index, (ArgType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic> m_startCol;
      const variable_if_dynamic<Index, ForwardLinearAccess ? Dynamic : 0> m_linear_offset;
    };
    template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
    struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, true>
        : mapbase_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>,
                            typename Block<ArgType, BlockRows, BlockCols, InnerPanel>::PlainObject> {
      typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
      typedef typename XprType::Scalar Scalar;
      inline explicit block_evaluator(const XprType& block)
          : mapbase_evaluator<XprType, typename XprType::PlainObject>(block) {
        ;
      }
    };
    template <typename ConditionMatrixType, typename ThenMatrixType, typename ElseMatrixType>
    struct evaluator<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>>
        : evaluator_base<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>> {
      typedef Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType> XprType;
      enum {
        CoeffReadCost =
            evaluator<ConditionMatrixType>::CoeffReadCost +
            plain_enum_max(evaluator<ThenMatrixType>::CoeffReadCost, evaluator<ElseMatrixType>::CoeffReadCost),
        Flags = (unsigned int)evaluator<ThenMatrixType>::Flags & evaluator<ElseMatrixType>::Flags & HereditaryBits,
        Alignment = plain_enum_min(evaluator<ThenMatrixType>::Alignment, evaluator<ElseMatrixType>::Alignment)
      };
      inline explicit evaluator(const XprType& select)
          : m_conditionImpl(select.conditionMatrix()),
            m_thenImpl(select.thenMatrix()),
            m_elseImpl(select.elseMatrix()) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const {
        if (m_conditionImpl.coeff(row, col))
          return m_thenImpl.coeff(row, col);
        else
          return m_elseImpl.coeff(row, col);
      }
      inline CoeffReturnType coeff(Index index) const {
        if (m_conditionImpl.coeff(index))
          return m_thenImpl.coeff(index);
        else
          return m_elseImpl.coeff(index);
      }

    protected:
      evaluator<ConditionMatrixType> m_conditionImpl;
      evaluator<ThenMatrixType> m_thenImpl;
      evaluator<ElseMatrixType> m_elseImpl;
    };
    template <typename ArgType, int RowFactor, int ColFactor>
    struct unary_evaluator<Replicate<ArgType, RowFactor, ColFactor>>
        : evaluator_base<Replicate<ArgType, RowFactor, ColFactor>> {
      typedef Replicate<ArgType, RowFactor, ColFactor> XprType;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      enum { Factor = (RowFactor == Dynamic || ColFactor == Dynamic) ? Dynamic : RowFactor * ColFactor };
      typedef typename internal::nested_eval<ArgType, Factor>::type ArgTypeNested;
      typedef internal::remove_all_t<ArgTypeNested> ArgTypeNestedCleaned;
      enum {
        CoeffReadCost = evaluator<ArgTypeNestedCleaned>::CoeffReadCost,
        LinearAccessMask = XprType::IsVectorAtCompileTime ? LinearAccessBit : 0,
        Flags = (evaluator<ArgTypeNestedCleaned>::Flags & (HereditaryBits | LinearAccessMask) & ~RowMajorBit) |
                (traits<XprType>::Flags & RowMajorBit),
        Alignment = evaluator<ArgTypeNestedCleaned>::Alignment
      };
      inline explicit unary_evaluator(const XprType& replicate)
          : m_arg(replicate.nestedExpression()),
            m_argImpl(m_arg),
            m_rows(replicate.nestedExpression().rows()),
            m_cols(replicate.nestedExpression().cols()) {}
      inline CoeffReturnType coeff(Index row, Index col) const {
        const Index actual_row = internal::traits<XprType>::RowsAtCompileTime == 1 ? 0
                                 : RowFactor == 1                                  ? row
                                                                                   : row % m_rows.value();
        const Index actual_col = internal::traits<XprType>::ColsAtCompileTime == 1 ? 0
                                 : ColFactor == 1                                  ? col
                                                                                   : col % m_cols.value();
        return m_argImpl.coeff(actual_row, actual_col);
      }
      inline CoeffReturnType coeff(Index index) const {
        const Index actual_index = internal::traits<XprType>::RowsAtCompileTime == 1
                                       ? (ColFactor == 1 ? index : index % m_cols.value())
                                       : (RowFactor == 1 ? index : index % m_rows.value());
        return m_argImpl.coeff(actual_index);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        const Index actual_row = internal::traits<XprType>::RowsAtCompileTime == 1 ? 0
                                 : RowFactor == 1                                  ? row
                                                                                   : row % m_rows.value();
        const Index actual_col = internal::traits<XprType>::ColsAtCompileTime == 1 ? 0
                                 : ColFactor == 1                                  ? col
                                                                                   : col % m_cols.value();
        return m_argImpl.template packet<LoadMode, PacketType>(actual_row, actual_col);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        const Index actual_index = internal::traits<XprType>::RowsAtCompileTime == 1
                                       ? (ColFactor == 1 ? index : index % m_cols.value())
                                       : (RowFactor == 1 ? index : index % m_rows.value());
        return m_argImpl.template packet<LoadMode, PacketType>(actual_index);
      }

    protected:
      const ArgTypeNested m_arg;
      evaluator<ArgTypeNestedCleaned> m_argImpl;
      const variable_if_dynamic<Index, ArgType::RowsAtCompileTime> m_rows;
      const variable_if_dynamic<Index, ArgType::ColsAtCompileTime> m_cols;
    };
    template <typename XprType>
    struct evaluator_wrapper_base : evaluator_base<XprType> {
      typedef remove_all_t<typename XprType::NestedExpressionType> ArgType;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        Flags = evaluator<ArgType>::Flags,
        Alignment = evaluator<ArgType>::Alignment
      };
      inline explicit evaluator_wrapper_base(const ArgType& arg) : m_argImpl(arg) {}
      typedef typename ArgType::Scalar Scalar;
      typedef typename ArgType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const { return m_argImpl.coeff(row, col); }
      inline CoeffReturnType coeff(Index index) const { return m_argImpl.coeff(index); }
      inline Scalar& coeffRef(Index row, Index col) { return m_argImpl.coeffRef(row, col); }
      inline Scalar& coeffRef(Index index) { return m_argImpl.coeffRef(index); }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return m_argImpl.template packet<LoadMode, PacketType>(row, col);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        return m_argImpl.template packet<LoadMode, PacketType>(index);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        m_argImpl.template writePacket<StoreMode>(row, col, x);
      }
      template <int StoreMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        m_argImpl.template writePacket<StoreMode>(index, x);
      }

    protected:
      evaluator<ArgType> m_argImpl;
    };
    template <typename TArgType>
    struct unary_evaluator<MatrixWrapper<TArgType>> : evaluator_wrapper_base<MatrixWrapper<TArgType>> {
      typedef MatrixWrapper<TArgType> XprType;
      inline explicit unary_evaluator(const XprType& wrapper)
          : evaluator_wrapper_base<MatrixWrapper<TArgType>>(wrapper.nestedExpression()) {}
    };
    template <typename TArgType>
    struct unary_evaluator<ArrayWrapper<TArgType>> : evaluator_wrapper_base<ArrayWrapper<TArgType>> {
      typedef ArrayWrapper<TArgType> XprType;
      inline explicit unary_evaluator(const XprType& wrapper)
          : evaluator_wrapper_base<ArrayWrapper<TArgType>>(wrapper.nestedExpression()) {}
    };
    template <typename PacketType, bool ReversePacket>
    struct reverse_packet_cond;
    template <typename ArgType, int Direction>
    struct unary_evaluator<Reverse<ArgType, Direction>> : evaluator_base<Reverse<ArgType, Direction>> {
      typedef Reverse<ArgType, Direction> XprType;
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      enum {
        IsRowMajor = XprType::IsRowMajor,
        IsColMajor = !IsRowMajor,
        ReverseRow = (Direction == Vertical) || (Direction == BothDirections),
        ReverseCol = (Direction == Horizontal) || (Direction == BothDirections),
        ReversePacket = (Direction == BothDirections) || ((Direction == Vertical) && IsColMajor) ||
                        ((Direction == Horizontal) && IsRowMajor),
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        Flags0 = evaluator<ArgType>::Flags,
        LinearAccess =
            ((Direction == BothDirections) && (int(Flags0) & PacketAccessBit)) ||
                    ((ReverseRow && XprType::ColsAtCompileTime == 1) || (ReverseCol && XprType::RowsAtCompileTime == 1))
                ? LinearAccessBit
                : 0,
        Flags = int(Flags0) & (HereditaryBits | PacketAccessBit | LinearAccess),
        Alignment = 0
      };
      inline explicit unary_evaluator(const XprType& reverse)
          : m_argImpl(reverse.nestedExpression()),
            m_rows(ReverseRow ? reverse.nestedExpression().rows() : 1),
            m_cols(ReverseCol ? reverse.nestedExpression().cols() : 1) {}
      inline CoeffReturnType coeff(Index row, Index col) const {
        return m_argImpl.coeff(ReverseRow ? m_rows.value() - row - 1 : row,
                               ReverseCol ? m_cols.value() - col - 1 : col);
      }
      inline CoeffReturnType coeff(Index index) const {
        return m_argImpl.coeff(m_rows.value() * m_cols.value() - index - 1);
      }
      inline Scalar& coeffRef(Index row, Index col) {
        return m_argImpl.coeffRef(ReverseRow ? m_rows.value() - row - 1 : row,
                                  ReverseCol ? m_cols.value() - col - 1 : col);
      }
      inline Scalar& coeffRef(Index index) { return m_argImpl.coeffRef(m_rows.value() * m_cols.value() - index - 1); }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        enum {
          PacketSize = unpacket_traits<PacketType>::size,
          OffsetRow = ReverseRow && IsColMajor ? PacketSize : 1,
          OffsetCol = ReverseCol && IsRowMajor ? PacketSize : 1
        };
        typedef internal::reverse_packet_cond<PacketType, ReversePacket> reverse_packet;
        return reverse_packet::run(m_argImpl.template packet<LoadMode, PacketType>(
            ReverseRow ? m_rows.value() - row - OffsetRow : row, ReverseCol ? m_cols.value() - col - OffsetCol : col));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index index) const {
        enum { PacketSize = unpacket_traits<PacketType>::size };
        return preverse(
            m_argImpl.template packet<LoadMode, PacketType>(m_rows.value() * m_cols.value() - index - PacketSize));
      }
      template <int LoadMode, typename PacketType>
      inline void writePacket(Index row, Index col, const PacketType& x) {
        enum {
          PacketSize = unpacket_traits<PacketType>::size,
          OffsetRow = ReverseRow && IsColMajor ? PacketSize : 1,
          OffsetCol = ReverseCol && IsRowMajor ? PacketSize : 1
        };
        typedef internal::reverse_packet_cond<PacketType, ReversePacket> reverse_packet;
        m_argImpl.template writePacket<LoadMode>(ReverseRow ? m_rows.value() - row - OffsetRow : row,
                                                 ReverseCol ? m_cols.value() - col - OffsetCol : col,
                                                 reverse_packet::run(x));
      }
      template <int LoadMode, typename PacketType>
      inline void writePacket(Index index, const PacketType& x) {
        enum { PacketSize = unpacket_traits<PacketType>::size };
        m_argImpl.template writePacket<LoadMode>(m_rows.value() * m_cols.value() - index - PacketSize, preverse(x));
      }

    protected:
      evaluator<ArgType> m_argImpl;
      const variable_if_dynamic<Index, ReverseRow ? ArgType::RowsAtCompileTime : 1> m_rows;
      const variable_if_dynamic<Index, ReverseCol ? ArgType::ColsAtCompileTime : 1> m_cols;
    };
    template <typename ArgType, int DiagIndex>
    struct evaluator<Diagonal<ArgType, DiagIndex>> : evaluator_base<Diagonal<ArgType, DiagIndex>> {
      typedef Diagonal<ArgType, DiagIndex> XprType;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        Flags = (unsigned int)(evaluator<ArgType>::Flags & (HereditaryBits | DirectAccessBit) & ~RowMajorBit) |
                LinearAccessBit,
        Alignment = 0
      };
      inline explicit evaluator(const XprType& diagonal)
          : m_argImpl(diagonal.nestedExpression()), m_index(diagonal.index()) {}
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index) const {
        return m_argImpl.coeff(row + rowOffset(), row + colOffset());
      }
      inline CoeffReturnType coeff(Index index) const {
        return m_argImpl.coeff(index + rowOffset(), index + colOffset());
      }
      inline Scalar& coeffRef(Index row, Index) { return m_argImpl.coeffRef(row + rowOffset(), row + colOffset()); }
      inline Scalar& coeffRef(Index index) { return m_argImpl.coeffRef(index + rowOffset(), index + colOffset()); }

    protected:
      evaluator<ArgType> m_argImpl;
      const internal::variable_if_dynamicindex<Index, XprType::DiagIndex> m_index;

    private:
      inline constexpr Index rowOffset() const { return m_index.value() > 0 ? 0 : -m_index.value(); }
      inline constexpr Index colOffset() const { return m_index.value() > 0 ? m_index.value() : 0; }
    };
    template <typename ArgType>
    class EvalToTemp;
    template <typename ArgType>
    struct traits<EvalToTemp<ArgType>> : public traits<ArgType> {};
    template <typename ArgType>
    class EvalToTemp : public dense_xpr_base<EvalToTemp<ArgType>>::type {
    public:
      typedef typename dense_xpr_base<EvalToTemp>::type Base;
      typedef typename Eigen::internal::traits<EvalToTemp>::Scalar Scalar;
      typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
      typedef typename Base::CoeffReturnType CoeffReturnType;
      typedef typename Eigen::internal::ref_selector<EvalToTemp>::type Nested;
      typedef typename Eigen::internal::traits<EvalToTemp>::StorageKind StorageKind;
      typedef typename Eigen::internal::traits<EvalToTemp>::StorageIndex StorageIndex;
      enum CompileTimeTraits {
        RowsAtCompileTime = Eigen::internal::traits<EvalToTemp>::RowsAtCompileTime,
        ColsAtCompileTime = Eigen::internal::traits<EvalToTemp>::ColsAtCompileTime,
        Flags = Eigen::internal::traits<EvalToTemp>::Flags,
        SizeAtCompileTime = Base::SizeAtCompileTime,
        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
        IsVectorAtCompileTime = Base::IsVectorAtCompileTime
      };
      using Base::const_cast_derived;
      using Base::derived;
      explicit EvalToTemp(const ArgType& arg) : m_arg(arg) {}
      const ArgType& arg() const { return m_arg; }
      constexpr Index rows() const noexcept { return m_arg.rows(); }
      constexpr Index cols() const noexcept { return m_arg.cols(); }

    private:
      const ArgType& m_arg;
    };
    template <typename ArgType>
    struct evaluator<EvalToTemp<ArgType>> : public evaluator<typename ArgType::PlainObject> {
      typedef EvalToTemp<ArgType> XprType;
      typedef typename ArgType::PlainObject PlainObject;
      typedef evaluator<PlainObject> Base;
      explicit evaluator(const XprType& xpr) : m_result(xpr.arg()) { internal::construct_at<Base>(this, m_result); }
      evaluator(const ArgType& arg) : m_result(arg) { internal::construct_at<Base>(this, m_result); }

    protected:
      PlainObject m_result;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename DstEvaluator, typename SrcEvaluator, typename AssignFunc, int MaxPacketSize = -1>
    struct copy_using_evaluator_traits {
      typedef typename DstEvaluator::XprType Dst;
      typedef typename Dst::Scalar DstScalar;
      enum { DstFlags = DstEvaluator::Flags, SrcFlags = SrcEvaluator::Flags };

    public:
      enum {
        DstAlignment = DstEvaluator::Alignment,
        SrcAlignment = SrcEvaluator::Alignment,
        DstHasDirectAccess = (DstFlags & DirectAccessBit) == DirectAccessBit,
        JointAlignment = plain_enum_min(DstAlignment, SrcAlignment)
      };

    private:
      enum {
        InnerSize = int(Dst::IsVectorAtCompileTime) ? int(Dst::SizeAtCompileTime)
                    : int(DstFlags) & RowMajorBit   ? int(Dst::ColsAtCompileTime)
                                                    : int(Dst::RowsAtCompileTime),
        InnerMaxSize = int(Dst::IsVectorAtCompileTime) ? int(Dst::MaxSizeAtCompileTime)
                       : int(DstFlags) & RowMajorBit   ? int(Dst::MaxColsAtCompileTime)
                                                       : int(Dst::MaxRowsAtCompileTime),
        RestrictedInnerSize = min_size_prefer_fixed(InnerSize, MaxPacketSize),
        RestrictedLinearSize = min_size_prefer_fixed(Dst::SizeAtCompileTime, MaxPacketSize),
        OuterStride = int(outer_stride_at_compile_time<Dst>::ret),
        MaxSizeAtCompileTime = Dst::SizeAtCompileTime
      };
      typedef typename find_best_packet<DstScalar, RestrictedLinearSize>::type LinearPacketType;
      typedef typename find_best_packet<DstScalar, RestrictedInnerSize>::type InnerPacketType;
      enum {
        LinearPacketSize = unpacket_traits<LinearPacketType>::size,
        InnerPacketSize = unpacket_traits<InnerPacketType>::size
      };

    public:
      enum {
        LinearRequiredAlignment = unpacket_traits<LinearPacketType>::alignment,
        InnerRequiredAlignment = unpacket_traits<InnerPacketType>::alignment
      };

    private:
      enum {
        DstIsRowMajor = DstFlags & RowMajorBit,
        SrcIsRowMajor = SrcFlags & RowMajorBit,
        StorageOrdersAgree = (int(DstIsRowMajor) == int(SrcIsRowMajor)),
        MightVectorize = bool(StorageOrdersAgree) && (int(DstFlags) & int(SrcFlags) & ActualPacketAccessBit) &&
                         bool(functor_traits<AssignFunc>::PacketAccess),
        MayInnerVectorize = MightVectorize && int(InnerSize) != Dynamic && int(InnerSize) % int(InnerPacketSize) == 0 &&
                            int(OuterStride) != Dynamic && int(OuterStride) % int(InnerPacketSize) == 0 &&
                            (1 || int(JointAlignment) >= int(InnerRequiredAlignment)),
        MayLinearize = bool(StorageOrdersAgree) && (int(DstFlags) & int(SrcFlags) & LinearAccessBit),
        MayLinearVectorize =
            bool(MightVectorize) && bool(MayLinearize) && bool(DstHasDirectAccess) &&
            (1 || (int(DstAlignment) >= int(LinearRequiredAlignment)) || MaxSizeAtCompileTime == Dynamic),
        MaySliceVectorize =
            bool(MightVectorize) && bool(DstHasDirectAccess) &&
            (int(InnerMaxSize) == Dynamic || int(InnerMaxSize) >= (1 ? InnerPacketSize : (3 * InnerPacketSize)))
      };

    public:
      enum {
        Traversal = int(Dst::SizeAtCompileTime) == 0                                    ? int(AllAtOnceTraversal)
                    : (int(MayLinearVectorize) && (LinearPacketSize > InnerPacketSize)) ? int(LinearVectorizedTraversal)
                    : int(MayInnerVectorize)                                            ? int(InnerVectorizedTraversal)
                    : int(MayLinearVectorize)                                           ? int(LinearVectorizedTraversal)
                    : int(MaySliceVectorize)                                            ? int(SliceVectorizedTraversal)
                    : int(MayLinearize)                                                 ? int(LinearTraversal)
                                                                                        : int(DefaultTraversal),
        Vectorized = int(Traversal) == InnerVectorizedTraversal || int(Traversal) == LinearVectorizedTraversal ||
                     int(Traversal) == SliceVectorizedTraversal
      };
      typedef std::conditional_t<int(Traversal) == LinearVectorizedTraversal, LinearPacketType, InnerPacketType>
          PacketType;

    private:
      enum {
        ActualPacketSize = int(Traversal) == LinearVectorizedTraversal ? LinearPacketSize
                           : Vectorized                                ? InnerPacketSize
                                                                       : 1,
        UnrollingLimit = 110 * ActualPacketSize,
        MayUnrollCompletely =
            int(Dst::SizeAtCompileTime) != Dynamic &&
            int(Dst::SizeAtCompileTime) * (int(DstEvaluator::CoeffReadCost) + int(SrcEvaluator::CoeffReadCost)) <=
                int(UnrollingLimit),
        MayUnrollInner = int(InnerSize) != Dynamic &&
                         int(InnerSize) * (int(DstEvaluator::CoeffReadCost) + int(SrcEvaluator::CoeffReadCost)) <=
                             int(UnrollingLimit)
      };

    public:
      enum {
        Unrolling = (int(Traversal) == int(InnerVectorizedTraversal) || int(Traversal) == int(DefaultTraversal))
                        ? (int(MayUnrollCompletely) ? int(CompleteUnrolling)
                           : int(MayUnrollInner)    ? int(InnerUnrolling)
                                                    : int(NoUnrolling))
                    : int(Traversal) == int(LinearVectorizedTraversal)
                        ? (bool(MayUnrollCompletely) && (1 || (int(DstAlignment) >= int(LinearRequiredAlignment)))
                               ? int(CompleteUnrolling)
                               : int(NoUnrolling))
                    : int(Traversal) == int(LinearTraversal)
                        ? (bool(MayUnrollCompletely) ? int(CompleteUnrolling) : int(NoUnrolling))
                    : int(Traversal) == int(SliceVectorizedTraversal)
                        ? (bool(MayUnrollInner) ? int(InnerUnrolling) : int(NoUnrolling))
                        : int(NoUnrolling)
      };
    };
    template <typename Kernel, int Index, int Stop>
    struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling {
      typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
      typedef typename DstEvaluatorType::XprType DstXprType;
      enum { outer = Index / DstXprType::InnerSizeAtCompileTime, inner = Index % DstXprType::InnerSizeAtCompileTime };
      static inline void run(Kernel& kernel) {
        kernel.assignCoeffByOuterInner(outer, inner);
        copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, Index + 1, Stop>::run(kernel);
      }
    };
    template <typename Kernel, int Stop>
    struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, Stop, Stop> {
      static inline constexpr void run(Kernel&) {}
    };
    template <typename Kernel, int Index_, int Stop>
    struct copy_using_evaluator_DefaultTraversal_InnerUnrolling {
      static inline void run(Kernel& kernel, Index outer) {
        kernel.assignCoeffByOuterInner(outer, Index_);
        copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, Index_ + 1, Stop>::run(kernel, outer);
      }
    };
    template <typename Kernel, int Stop>
    struct copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, Stop, Stop> {
      static inline void run(Kernel&, Index) {}
    };
    template <typename Kernel, int Index, int Stop>
    struct copy_using_evaluator_LinearTraversal_CompleteUnrolling {
      static inline void run(Kernel& kernel) {
        kernel.assignCoeff(Index);
        copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, Index + 1, Stop>::run(kernel);
      }
    };
    template <typename Kernel, int Stop>
    struct copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, Stop, Stop> {
      static inline void run(Kernel&) {}
    };
    template <typename Kernel, int Index, int Stop>
    struct copy_using_evaluator_innervec_CompleteUnrolling {
      typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
      typedef typename DstEvaluatorType::XprType DstXprType;
      typedef typename Kernel::PacketType PacketType;
      enum {
        outer = Index / DstXprType::InnerSizeAtCompileTime,
        inner = Index % DstXprType::InnerSizeAtCompileTime,
        SrcAlignment = Kernel::AssignmentTraits::SrcAlignment,
        DstAlignment = Kernel::AssignmentTraits::DstAlignment
      };
      static inline void run(Kernel& kernel) {
        kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, inner);
        enum { NextIndex = Index + unpacket_traits<PacketType>::size };
        copy_using_evaluator_innervec_CompleteUnrolling<Kernel, NextIndex, Stop>::run(kernel);
      }
    };
    template <typename Kernel, int Stop>
    struct copy_using_evaluator_innervec_CompleteUnrolling<Kernel, Stop, Stop> {
      static inline constexpr void run(Kernel&) {}
    };
    template <typename Kernel, int Index_, int Stop, int SrcAlignment, int DstAlignment>
    struct copy_using_evaluator_innervec_InnerUnrolling {
      typedef typename Kernel::PacketType PacketType;
      static inline void run(Kernel& kernel, Index outer) {
        kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, Index_);
        enum { NextIndex = Index_ + unpacket_traits<PacketType>::size };
        copy_using_evaluator_innervec_InnerUnrolling<Kernel, NextIndex, Stop, SrcAlignment, DstAlignment>::run(kernel,
                                                                                                               outer);
      }
    };
    template <typename Kernel, int Stop, int SrcAlignment, int DstAlignment>
    struct copy_using_evaluator_innervec_InnerUnrolling<Kernel, Stop, Stop, SrcAlignment, DstAlignment> {
      static inline void run(Kernel&, Index) {}
    };
    template <typename Kernel,
              int Traversal = Kernel::AssignmentTraits::Traversal,
              int Unrolling = Kernel::AssignmentTraits::Unrolling>
    struct dense_assignment_loop;
    template <typename Kernel, int Unrolling>
    struct dense_assignment_loop<Kernel, AllAtOnceTraversal, Unrolling> {
      static void inline constexpr run(Kernel&) {
        static_assert(int(Kernel::DstEvaluatorType::XprType::SizeAtCompileTime) == 0,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT");
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling> {
      static void inline run(Kernel& kernel) {
        for (Index outer = 0; outer < kernel.outerSize(); ++outer) {
          for (Index inner = 0; inner < kernel.innerSize(); ++inner) {
            kernel.assignCoeffByOuterInner(outer, inner);
          }
        }
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, DefaultTraversal, CompleteUnrolling> {
      static inline void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, DefaultTraversal, InnerUnrolling> {
      static inline void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        const Index outerSize = kernel.outerSize();
        for (Index outer = 0; outer < outerSize; ++outer)
          copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, 0, DstXprType::InnerSizeAtCompileTime>::run(
              kernel, outer);
      }
    };
    template <bool IsAligned = false>
    struct unaligned_dense_assignment_loop {
      template <typename Kernel>
      static inline constexpr void run(Kernel&, Index, Index) {}
    };
    template <>
    struct unaligned_dense_assignment_loop<false> {
      template <typename Kernel>
      static inline constexpr void run(Kernel& kernel, Index start, Index end) {
        for (Index index = start; index < end; ++index)
          kernel.assignCoeff(index);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, NoUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        const Index size = kernel.size();
        typedef typename Kernel::Scalar Scalar;
        typedef typename Kernel::PacketType PacketType;
        enum {
          requestedAlignment = Kernel::AssignmentTraits::LinearRequiredAlignment,
          packetSize = unpacket_traits<PacketType>::size,
          dstIsAligned = int(Kernel::AssignmentTraits::DstAlignment) >= int(requestedAlignment),
          dstAlignment = packet_traits<Scalar>::AlignedOnScalar ? int(requestedAlignment)
                                                                : int(Kernel::AssignmentTraits::DstAlignment),
          srcAlignment = Kernel::AssignmentTraits::JointAlignment
        };
        const Index alignedStart =
            dstIsAligned ? 0 : internal::first_aligned<requestedAlignment>(kernel.dstDataPtr(), size);
        const Index alignedEnd = alignedStart + ((size - alignedStart) / packetSize) * packetSize;
        unaligned_dense_assignment_loop<dstIsAligned != 0>::run(kernel, 0, alignedStart);
        for (Index index = alignedStart; index < alignedEnd; index += packetSize)
          kernel.template assignPacket<dstAlignment, srcAlignment, PacketType>(index);
        unaligned_dense_assignment_loop<>::run(kernel, alignedEnd, size);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, CompleteUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        typedef typename Kernel::PacketType PacketType;
        enum {
          size = DstXprType::SizeAtCompileTime,
          packetSize = unpacket_traits<PacketType>::size,
          alignedSize = (int(size) / packetSize) * packetSize
        };
        copy_using_evaluator_innervec_CompleteUnrolling<Kernel, 0, alignedSize>::run(kernel);
        copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, alignedSize, size>::run(kernel);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, NoUnrolling> {
      typedef typename Kernel::PacketType PacketType;
      enum {
        SrcAlignment = Kernel::AssignmentTraits::SrcAlignment,
        DstAlignment = Kernel::AssignmentTraits::DstAlignment
      };
      static inline constexpr void run(Kernel& kernel) {
        const Index innerSize = kernel.innerSize();
        const Index outerSize = kernel.outerSize();
        const Index packetSize = unpacket_traits<PacketType>::size;
        for (Index outer = 0; outer < outerSize; ++outer)
          for (Index inner = 0; inner < innerSize; inner += packetSize)
            kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, inner);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, CompleteUnrolling> {
      static inline void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        copy_using_evaluator_innervec_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, InnerUnrolling> {
      static inline void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        typedef typename Kernel::AssignmentTraits Traits;
        const Index outerSize = kernel.outerSize();
        for (Index outer = 0; outer < outerSize; ++outer)
          copy_using_evaluator_innervec_InnerUnrolling<Kernel,
                                                       0,
                                                       DstXprType::InnerSizeAtCompileTime,
                                                       Traits::SrcAlignment,
                                                       Traits::DstAlignment>::run(kernel, outer);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        const Index size = kernel.size();
        for (Index i = 0; i < size; ++i)
          kernel.assignCoeff(i);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, LinearTraversal, CompleteUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, NoUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        typedef typename Kernel::Scalar Scalar;
        typedef typename Kernel::PacketType PacketType;
        enum {
          packetSize = unpacket_traits<PacketType>::size,
          requestedAlignment = int(Kernel::AssignmentTraits::InnerRequiredAlignment),
          alignable =
              packet_traits<Scalar>::AlignedOnScalar || int(Kernel::AssignmentTraits::DstAlignment) >= sizeof(Scalar),
          dstIsAligned = int(Kernel::AssignmentTraits::DstAlignment) >= int(requestedAlignment),
          dstAlignment = alignable ? int(requestedAlignment) : int(Kernel::AssignmentTraits::DstAlignment)
        };
        const Scalar* dst_ptr = kernel.dstDataPtr();
        if ((!bool(dstIsAligned)) && (UIntPtr(dst_ptr) % sizeof(Scalar)) > 0) {
          return dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>::run(kernel);
        }
        const Index packetAlignedMask = packetSize - 1;
        const Index innerSize = kernel.innerSize();
        const Index outerSize = kernel.outerSize();
        const Index alignedStep = alignable ? (packetSize - kernel.outerStride() % packetSize) & packetAlignedMask : 0;
        Index alignedStart =
            ((!alignable) || bool(dstIsAligned)) ? 0 : internal::first_aligned<requestedAlignment>(dst_ptr, innerSize);
        for (Index outer = 0; outer < outerSize; ++outer) {
          const Index alignedEnd = alignedStart + ((innerSize - alignedStart) & ~packetAlignedMask);
          for (Index inner = 0; inner < alignedStart; ++inner)
            kernel.assignCoeffByOuterInner(outer, inner);
          for (Index inner = alignedStart; inner < alignedEnd; inner += packetSize)
            kernel.template assignPacketByOuterInner<dstAlignment, Unaligned, PacketType>(outer, inner);
          for (Index inner = alignedEnd; inner < innerSize; ++inner)
            kernel.assignCoeffByOuterInner(outer, inner);
          alignedStart = numext::mini((alignedStart + alignedStep) % packetSize, innerSize);
        }
      }
    };
    template <typename Kernel>
    struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, InnerUnrolling> {
      static inline constexpr void run(Kernel& kernel) {
        typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
        typedef typename Kernel::PacketType PacketType;
        enum {
          innerSize = DstXprType::InnerSizeAtCompileTime,
          packetSize = unpacket_traits<PacketType>::size,
          vectorizableSize = (int(innerSize) / int(packetSize)) * int(packetSize),
          size = DstXprType::SizeAtCompileTime
        };
        for (Index outer = 0; outer < kernel.outerSize(); ++outer) {
          copy_using_evaluator_innervec_InnerUnrolling<Kernel, 0, vectorizableSize, 0, 0>::run(kernel, outer);
          copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, innerSize>::run(kernel, outer);
        }
      }
    };
    template <typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
    class generic_dense_assignment_kernel {
    protected:
      typedef typename DstEvaluatorTypeT::XprType DstXprType;
      typedef typename SrcEvaluatorTypeT::XprType SrcXprType;

    public:
      typedef DstEvaluatorTypeT DstEvaluatorType;
      typedef SrcEvaluatorTypeT SrcEvaluatorType;
      typedef typename DstEvaluatorType::Scalar Scalar;
      typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor> AssignmentTraits;
      typedef typename AssignmentTraits::PacketType PacketType;
      inline generic_dense_assignment_kernel(DstEvaluatorType& dst,
                                             const SrcEvaluatorType& src,
                                             const Functor& func,
                                             DstXprType& dstExpr)
          : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr) {}
      constexpr Index size() const noexcept { return m_dstExpr.size(); }
      constexpr Index innerSize() const noexcept { return m_dstExpr.innerSize(); }
      constexpr Index outerSize() const noexcept { return m_dstExpr.outerSize(); }
      constexpr Index rows() const noexcept { return m_dstExpr.rows(); }
      constexpr Index cols() const noexcept { return m_dstExpr.cols(); }
      constexpr Index outerStride() const noexcept { return m_dstExpr.outerStride(); }
      DstEvaluatorType& dstEvaluator() noexcept { return m_dst; }
      const SrcEvaluatorType& srcEvaluator() const noexcept { return m_src; }
      inline void assignCoeff(Index row, Index col) {
        m_functor.assignCoeff(m_dst.coeffRef(row, col), m_src.coeff(row, col));
      }
      inline void assignCoeff(Index index) { m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index)); }
      inline void assignCoeffByOuterInner(Index outer, Index inner) {
        Index row = rowIndexByOuterInner(outer, inner);
        Index col = colIndexByOuterInner(outer, inner);
        assignCoeff(row, col);
      }
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacket(Index row, Index col) {
        m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(row, col),
                                                   m_src.template packet<LoadMode, PacketType>(row, col));
      }
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacket(Index index) {
        m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(index),
                                                   m_src.template packet<LoadMode, PacketType>(index));
      }
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacketByOuterInner(Index outer, Index inner) {
        Index row = rowIndexByOuterInner(outer, inner);
        Index col = colIndexByOuterInner(outer, inner);
        assignPacket<StoreMode, LoadMode, PacketType>(row, col);
      }
      static inline Index rowIndexByOuterInner(Index outer, Index inner) {
        typedef typename DstEvaluatorType::ExpressionTraits Traits;
        return int(Traits::RowsAtCompileTime) == 1          ? 0
               : int(Traits::ColsAtCompileTime) == 1        ? inner
               : int(DstEvaluatorType::Flags) & RowMajorBit ? outer
                                                            : inner;
      }
      static inline Index colIndexByOuterInner(Index outer, Index inner) {
        typedef typename DstEvaluatorType::ExpressionTraits Traits;
        return int(Traits::ColsAtCompileTime) == 1          ? 0
               : int(Traits::RowsAtCompileTime) == 1        ? inner
               : int(DstEvaluatorType::Flags) & RowMajorBit ? inner
                                                            : outer;
      }
      const Scalar* dstDataPtr() const { return m_dstExpr.data(); }

    protected:
      DstEvaluatorType& m_dst;
      const SrcEvaluatorType& m_src;
      const Functor& m_functor;
      DstXprType& m_dstExpr;
    };
    template <typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor>
    class restricted_packet_dense_assignment_kernel
        : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> {
    protected:
      typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> Base;

    public:
      typedef typename Base::Scalar Scalar;
      typedef typename Base::DstXprType DstXprType;
      typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, 4> AssignmentTraits;
      typedef typename AssignmentTraits::PacketType PacketType;
      restricted_packet_dense_assignment_kernel(DstEvaluatorTypeT& dst,
                                                const SrcEvaluatorTypeT& src,
                                                const Functor& func,
                                                DstXprType& dstExpr)
          : Base(dst, src, func, dstExpr) {}
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    inline void resize_if_allowed(DstXprType& dst, const SrcXprType& src, const Functor&) {
      ;
      ;
      (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
           ? void(0)
           : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/AssignEvaluator.h",
                           755,
                           __extension__ __PRETTY_FUNCTION__));
    }
    template <typename DstXprType, typename SrcXprType, typename T1, typename T2>
    inline void resize_if_allowed(DstXprType& dst, const SrcXprType& src, const internal::assign_op<T1, T2>&) {
      Index dstRows = src.rows();
      Index dstCols = src.cols();
      if (((dst.rows() != dstRows) || (dst.cols() != dstCols)))
        dst.resize(dstRows, dstCols);
      (static_cast<bool>(dst.rows() == dstRows && dst.cols() == dstCols)
           ? void(0)
           : __assert_fail("dst.rows() == dstRows && dst.cols() == dstCols",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/AssignEvaluator.h",
                           766,
                           __extension__ __PRETTY_FUNCTION__));
    }
    template <typename DstXprType, typename SrcXprType, typename Functor>
    inline constexpr void call_dense_assignment_loop(DstXprType& dst, const SrcXprType& src, const Functor& func) {
      typedef evaluator<DstXprType> DstEvaluatorType;
      typedef evaluator<SrcXprType> SrcEvaluatorType;
      SrcEvaluatorType srcEvaluator(src);
      resize_if_allowed(dst, src, func);
      DstEvaluatorType dstEvaluator(dst);
      typedef generic_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Functor> Kernel;
      Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
      dense_assignment_loop<Kernel>::run(kernel);
    }
    template <typename DstXprType>
    inline void call_dense_assignment_loop(
        DstXprType& dst,
        const Eigen::CwiseNullaryOp<Eigen::internal::scalar_constant_op<typename DstXprType::Scalar>, DstXprType>& src,
        const internal::assign_op<typename DstXprType::Scalar, typename DstXprType::Scalar>& func) {
      resize_if_allowed(dst, src, func);
      std::fill_n(dst.data(), dst.size(), src.functor()());
    }
    template <typename DstXprType, typename SrcXprType>
    inline void call_dense_assignment_loop(DstXprType& dst, const SrcXprType& src) {
      call_dense_assignment_loop(
          dst, src, internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>());
    }
    template <typename DstShape, typename SrcShape>
    struct AssignmentKind;
    struct Dense2Dense {};
    struct EigenBase2EigenBase {};
    template <typename, typename>
    struct AssignmentKind {
      typedef EigenBase2EigenBase Kind;
    };
    template <>
    struct AssignmentKind<DenseShape, DenseShape> {
      typedef Dense2Dense Kind;
    };
    template <typename DstXprType,
              typename SrcXprType,
              typename Functor,
              typename Kind = typename AssignmentKind<typename evaluator_traits<DstXprType>::Shape,
                                                      typename evaluator_traits<SrcXprType>::Shape>::Kind,
              typename EnableIf = void>
    struct Assignment;
    template <typename Dst, typename Src>
    inline void call_assignment(Dst& dst, const Src& src) {
      call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
    }
    template <typename Dst, typename Src>
    inline void call_assignment(const Dst& dst, const Src& src) {
      call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
    }
    template <typename Dst, typename Src, typename Func>
    inline constexpr void call_assignment(Dst& dst,
                                          const Src& src,
                                          const Func& func,
                                          std::enable_if_t<evaluator_assume_aliasing<Src>::value, void*> = 0) {
      typename plain_matrix_type<Src>::type tmp(src);
      call_assignment_no_alias(dst, tmp, func);
    }
    template <typename Dst, typename Src, typename Func>
    inline void call_assignment(Dst& dst,
                                const Src& src,
                                const Func& func,
                                std::enable_if_t<!evaluator_assume_aliasing<Src>::value, void*> = 0) {
      call_assignment_no_alias(dst, src, func);
    }
    template <typename Dst, template <typename> class StorageBase, typename Src, typename Func>
    inline constexpr void call_assignment(NoAlias<Dst, StorageBase>& dst, const Src& src, const Func& func) {
      call_assignment_no_alias(dst.expression(), src, func);
    }
    template <typename Dst, typename Src, typename Func>
    inline constexpr void call_assignment_no_alias(Dst& dst, const Src& src, const Func& func) {
      enum {
        NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 && int(Src::ColsAtCompileTime) == 1) ||
                           (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)) &&
                          int(Dst::SizeAtCompileTime) != 1
      };
      typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst> ActualDstTypeCleaned;
      typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst&> ActualDstType;
      ActualDstType actualDst(dst);
      static_assert(Eigen::internal::is_lvalue<Dst>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<ActualDstTypeCleaned>::ret) == 0 &&
                      int(Eigen::internal::size_of_xpr_at_compile_time<Src>::ret) == 0) ||
                     ((int(ActualDstTypeCleaned::RowsAtCompileTime) == Eigen::Dynamic ||
                       int(Src::RowsAtCompileTime) == Eigen::Dynamic ||
                       int(ActualDstTypeCleaned::RowsAtCompileTime) == int(Src::RowsAtCompileTime)) &&
                      (int(ActualDstTypeCleaned::ColsAtCompileTime) == Eigen::Dynamic ||
                       int(Src::ColsAtCompileTime) == Eigen::Dynamic ||
                       int(ActualDstTypeCleaned::ColsAtCompileTime) == int(Src::ColsAtCompileTime)))),
                    "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
      static_assert(
          (Eigen::internal::has_ReturnType<
              ScalarBinaryOpTraits<typename ActualDstTypeCleaned::Scalar, typename Src::Scalar, Func>>::value),
          "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_"
          "EXPLICITLY");
      ;
      Assignment<ActualDstTypeCleaned, Src, Func>::run(actualDst, src, func);
    }
    template <typename Dst, typename Src, typename Func>
    inline void call_restricted_packet_assignment_no_alias(Dst& dst, const Src& src, const Func& func) {
      typedef evaluator<Dst> DstEvaluatorType;
      typedef evaluator<Src> SrcEvaluatorType;
      typedef restricted_packet_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Func> Kernel;
      static_assert(Eigen::internal::is_lvalue<Dst>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      static_assert((Eigen::internal::has_ReturnType<
                        ScalarBinaryOpTraits<typename Dst::Scalar, typename Src::Scalar, Func>>::value),
                    "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                    "TYPES_EXPLICITLY");
      ;
      SrcEvaluatorType srcEvaluator(src);
      resize_if_allowed(dst, src, func);
      DstEvaluatorType dstEvaluator(dst);
      Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
      dense_assignment_loop<Kernel>::run(kernel);
    }
    template <typename Dst, typename Src>
    inline constexpr void call_assignment_no_alias(Dst& dst, const Src& src) {
      call_assignment_no_alias(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
    }
    template <typename Dst, typename Src, typename Func>
    inline constexpr void call_assignment_no_alias_no_transpose(Dst& dst, const Src& src, const Func& func) {
      static_assert(Eigen::internal::is_lvalue<Dst>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<Dst>::ret) == 0 &&
                      int(Eigen::internal::size_of_xpr_at_compile_time<Src>::ret) == 0) ||
                     ((int(Dst::RowsAtCompileTime) == Eigen::Dynamic || int(Src::RowsAtCompileTime) == Eigen::Dynamic ||
                       int(Dst::RowsAtCompileTime) == int(Src::RowsAtCompileTime)) &&
                      (int(Dst::ColsAtCompileTime) == Eigen::Dynamic || int(Src::ColsAtCompileTime) == Eigen::Dynamic ||
                       int(Dst::ColsAtCompileTime) == int(Src::ColsAtCompileTime)))),
                    "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
      static_assert((Eigen::internal::has_ReturnType<
                        ScalarBinaryOpTraits<typename Dst::Scalar, typename Src::Scalar, Func>>::value),
                    "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                    "TYPES_EXPLICITLY");
      ;
      Assignment<Dst, Src, Func>::run(dst, src, func);
    }
    template <typename Dst, typename Src>
    inline constexpr void call_assignment_no_alias_no_transpose(Dst& dst, const Src& src) {
      call_assignment_no_alias_no_transpose(
          dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
    }
    template <typename Dst, typename Src>
    void check_for_aliasing(const Dst& dst, const Src& src);
    template <typename DstXprType, typename SrcXprType, typename Functor, typename Weak>
    struct Assignment<DstXprType, SrcXprType, Functor, Dense2Dense, Weak> {
      static inline void run(DstXprType& dst, const SrcXprType& src, const Functor& func) {
        internal::check_for_aliasing(dst, src);
        call_dense_assignment_loop(dst, src, func);
      }
    };
    template <typename DstXprType, typename SrcXprType, typename Functor, typename Weak>
    struct Assignment<DstXprType, SrcXprType, Functor, EigenBase2EigenBase, Weak> {
      static inline void run(DstXprType& dst,
                             const SrcXprType& src,
                             const internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
             ? void(0)
             : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/AssignEvaluator.h",
                             974,
                             __extension__ __PRETTY_FUNCTION__));
        src.evalTo(dst);
      }
      template <typename SrcScalarType>
      static inline void run(DstXprType& dst,
                             const SrcXprType& src,
                             const internal::add_assign_op<typename DstXprType::Scalar, SrcScalarType>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
             ? void(0)
             : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/AssignEvaluator.h",
                             989,
                             __extension__ __PRETTY_FUNCTION__));
        src.addTo(dst);
      }
      template <typename SrcScalarType>
      static inline void run(DstXprType& dst,
                             const SrcXprType& src,
                             const internal::sub_assign_op<typename DstXprType::Scalar, SrcScalarType>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
             ? void(0)
             : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/AssignEvaluator.h",
                             1002,
                             __extension__ __PRETTY_FUNCTION__));
        src.subTo(dst);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& DenseBase<Derived>::lazyAssign(const DenseBase<OtherDerived>& other) {
    enum { SameType = internal::is_same<typename Derived::Scalar, typename OtherDerived::Scalar>::value };
    static_assert(Eigen::internal::is_lvalue<Derived>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
    static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<Derived>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<OtherDerived>::ret) == 0) ||
                   ((int(Derived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::RowsAtCompileTime) == int(OtherDerived::RowsAtCompileTime)) &&
                    (int(Derived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::ColsAtCompileTime) == int(OtherDerived::ColsAtCompileTime)))),
                  "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
    static_assert(SameType,
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    (static_cast<bool>(rows() == other.rows() && cols() == other.cols())
         ? void(0)
         : __assert_fail("rows() == other.rows() && cols() == other.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Assign.h",
                         32,
                         __extension__ __PRETTY_FUNCTION__));
    internal::call_assignment_no_alias(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& DenseBase<Derived>::operator=(const DenseBase<OtherDerived>& other) {
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::operator=(const DenseBase& other) {
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  inline Derived& MatrixBase<Derived>::operator=(const MatrixBase& other) {
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator=(const DenseBase<OtherDerived>& other) {
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator=(const EigenBase<OtherDerived>& other) {
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator=(const ReturnByValue<OtherDerived>& other) {
    other.derived().evalTo(derived());
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  template <typename ExpressionType>
  class MatrixWrapper;
  template <typename Derived>
  class ArrayBase : public DenseBase<Derived> {
  public:
    typedef ArrayBase StorageBaseType;
    typedef ArrayBase Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef DenseBase<Derived> Base;
    using Base::coeff;
    using Base::coeffRef;
    using Base::cols;
    using Base::ColsAtCompileTime;
    using Base::const_cast_derived;
    using Base::derived;
    using Base::Flags;
    using Base::IsVectorAtCompileTime;
    using Base::lazyAssign;
    using Base::MaxColsAtCompileTime;
    using Base::MaxRowsAtCompileTime;
    using Base::MaxSizeAtCompileTime;
    using Base::rows;
    using Base::RowsAtCompileTime;
    using Base::size;
    using Base::SizeAtCompileTime;
    using Base::operator-;
    using Base::operator=;
    using Base::operator+=;
    using Base::operator-=;
    using Base::operator*=;
    using Base::operator/=;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Base::PlainObject PlainObject;
    typedef CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> ConstantReturnType;
    typedef CwiseUnaryOp<internal::scalar_abs_op<Scalar>, const Derived> CwiseAbsReturnType;
    typedef CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const Derived> CwiseAbs2ReturnType;
    typedef CwiseUnaryOp<internal::scalar_arg_op<Scalar>, const Derived> CwiseArgReturnType;
    typedef CwiseUnaryOp<internal::scalar_sqrt_op<Scalar>, const Derived> CwiseSqrtReturnType;
    typedef CwiseUnaryOp<internal::scalar_sign_op<Scalar>, const Derived> CwiseSignReturnType;
    typedef CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const Derived> CwiseInverseReturnType;
    inline const CwiseAbsReturnType cwiseAbs() const { return CwiseAbsReturnType(derived()); }
    inline const CwiseAbs2ReturnType cwiseAbs2() const { return CwiseAbs2ReturnType(derived()); }
    inline const CwiseSqrtReturnType cwiseSqrt() const { return CwiseSqrtReturnType(derived()); }
    inline const CwiseSignReturnType cwiseSign() const { return CwiseSignReturnType(derived()); }
    inline const CwiseInverseReturnType cwiseInverse() const { return CwiseInverseReturnType(derived()); }
    inline const CwiseArgReturnType cwiseArg() const { return CwiseArgReturnType(derived()); }
    template <typename ScalarExponent>
    using CwisePowReturnType =
        std::enable_if_t<internal::is_arithmetic<typename NumTraits<ScalarExponent>::Real>::value,
                         CwiseUnaryOp<internal::scalar_unary_pow_op<Scalar, ScalarExponent>, const Derived>>;
    template <typename ScalarExponent>
    inline const CwisePowReturnType<ScalarExponent> cwisePow(const ScalarExponent& exponent) const {
      return CwisePowReturnType<ScalarExponent>(derived(),
                                                internal::scalar_unary_pow_op<Scalar, ScalarExponent>(exponent));
    }
    typedef CwiseUnaryOp<internal::scalar_abs_op<Scalar>, const Derived> AbsReturnType;
    typedef CwiseUnaryOp<internal::scalar_arg_op<Scalar>, const Derived> ArgReturnType;
    typedef CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const Derived> Abs2ReturnType;
    typedef CwiseUnaryOp<internal::scalar_sqrt_op<Scalar>, const Derived> SqrtReturnType;
    typedef CwiseUnaryOp<internal::scalar_rsqrt_op<Scalar>, const Derived> RsqrtReturnType;
    typedef CwiseUnaryOp<internal::scalar_sign_op<Scalar>, const Derived> SignReturnType;
    typedef CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const Derived> InverseReturnType;
    typedef CwiseUnaryOp<internal::scalar_boolean_not_op<Scalar>, const Derived> BooleanNotReturnType;
    typedef CwiseUnaryOp<internal::scalar_exp_op<Scalar>, const Derived> ExpReturnType;
    typedef CwiseUnaryOp<internal::scalar_expm1_op<Scalar>, const Derived> Expm1ReturnType;
    typedef CwiseUnaryOp<internal::scalar_log_op<Scalar>, const Derived> LogReturnType;
    typedef CwiseUnaryOp<internal::scalar_log1p_op<Scalar>, const Derived> Log1pReturnType;
    typedef CwiseUnaryOp<internal::scalar_log10_op<Scalar>, const Derived> Log10ReturnType;
    typedef CwiseUnaryOp<internal::scalar_log2_op<Scalar>, const Derived> Log2ReturnType;
    typedef CwiseUnaryOp<internal::scalar_cos_op<Scalar>, const Derived> CosReturnType;
    typedef CwiseUnaryOp<internal::scalar_sin_op<Scalar>, const Derived> SinReturnType;
    typedef CwiseUnaryOp<internal::scalar_tan_op<Scalar>, const Derived> TanReturnType;
    typedef CwiseUnaryOp<internal::scalar_acos_op<Scalar>, const Derived> AcosReturnType;
    typedef CwiseUnaryOp<internal::scalar_asin_op<Scalar>, const Derived> AsinReturnType;
    typedef CwiseUnaryOp<internal::scalar_atan_op<Scalar>, const Derived> AtanReturnType;
    typedef CwiseUnaryOp<internal::scalar_tanh_op<Scalar>, const Derived> TanhReturnType;
    typedef CwiseUnaryOp<internal::scalar_logistic_op<Scalar>, const Derived> LogisticReturnType;
    typedef CwiseUnaryOp<internal::scalar_sinh_op<Scalar>, const Derived> SinhReturnType;
    typedef CwiseUnaryOp<internal::scalar_atanh_op<Scalar>, const Derived> AtanhReturnType;
    typedef CwiseUnaryOp<internal::scalar_asinh_op<Scalar>, const Derived> AsinhReturnType;
    typedef CwiseUnaryOp<internal::scalar_acosh_op<Scalar>, const Derived> AcoshReturnType;
    typedef CwiseUnaryOp<internal::scalar_cosh_op<Scalar>, const Derived> CoshReturnType;
    typedef CwiseUnaryOp<internal::scalar_square_op<Scalar>, const Derived> SquareReturnType;
    typedef CwiseUnaryOp<internal::scalar_cube_op<Scalar>, const Derived> CubeReturnType;
    typedef CwiseUnaryOp<internal::scalar_round_op<Scalar>, const Derived> RoundReturnType;
    typedef CwiseUnaryOp<internal::scalar_rint_op<Scalar>, const Derived> RintReturnType;
    typedef CwiseUnaryOp<internal::scalar_floor_op<Scalar>, const Derived> FloorReturnType;
    typedef CwiseUnaryOp<internal::scalar_ceil_op<Scalar>, const Derived> CeilReturnType;
    typedef CwiseUnaryOp<internal::scalar_isnan_op<Scalar>, const Derived> IsNaNReturnType;
    typedef CwiseUnaryOp<internal::scalar_isinf_op<Scalar>, const Derived> IsInfReturnType;
    typedef CwiseUnaryOp<internal::scalar_isfinite_op<Scalar>, const Derived> IsFiniteReturnType;
    inline const AbsReturnType abs() const { return AbsReturnType(derived()); }
    inline const ArgReturnType arg() const { return ArgReturnType(derived()); }
    inline const Abs2ReturnType abs2() const { return Abs2ReturnType(derived()); }
    inline const ExpReturnType exp() const { return ExpReturnType(derived()); }
    inline const Expm1ReturnType expm1() const { return Expm1ReturnType(derived()); }
    inline const LogReturnType log() const { return LogReturnType(derived()); }
    inline const Log1pReturnType log1p() const { return Log1pReturnType(derived()); }
    inline const Log10ReturnType log10() const { return Log10ReturnType(derived()); }
    inline const Log2ReturnType log2() const { return Log2ReturnType(derived()); }
    inline const SqrtReturnType sqrt() const { return SqrtReturnType(derived()); }
    inline const RsqrtReturnType rsqrt() const { return RsqrtReturnType(derived()); }
    inline const SignReturnType sign() const { return SignReturnType(derived()); }
    inline const CosReturnType cos() const { return CosReturnType(derived()); }
    inline const SinReturnType sin() const { return SinReturnType(derived()); }
    inline const TanReturnType tan() const { return TanReturnType(derived()); }
    inline const AtanReturnType atan() const { return AtanReturnType(derived()); }
    inline const AcosReturnType acos() const { return AcosReturnType(derived()); }
    inline const AsinReturnType asin() const { return AsinReturnType(derived()); }
    inline const TanhReturnType tanh() const { return TanhReturnType(derived()); }
    inline const SinhReturnType sinh() const { return SinhReturnType(derived()); }
    inline const CoshReturnType cosh() const { return CoshReturnType(derived()); }
    inline const AtanhReturnType atanh() const { return AtanhReturnType(derived()); }
    inline const AsinhReturnType asinh() const { return AsinhReturnType(derived()); }
    inline const AcoshReturnType acosh() const { return AcoshReturnType(derived()); }
    inline const LogisticReturnType logistic() const { return LogisticReturnType(derived()); }
    inline const InverseReturnType inverse() const { return InverseReturnType(derived()); }
    inline const SquareReturnType square() const { return SquareReturnType(derived()); }
    inline const CubeReturnType cube() const { return CubeReturnType(derived()); }
    inline const RintReturnType rint() const { return RintReturnType(derived()); }
    inline const RoundReturnType round() const { return RoundReturnType(derived()); }
    inline const FloorReturnType floor() const { return FloorReturnType(derived()); }
    inline const CeilReturnType ceil() const { return CeilReturnType(derived()); }
    template <int N>
    struct ShiftRightXpr {
      typedef CwiseUnaryOp<internal::scalar_shift_right_op<Scalar, N>, const Derived> Type;
    };
    template <int N>
    typename ShiftRightXpr<N>::Type shiftRight() const {
      return typename ShiftRightXpr<N>::Type(derived());
    }
    template <int N>
    struct ShiftLeftXpr {
      typedef CwiseUnaryOp<internal::scalar_shift_left_op<Scalar, N>, const Derived> Type;
    };
    template <int N>
    typename ShiftLeftXpr<N>::Type shiftLeft() const {
      return typename ShiftLeftXpr<N>::Type(derived());
    }
    inline const IsNaNReturnType isNaN() const { return IsNaNReturnType(derived()); }
    inline const IsInfReturnType isInf() const { return IsInfReturnType(derived()); }
    inline const IsFiniteReturnType isFinite() const { return IsFiniteReturnType(derived()); }
    inline const BooleanNotReturnType operator!() const {
      static_assert((internal::is_same<bool, Scalar>::value), "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return BooleanNotReturnType(derived());
    }
    typedef CwiseUnaryOp<internal::scalar_lgamma_op<Scalar>, const Derived> LgammaReturnType;
    typedef CwiseUnaryOp<internal::scalar_digamma_op<Scalar>, const Derived> DigammaReturnType;
    typedef CwiseUnaryOp<internal::scalar_erf_op<Scalar>, const Derived> ErfReturnType;
    typedef CwiseUnaryOp<internal::scalar_erfc_op<Scalar>, const Derived> ErfcReturnType;
    typedef CwiseUnaryOp<internal::scalar_ndtri_op<Scalar>, const Derived> NdtriReturnType;
    inline const LgammaReturnType lgamma() const { return LgammaReturnType(derived()); }
    inline const DigammaReturnType digamma() const { return DigammaReturnType(derived()); }
    inline const ErfReturnType erf() const { return ErfReturnType(derived()); }
    inline const ErfcReturnType erfc() const { return ErfcReturnType(derived()); }
    inline const NdtriReturnType ndtri() const { return NdtriReturnType(derived()); }
    template <typename ScalarExponent>
    using UnaryPowReturnType =
        std::enable_if_t<internal::is_arithmetic<typename NumTraits<ScalarExponent>::Real>::value,
                         CwiseUnaryOp<internal::scalar_unary_pow_op<Scalar, ScalarExponent>, const Derived>>;
    template <typename ScalarExponent>
    inline const UnaryPowReturnType<ScalarExponent> pow(const ScalarExponent& exponent) const {
      return UnaryPowReturnType<ScalarExponent>(derived(),
                                                internal::scalar_unary_pow_op<Scalar, ScalarExponent>(exponent));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_difference_op<typename internal::traits<Derived>::Scalar,
                                                              typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(operator-)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_difference_op<typename internal::traits<Derived>::Scalar,
                                                          typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_sum_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(operator+)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_sum_op<typename internal::traits<Derived>::Scalar,
                                                   typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename CustomBinaryOp, typename OtherDerived>
    inline const CwiseBinaryOp<CustomBinaryOp, const Derived, const OtherDerived> binaryExpr(
        const Eigen::ArrayBase<OtherDerived>& other, const CustomBinaryOp& func = CustomBinaryOp()) const {
      return CwiseBinaryOp<CustomBinaryOp, const Derived, const OtherDerived>(derived(), other.derived(), func);
    }
    template <typename T>
    inline friend const CwiseBinaryOp<
        internal::scalar_product_op<
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::type,
            typename internal::traits<Derived>::Scalar>,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::
                type>::type,
        const Derived>(operator*)(const T& scalar, const StorageBaseType& matrix) {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_product_op<T, Scalar>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_product_op<PromotedT, typename internal::traits<Derived>::Scalar>,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type,
                           const Derived>(
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),
          matrix.derived());
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_product_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::
                type>::type>(operator*)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_product_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_quotient_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::
                type>::type>(operator/)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_quotient_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_boolean_and_op, const Derived, const OtherDerived> operator&&(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      static_assert(
          (internal::is_same<bool, Scalar>::value && internal::is_same<bool, typename OtherDerived::Scalar>::value),
          "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return CwiseBinaryOp<internal::scalar_boolean_and_op, const Derived, const OtherDerived>(derived(),
                                                                                               other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_boolean_or_op, const Derived, const OtherDerived> operator||(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      static_assert(
          (internal::is_same<bool, Scalar>::value && internal::is_same<bool, typename OtherDerived::Scalar>::value),
          "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return CwiseBinaryOp<internal::scalar_boolean_or_op, const Derived, const OtherDerived>(derived(),
                                                                                              other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                           typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>
    cwiseProduct(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived> cwiseEqual(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived> cwiseNotEqual(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
    cwiseMin(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const ConstantReturnType>
    cwiseMin(const Scalar& other) const {
      return cwiseMin<NaNPropagation>(Derived::Constant(rows(), cols(), other));
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
    cwiseMax(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const ConstantReturnType>
    cwiseMax(const Scalar& other) const {
      return cwiseMax<NaNPropagation>(Derived::Constant(rows(), cols(), other));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived> cwiseQuotient(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived>(derived(),
                                                                                                    other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>,
                          const Derived,
                          const ConstantReturnType>
        CwiseScalarEqualReturnType;
    inline const CwiseScalarEqualReturnType cwiseEqual(const Scalar& s) const {
      return CwiseScalarEqualReturnType(
          derived(), Derived::Constant(rows(), cols(), s), internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                           typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>
    operator*(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_quotient_op<Scalar, typename OtherDerived::Scalar>,
                               const Derived,
                               const OtherDerived>
    operator/(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_quotient_op<Scalar, typename OtherDerived::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const OtherDerived>(min)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>(min)(
        const Scalar& other) const {
      return (min<NaNPropagation>)(Derived::PlainObject::Constant(rows(), cols(), other));
    }
    template <int NaNPropagation = PropagateFast, typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const OtherDerived>(max)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
          derived(), other.derived());
    }
    template <int NaNPropagation = PropagateFast>
    inline const CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>,
                               const Derived,
                               const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>(max)(
        const Scalar& other) const {
      return (max<NaNPropagation>)(Derived::PlainObject::Constant(rows(), cols(), other));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_absolute_difference_op<typename internal::traits<Derived>::Scalar,
                                                                       typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(absolute_difference)(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_absolute_difference_op<typename internal::traits<Derived>::Scalar,
                                                                   typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    inline const CwiseBinaryOp<internal::scalar_absolute_difference_op<Scalar, Scalar>,
                               const Derived,
                               const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>(
        absolute_difference)(const Scalar& other) const {
      return (absolute_difference)(Derived::PlainObject::Constant(rows(), cols(), other));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_pow_op<typename internal::traits<Derived>::Scalar,
                                                       typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(pow)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_pow_op<typename internal::traits<Derived>::Scalar,
                                                   typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_atan2_op<typename internal::traits<Derived>::Scalar,
                                                         typename internal::traits<OtherDerived>::Scalar>,
                               const Derived,
                               const OtherDerived>(atan2)(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_atan2_op<typename internal::traits<Derived>::Scalar,
                                                     typename internal::traits<OtherDerived>::Scalar>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_LT>,
                               const Derived,
                               const OtherDerived>
    operator<(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_LT>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT>,
                          const Derived,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>
        CmpLTReturnType;
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT>,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>,
                          const Derived>
        RCmpLTReturnType;
    inline const CmpLTReturnType operator<(const Scalar& s) const {
      return this->operator<(Derived::PlainObject::Constant(rows(), cols(), s));
    }
    friend inline const RCmpLTReturnType operator<(const Scalar& s, const Eigen::ArrayBase<Derived>& d) {
      return Derived::PlainObject::Constant(d.rows(), d.cols(), s).operator<(d);
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_LE>,
                               const Derived,
                               const OtherDerived>
    operator<=(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_LE>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE>,
                          const Derived,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>
        CmpLEReturnType;
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE>,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>,
                          const Derived>
        RCmpLEReturnType;
    inline const CmpLEReturnType operator<=(const Scalar& s) const {
      return this->operator<=(Derived::PlainObject::Constant(rows(), cols(), s));
    }
    friend inline const RCmpLEReturnType operator<=(const Scalar& s, const Eigen::ArrayBase<Derived>& d) {
      return Derived::PlainObject::Constant(d.rows(), d.cols(), s).operator<=(d);
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<typename OtherDerived::Scalar, Scalar, internal::cmp_LT>,
                               const OtherDerived,
                               const Derived>
    operator>(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<typename OtherDerived::Scalar, Scalar, internal::cmp_LT>,
                           const OtherDerived,
                           const Derived>(other.derived(), derived());
    }
    inline const RCmpLTReturnType operator>(const Scalar& s) const {
      return Derived::PlainObject::Constant(rows(), cols(), s).operator<(*this);
    }
    friend inline const CmpLTReturnType operator>(const Scalar& s, const Derived& d) {
      return d.operator<(Derived::PlainObject::Constant(d.rows(), d.cols(), s));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<typename OtherDerived::Scalar, Scalar, internal::cmp_LE>,
                               const OtherDerived,
                               const Derived>
    operator>=(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<typename OtherDerived::Scalar, Scalar, internal::cmp_LE>,
                           const OtherDerived,
                           const Derived>(other.derived(), derived());
    }
    inline const RCmpLEReturnType operator>=(const Scalar& s) const {
      return Derived::PlainObject::Constant(rows(), cols(), s).operator<=(*this);
    }
    friend inline const CmpLEReturnType operator>=(const Scalar& s, const Derived& d) {
      return d.operator<=(Derived::PlainObject::Constant(d.rows(), d.cols(), s));
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_EQ>,
                               const Derived,
                               const OtherDerived>
    operator==(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_EQ>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>,
                          const Derived,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>
        CmpEQReturnType;
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>,
                          const Derived>
        RCmpEQReturnType;
    inline const CmpEQReturnType operator==(const Scalar& s) const {
      return this->operator==(Derived::PlainObject::Constant(rows(), cols(), s));
    }
    friend inline const RCmpEQReturnType operator==(const Scalar& s, const Eigen::ArrayBase<Derived>& d) {
      return Derived::PlainObject::Constant(d.rows(), d.cols(), s).operator==(d);
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_NEQ>,
                               const Derived,
                               const OtherDerived>
    operator!=(const Eigen::ArrayBase<OtherDerived>& other) const {
      return CwiseBinaryOp<internal::scalar_cmp_op<Scalar, typename OtherDerived::Scalar, internal::cmp_NEQ>,
                           const Derived,
                           const OtherDerived>(derived(), other.derived());
    }
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ>,
                          const Derived,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>>
        CmpNEQReturnType;
    typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ>,
                          const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>,
                          const Derived>
        RCmpNEQReturnType;
    inline const CmpNEQReturnType operator!=(const Scalar& s) const {
      return this->operator!=(Derived::PlainObject::Constant(rows(), cols(), s));
    }
    friend inline const RCmpNEQReturnType operator!=(const Scalar& s, const Eigen::ArrayBase<Derived>& d) {
      return Derived::PlainObject::Constant(d.rows(), d.cols(), s).operator!=(d);
    }
    template <typename T>
    inline friend const CwiseBinaryOp<
        internal::scalar_sum_op<
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_sum_op<T, Scalar>>>::value)>::type,
            typename internal::traits<Derived>::Scalar>,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_sum_op<T, Scalar>>>::value)>::type>::
            type,
        const Derived>(operator+)(const T& scalar, const StorageBaseType& matrix) {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_sum_op<T, Scalar>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_sum_op<PromotedT, typename internal::traits<Derived>::Scalar>,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type,
                           const Derived>(
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),
          matrix.derived());
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_sum_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_sum_op<Scalar, T>>>::value)>::type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_sum_op<Scalar, T>>>::value)>::type>::
            type>(operator+)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_sum_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_sum_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename T>
    inline friend const CwiseBinaryOp<
        internal::scalar_difference_op<
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_difference_op<T, Scalar>>>::value)>::type,
            typename internal::traits<Derived>::Scalar>,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_difference_op<T, Scalar>>>::value)>::
                type>::type,
        const Derived>(operator-)(const T& scalar, const StorageBaseType& matrix) {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_difference_op<T, Scalar>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_difference_op<PromotedT, typename internal::traits<Derived>::Scalar>,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type,
                           const Derived>(
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),
          matrix.derived());
    }
    template <typename T>
    inline const CwiseBinaryOp<
        internal::scalar_difference_op<
            typename internal::traits<Derived>::Scalar,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_difference_op<Scalar, T>>>::value)>::
                type>,
        const Derived,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_difference_op<Scalar, T>>>::value)>::
                type>::type>(operator-)(const T& scalar) const {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<Scalar, T, Eigen::internal::scalar_difference_op<Scalar, T>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_difference_op<typename internal::traits<Derived>::Scalar, PromotedT>,
                           const Derived,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type>(
          derived(),
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));
    }
    template <typename T>
    inline friend const CwiseBinaryOp<
        internal::scalar_quotient_op<
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_quotient_op<T, Scalar>>>::value)>::type,
            typename internal::traits<Derived>::Scalar>,
        const typename internal::plain_constant_type<
            Derived,
            typename internal::promote_scalar_arg<
                Scalar,
                T,
                (Eigen::internal::has_ReturnType<
                    Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_quotient_op<T, Scalar>>>::value)>::
                type>::type,
        const Derived>(operator/)(const T& scalar, const StorageBaseType& matrix) {
      typedef typename internal::promote_scalar_arg<
          Scalar,
          T,
          (Eigen::internal::has_ReturnType<
              Eigen::ScalarBinaryOpTraits<T, Scalar, Eigen::internal::scalar_quotient_op<T, Scalar>>>::value)>::type
          PromotedT;
      return CwiseBinaryOp<internal::scalar_quotient_op<PromotedT, typename internal::traits<Derived>::Scalar>,
                           const typename internal::plain_constant_type<Derived, PromotedT>::type,
                           const Derived>(
          typename internal::plain_constant_type<Derived, PromotedT>::type(
              matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),
          matrix.derived());
    }
    template <typename OtherDerived>
    inline const CwiseBinaryOp<internal::scalar_boolean_xor_op, const Derived, const OtherDerived> operator^(
        const Eigen::ArrayBase<OtherDerived>& other) const {
      static_assert(
          (internal::is_same<bool, Scalar>::value && internal::is_same<bool, typename OtherDerived::Scalar>::value),
          "THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL");
      ;
      return CwiseBinaryOp<internal::scalar_boolean_xor_op, const Derived, const OtherDerived>(derived(),
                                                                                               other.derived());
    }
    template <typename DerivedQ>
    inline const CwiseBinaryOp<internal::scalar_zeta_op<Scalar>, const Derived, const DerivedQ> zeta(
        const Eigen::ArrayBase<DerivedQ>& q) const {
      return CwiseBinaryOp<internal::scalar_zeta_op<Scalar>, const Derived, const DerivedQ>(this->derived(),
                                                                                            q.derived());
    }
    inline Derived& operator=(const ArrayBase& other) {
      internal::call_assignment(derived(), other.derived());
      return derived();
    }
    inline Derived& operator=(const Scalar& value) {
      Base::setConstant(value);
      return derived();
    }
    inline Derived& operator+=(const Scalar& scalar);
    inline Derived& operator-=(const Scalar& scalar);
    template <typename OtherDerived>
    inline Derived& operator+=(const ArrayBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Derived& operator-=(const ArrayBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Derived& operator*=(const ArrayBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Derived& operator/=(const ArrayBase<OtherDerived>& other);

  public:
    ArrayBase<Derived>& array() { return *this; }
    const ArrayBase<Derived>& array() const { return *this; }
    MatrixWrapper<Derived> matrix() { return MatrixWrapper<Derived>(derived()); }
    const MatrixWrapper<const Derived> matrix() const { return MatrixWrapper<const Derived>(derived()); }

  protected:
    ArrayBase(const ArrayBase&) = default;
    ArrayBase() = default;
    ~ArrayBase() = default;

  private:
    explicit ArrayBase(Index);
    ArrayBase(Index, Index);
    template <typename OtherDerived>
    explicit ArrayBase(const ArrayBase<OtherDerived>&);

  protected:
    template <typename OtherDerived>
    Derived& operator+=(const MatrixBase<OtherDerived>&) {
      static_assert(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1, "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      ;
      return *this;
    }
    template <typename OtherDerived>
    Derived& operator-=(const MatrixBase<OtherDerived>&) {
      static_assert(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1, "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      ;
      return *this;
    }
  };
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& ArrayBase<Derived>::operator-=(const ArrayBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& ArrayBase<Derived>::operator+=(const ArrayBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& ArrayBase<Derived>::operator*=(const ArrayBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::mul_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& ArrayBase<Derived>::operator/=(const ArrayBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::div_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              typename DataMapper,
              int mr,
              int nr,
              bool ConjugateLhs = false,
              bool ConjugateRhs = false>
    struct gebp_kernel;
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int nr,
              int StorageOrder,
              bool Conjugate = false,
              bool PanelMode = false>
    struct gemm_pack_rhs;
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int Pack1,
              int Pack2,
              typename Packet,
              int StorageOrder,
              bool Conjugate = false,
              bool PanelMode = false>
    struct gemm_pack_lhs;
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResStorageOrder,
              int ResInnerStride>
    struct general_matrix_matrix_product;
    template <typename Index,
              typename LhsScalar,
              typename LhsMapper,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              typename RhsMapper,
              bool ConjugateRhs,
              int Version = Specialized>
    struct general_matrix_vector_product;
    template <typename From, typename To>
    struct get_factor {
      static inline To run(const From& x) { return To(x); }
    };
    template <typename Scalar>
    struct get_factor<Scalar, typename NumTraits<Scalar>::Real> {
      static inline typename NumTraits<Scalar>::Real run(const Scalar& x) { return numext::real(x); }
    };
    template <typename Scalar, typename Index>
    class BlasVectorMapper {
    public:
      __attribute__((always_inline)) inline BlasVectorMapper(Scalar* data) : m_data(data) {}
      __attribute__((always_inline)) inline Scalar operator()(Index i) const { return m_data[i]; }
      template <typename Packet, int AlignmentType>
      __attribute__((always_inline)) inline Packet load(Index i) const {
        return ploadt<Packet, AlignmentType>(m_data + i);
      }
      template <typename Packet>
      bool aligned(Index i) const {
        return (UIntPtr(m_data + i) % sizeof(Packet)) == 0;
      }

    protected:
      Scalar* m_data;
    };
    template <typename Scalar, typename Index, int AlignmentType, int Incr = 1>
    class BlasLinearMapper;
    template <typename Scalar, typename Index, int AlignmentType>
    class BlasLinearMapper<Scalar, Index, AlignmentType> {
    public:
      __attribute__((always_inline)) inline BlasLinearMapper(Scalar* data, Index incr = 1) : m_data(data) {
        ;
        (static_cast<bool>(incr == 1)
             ? void(0)
             : __assert_fail("incr==1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/BlasUtil.h",
                             87,
                             __extension__ __PRETTY_FUNCTION__));
      }
      __attribute__((always_inline)) inline void prefetch(Index i) const { internal::prefetch(&operator()(i)); }
      __attribute__((always_inline)) inline Scalar& operator()(Index i) const { return m_data[i]; }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacket(Index i) const {
        return ploadt<PacketType, AlignmentType>(m_data + i);
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacketPartial(Index i, Index n, Index offset = 0) const {
        return ploadt_partial<PacketType, AlignmentType>(m_data + i, n, offset);
      }
      template <typename PacketType, int AlignmentT>
      __attribute__((always_inline)) inline PacketType load(Index i) const {
        return ploadt<PacketType, AlignmentT>(m_data + i);
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacket(Index i, const PacketType& p) const {
        pstoret<Scalar, PacketType, AlignmentType>(m_data + i, p);
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacketPartial(Index i,
                                                                    const PacketType& p,
                                                                    Index n,
                                                                    Index offset = 0) const {
        pstoret_partial<Scalar, PacketType, AlignmentType>(m_data + i, p, n, offset);
      }

    protected:
      Scalar* m_data;
    };
    template <typename Scalar, typename Index, int StorageOrder, int AlignmentType = Unaligned, int Incr = 1>
    class blas_data_mapper;
    template <typename Index, typename Scalar, typename Packet, int n, int idx, int StorageOrder>
    struct PacketBlockManagement {
      PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, StorageOrder> pbm;
      __attribute__((always_inline)) inline void store(
          Scalar* to, const Index stride, Index i, Index j, const PacketBlock<Packet, n>& block) const {
        pbm.store(to, stride, i, j, block);
        pstoreu<Scalar>(to + i + (j + idx) * stride, block.packet[idx]);
      }
    };
    template <typename Index, typename Scalar, typename Packet, int n, int idx>
    struct PacketBlockManagement<Index, Scalar, Packet, n, idx, RowMajor> {
      PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, RowMajor> pbm;
      __attribute__((always_inline)) inline void store(
          Scalar* to, const Index stride, Index i, Index j, const PacketBlock<Packet, n>& block) const {
        pbm.store(to, stride, i, j, block);
        pstoreu<Scalar>(to + j + (i + idx) * stride, block.packet[idx]);
      }
    };
    template <typename Index, typename Scalar, typename Packet, int n, int StorageOrder>
    struct PacketBlockManagement<Index, Scalar, Packet, n, -1, StorageOrder> {
      __attribute__((always_inline)) inline void store(
          Scalar* to, const Index stride, Index i, Index j, const PacketBlock<Packet, n>& block) const {
        Eigen::internal::ignore_unused_variable(to);
        ;
        Eigen::internal::ignore_unused_variable(stride);
        ;
        Eigen::internal::ignore_unused_variable(i);
        ;
        Eigen::internal::ignore_unused_variable(j);
        ;
        Eigen::internal::ignore_unused_variable(block);
        ;
      }
    };
    template <typename Index, typename Scalar, typename Packet, int n>
    struct PacketBlockManagement<Index, Scalar, Packet, n, -1, RowMajor> {
      __attribute__((always_inline)) inline void store(
          Scalar* to, const Index stride, Index i, Index j, const PacketBlock<Packet, n>& block) const {
        Eigen::internal::ignore_unused_variable(to);
        ;
        Eigen::internal::ignore_unused_variable(stride);
        ;
        Eigen::internal::ignore_unused_variable(i);
        ;
        Eigen::internal::ignore_unused_variable(j);
        ;
        Eigen::internal::ignore_unused_variable(block);
        ;
      }
    };
    template <typename Scalar, typename Index, int StorageOrder, int AlignmentType>
    class blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, 1> {
    public:
      typedef BlasLinearMapper<Scalar, Index, AlignmentType> LinearMapper;
      typedef BlasVectorMapper<Scalar, Index> VectorMapper;
      __attribute__((always_inline)) inline blas_data_mapper(Scalar* data, Index stride, Index incr = 1)
          : m_data(data), m_stride(stride) {
        ;
        (static_cast<bool>(incr == 1)
             ? void(0)
             : __assert_fail("incr==1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/util/BlasUtil.h",
                             191,
                             __extension__ __PRETTY_FUNCTION__));
      }
      __attribute__((always_inline)) inline blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType> getSubMapper(
          Index i, Index j) const {
        return blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType>(&operator()(i, j), m_stride);
      }
      __attribute__((always_inline)) inline LinearMapper getLinearMapper(Index i, Index j) const {
        return LinearMapper(&operator()(i, j));
      }
      __attribute__((always_inline)) inline VectorMapper getVectorMapper(Index i, Index j) const {
        return VectorMapper(&operator()(i, j));
      }
      __attribute__((always_inline)) inline void prefetch(Index i, Index j) const {
        internal::prefetch(&operator()(i, j));
      }
      __attribute__((always_inline)) inline Scalar& operator()(Index i, Index j) const {
        return m_data[StorageOrder == RowMajor ? j + i * m_stride : i + j * m_stride];
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacket(Index i, Index j) const {
        return ploadt<PacketType, AlignmentType>(&operator()(i, j));
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacketPartial(Index i,
                                                                         Index j,
                                                                         Index n,
                                                                         Index offset = 0) const {
        return ploadt_partial<PacketType, AlignmentType>(&operator()(i, j), n, offset);
      }
      template <typename PacketT, int AlignmentT>
      __attribute__((always_inline)) inline PacketT load(Index i, Index j) const {
        return ploadt<PacketT, AlignmentT>(&operator()(i, j));
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacket(Index i, Index j, const PacketType& p) const {
        pstoret<Scalar, PacketType, AlignmentType>(&operator()(i, j), p);
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacketPartial(
          Index i, Index j, const PacketType& p, Index n, Index offset = 0) const {
        pstoret_partial<Scalar, PacketType, AlignmentType>(&operator()(i, j), p, n, offset);
      }
      template <typename SubPacket>
      __attribute__((always_inline)) inline void scatterPacket(Index i, Index j, const SubPacket& p) const {
        pscatter<Scalar, SubPacket>(&operator()(i, j), p, m_stride);
      }
      template <typename SubPacket>
      __attribute__((always_inline)) inline SubPacket gatherPacket(Index i, Index j) const {
        return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
      }
      const Index stride() const { return m_stride; }
      const Index incr() const { return 1; }
      const Scalar* data() const { return m_data; }
      Index firstAligned(Index size) const {
        if (UIntPtr(m_data) % sizeof(Scalar)) {
          return -1;
        }
        return internal::first_default_aligned(m_data, size);
      }
      template <typename SubPacket, int n>
      __attribute__((always_inline)) inline void storePacketBlock(Index i,
                                                                  Index j,
                                                                  const PacketBlock<SubPacket, n>& block) const {
        PacketBlockManagement<Index, Scalar, SubPacket, n, n - 1, StorageOrder> pbm;
        pbm.store(m_data, m_stride, i, j, block);
      }

    protected:
      Scalar* __restrict m_data;
      const Index m_stride;
    };
    template <typename Scalar, typename Index, int AlignmentType, int Incr>
    class BlasLinearMapper {
    public:
      __attribute__((always_inline)) inline BlasLinearMapper(Scalar* data, Index incr) : m_data(data), m_incr(incr) {}
      __attribute__((always_inline)) inline void prefetch(int i) const { internal::prefetch(&operator()(i)); }
      __attribute__((always_inline)) inline Scalar& operator()(Index i) const { return m_data[i * m_incr.value()]; }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacket(Index i) const {
        return pgather<Scalar, PacketType>(m_data + i * m_incr.value(), m_incr.value());
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacketPartial(Index i, Index n, Index = 0) const {
        return pgather_partial<Scalar, PacketType>(m_data + i * m_incr.value(), m_incr.value(), n);
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacket(Index i, const PacketType& p) const {
        pscatter<Scalar, PacketType>(m_data + i * m_incr.value(), p, m_incr.value());
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacketPartial(Index i,
                                                                    const PacketType& p,
                                                                    Index n,
                                                                    Index = 0) const {
        pscatter_partial<Scalar, PacketType>(m_data + i * m_incr.value(), p, m_incr.value(), n);
      }

    protected:
      Scalar* m_data;
      const internal::variable_if_dynamic<Index, Incr> m_incr;
    };
    template <typename Scalar, typename Index, int StorageOrder, int AlignmentType, int Incr>
    class blas_data_mapper {
    public:
      typedef BlasLinearMapper<Scalar, Index, AlignmentType, Incr> LinearMapper;
      __attribute__((always_inline)) inline blas_data_mapper(Scalar* data, Index stride, Index incr)
          : m_data(data), m_stride(stride), m_incr(incr) {}
      __attribute__((always_inline)) inline blas_data_mapper getSubMapper(Index i, Index j) const {
        return blas_data_mapper(&operator()(i, j), m_stride, m_incr.value());
      }
      __attribute__((always_inline)) inline LinearMapper getLinearMapper(Index i, Index j) const {
        return LinearMapper(&operator()(i, j), m_incr.value());
      }
      __attribute__((always_inline)) inline void prefetch(Index i, Index j) const {
        internal::prefetch(&operator()(i, j));
      }
      __attribute__((always_inline)) inline Scalar& operator()(Index i, Index j) const {
        return m_data[StorageOrder == RowMajor ? j * m_incr.value() + i * m_stride : i * m_incr.value() + j * m_stride];
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacket(Index i, Index j) const {
        return pgather<Scalar, PacketType>(&operator()(i, j), m_incr.value());
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline PacketType loadPacketPartial(Index i, Index j, Index n, Index = 0) const {
        return pgather_partial<Scalar, PacketType>(&operator()(i, j), m_incr.value(), n);
      }
      template <typename PacketT, int AlignmentT>
      __attribute__((always_inline)) inline PacketT load(Index i, Index j) const {
        return pgather<Scalar, PacketT>(&operator()(i, j), m_incr.value());
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacket(Index i, Index j, const PacketType& p) const {
        pscatter<Scalar, PacketType>(&operator()(i, j), p, m_incr.value());
      }
      template <typename PacketType>
      __attribute__((always_inline)) inline void storePacketPartial(
          Index i, Index j, const PacketType& p, Index n, Index = 0) const {
        pscatter_partial<Scalar, PacketType>(&operator()(i, j), p, m_incr.value(), n);
      }
      template <typename SubPacket>
      __attribute__((always_inline)) inline void scatterPacket(Index i, Index j, const SubPacket& p) const {
        pscatter<Scalar, SubPacket>(&operator()(i, j), p, m_stride);
      }
      template <typename SubPacket>
      __attribute__((always_inline)) inline SubPacket gatherPacket(Index i, Index j) const {
        return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
      }
      template <typename SubPacket, typename Scalar_, int n, int idx>
      struct storePacketBlock_helper {
        storePacketBlock_helper<SubPacket, Scalar_, n, idx - 1> spbh;
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup,
            Index i,
            Index j,
            const PacketBlock<SubPacket, n>& block) const {
          spbh.store(sup, i, j, block);
          for (int l = 0; l < unpacket_traits<SubPacket>::size; l++) {
            Scalar_* v = &sup->operator()(i + l, j + idx);
            *v = block.packet[idx][l];
          }
        }
      };
      template <typename SubPacket, int n, int idx>
      struct storePacketBlock_helper<SubPacket, std::complex<float>, n, idx> {
        storePacketBlock_helper<SubPacket, std::complex<float>, n, idx - 1> spbh;
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup,
            Index i,
            Index j,
            const PacketBlock<SubPacket, n>& block) const {
          spbh.store(sup, i, j, block);
          for (int l = 0; l < unpacket_traits<SubPacket>::size; l++) {
            std::complex<float>* v = &sup->operator()(i + l, j + idx);
            v->real(block.packet[idx].v[2 * l + 0]);
            v->imag(block.packet[idx].v[2 * l + 1]);
          }
        }
      };
      template <typename SubPacket, int n, int idx>
      struct storePacketBlock_helper<SubPacket, std::complex<double>, n, idx> {
        storePacketBlock_helper<SubPacket, std::complex<double>, n, idx - 1> spbh;
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup,
            Index i,
            Index j,
            const PacketBlock<SubPacket, n>& block) const {
          spbh.store(sup, i, j, block);
          for (int l = 0; l < unpacket_traits<SubPacket>::size; l++) {
            std::complex<double>* v = &sup->operator()(i + l, j + idx);
            v->real(block.packet[idx].v[2 * l + 0]);
            v->imag(block.packet[idx].v[2 * l + 1]);
          }
        }
      };
      template <typename SubPacket, typename Scalar_, int n>
      struct storePacketBlock_helper<SubPacket, Scalar_, n, -1> {
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*,
            Index,
            Index,
            const PacketBlock<SubPacket, n>&) const {}
      };
      template <typename SubPacket, int n>
      struct storePacketBlock_helper<SubPacket, std::complex<float>, n, -1> {
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*,
            Index,
            Index,
            const PacketBlock<SubPacket, n>&) const {}
      };
      template <typename SubPacket, int n>
      struct storePacketBlock_helper<SubPacket, std::complex<double>, n, -1> {
        __attribute__((always_inline)) inline void store(
            const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*,
            Index,
            Index,
            const PacketBlock<SubPacket, n>&) const {}
      };
      template <typename SubPacket, int n>
      __attribute__((always_inline)) inline void storePacketBlock(Index i,
                                                                  Index j,
                                                                  const PacketBlock<SubPacket, n>& block) const {
        storePacketBlock_helper<SubPacket, Scalar, n, n - 1> spb;
        spb.store(this, i, j, block);
      }
      const Index stride() const { return m_stride; }
      const Index incr() const { return m_incr.value(); }
      Scalar* data() const { return m_data; }

    protected:
      Scalar* __restrict m_data;
      const Index m_stride;
      const internal::variable_if_dynamic<Index, Incr> m_incr;
    };
    template <typename Scalar, typename Index, int StorageOrder>
    class const_blas_data_mapper : public blas_data_mapper<const Scalar, Index, StorageOrder> {
    public:
      __attribute__((always_inline)) inline const_blas_data_mapper(const Scalar* data, Index stride)
          : blas_data_mapper<const Scalar, Index, StorageOrder>(data, stride) {}
      __attribute__((always_inline)) inline const_blas_data_mapper<Scalar, Index, StorageOrder> getSubMapper(
          Index i, Index j) const {
        return const_blas_data_mapper<Scalar, Index, StorageOrder>(&(this->operator()(i, j)), this->m_stride);
      }
    };
    template <typename XprType>
    struct blas_traits {
      typedef typename traits<XprType>::Scalar Scalar;
      typedef const XprType& ExtractType;
      typedef XprType ExtractType_;
      enum {
        IsComplex = NumTraits<Scalar>::IsComplex,
        IsTransposed = false,
        NeedToConjugate = false,
        HasUsableDirectAccess =
            ((int(XprType::Flags) & DirectAccessBit) &&
             (bool(XprType::IsVectorAtCompileTime) || int(inner_stride_at_compile_time<XprType>::ret) == 1))
                ? 1
                : 0,
        HasScalarFactor = false
      };
      typedef std::conditional_t<bool(HasUsableDirectAccess), ExtractType, typename ExtractType_::PlainObject>
          DirectLinearAccessType;
      static inline ExtractType extract(const XprType& x) { return x; }
      static inline const Scalar extractScalarFactor(const XprType&) { return Scalar(1); }
    };
    template <typename Scalar, typename NestedXpr>
    struct blas_traits<CwiseUnaryOp<scalar_conjugate_op<Scalar>, NestedXpr>> : blas_traits<NestedXpr> {
      typedef blas_traits<NestedXpr> Base;
      typedef CwiseUnaryOp<scalar_conjugate_op<Scalar>, NestedXpr> XprType;
      typedef typename Base::ExtractType ExtractType;
      enum { IsComplex = NumTraits<Scalar>::IsComplex, NeedToConjugate = Base::NeedToConjugate ? 0 : IsComplex };
      static inline ExtractType extract(const XprType& x) { return Base::extract(x.nestedExpression()); }
      static inline Scalar extractScalarFactor(const XprType& x) {
        return conj(Base::extractScalarFactor(x.nestedExpression()));
      }
    };
    template <typename Scalar, typename NestedXpr, typename Plain>
    struct blas_traits<
        CwiseBinaryOp<scalar_product_op<Scalar>, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>, NestedXpr>>
        : blas_traits<NestedXpr> {
      enum { HasScalarFactor = true };
      typedef blas_traits<NestedXpr> Base;
      typedef CwiseBinaryOp<scalar_product_op<Scalar>, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>, NestedXpr>
          XprType;
      typedef typename Base::ExtractType ExtractType;
      static inline ExtractType extract(const XprType& x) { return Base::extract(x.rhs()); }
      static inline Scalar extractScalarFactor(const XprType& x) {
        return x.lhs().functor().m_other * Base::extractScalarFactor(x.rhs());
      }
    };
    template <typename Scalar, typename NestedXpr, typename Plain>
    struct blas_traits<
        CwiseBinaryOp<scalar_product_op<Scalar>, NestedXpr, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>>>
        : blas_traits<NestedXpr> {
      enum { HasScalarFactor = true };
      typedef blas_traits<NestedXpr> Base;
      typedef CwiseBinaryOp<scalar_product_op<Scalar>, NestedXpr, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>>
          XprType;
      typedef typename Base::ExtractType ExtractType;
      static inline ExtractType extract(const XprType& x) { return Base::extract(x.lhs()); }
      static inline Scalar extractScalarFactor(const XprType& x) {
        return Base::extractScalarFactor(x.lhs()) * x.rhs().functor().m_other;
      }
    };
    template <typename Scalar, typename Plain1, typename Plain2>
    struct blas_traits<CwiseBinaryOp<scalar_product_op<Scalar>,
                                     const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain1>,
                                     const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain2>>>
        : blas_traits<CwiseNullaryOp<scalar_constant_op<Scalar>, Plain1>> {};
    template <typename Scalar, typename NestedXpr>
    struct blas_traits<CwiseUnaryOp<scalar_opposite_op<Scalar>, NestedXpr>> : blas_traits<NestedXpr> {
      enum { HasScalarFactor = true };
      typedef blas_traits<NestedXpr> Base;
      typedef CwiseUnaryOp<scalar_opposite_op<Scalar>, NestedXpr> XprType;
      typedef typename Base::ExtractType ExtractType;
      static inline ExtractType extract(const XprType& x) { return Base::extract(x.nestedExpression()); }
      static inline Scalar extractScalarFactor(const XprType& x) {
        return -Base::extractScalarFactor(x.nestedExpression());
      }
    };
    template <typename NestedXpr>
    struct blas_traits<Transpose<NestedXpr>> : blas_traits<NestedXpr> {
      typedef typename NestedXpr::Scalar Scalar;
      typedef blas_traits<NestedXpr> Base;
      typedef Transpose<NestedXpr> XprType;
      typedef Transpose<const typename Base::ExtractType_> ExtractType;
      typedef Transpose<const typename Base::ExtractType_> ExtractType_;
      typedef std::conditional_t<bool(Base::HasUsableDirectAccess), ExtractType, typename ExtractType::PlainObject>
          DirectLinearAccessType;
      enum { IsTransposed = Base::IsTransposed ? 0 : 1 };
      static inline ExtractType extract(const XprType& x) { return ExtractType(Base::extract(x.nestedExpression())); }
      static inline Scalar extractScalarFactor(const XprType& x) {
        return Base::extractScalarFactor(x.nestedExpression());
      }
    };
    template <typename T>
    struct blas_traits<const T> : blas_traits<T> {};
    template <typename T, bool HasUsableDirectAccess = blas_traits<T>::HasUsableDirectAccess>
    struct extract_data_selector {
      __attribute__((always_inline)) inline static const typename T::Scalar* run(const T& m) {
        return blas_traits<T>::extract(m).data();
      }
    };
    template <typename T>
    struct extract_data_selector<T, false> {
      static typename T::Scalar* run(const T&) { return 0; }
    };
    template <typename T>
    __attribute__((always_inline)) inline const typename T::Scalar* extract_data(const T& m) {
      return extract_data_selector<T>::run(m);
    }
    template <typename ResScalar, typename Lhs, typename Rhs>
    struct combine_scalar_factors_impl {
      __attribute__((always_inline)) inline static ResScalar run(const Lhs& lhs, const Rhs& rhs) {
        return blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
      }
      __attribute__((always_inline)) inline static ResScalar run(const ResScalar& alpha,
                                                                 const Lhs& lhs,
                                                                 const Rhs& rhs) {
        return alpha * blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
      }
    };
    template <typename Lhs, typename Rhs>
    struct combine_scalar_factors_impl<bool, Lhs, Rhs> {
      __attribute__((always_inline)) inline static bool run(const Lhs& lhs, const Rhs& rhs) {
        return blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
      }
      __attribute__((always_inline)) inline static bool run(const bool& alpha, const Lhs& lhs, const Rhs& rhs) {
        return alpha && blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
      }
    };
    template <typename ResScalar, typename Lhs, typename Rhs>
    __attribute__((always_inline)) inline ResScalar combine_scalar_factors(const ResScalar& alpha,
                                                                           const Lhs& lhs,
                                                                           const Rhs& rhs) {
      return combine_scalar_factors_impl<ResScalar, Lhs, Rhs>::run(alpha, lhs, rhs);
    }
    template <typename ResScalar, typename Lhs, typename Rhs>
    __attribute__((always_inline)) inline ResScalar combine_scalar_factors(const Lhs& lhs, const Rhs& rhs) {
      return combine_scalar_factors_impl<ResScalar, Lhs, Rhs>::run(lhs, rhs);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    struct constructor_without_unaligned_array_assert {};
    template <typename T, int Size>
    void check_static_allocation_size() {
      static_assert(Size * sizeof(T) <= 131072, "OBJECT_ALLOCATED_ON_STACK_IS_TOO_BIG");
      ;
    }
    template <typename T,
              int Size,
              int MatrixOrArrayOptions,
              int Alignment = (MatrixOrArrayOptions & DontAlign) ? 0 : compute_default_alignment<T, Size>::value>
    struct plain_array {
      T array[Size];
      plain_array() { check_static_allocation_size<T, Size>(); }
      plain_array(constructor_without_unaligned_array_assert) { check_static_allocation_size<T, Size>(); }
    };
    template <typename PtrType>
    __attribute__((always_inline)) inline PtrType eigen_unaligned_array_assert_workaround_gcc47(PtrType array) {
      return array;
    }
    template <typename T, int Size, int MatrixOrArrayOptions>
    struct plain_array<T, Size, MatrixOrArrayOptions, 8> {
      alignas(8) T array[Size];
      plain_array() {
        (static_cast<bool>((internal::is_constant_evaluated() ||
                            (internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (7)) == 0) &&
                           "this assertion is explained here: "
                           "http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html"
                           " **** READ THIS WEB PAGE !!! ****")
             ? void(0)
             : __assert_fail("(internal::is_constant_evaluated() || "
                             "(internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (7)) == 0) && "
                             "\"this assertion is explained here: \" "
                             "\"http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html\" \" **** "
                             "READ THIS WEB PAGE !!! ****\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/DenseStorage.h",
                             93,
                             __extension__ __PRETTY_FUNCTION__));
        ;
        check_static_allocation_size<T, Size>();
      }
      plain_array(constructor_without_unaligned_array_assert) { check_static_allocation_size<T, Size>(); }
    };
    template <typename T, int Size, int MatrixOrArrayOptions>
    struct plain_array<T, Size, MatrixOrArrayOptions, 16> {
      alignas(16) T array[Size];
      plain_array() {
        (static_cast<bool>((internal::is_constant_evaluated() ||
                            (internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (15)) == 0) &&
                           "this assertion is explained here: "
                           "http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html"
                           " **** READ THIS WEB PAGE !!! ****")
             ? void(0)
             : __assert_fail("(internal::is_constant_evaluated() || "
                             "(internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (15)) == 0) "
                             "&& \"this assertion is explained here: \" "
                             "\"http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html\" \" **** "
                             "READ THIS WEB PAGE !!! ****\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/DenseStorage.h",
                             112,
                             __extension__ __PRETTY_FUNCTION__));
        ;
        check_static_allocation_size<T, Size>();
      }
      plain_array(constructor_without_unaligned_array_assert) { check_static_allocation_size<T, Size>(); }
    };
    template <typename T, int Size, int MatrixOrArrayOptions>
    struct plain_array<T, Size, MatrixOrArrayOptions, 32> {
      alignas(32) T array[Size];
      plain_array() {
        (static_cast<bool>((internal::is_constant_evaluated() ||
                            (internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (31)) == 0) &&
                           "this assertion is explained here: "
                           "http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html"
                           " **** READ THIS WEB PAGE !!! ****")
             ? void(0)
             : __assert_fail("(internal::is_constant_evaluated() || "
                             "(internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (31)) == 0) "
                             "&& \"this assertion is explained here: \" "
                             "\"http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html\" \" **** "
                             "READ THIS WEB PAGE !!! ****\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/DenseStorage.h",
                             131,
                             __extension__ __PRETTY_FUNCTION__));
        ;
        check_static_allocation_size<T, Size>();
      }
      plain_array(constructor_without_unaligned_array_assert) { check_static_allocation_size<T, Size>(); }
    };
    template <typename T, int Size, int MatrixOrArrayOptions>
    struct plain_array<T, Size, MatrixOrArrayOptions, 64> {
      alignas(64) T array[Size];
      plain_array() {
        (static_cast<bool>((internal::is_constant_evaluated() ||
                            (internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (63)) == 0) &&
                           "this assertion is explained here: "
                           "http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html"
                           " **** READ THIS WEB PAGE !!! ****")
             ? void(0)
             : __assert_fail("(internal::is_constant_evaluated() || "
                             "(internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (63)) == 0) "
                             "&& \"this assertion is explained here: \" "
                             "\"http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html\" \" **** "
                             "READ THIS WEB PAGE !!! ****\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/DenseStorage.h",
                             150,
                             __extension__ __PRETTY_FUNCTION__));
        ;
        check_static_allocation_size<T, Size>();
      }
      plain_array(constructor_without_unaligned_array_assert) { check_static_allocation_size<T, Size>(); }
    };
    template <typename T, int MatrixOrArrayOptions, int Alignment>
    struct plain_array<T, 0, MatrixOrArrayOptions, Alignment> {
      T array[1];
      plain_array() {}
      plain_array(constructor_without_unaligned_array_assert) {}
    };
    struct plain_array_helper {
      template <typename T, int Size, int MatrixOrArrayOptions, int Alignment>
      inline static void copy(const plain_array<T, Size, MatrixOrArrayOptions, Alignment>& src,
                              const Eigen::Index size,
                              plain_array<T, Size, MatrixOrArrayOptions, Alignment>& dst) {
        smart_copy(src.array, src.array + size, dst.array);
      }
      template <typename T, int Size, int MatrixOrArrayOptions, int Alignment>
      inline static void swap(plain_array<T, Size, MatrixOrArrayOptions, Alignment>& a,
                              const Eigen::Index a_size,
                              plain_array<T, Size, MatrixOrArrayOptions, Alignment>& b,
                              const Eigen::Index b_size) {
        if (a_size < b_size) {
          std::swap_ranges(b.array, b.array + a_size, a.array);
          smart_move(b.array + a_size, b.array + b_size, a.array + a_size);
        } else if (a_size > b_size) {
          std::swap_ranges(a.array, a.array + b_size, b.array);
          smart_move(a.array + b_size, a.array + a_size, b.array + b_size);
        } else {
          std::swap_ranges(a.array, a.array + a_size, b.array);
        }
      }
    };
  }  // namespace internal
  template <typename T, int Size, int Rows_, int Cols_, int Options_>
  class DenseStorage;
  template <typename T, int Size, int Rows_, int Cols_, int Options_>
  class DenseStorage {
    internal::plain_array<T, Size, Options_> m_data;

  public:
    DenseStorage() {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
        : m_data(internal::constructor_without_unaligned_array_assert()) {}
    DenseStorage(const DenseStorage&) = default;
    DenseStorage& operator=(const DenseStorage&) = default;
    DenseStorage(DenseStorage&&) = default;
    DenseStorage& operator=(DenseStorage&&) = default;
    DenseStorage(Index size, Index rows, Index cols) {
      ;
      Eigen::internal::ignore_unused_variable(size);
      ;
      Eigen::internal::ignore_unused_variable(rows);
      ;
      Eigen::internal::ignore_unused_variable(cols);
      ;
    }
    void swap(DenseStorage& other) { numext::swap(m_data, other.m_data); }
    static constexpr Index rows(void) noexcept { return Rows_; }
    static constexpr Index cols(void) noexcept { return Cols_; }
    void conservativeResize(Index, Index, Index) {}
    void resize(Index, Index, Index) {}
    const T* data() const { return m_data.array; }
    T* data() { return m_data.array; }
  };
  template <typename T, int Rows_, int Cols_, int Options_>
  class DenseStorage<T, 0, Rows_, Cols_, Options_> {
  public:
    DenseStorage() {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert) {}
    DenseStorage(const DenseStorage&) {}
    DenseStorage& operator=(const DenseStorage&) { return *this; }
    DenseStorage(Index, Index, Index) {}
    void swap(DenseStorage&) {}
    static constexpr Index rows(void) noexcept { return Rows_; }
    static constexpr Index cols(void) noexcept { return Cols_; }
    void conservativeResize(Index, Index, Index) {}
    void resize(Index, Index, Index) {}
    const T* data() const { return 0; }
    T* data() { return 0; }
  };
  template <typename T, int Options_>
  class DenseStorage<T, 0, Dynamic, Dynamic, Options_> : public DenseStorage<T, 0, 0, 0, Options_> {};
  template <typename T, int Rows_, int Options_>
  class DenseStorage<T, 0, Rows_, Dynamic, Options_> : public DenseStorage<T, 0, 0, 0, Options_> {};
  template <typename T, int Cols_, int Options_>
  class DenseStorage<T, 0, Dynamic, Cols_, Options_> : public DenseStorage<T, 0, 0, 0, Options_> {};
  template <typename T, int Size, int Options_>
  class DenseStorage<T, Size, Dynamic, Dynamic, Options_> {
    internal::plain_array<T, Size, Options_> m_data;
    Index m_rows;
    Index m_cols;

  public:
    DenseStorage() : m_rows(0), m_cols(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0), m_cols(0) {}
    DenseStorage(const DenseStorage& other)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows), m_cols(other.m_cols) {
      internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        m_rows = other.m_rows;
        m_cols = other.m_cols;
        internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
      }
      return *this;
    }
    DenseStorage(Index, Index rows, Index cols) : m_rows(rows), m_cols(cols) {}
    void swap(DenseStorage& other) {
      internal::plain_array_helper::swap(m_data, m_rows * m_cols, other.m_data, other.m_rows * other.m_cols);
      numext::swap(m_rows, other.m_rows);
      numext::swap(m_cols, other.m_cols);
    }
    Index rows() const { return m_rows; }
    Index cols() const { return m_cols; }
    void conservativeResize(Index, Index rows, Index cols) {
      m_rows = rows;
      m_cols = cols;
    }
    void resize(Index, Index rows, Index cols) {
      m_rows = rows;
      m_cols = cols;
    }
    const T* data() const { return m_data.array; }
    T* data() { return m_data.array; }
  };
  template <typename T, int Size, int Cols_, int Options_>
  class DenseStorage<T, Size, Dynamic, Cols_, Options_> {
    internal::plain_array<T, Size, Options_> m_data;
    Index m_rows;

  public:
    DenseStorage() : m_rows(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0) {}
    DenseStorage(const DenseStorage& other)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows) {
      internal::plain_array_helper::copy(other.m_data, m_rows * Cols_, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        m_rows = other.m_rows;
        internal::plain_array_helper::copy(other.m_data, m_rows * Cols_, m_data);
      }
      return *this;
    }
    DenseStorage(Index, Index rows, Index) : m_rows(rows) {}
    void swap(DenseStorage& other) {
      internal::plain_array_helper::swap(m_data, m_rows * Cols_, other.m_data, other.m_rows * Cols_);
      numext::swap(m_rows, other.m_rows);
    }
    Index rows(void) const noexcept { return m_rows; }
    constexpr Index cols(void) const noexcept { return Cols_; }
    void conservativeResize(Index, Index rows, Index) { m_rows = rows; }
    void resize(Index, Index rows, Index) { m_rows = rows; }
    const T* data() const { return m_data.array; }
    T* data() { return m_data.array; }
  };
  template <typename T, int Size, int Rows_, int Options_>
  class DenseStorage<T, Size, Rows_, Dynamic, Options_> {
    internal::plain_array<T, Size, Options_> m_data;
    Index m_cols;

  public:
    DenseStorage() : m_cols(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(0) {}
    DenseStorage(const DenseStorage& other)
        : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(other.m_cols) {
      internal::plain_array_helper::copy(other.m_data, Rows_ * m_cols, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        m_cols = other.m_cols;
        internal::plain_array_helper::copy(other.m_data, Rows_ * m_cols, m_data);
      }
      return *this;
    }
    DenseStorage(Index, Index, Index cols) : m_cols(cols) {}
    void swap(DenseStorage& other) {
      internal::plain_array_helper::swap(m_data, Rows_ * m_cols, other.m_data, Rows_ * other.m_cols);
      numext::swap(m_cols, other.m_cols);
    }
    constexpr Index rows(void) const noexcept { return Rows_; }
    Index cols(void) const noexcept { return m_cols; }
    void conservativeResize(Index, Index, Index cols) { m_cols = cols; }
    void resize(Index, Index, Index cols) { m_cols = cols; }
    const T* data() const { return m_data.array; }
    T* data() { return m_data.array; }
  };
  template <typename T, int Options_>
  class DenseStorage<T, Dynamic, Dynamic, Dynamic, Options_> {
    T* m_data;
    Index m_rows;
    Index m_cols;

  public:
    DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert) : m_data(0), m_rows(0), m_cols(0) {}
    DenseStorage(Index size, Index rows, Index cols)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size)),
          m_rows(rows),
          m_cols(cols) {
      ;
    }
    DenseStorage(const DenseStorage& other)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(other.m_rows * other.m_cols)),
          m_rows(other.m_rows),
          m_cols(other.m_cols) {
      internal::smart_copy(other.m_data, other.m_data + other.m_rows * other.m_cols, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        DenseStorage tmp(other);
        this->swap(tmp);
      }
      return *this;
    }
    DenseStorage(DenseStorage&& other) noexcept
        : m_data(std::move(other.m_data)), m_rows(std::move(other.m_rows)), m_cols(std::move(other.m_cols)) {
      other.m_data = nullptr;
      other.m_rows = 0;
      other.m_cols = 0;
    }
    DenseStorage& operator=(DenseStorage&& other) noexcept {
      numext::swap(m_data, other.m_data);
      numext::swap(m_rows, other.m_rows);
      numext::swap(m_cols, other.m_cols);
      return *this;
    }
    ~DenseStorage() {
      internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, m_rows * m_cols);
    }
    void swap(DenseStorage& other) {
      numext::swap(m_data, other.m_data);
      numext::swap(m_rows, other.m_rows);
      numext::swap(m_cols, other.m_cols);
    }
    Index rows(void) const noexcept { return m_rows; }
    Index cols(void) const noexcept { return m_cols; }
    void conservativeResize(Index size, Index rows, Index cols) {
      m_data =
          internal::conditional_aligned_realloc_new_auto<T, (Options_ & DontAlign) == 0>(m_data, size, m_rows * m_cols);
      m_rows = rows;
      m_cols = cols;
    }
    void resize(Index size, Index rows, Index cols) {
      if (size != m_rows * m_cols) {
        internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, m_rows * m_cols);
        if (size > 0)
          m_data = internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size);
        else
          m_data = 0;
      }
      m_rows = rows;
      m_cols = cols;
    }
    const T* data() const { return m_data; }
    T* data() { return m_data; }
  };
  template <typename T, int Rows_, int Options_>
  class DenseStorage<T, Dynamic, Rows_, Dynamic, Options_> {
    T* m_data;
    Index m_cols;

  public:
    DenseStorage() : m_data(0), m_cols(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert) : m_data(0), m_cols(0) {}
    DenseStorage(Index size, Index rows, Index cols)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size)), m_cols(cols) {
      ;
      Eigen::internal::ignore_unused_variable(rows);
      ;
    }
    DenseStorage(const DenseStorage& other)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(Rows_ * other.m_cols)),
          m_cols(other.m_cols) {
      internal::smart_copy(other.m_data, other.m_data + Rows_ * m_cols, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        DenseStorage tmp(other);
        this->swap(tmp);
      }
      return *this;
    }
    DenseStorage(DenseStorage&& other) noexcept : m_data(std::move(other.m_data)), m_cols(std::move(other.m_cols)) {
      other.m_data = nullptr;
      other.m_cols = 0;
    }
    DenseStorage& operator=(DenseStorage&& other) noexcept {
      numext::swap(m_data, other.m_data);
      numext::swap(m_cols, other.m_cols);
      return *this;
    }
    ~DenseStorage() {
      internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, Rows_ * m_cols);
    }
    void swap(DenseStorage& other) {
      numext::swap(m_data, other.m_data);
      numext::swap(m_cols, other.m_cols);
    }
    static constexpr Index rows(void) noexcept { return Rows_; }
    Index cols(void) const noexcept { return m_cols; }
    void conservativeResize(Index size, Index, Index cols) {
      m_data =
          internal::conditional_aligned_realloc_new_auto<T, (Options_ & DontAlign) == 0>(m_data, size, Rows_ * m_cols);
      m_cols = cols;
    }
    inline void resize(Index size, Index, Index cols) {
      if (size != Rows_ * m_cols) {
        internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, Rows_ * m_cols);
        if (size > 0)
          m_data = internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size);
        else
          m_data = 0;
      }
      m_cols = cols;
    }
    const T* data() const { return m_data; }
    T* data() { return m_data; }
  };
  template <typename T, int Cols_, int Options_>
  class DenseStorage<T, Dynamic, Dynamic, Cols_, Options_> {
    T* m_data;
    Index m_rows;

  public:
    DenseStorage() : m_data(0), m_rows(0) {}
    explicit DenseStorage(internal::constructor_without_unaligned_array_assert) : m_data(0), m_rows(0) {}
    DenseStorage(Index size, Index rows, Index cols)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size)), m_rows(rows) {
      ;
      Eigen::internal::ignore_unused_variable(cols);
      ;
    }
    DenseStorage(const DenseStorage& other)
        : m_data(internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(other.m_rows * Cols_)),
          m_rows(other.m_rows) {
      internal::smart_copy(other.m_data, other.m_data + other.m_rows * Cols_, m_data);
    }
    DenseStorage& operator=(const DenseStorage& other) {
      if (this != &other) {
        DenseStorage tmp(other);
        this->swap(tmp);
      }
      return *this;
    }
    DenseStorage(DenseStorage&& other) noexcept : m_data(std::move(other.m_data)), m_rows(std::move(other.m_rows)) {
      other.m_data = nullptr;
      other.m_rows = 0;
    }
    DenseStorage& operator=(DenseStorage&& other) noexcept {
      numext::swap(m_data, other.m_data);
      numext::swap(m_rows, other.m_rows);
      return *this;
    }
    ~DenseStorage() {
      internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, Cols_ * m_rows);
    }
    void swap(DenseStorage& other) {
      numext::swap(m_data, other.m_data);
      numext::swap(m_rows, other.m_rows);
    }
    Index rows(void) const noexcept { return m_rows; }
    static constexpr Index cols(void) { return Cols_; }
    void conservativeResize(Index size, Index rows, Index) {
      m_data =
          internal::conditional_aligned_realloc_new_auto<T, (Options_ & DontAlign) == 0>(m_data, size, m_rows * Cols_);
      m_rows = rows;
    }
    inline void resize(Index size, Index rows, Index) {
      if (size != m_rows * Cols_) {
        internal::conditional_aligned_delete_auto<T, (Options_ & DontAlign) == 0>(m_data, Cols_ * m_rows);
        if (size > 0)
          m_data = internal::conditional_aligned_new_auto<T, (Options_ & DontAlign) == 0>(size);
        else
          m_data = 0;
      }
      m_rows = rows;
    }
    const T* data() const { return m_data; }
    T* data() { return m_data; }
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename ExpressionType>
    struct traits<NestByValue<ExpressionType>> : public traits<ExpressionType> {
      enum { Flags = traits<ExpressionType>::Flags & ~NestByRefBit };
    };
  }  // namespace internal
  template <typename ExpressionType>
  class NestByValue : public internal::dense_xpr_base<NestByValue<ExpressionType>>::type {
  public:
    typedef typename internal::dense_xpr_base<NestByValue>::type Base;
    typedef typename Eigen::internal::traits<NestByValue>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<NestByValue>::type Nested;
    typedef typename Eigen::internal::traits<NestByValue>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<NestByValue>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<NestByValue>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<NestByValue>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<NestByValue>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    explicit inline NestByValue(const ExpressionType& matrix) : m_expression(matrix) {}
    constexpr inline Index rows() const noexcept { return m_expression.rows(); }
    constexpr inline Index cols() const noexcept { return m_expression.cols(); }
    operator const ExpressionType&() const { return m_expression; }
    const ExpressionType& nestedExpression() const { return m_expression; }

  protected:
    const ExpressionType m_expression;
  };
  template <typename Derived>
  inline const NestByValue<Derived> DenseBase<Derived>::nestByValue() const {
    return NestByValue<Derived>(derived());
  }
  namespace internal {
    template <typename ArgType>
    struct evaluator<NestByValue<ArgType>> : public evaluator<ArgType> {
      typedef evaluator<ArgType> Base;
      explicit evaluator(const NestByValue<ArgType>& xpr) : Base(xpr.nestedExpression()) {}
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived>
    struct traits<ReturnByValue<Derived>> : public traits<typename traits<Derived>::ReturnType> {
      enum { Flags = (traits<typename traits<Derived>::ReturnType>::Flags | EvalBeforeNestingBit) & ~DirectAccessBit };
    };
    template <typename Derived, int n, typename PlainObject>
    struct nested_eval<ReturnByValue<Derived>, n, PlainObject> {
      typedef typename traits<Derived>::ReturnType type;
    };
  }  // namespace internal
  template <typename Derived>
  class ReturnByValue : public internal::dense_xpr_base<ReturnByValue<Derived>>::type,
                        internal::no_assignment_operator {
  public:
    typedef typename internal::traits<Derived>::ReturnType ReturnType;
    typedef typename internal::dense_xpr_base<ReturnByValue>::type Base;
    typedef typename Eigen::internal::traits<ReturnByValue>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<ReturnByValue>::type Nested;
    typedef typename Eigen::internal::traits<ReturnByValue>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<ReturnByValue>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<ReturnByValue>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<ReturnByValue>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<ReturnByValue>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    template <typename Dest>
    inline void evalTo(Dest& dst) const {
      static_cast<const Derived*>(this)->evalTo(dst);
    }
    constexpr inline Index rows() const noexcept { return static_cast<const Derived*>(this)->rows(); }
    constexpr inline Index cols() const noexcept { return static_cast<const Derived*>(this)->cols(); }
    class YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT {
      YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT(
          const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&) {
      }
      YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&
      operator=(
          const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&) {
        return *this;
      }
    };
    const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&
    coeff(Index) const {
      return *reinterpret_cast<
          const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT*>(
          this);
    }
    const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&
    coeff(Index, Index) const {
      return *reinterpret_cast<
          const YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT*>(
          this);
    }
    YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&
    coeffRef(Index) {
      return *reinterpret_cast<
          YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT*>(
          this);
    }
    YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT&
    coeffRef(Index, Index) {
      return *reinterpret_cast<
          YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT*>(
          this);
    }
  };
  template <typename Derived>
  template <typename OtherDerived>
  Derived& DenseBase<Derived>::operator=(const ReturnByValue<OtherDerived>& other) {
    other.evalTo(derived());
    return derived();
  }
  namespace internal {
    template <typename Derived>
    struct evaluator<ReturnByValue<Derived>> : public evaluator<typename internal::traits<Derived>::ReturnType> {
      typedef ReturnByValue<Derived> XprType;
      typedef typename internal::traits<Derived>::ReturnType PlainObject;
      typedef evaluator<PlainObject> Base;
      explicit evaluator(const XprType& xpr) : m_result(xpr.rows(), xpr.cols()) {
        internal::construct_at<Base>(this, m_result);
        xpr.evalTo(m_result);
      }

    protected:
      PlainObject m_result;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename ExpressionType, template <typename> class StorageBase>
  class NoAlias {
  public:
    typedef typename ExpressionType::Scalar Scalar;
    explicit NoAlias(ExpressionType& expression) : m_expression(expression) {}
    template <typename OtherDerived>
    inline ExpressionType& operator=(const StorageBase<OtherDerived>& other) {
      call_assignment_no_alias(
          m_expression, other.derived(), internal::assign_op<Scalar, typename OtherDerived::Scalar>());
      return m_expression;
    }
    template <typename OtherDerived>
    inline ExpressionType& operator+=(const StorageBase<OtherDerived>& other) {
      call_assignment_no_alias(
          m_expression, other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
      return m_expression;
    }
    template <typename OtherDerived>
    inline ExpressionType& operator-=(const StorageBase<OtherDerived>& other) {
      call_assignment_no_alias(
          m_expression, other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
      return m_expression;
    }
    ExpressionType& expression() const { return m_expression; }

  protected:
    ExpressionType& m_expression;
  };
  template <typename Derived>
  NoAlias<Derived, MatrixBase> MatrixBase<Derived>::noalias() {
    return NoAlias<Derived, Eigen::MatrixBase>(derived());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <int MaxSizeAtCompileTime>
    struct check_rows_cols_for_overflow {
      template <typename Index>
      static __attribute__((always_inline)) inline void run(Index, Index) {}
    };
    template <>
    struct check_rows_cols_for_overflow<Dynamic> {
      template <typename Index>
      static __attribute__((always_inline)) inline void run(Index rows, Index cols) {
        Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1;
        bool error = (rows == 0 || cols == 0) ? false : (rows > max_index / cols);
        if (error)
          throw_std_bad_alloc();
      }
    };
    template <typename Derived,
              typename OtherDerived = Derived,
              bool IsVector = bool(Derived::IsVectorAtCompileTime) && bool(OtherDerived::IsVectorAtCompileTime)>
    struct conservative_resize_like_impl;
    template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
    struct matrix_swap_impl;
  }  // namespace internal
  template <typename Derived>
  class PlainObjectBase : public internal::dense_xpr_base<Derived>::type {
  public:
    enum { Options = internal::traits<Derived>::Options };
    typedef typename internal::dense_xpr_base<Derived>::type Base;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Derived DenseType;
    using Base::ColsAtCompileTime;
    using Base::Flags;
    using Base::IsVectorAtCompileTime;
    using Base::MaxColsAtCompileTime;
    using Base::MaxRowsAtCompileTime;
    using Base::MaxSizeAtCompileTime;
    using Base::RowsAtCompileTime;
    using Base::SizeAtCompileTime;
    typedef Eigen::Map<Derived, Unaligned> MapType;
    typedef const Eigen::Map<const Derived, Unaligned> ConstMapType;
    typedef Eigen::Map<Derived, AlignedMax> AlignedMapType;
    typedef const Eigen::Map<const Derived, AlignedMax> ConstAlignedMapType;
    template <typename StrideType>
    struct StridedMapType {
      typedef Eigen::Map<Derived, Unaligned, StrideType> type;
    };
    template <typename StrideType>
    struct StridedConstMapType {
      typedef Eigen::Map<const Derived, Unaligned, StrideType> type;
    };
    template <typename StrideType>
    struct StridedAlignedMapType {
      typedef Eigen::Map<Derived, AlignedMax, StrideType> type;
    };
    template <typename StrideType>
    struct StridedConstAlignedMapType {
      typedef Eigen::Map<const Derived, AlignedMax, StrideType> type;
    };

  protected:
    DenseStorage<Scalar, Base::MaxSizeAtCompileTime, Base::RowsAtCompileTime, Base::ColsAtCompileTime, Options>
        m_storage;

  public:
    enum { NeedsToAlign = (SizeAtCompileTime != Dynamic) && (internal::traits<Derived>::Alignment > 0) };
    static_assert(internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1,
                                              (int(Options) & RowMajor) == RowMajor),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert(internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1,
                                              (int(Options) & RowMajor) == 0),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime >= 0), "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime >= 0), "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime >= 0),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime >= 0),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime == Dynamic),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert((MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime == Dynamic),
                  "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    static_assert(((Options & (DontAlign | RowMajor)) == Options), "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    Base& base() { return *static_cast<Base*>(this); }
    const Base& base() const { return *static_cast<const Base*>(this); }
    inline constexpr Index rows() const noexcept { return m_storage.rows(); }
    inline constexpr Index cols() const noexcept { return m_storage.cols(); }
    inline const Scalar& coeff(Index rowId, Index colId) const {
      if (Flags & RowMajorBit)
        return m_storage.data()[colId + rowId * m_storage.cols()];
      else
        return m_storage.data()[rowId + colId * m_storage.rows()];
    }
    inline const Scalar& coeff(Index index) const { return m_storage.data()[index]; }
    inline Scalar& coeffRef(Index rowId, Index colId) {
      if (Flags & RowMajorBit)
        return m_storage.data()[colId + rowId * m_storage.cols()];
      else
        return m_storage.data()[rowId + colId * m_storage.rows()];
    }
    inline Scalar& coeffRef(Index index) { return m_storage.data()[index]; }
    inline const Scalar& coeffRef(Index rowId, Index colId) const {
      if (Flags & RowMajorBit)
        return m_storage.data()[colId + rowId * m_storage.cols()];
      else
        return m_storage.data()[rowId + colId * m_storage.rows()];
    }
    inline const Scalar& coeffRef(Index index) const { return m_storage.data()[index]; }
    template <int LoadMode>
    inline PacketScalar packet(Index rowId, Index colId) const {
      return internal::ploadt<PacketScalar, LoadMode>(m_storage.data() + (Flags & RowMajorBit
                                                                              ? colId + rowId * m_storage.cols()
                                                                              : rowId + colId * m_storage.rows()));
    }
    template <int LoadMode>
    inline PacketScalar packet(Index index) const {
      return internal::ploadt<PacketScalar, LoadMode>(m_storage.data() + index);
    }
    template <int StoreMode>
    inline void writePacket(Index rowId, Index colId, const PacketScalar& val) {
      internal::pstoret<Scalar, PacketScalar, StoreMode>(
          m_storage.data() +
              (Flags & RowMajorBit ? colId + rowId * m_storage.cols() : rowId + colId * m_storage.rows()),
          val);
    }
    template <int StoreMode>
    inline void writePacket(Index index, const PacketScalar& val) {
      internal::pstoret<Scalar, PacketScalar, StoreMode>(m_storage.data() + index, val);
    }
    inline const Scalar* data() const { return m_storage.data(); }
    inline Scalar* data() { return m_storage.data(); }
    inline void resize(Index rows, Index cols) {
      (static_cast<bool>(internal::check_implication(RowsAtCompileTime != Dynamic, rows == RowsAtCompileTime) &&
                         internal::check_implication(ColsAtCompileTime != Dynamic, cols == ColsAtCompileTime) &&
                         internal::check_implication(RowsAtCompileTime == Dynamic && MaxRowsAtCompileTime != Dynamic,
                                                     rows <= MaxRowsAtCompileTime) &&
                         internal::check_implication(ColsAtCompileTime == Dynamic && MaxColsAtCompileTime != Dynamic,
                                                     cols <= MaxColsAtCompileTime) &&
                         rows >= 0 && cols >= 0 && "Invalid sizes when resizing a matrix or array.")
           ? void(0)
           : __assert_fail("internal::check_implication(RowsAtCompileTime!=Dynamic, rows==RowsAtCompileTime) && "
                           "internal::check_implication(ColsAtCompileTime!=Dynamic, cols==ColsAtCompileTime) && "
                           "internal::check_implication(RowsAtCompileTime==Dynamic && MaxRowsAtCompileTime!=Dynamic, "
                           "rows<=MaxRowsAtCompileTime) && internal::check_implication(ColsAtCompileTime==Dynamic && "
                           "MaxColsAtCompileTime!=Dynamic, cols<=MaxColsAtCompileTime) && rows>=0 && cols>=0 && "
                           "\"Invalid sizes when resizing a matrix or array.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/PlainObjectBase.h",
                           289,
                           __extension__ __PRETTY_FUNCTION__));
      internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(rows, cols);
      m_storage.resize(rows * cols, rows, cols);
    }
    inline void resize(Index size) {
      static_assert(PlainObjectBase::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      (static_cast<bool>(
           ((SizeAtCompileTime == Dynamic && (MaxSizeAtCompileTime == Dynamic || size <= MaxSizeAtCompileTime)) ||
            SizeAtCompileTime == size) &&
           size >= 0)
           ? void(0)
           : __assert_fail("((SizeAtCompileTime == Dynamic && (MaxSizeAtCompileTime==Dynamic || "
                           "size<=MaxSizeAtCompileTime)) || SizeAtCompileTime == size) && size>=0",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/PlainObjectBase.h",
                           316,
                           __extension__ __PRETTY_FUNCTION__));
      if (RowsAtCompileTime == 1)
        m_storage.resize(size, 1, size);
      else
        m_storage.resize(size, size, 1);
    }
    inline void resize(NoChange_t, Index cols) { resize(rows(), cols); }
    inline void resize(Index rows, NoChange_t) { resize(rows, cols()); }
    template <typename OtherDerived>
    inline void resizeLike(const EigenBase<OtherDerived>& _other) {
      const OtherDerived& other = _other.derived();
      internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(other.rows(), other.cols());
      const Index othersize = other.rows() * other.cols();
      if (RowsAtCompileTime == 1) {
        (static_cast<bool>(other.rows() == 1 || other.cols() == 1)
             ? void(0)
             : __assert_fail("other.rows() == 1 || other.cols() == 1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/PlainObjectBase.h",
                             373,
                             __extension__ __PRETTY_FUNCTION__));
        resize(1, othersize);
      } else if (ColsAtCompileTime == 1) {
        (static_cast<bool>(other.rows() == 1 || other.cols() == 1)
             ? void(0)
             : __assert_fail("other.rows() == 1 || other.cols() == 1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/PlainObjectBase.h",
                             378,
                             __extension__ __PRETTY_FUNCTION__));
        resize(othersize, 1);
      } else
        resize(other.rows(), other.cols());
    }
    inline void conservativeResize(Index rows, Index cols) {
      internal::conservative_resize_like_impl<Derived>::run(*this, rows, cols);
    }
    inline void conservativeResize(Index rows, NoChange_t) { conservativeResize(rows, cols()); }
    inline void conservativeResize(NoChange_t, Index cols) { conservativeResize(rows(), cols); }
    inline void conservativeResize(Index size) { internal::conservative_resize_like_impl<Derived>::run(*this, size); }
    template <typename OtherDerived>
    inline void conservativeResizeLike(const DenseBase<OtherDerived>& other) {
      internal::conservative_resize_like_impl<Derived, OtherDerived>::run(*this, other);
    }
    inline Derived& operator=(const PlainObjectBase& other) { return _set(other); }
    template <typename OtherDerived>
    inline Derived& lazyAssign(const DenseBase<OtherDerived>& other) {
      _resize_to_match(other);
      return Base::lazyAssign(other.derived());
    }
    template <typename OtherDerived>
    inline Derived& operator=(const ReturnByValue<OtherDerived>& func) {
      resize(func.rows(), func.cols());
      return Base::operator=(func);
    }

  protected:
    inline PlainObjectBase() : m_storage() {}
    explicit PlainObjectBase(internal::constructor_without_unaligned_array_assert)
        : m_storage(internal::constructor_without_unaligned_array_assert()) {}
    PlainObjectBase(PlainObjectBase&& other) noexcept : m_storage(std::move(other.m_storage)) {}
    PlainObjectBase& operator=(PlainObjectBase&& other) noexcept {
      m_storage = std::move(other.m_storage);
      return *this;
    }
    inline PlainObjectBase(const PlainObjectBase& other) : Base(), m_storage(other.m_storage) {}
    inline PlainObjectBase(Index size, Index rows, Index cols) : m_storage(size, rows, cols) {}
    template <typename... ArgTypes>
    inline PlainObjectBase(
        const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
        : m_storage() {
      static_assert(PlainObjectBase::IsVectorAtCompileTime && PlainObjectBase::SizeAtCompileTime == sizeof...(args) + 4,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      ;
      m_storage.data()[0] = a0;
      m_storage.data()[1] = a1;
      m_storage.data()[2] = a2;
      m_storage.data()[3] = a3;
      Index i = 4;
      auto x = {(m_storage.data()[i++] = args, 0)...};
      static_cast<void>(x);
    }
    explicit inline PlainObjectBase(const std::initializer_list<std::initializer_list<Scalar>>& list) : m_storage() {
      size_t list_size = 0;
      if (list.begin() != list.end()) {
        list_size = list.begin()->size();
      }
      if (ColsAtCompileTime == 1 && list.size() == 1) {
        (static_cast<bool>(list_size == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic)
             ? void(0)
             : __assert_fail("list_size == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/PlainObjectBase.h",
                             566,
                             __extension__ __PRETTY_FUNCTION__));
        resize(list_size, ColsAtCompileTime);
        std::copy(list.begin()->begin(), list.begin()->end(), m_storage.data());
      } else {
        (static_cast<bool>(list.size() == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic)
             ? void(0)
             : __assert_fail("list.size() == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/PlainObjectBase.h",
                             570,
                             __extension__ __PRETTY_FUNCTION__));
        (static_cast<bool>(list_size == static_cast<size_t>(ColsAtCompileTime) || ColsAtCompileTime == Dynamic)
             ? void(0)
             : __assert_fail("list_size == static_cast<size_t>(ColsAtCompileTime) || ColsAtCompileTime == Dynamic",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/PlainObjectBase.h",
                             571,
                             __extension__ __PRETTY_FUNCTION__));
        resize(list.size(), list_size);
        Index row_index = 0;
        for (const std::initializer_list<Scalar>& row : list) {
          (static_cast<bool>(list_size == row.size())
               ? void(0)
               : __assert_fail("list_size == row.size()",
                               "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                               "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/"
                               "eigen3/Eigen/src/Core/PlainObjectBase.h",
                               576,
                               __extension__ __PRETTY_FUNCTION__));
          Index col_index = 0;
          for (const Scalar& e : row) {
            coeffRef(row_index, col_index) = e;
            ++col_index;
          }
          ++row_index;
        }
      }
    }
    template <typename OtherDerived>
    inline PlainObjectBase(const DenseBase<OtherDerived>& other) : m_storage() {
      resizeLike(other);
      _set_noalias(other);
    }
    template <typename OtherDerived>
    inline PlainObjectBase(const EigenBase<OtherDerived>& other) : m_storage() {
      resizeLike(other);
      *this = other.derived();
    }
    template <typename OtherDerived>
    inline PlainObjectBase(const ReturnByValue<OtherDerived>& other) {
      resize(other.rows(), other.cols());
      other.evalTo(this->derived());
    }

  public:
    template <typename OtherDerived>
    inline Derived& operator=(const EigenBase<OtherDerived>& other) {
      _resize_to_match(other);
      Base::operator=(other.derived());
      return this->derived();
    }
    static inline ConstMapType Map(const Scalar* data) { return ConstMapType(data); }
    static inline MapType Map(Scalar* data) { return MapType(data); }
    static inline ConstMapType Map(const Scalar* data, Index size) { return ConstMapType(data, size); }
    static inline MapType Map(Scalar* data, Index size) { return MapType(data, size); }
    static inline ConstMapType Map(const Scalar* data, Index rows, Index cols) {
      return ConstMapType(data, rows, cols);
    }
    static inline MapType Map(Scalar* data, Index rows, Index cols) { return MapType(data, rows, cols); }
    static inline ConstAlignedMapType MapAligned(const Scalar* data) { return ConstAlignedMapType(data); }
    static inline AlignedMapType MapAligned(Scalar* data) { return AlignedMapType(data); }
    static inline ConstAlignedMapType MapAligned(const Scalar* data, Index size) {
      return ConstAlignedMapType(data, size);
    }
    static inline AlignedMapType MapAligned(Scalar* data, Index size) { return AlignedMapType(data, size); }
    static inline ConstAlignedMapType MapAligned(const Scalar* data, Index rows, Index cols) {
      return ConstAlignedMapType(data, rows, cols);
    }
    static inline AlignedMapType MapAligned(Scalar* data, Index rows, Index cols) {
      return AlignedMapType(data, rows, cols);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data,
                                                                               const Stride<Outer, Inner>& stride) {
      return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data,
                                                                          const Stride<Outer, Inner>& stride) {
      return typename StridedMapType<Stride<Outer, Inner>>::type(data, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data,
                                                                               Index size,
                                                                               const Stride<Outer, Inner>& stride) {
      return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, size, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data,
                                                                          Index size,
                                                                          const Stride<Outer, Inner>& stride) {
      return typename StridedMapType<Stride<Outer, Inner>>::type(data, size, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data,
                                                                               Index rows,
                                                                               Index cols,
                                                                               const Stride<Outer, Inner>& stride) {
      return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data,
                                                                          Index rows,
                                                                          Index cols,
                                                                          const Stride<Outer, Inner>& stride) {
      return typename StridedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        const Scalar* data, const Stride<Outer, Inner>& stride) {
      return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        Scalar* data, const Stride<Outer, Inner>& stride) {
      return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        const Scalar* data, Index size, const Stride<Outer, Inner>& stride) {
      return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, size, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        Scalar* data, Index size, const Stride<Outer, Inner>& stride) {
      return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, size, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        const Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride) {
      return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
    }
    template <int Outer, int Inner>
    static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
        Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride) {
      return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
    }
    using Base::setConstant;
    Derived& setConstant(Index size, const Scalar& val);
    Derived& setConstant(Index rows, Index cols, const Scalar& val);
    Derived& setConstant(NoChange_t, Index cols, const Scalar& val);
    Derived& setConstant(Index rows, NoChange_t, const Scalar& val);
    using Base::setZero;
    Derived& setZero(Index size);
    Derived& setZero(Index rows, Index cols);
    Derived& setZero(NoChange_t, Index cols);
    Derived& setZero(Index rows, NoChange_t);
    using Base::setOnes;
    Derived& setOnes(Index size);
    Derived& setOnes(Index rows, Index cols);
    Derived& setOnes(NoChange_t, Index cols);
    Derived& setOnes(Index rows, NoChange_t);
    using Base::setRandom;
    Derived& setRandom(Index size);
    Derived& setRandom(Index rows, Index cols);
    Derived& setRandom(NoChange_t, Index cols);
    Derived& setRandom(Index rows, NoChange_t);

  protected:
    template <typename OtherDerived>
    inline void _resize_to_match(const EigenBase<OtherDerived>& other) {
      resizeLike(other);
    }
    template <typename OtherDerived>
    inline Derived& _set(const DenseBase<OtherDerived>& other) {
      internal::call_assignment(this->derived(), other.derived());
      return this->derived();
    }
    template <typename OtherDerived>
    inline Derived& _set_noalias(const DenseBase<OtherDerived>& other) {
      internal::call_assignment_no_alias(
          this->derived(), other.derived(), internal::assign_op<Scalar, typename OtherDerived::Scalar>());
      return this->derived();
    }
    template <typename T0, typename T1>
    inline void _init2(Index rows, Index cols, std::enable_if_t<Base::SizeAtCompileTime != 2, T0>* = 0) {
      const bool t0_is_integer_alike = internal::is_valid_index_type<T0>::value;
      const bool t1_is_integer_alike = internal::is_valid_index_type<T1>::value;
      static_assert(t0_is_integer_alike && t1_is_integer_alike, "FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED");
      resize(rows, cols);
    }
    template <typename T0, typename T1>
    inline void _init2(const T0& val0, const T1& val1, std::enable_if_t<Base::SizeAtCompileTime == 2, T0>* = 0) {
      static_assert(PlainObjectBase::IsVectorAtCompileTime && PlainObjectBase::SizeAtCompileTime == 2,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = Scalar(val0);
      m_storage.data()[1] = Scalar(val1);
    }
    template <typename T0, typename T1>
    inline void _init2(
        const Index& val0,
        const Index& val1,
        std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<T0, Index>::value) &&
                             (internal::is_same<T1, Index>::value) && Base::SizeAtCompileTime == 2,
                         T1>* = 0) {
      static_assert(PlainObjectBase::IsVectorAtCompileTime && PlainObjectBase::SizeAtCompileTime == 2,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = Scalar(val0);
      m_storage.data()[1] = Scalar(val1);
    }
    template <typename T>
    inline void _init1(
        Index size,
        std::enable_if_t<(Base::SizeAtCompileTime != 1 || !internal::is_convertible<T, Scalar>::value) &&
                             ((!internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value ||
                               Base::SizeAtCompileTime == Dynamic)),
                         T>* = 0) {
      const bool is_integer_alike = internal::is_valid_index_type<T>::value;
      Eigen::internal::ignore_unused_variable(is_integer_alike);
      ;
      static_assert(is_integer_alike, "FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED");
      resize(size);
    }
    template <typename T>
    inline void _init1(
        const Scalar& val0,
        std::enable_if_t<Base::SizeAtCompileTime == 1 && internal::is_convertible<T, Scalar>::value, T>* = 0) {
      static_assert(PlainObjectBase::IsVectorAtCompileTime && PlainObjectBase::SizeAtCompileTime == 1,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = val0;
    }
    template <typename T>
    inline void _init1(
        const Index& val0,
        std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<Index, T>::value) &&
                             Base::SizeAtCompileTime == 1 && internal::is_convertible<T, Scalar>::value,
                         T*>* = 0) {
      static_assert(PlainObjectBase::IsVectorAtCompileTime && PlainObjectBase::SizeAtCompileTime == 1,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = Scalar(val0);
    }
    template <typename T>
    inline void _init1(const Scalar* data) {
      this->_set_noalias(ConstMapType(data));
    }
    template <typename T, typename OtherDerived>
    inline void _init1(const DenseBase<OtherDerived>& other) {
      this->_set_noalias(other);
    }
    template <typename T>
    inline void _init1(const Derived& other) {
      this->_set_noalias(other);
    }
    template <typename T, typename OtherDerived>
    inline void _init1(const EigenBase<OtherDerived>& other) {
      this->derived() = other;
    }
    template <typename T, typename OtherDerived>
    inline void _init1(const ReturnByValue<OtherDerived>& other) {
      resize(other.rows(), other.cols());
      other.evalTo(this->derived());
    }
    template <typename T, typename OtherDerived, int ColsAtCompileTime>
    inline void _init1(const RotationBase<OtherDerived, ColsAtCompileTime>& r) {
      this->derived() = r;
    }
    template <typename T>
    inline void _init1(
        const Scalar& val0,
        std::enable_if_t<Base::SizeAtCompileTime != Dynamic && Base::SizeAtCompileTime != 1 &&
                             internal::is_convertible<T, Scalar>::value &&
                             internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value,
                         T>* = 0) {
      Base::setConstant(val0);
    }
    template <typename T>
    inline void _init1(
        const Index& val0,
        std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<Index, T>::value) &&
                             Base::SizeAtCompileTime != Dynamic && Base::SizeAtCompileTime != 1 &&
                             internal::is_convertible<T, Scalar>::value &&
                             internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value,
                         T*>* = 0) {
      Base::setConstant(val0);
    }
    template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
    friend struct internal::matrix_swap_impl;

  public:
    template <typename OtherDerived>
    inline void swap(DenseBase<OtherDerived>& other) {
      enum { SwapPointers = internal::is_same<Derived, OtherDerived>::value && Base::SizeAtCompileTime == Dynamic };
      internal::matrix_swap_impl<Derived, OtherDerived, bool(SwapPointers)>::run(this->derived(), other.derived());
    }
    template <typename OtherDerived>
    inline void swap(DenseBase<OtherDerived> const& other) {
      Base::swap(other.derived());
    }
    enum { IsPlainObjectBase = 1 };

  public:
    template <typename PlainObjectType, int MapOptions, typename StrideType>
    friend class Eigen::Map;
    friend class Eigen::Map<Derived, Unaligned>;
    friend class Eigen::Map<const Derived, Unaligned>;
    friend class Eigen::Map<Derived, AlignedMax>;
    friend class Eigen::Map<const Derived, AlignedMax>;
  };
  namespace internal {
    template <typename Derived, typename OtherDerived, bool IsVector>
    struct conservative_resize_like_impl {
      static constexpr bool IsRelocatable = std::is_trivially_copyable<typename Derived::Scalar>::value;
      static void run(DenseBase<Derived>& _this, Index rows, Index cols) {
        if (_this.rows() == rows && _this.cols() == cols)
          return;
        static_assert(Derived::SizeAtCompileTime == Eigen::Dynamic,
                      "YOU_CALLED_A_DYNAMIC_SIZE_METHOD_ON_A_FIXED_SIZE_MATRIX_OR_VECTOR");
        if (IsRelocatable &&
            ((Derived::IsRowMajor && _this.cols() == cols) || (!Derived::IsRowMajor && _this.rows() == rows))) {
          internal::check_rows_cols_for_overflow<Derived::MaxSizeAtCompileTime>::run(rows, cols);
          _this.derived().m_storage.conservativeResize(rows * cols, rows, cols);
        } else {
          Derived tmp(rows, cols);
          const Index common_rows = numext::mini(rows, _this.rows());
          const Index common_cols = numext::mini(cols, _this.cols());
          tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);
          _this.derived().swap(tmp);
        }
      }
      static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other) {
        if (_this.rows() == other.rows() && _this.cols() == other.cols())
          return;
        static_assert(Derived::SizeAtCompileTime == Eigen::Dynamic,
                      "YOU_CALLED_A_DYNAMIC_SIZE_METHOD_ON_A_FIXED_SIZE_MATRIX_OR_VECTOR");
        static_assert(OtherDerived::SizeAtCompileTime == Eigen::Dynamic,
                      "YOU_CALLED_A_DYNAMIC_SIZE_METHOD_ON_A_FIXED_SIZE_MATRIX_OR_VECTOR");
        if (IsRelocatable && ((Derived::IsRowMajor && _this.cols() == other.cols()) ||
                              (!Derived::IsRowMajor && _this.rows() == other.rows()))) {
          const Index new_rows = other.rows() - _this.rows();
          const Index new_cols = other.cols() - _this.cols();
          _this.derived().m_storage.conservativeResize(other.size(), other.rows(), other.cols());
          if (new_rows > 0)
            _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);
          else if (new_cols > 0)
            _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);
        } else {
          Derived tmp(other);
          const Index common_rows = numext::mini(tmp.rows(), _this.rows());
          const Index common_cols = numext::mini(tmp.cols(), _this.cols());
          tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);
          _this.derived().swap(tmp);
        }
      }
    };
    template <typename Derived, typename OtherDerived>
    struct conservative_resize_like_impl<Derived, OtherDerived, true>
        : conservative_resize_like_impl<Derived, OtherDerived, false> {
      typedef conservative_resize_like_impl<Derived, OtherDerived, false> Base;
      using Base::IsRelocatable;
      using Base::run;
      static void run(DenseBase<Derived>& _this, Index size) {
        const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : size;
        const Index new_cols = Derived::RowsAtCompileTime == 1 ? size : 1;
        if (IsRelocatable)
          _this.derived().m_storage.conservativeResize(size, new_rows, new_cols);
        else
          Base::run(_this.derived(), new_rows, new_cols);
      }
      static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other) {
        if (_this.rows() == other.rows() && _this.cols() == other.cols())
          return;
        const Index num_new_elements = other.size() - _this.size();
        const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : other.rows();
        const Index new_cols = Derived::RowsAtCompileTime == 1 ? other.cols() : 1;
        if (IsRelocatable)
          _this.derived().m_storage.conservativeResize(other.size(), new_rows, new_cols);
        else
          Base::run(_this.derived(), new_rows, new_cols);
        if (num_new_elements > 0)
          _this.tail(num_new_elements) = other.tail(num_new_elements);
      }
    };
    template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
    struct matrix_swap_impl {
      static inline void run(MatrixTypeA& a, MatrixTypeB& b) { a.base().swap(b); }
    };
    template <typename MatrixTypeA, typename MatrixTypeB>
    struct matrix_swap_impl<MatrixTypeA, MatrixTypeB, true> {
      static inline void run(MatrixTypeA& a, MatrixTypeB& b) {
        static_cast<typename MatrixTypeA::Base&>(a).m_storage.swap(
            static_cast<typename MatrixTypeB::Base&>(b).m_storage);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
    struct traits<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
    private:
      constexpr static int size = internal::size_at_compile_time(Rows_, Cols_);
      typedef typename find_best_packet<Scalar_, size>::type PacketScalar;
      enum {
        row_major_bit = Options_ & RowMajor ? RowMajorBit : 0,
        is_dynamic_size_storage = MaxRows_ == Dynamic || MaxCols_ == Dynamic,
        max_size = is_dynamic_size_storage ? Dynamic : MaxRows_ * MaxCols_,
        default_alignment = compute_default_alignment<Scalar_, max_size>::value,
        actual_alignment = ((Options_ & DontAlign) == 0) ? default_alignment : 0,
        required_alignment = unpacket_traits<PacketScalar>::alignment,
        packet_access_bit = (packet_traits<Scalar_>::Vectorizable && (1 || (actual_alignment >= required_alignment)))
                                ? PacketAccessBit
                                : 0
      };

    public:
      typedef Scalar_ Scalar;
      typedef Dense StorageKind;
      typedef Eigen::Index StorageIndex;
      typedef MatrixXpr XprKind;
      enum {
        RowsAtCompileTime = Rows_,
        ColsAtCompileTime = Cols_,
        MaxRowsAtCompileTime = MaxRows_,
        MaxColsAtCompileTime = MaxCols_,
        Flags = compute_matrix_flags(Options_),
        Options = Options_,
        InnerStrideAtCompileTime = 1,
        OuterStrideAtCompileTime = (Options & RowMajor) ? ColsAtCompileTime : RowsAtCompileTime,
        EvaluatorFlags = LinearAccessBit | DirectAccessBit | packet_access_bit | row_major_bit,
        Alignment = actual_alignment
      };
    };
  }  // namespace internal
  template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  class Matrix : public PlainObjectBase<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
  public:
    typedef PlainObjectBase<Matrix> Base;
    enum { Options = Options_ };
    typedef typename Eigen::internal::traits<Matrix>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Matrix>::type Nested;
    typedef typename Eigen::internal::traits<Matrix>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Matrix>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Matrix>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Matrix>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Matrix>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    typedef typename Base::PlainObject PlainObject;
    using Base::base;
    using Base::coeffRef;
    inline Matrix& operator=(const Matrix& other) { return Base::_set(other); }
    template <typename OtherDerived>
    inline Matrix& operator=(const DenseBase<OtherDerived>& other) {
      return Base::_set(other);
    }
    template <typename OtherDerived>
    inline Matrix& operator=(const EigenBase<OtherDerived>& other) {
      return Base::operator=(other);
    }
    template <typename OtherDerived>
    inline Matrix& operator=(const ReturnByValue<OtherDerived>& func) {
      return Base::operator=(func);
    }
    inline Matrix() : Base() {}
    inline explicit Matrix(internal::constructor_without_unaligned_array_assert)
        : Base(internal::constructor_without_unaligned_array_assert()) {}
    inline Matrix(Matrix&& other) noexcept(std::is_nothrow_move_constructible<Scalar>::value)
        : Base(std::move(other)) {}
    inline Matrix& operator=(Matrix&& other) noexcept(std::is_nothrow_move_assignable<Scalar>::value) {
      Base::operator=(std::move(other));
      return *this;
    }
    template <typename... ArgTypes>
    inline Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
        : Base(a0, a1, a2, a3, args...) {}
    explicit inline Matrix(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
    template <typename T>
    inline explicit Matrix(const T& x) {
      Base::template _init1<T>(x);
    }
    template <typename T0, typename T1>
    inline Matrix(const T0& x, const T1& y) {
      Base::template _init2<T0, T1>(x, y);
    }
    inline Matrix(const Scalar& x, const Scalar& y, const Scalar& z) {
      static_assert(Matrix::IsVectorAtCompileTime && Matrix::SizeAtCompileTime == 3,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = x;
      m_storage.data()[1] = y;
      m_storage.data()[2] = z;
    }
    inline Matrix(const Scalar& x, const Scalar& y, const Scalar& z, const Scalar& w) {
      static_assert(Matrix::IsVectorAtCompileTime && Matrix::SizeAtCompileTime == 4,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = x;
      m_storage.data()[1] = y;
      m_storage.data()[2] = z;
      m_storage.data()[3] = w;
    }
    inline Matrix(const Matrix& other) : Base(other) {}
    template <typename OtherDerived>
    inline Matrix(const EigenBase<OtherDerived>& other) : Base(other.derived()) {}
    constexpr inline Index innerStride() const noexcept { return 1; }
    constexpr inline Index outerStride() const noexcept { return this->innerSize(); }
    template <typename OtherDerived>
    explicit Matrix(const RotationBase<OtherDerived, ColsAtCompileTime>& r);
    template <typename OtherDerived>
    Matrix& operator=(const RotationBase<OtherDerived, ColsAtCompileTime>& r);

  protected:
    template <typename Derived, typename OtherDerived, bool IsVector>
    friend struct internal::conservative_resize_like_impl;
    using Base::m_storage;
  };
  typedef Matrix<int, 2, 2> Matrix2i;
  typedef Matrix<int, 2, 1> Vector2i;
  typedef Matrix<int, 1, 2> RowVector2i;
  typedef Matrix<int, 3, 3> Matrix3i;
  typedef Matrix<int, 3, 1> Vector3i;
  typedef Matrix<int, 1, 3> RowVector3i;
  typedef Matrix<int, 4, 4> Matrix4i;
  typedef Matrix<int, 4, 1> Vector4i;
  typedef Matrix<int, 1, 4> RowVector4i;
  typedef Matrix<int, Dynamic, Dynamic> MatrixXi;
  typedef Matrix<int, Dynamic, 1> VectorXi;
  typedef Matrix<int, 1, Dynamic> RowVectorXi;
  typedef Matrix<int, 2, Dynamic> Matrix2Xi;
  typedef Matrix<int, Dynamic, 2> MatrixX2i;
  typedef Matrix<int, 3, Dynamic> Matrix3Xi;
  typedef Matrix<int, Dynamic, 3> MatrixX3i;
  typedef Matrix<int, 4, Dynamic> Matrix4Xi;
  typedef Matrix<int, Dynamic, 4> MatrixX4i;
  typedef Matrix<float, 2, 2> Matrix2f;
  typedef Matrix<float, 2, 1> Vector2f;
  typedef Matrix<float, 1, 2> RowVector2f;
  typedef Matrix<float, 3, 3> Matrix3f;
  typedef Matrix<float, 3, 1> Vector3f;
  typedef Matrix<float, 1, 3> RowVector3f;
  typedef Matrix<float, 4, 4> Matrix4f;
  typedef Matrix<float, 4, 1> Vector4f;
  typedef Matrix<float, 1, 4> RowVector4f;
  typedef Matrix<float, Dynamic, Dynamic> MatrixXf;
  typedef Matrix<float, Dynamic, 1> VectorXf;
  typedef Matrix<float, 1, Dynamic> RowVectorXf;
  typedef Matrix<float, 2, Dynamic> Matrix2Xf;
  typedef Matrix<float, Dynamic, 2> MatrixX2f;
  typedef Matrix<float, 3, Dynamic> Matrix3Xf;
  typedef Matrix<float, Dynamic, 3> MatrixX3f;
  typedef Matrix<float, 4, Dynamic> Matrix4Xf;
  typedef Matrix<float, Dynamic, 4> MatrixX4f;
  typedef Matrix<double, 2, 2> Matrix2d;
  typedef Matrix<double, 2, 1> Vector2d;
  typedef Matrix<double, 1, 2> RowVector2d;
  typedef Matrix<double, 3, 3> Matrix3d;
  typedef Matrix<double, 3, 1> Vector3d;
  typedef Matrix<double, 1, 3> RowVector3d;
  typedef Matrix<double, 4, 4> Matrix4d;
  typedef Matrix<double, 4, 1> Vector4d;
  typedef Matrix<double, 1, 4> RowVector4d;
  typedef Matrix<double, Dynamic, Dynamic> MatrixXd;
  typedef Matrix<double, Dynamic, 1> VectorXd;
  typedef Matrix<double, 1, Dynamic> RowVectorXd;
  typedef Matrix<double, 2, Dynamic> Matrix2Xd;
  typedef Matrix<double, Dynamic, 2> MatrixX2d;
  typedef Matrix<double, 3, Dynamic> Matrix3Xd;
  typedef Matrix<double, Dynamic, 3> MatrixX3d;
  typedef Matrix<double, 4, Dynamic> Matrix4Xd;
  typedef Matrix<double, Dynamic, 4> MatrixX4d;
  typedef Matrix<std::complex<float>, 2, 2> Matrix2cf;
  typedef Matrix<std::complex<float>, 2, 1> Vector2cf;
  typedef Matrix<std::complex<float>, 1, 2> RowVector2cf;
  typedef Matrix<std::complex<float>, 3, 3> Matrix3cf;
  typedef Matrix<std::complex<float>, 3, 1> Vector3cf;
  typedef Matrix<std::complex<float>, 1, 3> RowVector3cf;
  typedef Matrix<std::complex<float>, 4, 4> Matrix4cf;
  typedef Matrix<std::complex<float>, 4, 1> Vector4cf;
  typedef Matrix<std::complex<float>, 1, 4> RowVector4cf;
  typedef Matrix<std::complex<float>, Dynamic, Dynamic> MatrixXcf;
  typedef Matrix<std::complex<float>, Dynamic, 1> VectorXcf;
  typedef Matrix<std::complex<float>, 1, Dynamic> RowVectorXcf;
  typedef Matrix<std::complex<float>, 2, Dynamic> Matrix2Xcf;
  typedef Matrix<std::complex<float>, Dynamic, 2> MatrixX2cf;
  typedef Matrix<std::complex<float>, 3, Dynamic> Matrix3Xcf;
  typedef Matrix<std::complex<float>, Dynamic, 3> MatrixX3cf;
  typedef Matrix<std::complex<float>, 4, Dynamic> Matrix4Xcf;
  typedef Matrix<std::complex<float>, Dynamic, 4> MatrixX4cf;
  typedef Matrix<std::complex<double>, 2, 2> Matrix2cd;
  typedef Matrix<std::complex<double>, 2, 1> Vector2cd;
  typedef Matrix<std::complex<double>, 1, 2> RowVector2cd;
  typedef Matrix<std::complex<double>, 3, 3> Matrix3cd;
  typedef Matrix<std::complex<double>, 3, 1> Vector3cd;
  typedef Matrix<std::complex<double>, 1, 3> RowVector3cd;
  typedef Matrix<std::complex<double>, 4, 4> Matrix4cd;
  typedef Matrix<std::complex<double>, 4, 1> Vector4cd;
  typedef Matrix<std::complex<double>, 1, 4> RowVector4cd;
  typedef Matrix<std::complex<double>, Dynamic, Dynamic> MatrixXcd;
  typedef Matrix<std::complex<double>, Dynamic, 1> VectorXcd;
  typedef Matrix<std::complex<double>, 1, Dynamic> RowVectorXcd;
  typedef Matrix<std::complex<double>, 2, Dynamic> Matrix2Xcd;
  typedef Matrix<std::complex<double>, Dynamic, 2> MatrixX2cd;
  typedef Matrix<std::complex<double>, 3, Dynamic> Matrix3Xcd;
  typedef Matrix<std::complex<double>, Dynamic, 3> MatrixX3cd;
  typedef Matrix<std::complex<double>, 4, Dynamic> Matrix4Xcd;
  typedef Matrix<std::complex<double>, Dynamic, 4> MatrixX4cd;
  template <typename Type>
  using Matrix2 = Matrix<Type, 2, 2>;
  template <typename Type>
  using Vector2 = Matrix<Type, 2, 1>;
  template <typename Type>
  using RowVector2 = Matrix<Type, 1, 2>;
  template <typename Type>
  using Matrix3 = Matrix<Type, 3, 3>;
  template <typename Type>
  using Vector3 = Matrix<Type, 3, 1>;
  template <typename Type>
  using RowVector3 = Matrix<Type, 1, 3>;
  template <typename Type>
  using Matrix4 = Matrix<Type, 4, 4>;
  template <typename Type>
  using Vector4 = Matrix<Type, 4, 1>;
  template <typename Type>
  using RowVector4 = Matrix<Type, 1, 4>;
  template <typename Type>
  using MatrixX = Matrix<Type, Dynamic, Dynamic>;
  template <typename Type>
  using VectorX = Matrix<Type, Dynamic, 1>;
  template <typename Type>
  using RowVectorX = Matrix<Type, 1, Dynamic>;
  template <typename Type>
  using Matrix2X = Matrix<Type, 2, Dynamic>;
  template <typename Type>
  using MatrixX2 = Matrix<Type, Dynamic, 2>;
  template <typename Type>
  using Matrix3X = Matrix<Type, 3, Dynamic>;
  template <typename Type>
  using MatrixX3 = Matrix<Type, Dynamic, 3>;
  template <typename Type>
  using Matrix4X = Matrix<Type, 4, Dynamic>;
  template <typename Type>
  using MatrixX4 = Matrix<Type, Dynamic, 4>;
  template <typename Type, int Size>
  using Vector = Matrix<Type, Size, 1>;
  template <typename Type, int Size>
  using RowVector = Matrix<Type, 1, Size>;
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
    struct traits<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>>
        : traits<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
      typedef ArrayXpr XprKind;
      typedef ArrayBase<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> XprBase;
    };
  }  // namespace internal
  template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  class Array : public PlainObjectBase<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
  public:
    typedef PlainObjectBase<Array> Base;
    typedef typename Eigen::internal::traits<Array>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Array>::type Nested;
    typedef typename Eigen::internal::traits<Array>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Array>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Array>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Array>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Array>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    enum { Options = Options_ };
    typedef typename Base::PlainObject PlainObject;

  protected:
    template <typename Derived, typename OtherDerived, bool IsVector>
    friend struct internal::conservative_resize_like_impl;
    using Base::m_storage;

  public:
    using Base::base;
    using Base::coeff;
    using Base::coeffRef;
    template <typename OtherDerived>
    inline Array& operator=(const EigenBase<OtherDerived>& other) {
      return Base::operator=(other);
    }
    inline Array& operator=(const Scalar& value) {
      Base::setConstant(value);
      return *this;
    }
    template <typename OtherDerived>
    inline Array& operator=(const DenseBase<OtherDerived>& other) {
      return Base::_set(other);
    }
    inline Array& operator=(const Array& other) { return Base::_set(other); }
    inline Array() : Base() {}
    Array(internal::constructor_without_unaligned_array_assert)
        : Base(internal::constructor_without_unaligned_array_assert()) {}
    Array(Array&& other) noexcept(std::is_nothrow_move_constructible<Scalar>::value) : Base(std::move(other)) {}
    Array& operator=(Array&& other) noexcept(std::is_nothrow_move_assignable<Scalar>::value) {
      Base::operator=(std::move(other));
      return *this;
    }
    template <typename... ArgTypes>
    inline Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
        : Base(a0, a1, a2, a3, args...) {}
    inline Array(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
    template <typename T>
    inline explicit Array(const T& x) {
      Base::template _init1<T>(x);
    }
    template <typename T0, typename T1>
    inline Array(const T0& val0, const T1& val1) {
      this->template _init2<T0, T1>(val0, val1);
    }
    inline Array(const Scalar& val0, const Scalar& val1, const Scalar& val2) {
      static_assert(Array::IsVectorAtCompileTime && Array::SizeAtCompileTime == 3,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = val0;
      m_storage.data()[1] = val1;
      m_storage.data()[2] = val2;
    }
    inline Array(const Scalar& val0, const Scalar& val1, const Scalar& val2, const Scalar& val3) {
      static_assert(Array::IsVectorAtCompileTime && Array::SizeAtCompileTime == 4,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      m_storage.data()[0] = val0;
      m_storage.data()[1] = val1;
      m_storage.data()[2] = val2;
      m_storage.data()[3] = val3;
    }
    inline Array(const Array& other) : Base(other) {}

  private:
    struct PrivateType {};

  public:
    template <typename OtherDerived>
    inline Array(const EigenBase<OtherDerived>& other,
                 std::enable_if_t<internal::is_convertible<typename OtherDerived::Scalar, Scalar>::value, PrivateType> =
                     PrivateType())
        : Base(other.derived()) {}
    constexpr inline Index innerStride() const noexcept { return 1; }
    constexpr inline Index outerStride() const noexcept { return this->innerSize(); }

  private:
    template <typename MatrixType, typename OtherDerived, bool SwapPointers>
    friend struct internal::matrix_swap_impl;
  };
  typedef Array<int, 2, 2> Array22i;
  typedef Array<int, 2, 1> Array2i;
  typedef Array<int, 3, 3> Array33i;
  typedef Array<int, 3, 1> Array3i;
  typedef Array<int, 4, 4> Array44i;
  typedef Array<int, 4, 1> Array4i;
  typedef Array<int, Dynamic, Dynamic> ArrayXXi;
  typedef Array<int, Dynamic, 1> ArrayXi;
  typedef Array<int, 2, Dynamic> Array2Xi;
  typedef Array<int, Dynamic, 2> ArrayX2i;
  typedef Array<int, 3, Dynamic> Array3Xi;
  typedef Array<int, Dynamic, 3> ArrayX3i;
  typedef Array<int, 4, Dynamic> Array4Xi;
  typedef Array<int, Dynamic, 4> ArrayX4i;
  typedef Array<float, 2, 2> Array22f;
  typedef Array<float, 2, 1> Array2f;
  typedef Array<float, 3, 3> Array33f;
  typedef Array<float, 3, 1> Array3f;
  typedef Array<float, 4, 4> Array44f;
  typedef Array<float, 4, 1> Array4f;
  typedef Array<float, Dynamic, Dynamic> ArrayXXf;
  typedef Array<float, Dynamic, 1> ArrayXf;
  typedef Array<float, 2, Dynamic> Array2Xf;
  typedef Array<float, Dynamic, 2> ArrayX2f;
  typedef Array<float, 3, Dynamic> Array3Xf;
  typedef Array<float, Dynamic, 3> ArrayX3f;
  typedef Array<float, 4, Dynamic> Array4Xf;
  typedef Array<float, Dynamic, 4> ArrayX4f;
  typedef Array<double, 2, 2> Array22d;
  typedef Array<double, 2, 1> Array2d;
  typedef Array<double, 3, 3> Array33d;
  typedef Array<double, 3, 1> Array3d;
  typedef Array<double, 4, 4> Array44d;
  typedef Array<double, 4, 1> Array4d;
  typedef Array<double, Dynamic, Dynamic> ArrayXXd;
  typedef Array<double, Dynamic, 1> ArrayXd;
  typedef Array<double, 2, Dynamic> Array2Xd;
  typedef Array<double, Dynamic, 2> ArrayX2d;
  typedef Array<double, 3, Dynamic> Array3Xd;
  typedef Array<double, Dynamic, 3> ArrayX3d;
  typedef Array<double, 4, Dynamic> Array4Xd;
  typedef Array<double, Dynamic, 4> ArrayX4d;
  typedef Array<std::complex<float>, 2, 2> Array22cf;
  typedef Array<std::complex<float>, 2, 1> Array2cf;
  typedef Array<std::complex<float>, 3, 3> Array33cf;
  typedef Array<std::complex<float>, 3, 1> Array3cf;
  typedef Array<std::complex<float>, 4, 4> Array44cf;
  typedef Array<std::complex<float>, 4, 1> Array4cf;
  typedef Array<std::complex<float>, Dynamic, Dynamic> ArrayXXcf;
  typedef Array<std::complex<float>, Dynamic, 1> ArrayXcf;
  typedef Array<std::complex<float>, 2, Dynamic> Array2Xcf;
  typedef Array<std::complex<float>, Dynamic, 2> ArrayX2cf;
  typedef Array<std::complex<float>, 3, Dynamic> Array3Xcf;
  typedef Array<std::complex<float>, Dynamic, 3> ArrayX3cf;
  typedef Array<std::complex<float>, 4, Dynamic> Array4Xcf;
  typedef Array<std::complex<float>, Dynamic, 4> ArrayX4cf;
  typedef Array<std::complex<double>, 2, 2> Array22cd;
  typedef Array<std::complex<double>, 2, 1> Array2cd;
  typedef Array<std::complex<double>, 3, 3> Array33cd;
  typedef Array<std::complex<double>, 3, 1> Array3cd;
  typedef Array<std::complex<double>, 4, 4> Array44cd;
  typedef Array<std::complex<double>, 4, 1> Array4cd;
  typedef Array<std::complex<double>, Dynamic, Dynamic> ArrayXXcd;
  typedef Array<std::complex<double>, Dynamic, 1> ArrayXcd;
  typedef Array<std::complex<double>, 2, Dynamic> Array2Xcd;
  typedef Array<std::complex<double>, Dynamic, 2> ArrayX2cd;
  typedef Array<std::complex<double>, 3, Dynamic> Array3Xcd;
  typedef Array<std::complex<double>, Dynamic, 3> ArrayX3cd;
  typedef Array<std::complex<double>, 4, Dynamic> Array4Xcd;
  typedef Array<std::complex<double>, Dynamic, 4> ArrayX4cd;
  template <typename Type>
  using Array22 = Array<Type, 2, 2>;
  template <typename Type>
  using Array2 = Array<Type, 2, 1>;
  template <typename Type>
  using Array33 = Array<Type, 3, 3>;
  template <typename Type>
  using Array3 = Array<Type, 3, 1>;
  template <typename Type>
  using Array44 = Array<Type, 4, 4>;
  template <typename Type>
  using Array4 = Array<Type, 4, 1>;
  template <typename Type>
  using ArrayXX = Array<Type, Dynamic, Dynamic>;
  template <typename Type>
  using ArrayX = Array<Type, Dynamic, 1>;
  template <typename Type>
  using Array2X = Array<Type, 2, Dynamic>;
  template <typename Type>
  using ArrayX2 = Array<Type, Dynamic, 2>;
  template <typename Type>
  using Array3X = Array<Type, 3, Dynamic>;
  template <typename Type>
  using ArrayX3 = Array<Type, Dynamic, 3>;
  template <typename Type>
  using Array4X = Array<Type, 4, Dynamic>;
  template <typename Type>
  using ArrayX4 = Array<Type, Dynamic, 4>;
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
    struct traits<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> {
      typedef remove_all_t<Arg1> Ancestor;
      typedef typename traits<Ancestor>::XprKind XprKind;
      enum {
        RowsAtCompileTime = traits<Ancestor>::RowsAtCompileTime,
        ColsAtCompileTime = traits<Ancestor>::ColsAtCompileTime,
        MaxRowsAtCompileTime = traits<Ancestor>::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = traits<Ancestor>::MaxColsAtCompileTime
      };
      typedef typename result_of<TernaryOp(
          const typename Arg1::Scalar&, const typename Arg2::Scalar&, const typename Arg3::Scalar&)>::type Scalar;
      typedef typename internal::traits<Arg1>::StorageKind StorageKind;
      typedef typename internal::traits<Arg1>::StorageIndex StorageIndex;
      typedef typename Arg1::Nested Arg1Nested;
      typedef typename Arg2::Nested Arg2Nested;
      typedef typename Arg3::Nested Arg3Nested;
      typedef std::remove_reference_t<Arg1Nested> Arg1Nested_;
      typedef std::remove_reference_t<Arg2Nested> Arg2Nested_;
      typedef std::remove_reference_t<Arg3Nested> Arg3Nested_;
      enum { Flags = Arg1Nested_::Flags & RowMajorBit };
    };
  }  // namespace internal
  template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3, typename StorageKind>
  class CwiseTernaryOpImpl;
  template <typename TernaryOp, typename Arg1Type, typename Arg2Type, typename Arg3Type>
  class CwiseTernaryOp : public CwiseTernaryOpImpl<TernaryOp,
                                                   Arg1Type,
                                                   Arg2Type,
                                                   Arg3Type,
                                                   typename internal::traits<Arg1Type>::StorageKind>,
                         internal::no_assignment_operator {
  public:
    typedef internal::remove_all_t<Arg1Type> Arg1;
    typedef internal::remove_all_t<Arg2Type> Arg2;
    typedef internal::remove_all_t<Arg3Type> Arg3;
    static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<Arg1>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<Arg2>::ret) == 0) ||
                   ((int(Arg1::RowsAtCompileTime) == Eigen::Dynamic || int(Arg2::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Arg1::RowsAtCompileTime) == int(Arg2::RowsAtCompileTime)) &&
                    (int(Arg1::ColsAtCompileTime) == Eigen::Dynamic || int(Arg2::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Arg1::ColsAtCompileTime) == int(Arg2::ColsAtCompileTime)))),
                  "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
    static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<Arg1>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<Arg3>::ret) == 0) ||
                   ((int(Arg1::RowsAtCompileTime) == Eigen::Dynamic || int(Arg3::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Arg1::RowsAtCompileTime) == int(Arg3::RowsAtCompileTime)) &&
                    (int(Arg1::ColsAtCompileTime) == Eigen::Dynamic || int(Arg3::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Arg1::ColsAtCompileTime) == int(Arg3::ColsAtCompileTime)))),
                  "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
    static_assert((internal::is_same<typename internal::traits<Arg1Type>::StorageKind,
                                     typename internal::traits<Arg2Type>::StorageKind>::value),
                  "STORAGE_KIND_MUST_MATCH");
    static_assert((internal::is_same<typename internal::traits<Arg1Type>::StorageKind,
                                     typename internal::traits<Arg3Type>::StorageKind>::value),
                  "STORAGE_KIND_MUST_MATCH");
    typedef typename CwiseTernaryOpImpl<TernaryOp,
                                        Arg1Type,
                                        Arg2Type,
                                        Arg3Type,
                                        typename internal::traits<Arg1Type>::StorageKind>::Base Base;
    typedef typename Eigen::internal::traits<CwiseTernaryOp>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CwiseTernaryOp>::type Nested;
    typedef typename Eigen::internal::traits<CwiseTernaryOp>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CwiseTernaryOp>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CwiseTernaryOp>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CwiseTernaryOp>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CwiseTernaryOp>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename internal::ref_selector<Arg1Type>::type Arg1Nested;
    typedef typename internal::ref_selector<Arg2Type>::type Arg2Nested;
    typedef typename internal::ref_selector<Arg3Type>::type Arg3Nested;
    typedef std::remove_reference_t<Arg1Nested> Arg1Nested_;
    typedef std::remove_reference_t<Arg2Nested> Arg2Nested_;
    typedef std::remove_reference_t<Arg3Nested> Arg3Nested_;
    inline CwiseTernaryOp(const Arg1& a1, const Arg2& a2, const Arg3& a3, const TernaryOp& func = TernaryOp())
        : m_arg1(a1), m_arg2(a2), m_arg3(a3), m_functor(func) {
      (static_cast<bool>(a1.rows() == a2.rows() && a1.cols() == a2.cols() && a1.rows() == a3.rows() &&
                         a1.cols() == a3.cols())
           ? void(0)
           : __assert_fail(
                 "a1.rows() == a2.rows() && a1.cols() == a2.cols() && a1.rows() == a3.rows() && a1.cols() == a3.cols()",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/CwiseTernaryOp.h",
                 128,
                 __extension__ __PRETTY_FUNCTION__));
    }
    inline Index rows() const {
      if (internal::traits<internal::remove_all_t<Arg1Nested>>::RowsAtCompileTime == Dynamic &&
          internal::traits<internal::remove_all_t<Arg2Nested>>::RowsAtCompileTime == Dynamic)
        return m_arg3.rows();
      else if (internal::traits<internal::remove_all_t<Arg1Nested>>::RowsAtCompileTime == Dynamic &&
               internal::traits<internal::remove_all_t<Arg3Nested>>::RowsAtCompileTime == Dynamic)
        return m_arg2.rows();
      else
        return m_arg1.rows();
    }
    inline Index cols() const {
      if (internal::traits<internal::remove_all_t<Arg1Nested>>::ColsAtCompileTime == Dynamic &&
          internal::traits<internal::remove_all_t<Arg2Nested>>::ColsAtCompileTime == Dynamic)
        return m_arg3.cols();
      else if (internal::traits<internal::remove_all_t<Arg1Nested>>::ColsAtCompileTime == Dynamic &&
               internal::traits<internal::remove_all_t<Arg3Nested>>::ColsAtCompileTime == Dynamic)
        return m_arg2.cols();
      else
        return m_arg1.cols();
    }
    const Arg1Nested_& arg1() const { return m_arg1; }
    const Arg2Nested_& arg2() const { return m_arg2; }
    const Arg3Nested_& arg3() const { return m_arg3; }
    const TernaryOp& functor() const { return m_functor; }

  protected:
    Arg1Nested m_arg1;
    Arg2Nested m_arg2;
    Arg3Nested m_arg3;
    const TernaryOp m_functor;
  };
  template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3, typename StorageKind>
  class CwiseTernaryOpImpl : public internal::generic_xpr_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>>::type {
  public:
    typedef typename internal::generic_xpr_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>>::type Base;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename BinaryOp, typename Lhs, typename Rhs>
    struct traits<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
      typedef remove_all_t<Lhs> Ancestor;
      typedef typename traits<Ancestor>::XprKind XprKind;
      enum {
        RowsAtCompileTime = traits<Ancestor>::RowsAtCompileTime,
        ColsAtCompileTime = traits<Ancestor>::ColsAtCompileTime,
        MaxRowsAtCompileTime = traits<Ancestor>::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = traits<Ancestor>::MaxColsAtCompileTime
      };
      typedef typename result_of<BinaryOp(const typename Lhs::Scalar&, const typename Rhs::Scalar&)>::type Scalar;
      typedef typename cwise_promote_storage_type<typename traits<Lhs>::StorageKind,
                                                  typename traits<Rhs>::StorageKind,
                                                  BinaryOp>::ret StorageKind;
      typedef typename promote_index_type<typename traits<Lhs>::StorageIndex, typename traits<Rhs>::StorageIndex>::type
          StorageIndex;
      typedef typename Lhs::Nested LhsNested;
      typedef typename Rhs::Nested RhsNested;
      typedef std::remove_reference_t<LhsNested> LhsNested_;
      typedef std::remove_reference_t<RhsNested> RhsNested_;
      enum {
        Flags = cwise_promote_storage_order<typename traits<Lhs>::StorageKind,
                                            typename traits<Rhs>::StorageKind,
                                            LhsNested_::Flags & RowMajorBit,
                                            RhsNested_::Flags & RowMajorBit>::value
      };
    };
  }  // namespace internal
  template <typename BinaryOp, typename Lhs, typename Rhs, typename StorageKind>
  class CwiseBinaryOpImpl;
  template <typename BinaryOp, typename LhsType, typename RhsType>
  class CwiseBinaryOp
      : public CwiseBinaryOpImpl<
            BinaryOp,
            LhsType,
            RhsType,
            typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
                                                          typename internal::traits<RhsType>::StorageKind,
                                                          BinaryOp>::ret>,
        internal::no_assignment_operator {
  public:
    typedef internal::remove_all_t<BinaryOp> Functor;
    typedef internal::remove_all_t<LhsType> Lhs;
    typedef internal::remove_all_t<RhsType> Rhs;
    typedef typename CwiseBinaryOpImpl<
        BinaryOp,
        LhsType,
        RhsType,
        typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
                                                      typename internal::traits<Rhs>::StorageKind,
                                                      BinaryOp>::ret>::Base Base;
    typedef typename Eigen::internal::traits<CwiseBinaryOp>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CwiseBinaryOp>::type Nested;
    typedef typename Eigen::internal::traits<CwiseBinaryOp>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CwiseBinaryOp>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CwiseBinaryOp>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CwiseBinaryOp>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CwiseBinaryOp>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    static_assert((Eigen::internal::has_ReturnType<
                      ScalarBinaryOpTraits<typename Lhs::Scalar, typename Rhs::Scalar, BinaryOp>>::value),
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<Lhs>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<Rhs>::ret) == 0) ||
                   ((int(Lhs::RowsAtCompileTime) == Eigen::Dynamic || int(Rhs::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Lhs::RowsAtCompileTime) == int(Rhs::RowsAtCompileTime)) &&
                    (int(Lhs::ColsAtCompileTime) == Eigen::Dynamic || int(Rhs::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Lhs::ColsAtCompileTime) == int(Rhs::ColsAtCompileTime)))),
                  "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
    typedef typename internal::ref_selector<LhsType>::type LhsNested;
    typedef typename internal::ref_selector<RhsType>::type RhsNested;
    typedef std::remove_reference_t<LhsNested> LhsNested_;
    typedef std::remove_reference_t<RhsNested> RhsNested_;
    inline CwiseBinaryOp(const Lhs& aLhs, const Rhs& aRhs, const BinaryOp& func = BinaryOp())
        : m_lhs(aLhs), m_rhs(aRhs), m_functor(func) {
      (static_cast<bool>(aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols())
           ? void(0)
           : __assert_fail("aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CwiseBinaryOp.h",
                           118,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline constexpr Index rows() const noexcept {
      return internal::traits<internal::remove_all_t<LhsNested>>::RowsAtCompileTime == Dynamic ? m_rhs.rows()
                                                                                               : m_lhs.rows();
    }
    inline constexpr Index cols() const noexcept {
      return internal::traits<internal::remove_all_t<LhsNested>>::ColsAtCompileTime == Dynamic ? m_rhs.cols()
                                                                                               : m_lhs.cols();
    }
    inline const LhsNested_& lhs() const { return m_lhs; }
    inline const RhsNested_& rhs() const { return m_rhs; }
    inline const BinaryOp& functor() const { return m_functor; }

  protected:
    LhsNested m_lhs;
    RhsNested m_rhs;
    const BinaryOp m_functor;
  };
  template <typename BinaryOp, typename Lhs, typename Rhs, typename StorageKind>
  class CwiseBinaryOpImpl : public internal::generic_xpr_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>>::type {
  public:
    typedef typename internal::generic_xpr_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>>::type Base;
  };
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator-=(const MatrixBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline Derived& MatrixBase<Derived>::operator+=(const MatrixBase<OtherDerived>& other) {
    call_assignment(derived(), other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename UnaryOp, typename XprType>
    struct traits<CwiseUnaryOp<UnaryOp, XprType>> : traits<XprType> {
      typedef typename result_of<UnaryOp(const typename XprType::Scalar&)>::type Scalar;
      typedef typename XprType::Nested XprTypeNested;
      typedef std::remove_reference_t<XprTypeNested> XprTypeNested_;
      enum { Flags = XprTypeNested_::Flags & RowMajorBit };
    };
  }  // namespace internal
  template <typename UnaryOp, typename XprType, typename StorageKind>
  class CwiseUnaryOpImpl;
  template <typename UnaryOp, typename XprType>
  class CwiseUnaryOp : public CwiseUnaryOpImpl<UnaryOp, XprType, typename internal::traits<XprType>::StorageKind>,
                       internal::no_assignment_operator {
  public:
    typedef typename CwiseUnaryOpImpl<UnaryOp, XprType, typename internal::traits<XprType>::StorageKind>::Base Base;
    typedef typename Eigen::internal::traits<CwiseUnaryOp>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CwiseUnaryOp>::type Nested;
    typedef typename Eigen::internal::traits<CwiseUnaryOp>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CwiseUnaryOp>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CwiseUnaryOp>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CwiseUnaryOp>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CwiseUnaryOp>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename internal::ref_selector<XprType>::type XprTypeNested;
    typedef internal::remove_all_t<XprType> NestedExpression;
    inline explicit CwiseUnaryOp(const XprType& xpr, const UnaryOp& func = UnaryOp()) : m_xpr(xpr), m_functor(func) {}
    inline constexpr Index rows() const noexcept { return m_xpr.rows(); }
    inline constexpr Index cols() const noexcept { return m_xpr.cols(); }
    inline const UnaryOp& functor() const { return m_functor; }
    inline const internal::remove_all_t<XprTypeNested>& nestedExpression() const { return m_xpr; }
    inline internal::remove_all_t<XprTypeNested>& nestedExpression() { return m_xpr; }

  protected:
    XprTypeNested m_xpr;
    const UnaryOp m_functor;
  };
  template <typename UnaryOp, typename XprType, typename StorageKind>
  class CwiseUnaryOpImpl : public internal::generic_xpr_base<CwiseUnaryOp<UnaryOp, XprType>>::type {
  public:
    typedef typename internal::generic_xpr_base<CwiseUnaryOp<UnaryOp, XprType>>::type Base;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename NullaryOp, typename PlainObjectType>
    struct traits<CwiseNullaryOp<NullaryOp, PlainObjectType>> : traits<PlainObjectType> {
      enum { Flags = traits<PlainObjectType>::Flags & RowMajorBit };
    };
  }  // namespace internal
  template <typename NullaryOp, typename PlainObjectType>
  class CwiseNullaryOp : public internal::dense_xpr_base<CwiseNullaryOp<NullaryOp, PlainObjectType>>::type,
                         internal::no_assignment_operator {
  public:
    typedef typename internal::dense_xpr_base<CwiseNullaryOp>::type Base;
    typedef typename Eigen::internal::traits<CwiseNullaryOp>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CwiseNullaryOp>::type Nested;
    typedef typename Eigen::internal::traits<CwiseNullaryOp>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CwiseNullaryOp>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CwiseNullaryOp>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CwiseNullaryOp>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CwiseNullaryOp>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    CwiseNullaryOp(Index rows, Index cols, const NullaryOp& func = NullaryOp())
        : m_rows(rows), m_cols(cols), m_functor(func) {
      (static_cast<bool>(rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) && cols >= 0 &&
                         (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols))
           ? void(0)
           : __assert_fail("rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) && cols >= 0 && "
                           "(ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CwiseNullaryOp.h",
                           76,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline constexpr Index rows() const { return m_rows.value(); }
    inline constexpr Index cols() const { return m_cols.value(); }
    const NullaryOp& functor() const { return m_functor; }

  protected:
    const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
    const internal::variable_if_dynamic<Index, ColsAtCompileTime> m_cols;
    const NullaryOp m_functor;
  };
  template <typename Derived>
  template <typename CustomNullaryOp>
  inline const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  DenseBase<Derived>::NullaryExpr(Index rows, Index cols, const CustomNullaryOp& func) {
    return CwiseNullaryOp<CustomNullaryOp, PlainObject>(rows, cols, func);
  }
  template <typename Derived>
  template <typename CustomNullaryOp>
  inline const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  DenseBase<Derived>::NullaryExpr(Index size, const CustomNullaryOp& func) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    if (RowsAtCompileTime == 1)
      return CwiseNullaryOp<CustomNullaryOp, PlainObject>(1, size, func);
    else
      return CwiseNullaryOp<CustomNullaryOp, PlainObject>(size, 1, func);
  }
  template <typename Derived>
  template <typename CustomNullaryOp>
  inline const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  DenseBase<Derived>::NullaryExpr(const CustomNullaryOp& func) {
    return CwiseNullaryOp<CustomNullaryOp, PlainObject>(RowsAtCompileTime, ColsAtCompileTime, func);
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Constant(Index rows,
                                                                                            Index cols,
                                                                                            const Scalar& value) {
    return DenseBase<Derived>::NullaryExpr(rows, cols, internal::scalar_constant_op<Scalar>(value));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Constant(Index size,
                                                                                            const Scalar& value) {
    return DenseBase<Derived>::NullaryExpr(size, internal::scalar_constant_op<Scalar>(value));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Constant(const Scalar& value) {
    static_assert(Derived::SizeAtCompileTime != Eigen::Dynamic,
                  "YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR");
    return DenseBase<Derived>::NullaryExpr(
        RowsAtCompileTime, ColsAtCompileTime, internal::scalar_constant_op<Scalar>(value));
  }
  template <typename Derived>
  __attribute__((deprecated)) inline const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType
  DenseBase<Derived>::LinSpaced(Sequential_t, Index size, const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return DenseBase<Derived>::NullaryExpr(size, internal::linspaced_op<Scalar>(low, high, size));
  }
  template <typename Derived>
  __attribute__((deprecated)) inline const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType
  DenseBase<Derived>::LinSpaced(Sequential_t, const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    static_assert(Derived::SizeAtCompileTime != Eigen::Dynamic,
                  "YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR");
    return DenseBase<Derived>::NullaryExpr(Derived::SizeAtCompileTime,
                                           internal::linspaced_op<Scalar>(low, high, Derived::SizeAtCompileTime));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType DenseBase<Derived>::LinSpaced(
      Index size, const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return DenseBase<Derived>::NullaryExpr(size, internal::linspaced_op<Scalar>(low, high, size));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType DenseBase<Derived>::LinSpaced(
      const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    static_assert(Derived::SizeAtCompileTime != Eigen::Dynamic,
                  "YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR");
    return DenseBase<Derived>::NullaryExpr(Derived::SizeAtCompileTime,
                                           internal::linspaced_op<Scalar>(low, high, Derived::SizeAtCompileTime));
  }
  template <typename Derived>
  bool DenseBase<Derived>::isApproxToConstant(const Scalar& val, const RealScalar& prec) const {
    typename internal::nested_eval<Derived, 1>::type self(derived());
    for (Index j = 0; j < cols(); ++j)
      for (Index i = 0; i < rows(); ++i)
        if (!internal::isApprox(self.coeff(i, j), val, prec))
          return false;
    return true;
  }
  template <typename Derived>
  bool DenseBase<Derived>::isConstant(const Scalar& val, const RealScalar& prec) const {
    return isApproxToConstant(val, prec);
  }
  template <typename Derived>
  inline void DenseBase<Derived>::fill(const Scalar& val) {
    setConstant(val);
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setConstant(const Scalar& val) {
    return derived() = Constant(rows(), cols(), val);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setConstant(Index size, const Scalar& val) {
    resize(size);
    return setConstant(val);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setConstant(Index rows, Index cols, const Scalar& val) {
    resize(rows, cols);
    return setConstant(val);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setConstant(NoChange_t, Index cols, const Scalar& val) {
    return setConstant(rows(), cols, val);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setConstant(Index rows, NoChange_t, const Scalar& val) {
    return setConstant(rows, cols(), val);
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setLinSpaced(Index newSize, const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return derived() = Derived::NullaryExpr(newSize, internal::linspaced_op<Scalar>(low, high, newSize));
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setLinSpaced(const Scalar& low, const Scalar& high) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return setLinSpaced(size(), low, high);
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Zero(Index rows, Index cols) {
    return Constant(rows, cols, Scalar(0));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Zero(Index size) {
    return Constant(size, Scalar(0));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Zero() {
    return Constant(Scalar(0));
  }
  template <typename Derived>
  bool DenseBase<Derived>::isZero(const RealScalar& prec) const {
    typename internal::nested_eval<Derived, 1>::type self(derived());
    for (Index j = 0; j < cols(); ++j)
      for (Index i = 0; i < rows(); ++i)
        if (!internal::isMuchSmallerThan(self.coeff(i, j), static_cast<Scalar>(1), prec))
          return false;
    return true;
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setZero() {
    return setConstant(Scalar(0));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setZero(Index newSize) {
    resize(newSize);
    return setConstant(Scalar(0));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setZero(Index rows, Index cols) {
    resize(rows, cols);
    return setConstant(Scalar(0));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setZero(NoChange_t, Index cols) {
    return setZero(rows(), cols);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setZero(Index rows, NoChange_t) {
    return setZero(rows, cols());
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones(Index rows, Index cols) {
    return Constant(rows, cols, Scalar(1));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones(Index newSize) {
    return Constant(newSize, Scalar(1));
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones() {
    return Constant(Scalar(1));
  }
  template <typename Derived>
  bool DenseBase<Derived>::isOnes(const RealScalar& prec) const {
    return isApproxToConstant(Scalar(1), prec);
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setOnes() {
    return setConstant(Scalar(1));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setOnes(Index newSize) {
    resize(newSize);
    return setConstant(Scalar(1));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setOnes(Index rows, Index cols) {
    resize(rows, cols);
    return setConstant(Scalar(1));
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setOnes(Index rows, NoChange_t) {
    return setOnes(rows, cols());
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setOnes(NoChange_t, Index cols) {
    return setOnes(rows(), cols);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::IdentityReturnType MatrixBase<Derived>::Identity(Index rows, Index cols) {
    return DenseBase<Derived>::NullaryExpr(rows, cols, internal::scalar_identity_op<Scalar>());
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::IdentityReturnType MatrixBase<Derived>::Identity() {
    static_assert(Derived::SizeAtCompileTime != Eigen::Dynamic,
                  "YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR");
    return MatrixBase<Derived>::NullaryExpr(
        RowsAtCompileTime, ColsAtCompileTime, internal::scalar_identity_op<Scalar>());
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isIdentity(const RealScalar& prec) const {
    typename internal::nested_eval<Derived, 1>::type self(derived());
    for (Index j = 0; j < cols(); ++j) {
      for (Index i = 0; i < rows(); ++i) {
        if (i == j) {
          if (!internal::isApprox(self.coeff(i, j), static_cast<Scalar>(1), prec))
            return false;
        } else {
          if (!internal::isMuchSmallerThan(self.coeff(i, j), static_cast<RealScalar>(1), prec))
            return false;
        }
      }
    }
    return true;
  }
  namespace internal {
    template <typename Derived, bool Big = (Derived::SizeAtCompileTime >= 16)>
    struct setIdentity_impl {
      static inline Derived& run(Derived& m) { return m = Derived::Identity(m.rows(), m.cols()); }
    };
    template <typename Derived>
    struct setIdentity_impl<Derived, true> {
      static inline Derived& run(Derived& m) {
        m.setZero();
        const Index size = numext::mini(m.rows(), m.cols());
        for (Index i = 0; i < size; ++i)
          m.coeffRef(i, i) = typename Derived::Scalar(1);
        return m;
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline Derived& MatrixBase<Derived>::setIdentity() {
    return internal::setIdentity_impl<Derived>::run(derived());
  }
  template <typename Derived>
  inline Derived& MatrixBase<Derived>::setIdentity(Index rows, Index cols) {
    derived().resize(rows, cols);
    return setIdentity();
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::Unit(Index newSize, Index i) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return BasisReturnType(SquareMatrixType::Identity(newSize, newSize), i);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::Unit(Index i) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return BasisReturnType(SquareMatrixType::Identity(), i);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitX() {
    return Derived::Unit(0);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitY() {
    return Derived::Unit(1);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitZ() {
    return Derived::Unit(2);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitW() {
    return Derived::Unit(3);
  }
  template <typename Derived>
  inline Derived& MatrixBase<Derived>::setUnit(Index i) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    (static_cast<bool>(i < size())
         ? void(0)
         : __assert_fail("i<size()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/CwiseNullaryOp.h",
                         977,
                         __extension__ __PRETTY_FUNCTION__));
    derived().setZero();
    derived().coeffRef(i) = Scalar(1);
    return derived();
  }
  template <typename Derived>
  inline Derived& MatrixBase<Derived>::setUnit(Index newSize, Index i) {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    (static_cast<bool>(i < newSize)
         ? void(0)
         : __assert_fail("i<newSize",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/CwiseNullaryOp.h",
                         996,
                         __extension__ __PRETTY_FUNCTION__));
    derived().resize(newSize);
    return setUnit(i);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename ViewOp, typename MatrixType, typename StrideType>
    struct traits<CwiseUnaryView<ViewOp, MatrixType, StrideType>> : traits<MatrixType> {
      typedef typename result_of<ViewOp(const typename traits<MatrixType>::Scalar&)>::type Scalar;
      typedef typename MatrixType::Nested MatrixTypeNested;
      typedef remove_all_t<MatrixTypeNested> MatrixTypeNested_;
      enum {
        FlagsLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
        Flags = traits<MatrixTypeNested_>::Flags & (RowMajorBit | FlagsLvalueBit | DirectAccessBit),
        MatrixTypeInnerStride = inner_stride_at_compile_time<MatrixType>::ret,
        InnerStrideAtCompileTime =
            StrideType::InnerStrideAtCompileTime == 0
                ? (MatrixTypeInnerStride == Dynamic
                       ? int(Dynamic)
                       : int(MatrixTypeInnerStride) * int(sizeof(typename traits<MatrixType>::Scalar) / sizeof(Scalar)))
                : int(StrideType::InnerStrideAtCompileTime),
        OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
                                       ? (outer_stride_at_compile_time<MatrixType>::ret == Dynamic
                                              ? int(Dynamic)
                                              : outer_stride_at_compile_time<MatrixType>::ret *
                                                    int(sizeof(typename traits<MatrixType>::Scalar) / sizeof(Scalar)))
                                       : int(StrideType::OuterStrideAtCompileTime)
      };
    };
  }  // namespace internal
  template <typename ViewOp, typename MatrixType, typename StrideType, typename StorageKind>
  class CwiseUnaryViewImpl;
  template <typename ViewOp, typename MatrixType, typename StrideType>
  class CwiseUnaryView
      : public CwiseUnaryViewImpl<ViewOp, MatrixType, StrideType, typename internal::traits<MatrixType>::StorageKind> {
  public:
    typedef
        typename CwiseUnaryViewImpl<ViewOp, MatrixType, StrideType, typename internal::traits<MatrixType>::StorageKind>::
            Base Base;
    typedef typename Eigen::internal::traits<CwiseUnaryView>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CwiseUnaryView>::type Nested;
    typedef typename Eigen::internal::traits<CwiseUnaryView>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CwiseUnaryView>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CwiseUnaryView>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CwiseUnaryView>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CwiseUnaryView>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename internal::ref_selector<MatrixType>::non_const_type MatrixTypeNested;
    typedef internal::remove_all_t<MatrixType> NestedExpression;
    explicit inline CwiseUnaryView(MatrixType& mat, const ViewOp& func = ViewOp()) : m_matrix(mat), m_functor(func) {}
    using Base::operator=;
    inline CwiseUnaryView& operator=(const CwiseUnaryView& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline CwiseUnaryView& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    CwiseUnaryView(const CwiseUnaryView&) = default;
    inline constexpr Index rows() const noexcept { return m_matrix.rows(); }
    inline constexpr Index cols() const noexcept { return m_matrix.cols(); }
    const ViewOp& functor() const { return m_functor; }
    const internal::remove_all_t<MatrixTypeNested>& nestedExpression() const { return m_matrix; }
    std::remove_reference_t<MatrixTypeNested>& nestedExpression() { return m_matrix; }

  protected:
    MatrixTypeNested m_matrix;
    ViewOp m_functor;
  };
  template <typename ViewOp, typename XprType, typename StrideType, typename StorageKind>
  class CwiseUnaryViewImpl : public internal::generic_xpr_base<CwiseUnaryView<ViewOp, XprType, StrideType>>::type {
  public:
    typedef typename internal::generic_xpr_base<CwiseUnaryView<ViewOp, XprType, StrideType>>::type Base;
  };
  template <typename ViewOp, typename MatrixType, typename StrideType>
  class CwiseUnaryViewImpl<ViewOp, MatrixType, StrideType, Dense>
      : public internal::dense_xpr_base<CwiseUnaryView<ViewOp, MatrixType, StrideType>>::type {
  public:
    typedef CwiseUnaryView<ViewOp, MatrixType, StrideType> Derived;
    typedef typename internal::dense_xpr_base<CwiseUnaryView<ViewOp, MatrixType, StrideType>>::type Base;
    typedef typename Eigen::internal::traits<Derived>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Derived>::type Nested;
    typedef typename Eigen::internal::traits<Derived>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Derived>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Derived>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Derived>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    using Base::operator=;
    inline CwiseUnaryViewImpl& operator=(const CwiseUnaryViewImpl& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline CwiseUnaryViewImpl& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    CwiseUnaryViewImpl(const CwiseUnaryViewImpl&) = default;
    inline Scalar* data() { return &(this->coeffRef(0)); }
    inline const Scalar* data() const { return &(this->coeff(0)); }
    constexpr inline Index innerStride() const {
      return StrideType::InnerStrideAtCompileTime != 0
                 ? int(StrideType::InnerStrideAtCompileTime)
                 : derived().nestedExpression().innerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) /
                       sizeof(Scalar);
    }
    constexpr inline Index outerStride() const {
      return StrideType::OuterStrideAtCompileTime != 0
                 ? int(StrideType::OuterStrideAtCompileTime)
                 : derived().nestedExpression().outerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) /
                       sizeof(Scalar);
    }

  protected:
    CwiseUnaryViewImpl() = default;
    ~CwiseUnaryViewImpl() = default;
  };
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  inline Derived& DenseBase<Derived>::operator*=(const Scalar& other) {
    internal::call_assignment(
        this->derived(), PlainObject::Constant(rows(), cols(), other), internal::mul_assign_op<Scalar, Scalar>());
    return derived();
  }
  template <typename Derived>
  inline Derived& ArrayBase<Derived>::operator+=(const Scalar& other) {
    internal::call_assignment(
        this->derived(), PlainObject::Constant(rows(), cols(), other), internal::add_assign_op<Scalar, Scalar>());
    return derived();
  }
  template <typename Derived>
  inline Derived& ArrayBase<Derived>::operator-=(const Scalar& other) {
    internal::call_assignment(
        this->derived(), PlainObject::Constant(rows(), cols(), other), internal::sub_assign_op<Scalar, Scalar>());
    return derived();
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::operator/=(const Scalar& other) {
    internal::call_assignment(
        this->derived(), PlainObject::Constant(rows(), cols(), other), internal::div_assign_op<Scalar, Scalar>());
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename T,
              typename U,
              bool NeedToTranspose = T::IsVectorAtCompileTime && U::IsVectorAtCompileTime &&
                                     ((int(T::RowsAtCompileTime) == 1 && int(U::ColsAtCompileTime) == 1) ||
                                      (int(T::ColsAtCompileTime) == 1 && int(U::RowsAtCompileTime) == 1))>
    struct dot_nocheck {
      typedef scalar_conj_product_op<typename traits<T>::Scalar, typename traits<U>::Scalar> conj_prod;
      typedef typename conj_prod::result_type ResScalar;
      inline static ResScalar run(const MatrixBase<T>& a, const MatrixBase<U>& b) {
        return a.template binaryExpr<conj_prod>(b).sum();
      }
    };
    template <typename T, typename U>
    struct dot_nocheck<T, U, true> {
      typedef scalar_conj_product_op<typename traits<T>::Scalar, typename traits<U>::Scalar> conj_prod;
      typedef typename conj_prod::result_type ResScalar;
      inline static ResScalar run(const MatrixBase<T>& a, const MatrixBase<U>& b) {
        return a.transpose().template binaryExpr<conj_prod>(b).sum();
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename OtherDerived>
  inline typename ScalarBinaryOpTraits<typename internal::traits<Derived>::Scalar,
                                       typename internal::traits<OtherDerived>::Scalar>::ReturnType
  MatrixBase<Derived>::dot(const MatrixBase<OtherDerived>& other) const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    static_assert(
        (int(Derived::SizeAtCompileTime) == Eigen::Dynamic || int(OtherDerived::SizeAtCompileTime) == Eigen::Dynamic ||
         int(Derived::SizeAtCompileTime) == int(OtherDerived::SizeAtCompileTime)),
        "YOU_MIXED_VECTORS_OF_DIFFERENT_SIZES");
    typedef internal::scalar_conj_product_op<Scalar, typename OtherDerived::Scalar> func;
    static_assert(
        (Eigen::internal::has_ReturnType<ScalarBinaryOpTraits<Scalar, typename OtherDerived::Scalar, func>>::value),
        "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_"
        "EXPLICITLY");
    ;
    (static_cast<bool>(size() == other.size())
         ? void(0)
         : __assert_fail("size() == other.size()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Dot.h",
                         79,
                         __extension__ __PRETTY_FUNCTION__));
    return internal::dot_nocheck<Derived, OtherDerived>::run(*this, other);
  }
  template <typename Derived>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::squaredNorm() const {
    return numext::real((*this).cwiseAbs2().sum());
  }
  template <typename Derived>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::norm() const {
    return numext::sqrt(squaredNorm());
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::PlainObject MatrixBase<Derived>::normalized() const {
    typedef typename internal::nested_eval<Derived, 2>::type Nested_;
    Nested_ n(derived());
    RealScalar z = n.squaredNorm();
    if (z > RealScalar(0))
      return n / numext::sqrt(z);
    else
      return n;
  }
  template <typename Derived>
  inline void MatrixBase<Derived>::normalize() {
    RealScalar z = squaredNorm();
    if (z > RealScalar(0))
      derived() /= numext::sqrt(z);
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::PlainObject MatrixBase<Derived>::stableNormalized() const {
    typedef typename internal::nested_eval<Derived, 3>::type Nested_;
    Nested_ n(derived());
    RealScalar w = n.cwiseAbs().maxCoeff();
    RealScalar z = (n / w).squaredNorm();
    if (z > RealScalar(0))
      return n / (numext::sqrt(z) * w);
    else
      return n;
  }
  template <typename Derived>
  inline void MatrixBase<Derived>::stableNormalize() {
    RealScalar w = cwiseAbs().maxCoeff();
    RealScalar z = (derived() / w).squaredNorm();
    if (z > RealScalar(0))
      derived() /= numext::sqrt(z) * w;
  }
  namespace internal {
    template <typename Derived, int p>
    struct lpNorm_selector {
      typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
      static inline RealScalar run(const MatrixBase<Derived>& m) {
        using std::pow;
        return pow(m.cwiseAbs().array().pow(p).sum(), RealScalar(1) / p);
      }
    };
    template <typename Derived>
    struct lpNorm_selector<Derived, 1> {
      static inline typename NumTraits<typename traits<Derived>::Scalar>::Real run(const MatrixBase<Derived>& m) {
        return m.cwiseAbs().sum();
      }
    };
    template <typename Derived>
    struct lpNorm_selector<Derived, 2> {
      static inline typename NumTraits<typename traits<Derived>::Scalar>::Real run(const MatrixBase<Derived>& m) {
        return m.norm();
      }
    };
    template <typename Derived>
    struct lpNorm_selector<Derived, Infinity> {
      typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
      static inline RealScalar run(const MatrixBase<Derived>& m) {
        if (Derived::SizeAtCompileTime == 0 || (Derived::SizeAtCompileTime == Dynamic && m.size() == 0))
          return RealScalar(0);
        return m.cwiseAbs().maxCoeff();
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <int p>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::lpNorm() const {
    return internal::lpNorm_selector<Derived, p>::run(*this);
  }
  template <typename Derived>
  template <typename OtherDerived>
  bool MatrixBase<Derived>::isOrthogonal(const MatrixBase<OtherDerived>& other, const RealScalar& prec) const {
    typename internal::nested_eval<Derived, 2>::type nested(derived());
    typename internal::nested_eval<OtherDerived, 2>::type otherNested(other.derived());
    return numext::abs2(nested.dot(otherNested)) <= prec * prec * nested.squaredNorm() * otherNested.squaredNorm();
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isUnitary(const RealScalar& prec) const {
    typename internal::nested_eval<Derived, 1>::type self(derived());
    for (Index i = 0; i < cols(); ++i) {
      if (!internal::isApprox(self.col(i).squaredNorm(), static_cast<RealScalar>(1), prec))
        return false;
      for (Index j = 0; j < i; ++j)
        if (!internal::isMuchSmallerThan(self.col(i).dot(self.col(j)), static_cast<Scalar>(1), prec))
          return false;
    }
    return true;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename ExpressionType, typename Scalar>
    inline void stable_norm_kernel(const ExpressionType& bl, Scalar& ssq, Scalar& scale, Scalar& invScale) {
      Scalar maxCoeff = bl.cwiseAbs().maxCoeff();
      if (maxCoeff > scale) {
        ssq = ssq * numext::abs2(scale / maxCoeff);
        Scalar tmp = Scalar(1) / maxCoeff;
        if (tmp > NumTraits<Scalar>::highest()) {
          invScale = NumTraits<Scalar>::highest();
          scale = Scalar(1) / invScale;
        } else if (maxCoeff > NumTraits<Scalar>::highest()) {
          invScale = Scalar(1);
          scale = maxCoeff;
        } else {
          scale = maxCoeff;
          invScale = tmp;
        }
      } else if (maxCoeff != maxCoeff) {
        scale = maxCoeff;
      }
      if (scale > Scalar(0))
        ssq += (bl * invScale).squaredNorm();
    }
    template <typename VectorType, typename RealScalar>
    void stable_norm_impl_inner_step(const VectorType& vec, RealScalar& ssq, RealScalar& scale, RealScalar& invScale) {
      typedef typename VectorType::Scalar Scalar;
      const Index blockSize = 4096;
      typedef typename internal::nested_eval<VectorType, 2>::type VectorTypeCopy;
      typedef internal::remove_all_t<VectorTypeCopy> VectorTypeCopyClean;
      const VectorTypeCopy copy(vec);
      enum {
        CanAlign = ((int(VectorTypeCopyClean::Flags) & DirectAccessBit) ||
                    (int(internal::evaluator<VectorTypeCopyClean>::Alignment) > 0)) &&
                   (blockSize * sizeof(Scalar) * 2 < 131072) && (16 > 0)
      };
      typedef std::conditional_t<
          CanAlign,
          Ref<const Matrix<Scalar, Dynamic, 1, 0, blockSize, 1>, internal::evaluator<VectorTypeCopyClean>::Alignment>,
          typename VectorTypeCopyClean::ConstSegmentReturnType>
          SegmentWrapper;
      Index n = vec.size();
      Index bi = internal::first_default_aligned(copy);
      if (bi > 0)
        internal::stable_norm_kernel(copy.head(bi), ssq, scale, invScale);
      for (; bi < n; bi += blockSize)
        internal::stable_norm_kernel(
            SegmentWrapper(copy.segment(bi, numext::mini(blockSize, n - bi))), ssq, scale, invScale);
    }
    template <typename VectorType>
    typename VectorType::RealScalar stable_norm_impl(const VectorType& vec,
                                                     std::enable_if_t<VectorType::IsVectorAtCompileTime>* = 0) {
      using std::abs;
      using std::sqrt;
      Index n = vec.size();
      if (n == 1)
        return abs(vec.coeff(0));
      typedef typename VectorType::RealScalar RealScalar;
      RealScalar scale(0);
      RealScalar invScale(1);
      RealScalar ssq(0);
      stable_norm_impl_inner_step(vec, ssq, scale, invScale);
      return scale * sqrt(ssq);
    }
    template <typename MatrixType>
    typename MatrixType::RealScalar stable_norm_impl(const MatrixType& mat,
                                                     std::enable_if_t<!MatrixType::IsVectorAtCompileTime>* = 0) {
      using std::sqrt;
      typedef typename MatrixType::RealScalar RealScalar;
      RealScalar scale(0);
      RealScalar invScale(1);
      RealScalar ssq(0);
      for (Index j = 0; j < mat.outerSize(); ++j)
        stable_norm_impl_inner_step(mat.innerVector(j), ssq, scale, invScale);
      return scale * sqrt(ssq);
    }
    template <typename Derived>
    inline typename NumTraits<typename traits<Derived>::Scalar>::Real blueNorm_impl(const EigenBase<Derived>& _vec) {
      typedef typename Derived::RealScalar RealScalar;
      using std::abs;
      using std::pow;
      using std::sqrt;
      static const int ibeta = std::numeric_limits<RealScalar>::radix;
      static const int it = NumTraits<RealScalar>::digits();
      static const int iemin = NumTraits<RealScalar>::min_exponent();
      static const int iemax = NumTraits<RealScalar>::max_exponent();
      static const RealScalar rbig = NumTraits<RealScalar>::highest();
      static const RealScalar b1 = RealScalar(pow(RealScalar(ibeta), RealScalar(-((1 - iemin) / 2))));
      static const RealScalar b2 = RealScalar(pow(RealScalar(ibeta), RealScalar((iemax + 1 - it) / 2)));
      static const RealScalar s1m = RealScalar(pow(RealScalar(ibeta), RealScalar((2 - iemin) / 2)));
      static const RealScalar s2m = RealScalar(pow(RealScalar(ibeta), RealScalar(-((iemax + it) / 2))));
      static const RealScalar eps = RealScalar(pow(double(ibeta), 1 - it));
      static const RealScalar relerr = sqrt(eps);
      const Derived& vec(_vec.derived());
      Index n = vec.size();
      RealScalar ab2 = b2 / RealScalar(n);
      RealScalar asml = RealScalar(0);
      RealScalar amed = RealScalar(0);
      RealScalar abig = RealScalar(0);
      for (Index j = 0; j < vec.outerSize(); ++j) {
        for (typename Derived::InnerIterator iter(vec, j); iter; ++iter) {
          RealScalar ax = abs(iter.value());
          if (ax > ab2)
            abig += numext::abs2(ax * s2m);
          else if (ax < b1)
            asml += numext::abs2(ax * s1m);
          else
            amed += numext::abs2(ax);
        }
      }
      if (amed != amed)
        return amed;
      if (abig > RealScalar(0)) {
        abig = sqrt(abig);
        if (abig > rbig)
          return abig;
        if (amed > RealScalar(0)) {
          abig = abig / s2m;
          amed = sqrt(amed);
        } else
          return abig / s2m;
      } else if (asml > RealScalar(0)) {
        if (amed > RealScalar(0)) {
          abig = sqrt(amed);
          amed = sqrt(asml) / s1m;
        } else
          return sqrt(asml) / s1m;
      } else
        return sqrt(amed);
      asml = numext::mini(abig, amed);
      abig = numext::maxi(abig, amed);
      if (asml <= abig * relerr)
        return abig;
      else
        return abig * sqrt(RealScalar(1) + numext::abs2(asml / abig));
    }
  }  // namespace internal
  template <typename Derived>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::stableNorm() const {
    return internal::stable_norm_impl(derived());
  }
  template <typename Derived>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::blueNorm() const {
    return internal::blueNorm_impl(*this);
  }
  template <typename Derived>
  inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::hypotNorm() const {
    if (size() == 1)
      return numext::abs(coeff(0, 0));
    else
      return this->cwiseAbs().redux(internal::scalar_hypot_op<RealScalar>());
  }
}  // namespace Eigen

namespace Eigen {
  template <int OuterStrideAtCompileTime_, int InnerStrideAtCompileTime_>
  class Stride {
  public:
    typedef Eigen::Index Index;
    enum { InnerStrideAtCompileTime = InnerStrideAtCompileTime_, OuterStrideAtCompileTime = OuterStrideAtCompileTime_ };
    Stride() : m_outer(OuterStrideAtCompileTime), m_inner(InnerStrideAtCompileTime) {
      (static_cast<bool>(InnerStrideAtCompileTime != Dynamic && OuterStrideAtCompileTime != Dynamic)
           ? void(0)
           : __assert_fail("InnerStrideAtCompileTime != Dynamic && OuterStrideAtCompileTime != Dynamic",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Stride.h",
                           70,
                           __extension__ __PRETTY_FUNCTION__));
    }
    Stride(Index outerStride, Index innerStride) : m_outer(outerStride), m_inner(innerStride) {}
    Stride(const Stride& other) : m_outer(other.outer()), m_inner(other.inner()) {}
    constexpr inline Index outer() const { return m_outer.value(); }
    constexpr inline Index inner() const { return m_inner.value(); }

  protected:
    internal::variable_if_dynamic<Index, OuterStrideAtCompileTime> m_outer;
    internal::variable_if_dynamic<Index, InnerStrideAtCompileTime> m_inner;
  };
  template <int Value>
  class InnerStride : public Stride<0, Value> {
    typedef Stride<0, Value> Base;

  public:
    InnerStride() : Base() {}
    InnerStride(Index v) : Base(0, v) {}
  };
  template <int Value>
  class OuterStride : public Stride<Value, 0> {
    typedef Stride<Value, 0> Base;

  public:
    OuterStride() : Base() {}
    OuterStride(Index v) : Base(v, 0) {}
  };
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  class MapBase<Derived, ReadOnlyAccessors> : public internal::dense_xpr_base<Derived>::type {
  public:
    typedef typename internal::dense_xpr_base<Derived>::type Base;
    enum {
      RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
      InnerStrideAtCompileTime = internal::traits<Derived>::InnerStrideAtCompileTime,
      SizeAtCompileTime = Base::SizeAtCompileTime
    };
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef std::conditional_t<bool(internal::is_lvalue<Derived>::value), Scalar*, const Scalar*> PointerType;
    using Base::coeff;
    using Base::coeffRef;
    using Base::cols;
    using Base::colStride;
    using Base::derived;
    using Base::eval;
    using Base::Flags;
    using Base::innerStride;
    using Base::IsRowMajor;
    using Base::IsVectorAtCompileTime;
    using Base::lazyAssign;
    using Base::MaxColsAtCompileTime;
    using Base::MaxRowsAtCompileTime;
    using Base::MaxSizeAtCompileTime;
    using Base::outerStride;
    using Base::rows;
    using Base::rowStride;
    using Base::size;
    using Base::operator=;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    constexpr inline Index rows() const noexcept { return m_rows.value(); }
    constexpr inline Index cols() const noexcept { return m_cols.value(); }
    inline const Scalar* data() const { return m_data; }
    inline const Scalar& coeff(Index rowId, Index colId) const {
      return m_data[colId * colStride() + rowId * rowStride()];
    }
    inline const Scalar& coeff(Index index) const {
      static_assert((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime,
                    "YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT");
      return m_data[index * innerStride()];
    }
    inline const Scalar& coeffRef(Index rowId, Index colId) const {
      return this->m_data[colId * colStride() + rowId * rowStride()];
    }
    inline const Scalar& coeffRef(Index index) const {
      static_assert((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime,
                    "YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT");
      return this->m_data[index * innerStride()];
    }
    template <int LoadMode>
    inline PacketScalar packet(Index rowId, Index colId) const {
      return internal::ploadt<PacketScalar, LoadMode>(m_data + (colId * colStride() + rowId * rowStride()));
    }
    template <int LoadMode>
    inline PacketScalar packet(Index index) const {
      static_assert((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime,
                    "YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT");
      return internal::ploadt<PacketScalar, LoadMode>(m_data + index * innerStride());
    }
    explicit inline MapBase(PointerType dataPtr)
        : m_data(dataPtr), m_rows(RowsAtCompileTime), m_cols(ColsAtCompileTime) {
      static_assert(Derived::SizeAtCompileTime != Eigen::Dynamic,
                    "YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR");
      checkSanity<Derived>();
    }
    inline MapBase(PointerType dataPtr, Index vecSize)
        : m_data(dataPtr),
          m_rows(RowsAtCompileTime == Dynamic ? vecSize : Index(RowsAtCompileTime)),
          m_cols(ColsAtCompileTime == Dynamic ? vecSize : Index(ColsAtCompileTime)) {
      static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      (static_cast<bool>(vecSize >= 0)
           ? void(0)
           : __assert_fail("vecSize >= 0",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/MapBase.h",
                           168,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(dataPtr == 0 || SizeAtCompileTime == Dynamic || SizeAtCompileTime == vecSize)
           ? void(0)
           : __assert_fail("dataPtr == 0 || SizeAtCompileTime == Dynamic || SizeAtCompileTime == vecSize",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/MapBase.h",
                           169,
                           __extension__ __PRETTY_FUNCTION__));
      checkSanity<Derived>();
    }
    inline MapBase(PointerType dataPtr, Index rows, Index cols) : m_data(dataPtr), m_rows(rows), m_cols(cols) {
      (static_cast<bool>((dataPtr == 0) || (rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) &&
                                            cols >= 0 && (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols)))
           ? void(0)
           : __assert_fail("(dataPtr == 0) || ( rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == "
                           "rows) && cols >= 0 && (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols))",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/MapBase.h",
                           180,
                           __extension__ __PRETTY_FUNCTION__));
      checkSanity<Derived>();
    }

  protected:
    MapBase(const MapBase&) = default;
    MapBase() = default;
    ~MapBase() = default;
    template <typename T>
    void checkSanity(std::enable_if_t<(internal::traits<T>::Alignment > 0), void*> = 0) const {
      const Index minInnerStride = InnerStrideAtCompileTime == Dynamic ? 1 : Index(InnerStrideAtCompileTime);
      ;
      (static_cast<bool>((((internal::UIntPtr(m_data) % internal::traits<Derived>::Alignment) == 0) ||
                          (cols() * rows() * minInnerStride * sizeof(Scalar)) < internal::traits<Derived>::Alignment) &&
                         "data is not aligned")
           ? void(0)
           : __assert_fail(
                 "( ((internal::UIntPtr(m_data) % internal::traits<Derived>::Alignment) == 0) || (cols() * rows() * "
                 "minInnerStride * sizeof(Scalar)) < internal::traits<Derived>::Alignment ) && \"data is not aligned\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/MapBase.h",
                 201,
                 __extension__ __PRETTY_FUNCTION__));
    }
    template <typename T>
    void checkSanity(std::enable_if_t<internal::traits<T>::Alignment == 0, void*> = 0) const {}
    PointerType m_data;
    const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
    const internal::variable_if_dynamic<Index, ColsAtCompileTime> m_cols;
  };
  template <typename Derived>
  class MapBase<Derived, WriteAccessors> : public MapBase<Derived, ReadOnlyAccessors> {
    typedef MapBase<Derived, ReadOnlyAccessors> ReadOnlyMapBase;

  public:
    typedef MapBase<Derived, ReadOnlyAccessors> Base;
    typedef typename Base::Scalar Scalar;
    typedef typename Base::PacketScalar PacketScalar;
    typedef typename Base::StorageIndex StorageIndex;
    typedef typename Base::PointerType PointerType;
    using Base::coeff;
    using Base::coeffRef;
    using Base::cols;
    using Base::colStride;
    using Base::derived;
    using Base::innerStride;
    using Base::outerStride;
    using Base::rows;
    using Base::rowStride;
    using Base::size;
    typedef std::conditional_t<internal::is_lvalue<Derived>::value, Scalar, const Scalar> ScalarWithConstIfNotLvalue;
    inline const Scalar* data() const { return this->m_data; }
    inline ScalarWithConstIfNotLvalue* data() { return this->m_data; }
    inline ScalarWithConstIfNotLvalue& coeffRef(Index row, Index col) {
      return this->m_data[col * colStride() + row * rowStride()];
    }
    inline ScalarWithConstIfNotLvalue& coeffRef(Index index) {
      static_assert((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime,
                    "YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT");
      return this->m_data[index * innerStride()];
    }
    template <int StoreMode>
    inline void writePacket(Index row, Index col, const PacketScalar& val) {
      internal::pstoret<Scalar, PacketScalar, StoreMode>(this->m_data + (col * colStride() + row * rowStride()), val);
    }
    template <int StoreMode>
    inline void writePacket(Index index, const PacketScalar& val) {
      static_assert((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime,
                    "YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT");
      internal::pstoret<Scalar, PacketScalar, StoreMode>(this->m_data + index * innerStride(), val);
    }
    explicit inline MapBase(PointerType dataPtr) : Base(dataPtr) {}
    inline MapBase(PointerType dataPtr, Index vecSize) : Base(dataPtr, vecSize) {}
    inline MapBase(PointerType dataPtr, Index rows, Index cols) : Base(dataPtr, rows, cols) {}
    Derived& operator=(const MapBase& other) {
      ReadOnlyMapBase::Base::operator=(other);
      return derived();
    }
    using ReadOnlyMapBase::Base::operator=;

  protected:
    MapBase(const MapBase&) = default;
    MapBase() = default;
    ~MapBase() = default;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename PlainObjectType, int MapOptions, typename StrideType>
    struct traits<Map<PlainObjectType, MapOptions, StrideType>> : public traits<PlainObjectType> {
      typedef traits<PlainObjectType> TraitsBase;
      enum {
        PlainObjectTypeInnerSize = ((traits<PlainObjectType>::Flags & RowMajorBit) == RowMajorBit)
                                       ? PlainObjectType::ColsAtCompileTime
                                       : PlainObjectType::RowsAtCompileTime,
        InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
                                       ? int(PlainObjectType::InnerStrideAtCompileTime)
                                       : int(StrideType::InnerStrideAtCompileTime),
        OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
                                       ? (InnerStrideAtCompileTime == Dynamic || PlainObjectTypeInnerSize == Dynamic
                                              ? Dynamic
                                              : int(InnerStrideAtCompileTime) * int(PlainObjectTypeInnerSize))
                                       : int(StrideType::OuterStrideAtCompileTime),
        Alignment = int(MapOptions) & int(AlignedMask),
        Flags0 = TraitsBase::Flags & (~NestByRefBit),
        Flags = is_lvalue<PlainObjectType>::value ? int(Flags0) : (int(Flags0) & ~LvalueBit)
      };

    private:
      enum { Options };
    };
  }  // namespace internal
  template <typename PlainObjectType, int MapOptions, typename StrideType>
  class Map : public MapBase<Map<PlainObjectType, MapOptions, StrideType>> {
  public:
    typedef MapBase<Map> Base;
    typedef typename Eigen::internal::traits<Map>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Map>::type Nested;
    typedef typename Eigen::internal::traits<Map>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Map>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Map>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Map>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Map>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    typedef typename Base::PointerType PointerType;
    typedef PointerType PointerArgType;
    inline PointerType cast_to_pointer_type(PointerArgType ptr) { return ptr; }
    constexpr inline Index innerStride() const {
      return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
    }
    constexpr inline Index outerStride() const {
      return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
             : internal::traits<Map>::OuterStrideAtCompileTime != Dynamic
                 ? Index(internal::traits<Map>::OuterStrideAtCompileTime)
             : IsVectorAtCompileTime    ? (this->size() * innerStride())
             : int(Flags) & RowMajorBit ? (this->cols() * innerStride())
                                        : (this->rows() * innerStride());
    }
    explicit inline Map(PointerArgType dataPtr, const StrideType& stride = StrideType())
        : Base(cast_to_pointer_type(dataPtr)), m_stride(stride) {}
    inline Map(PointerArgType dataPtr, Index size, const StrideType& stride = StrideType())
        : Base(cast_to_pointer_type(dataPtr), size), m_stride(stride) {}
    inline Map(PointerArgType dataPtr, Index rows, Index cols, const StrideType& stride = StrideType())
        : Base(cast_to_pointer_type(dataPtr), rows, cols), m_stride(stride) {}
    using Base::operator=;
    inline Map& operator=(const Map& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Map& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Map(const Map&) = default;

  protected:
    StrideType m_stride;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename PlainObjectType_, int Options_, typename StrideType_>
    struct traits<Ref<PlainObjectType_, Options_, StrideType_>>
        : public traits<Map<PlainObjectType_, Options_, StrideType_>> {
      typedef PlainObjectType_ PlainObjectType;
      typedef StrideType_ StrideType;
      enum {
        Options = Options_,
        Flags = traits<Map<PlainObjectType_, Options_, StrideType_>>::Flags | NestByRefBit,
        Alignment = traits<Map<PlainObjectType_, Options_, StrideType_>>::Alignment
      };
      template <typename Derived>
      struct match {
        enum {
          IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime || Derived::IsVectorAtCompileTime,
          HasDirectAccess = internal::has_direct_access<Derived>::ret,
          StorageOrderMatch =
              IsVectorAtCompileTime || ((PlainObjectType::Flags & RowMajorBit) == (Derived::Flags & RowMajorBit)),
          InnerStrideMatch =
              int(StrideType::InnerStrideAtCompileTime) == int(Dynamic) ||
              int(StrideType::InnerStrideAtCompileTime) == int(Derived::InnerStrideAtCompileTime) ||
              (int(StrideType::InnerStrideAtCompileTime) == 0 && int(Derived::InnerStrideAtCompileTime) == 1),
          OuterStrideMatch = IsVectorAtCompileTime || int(StrideType::OuterStrideAtCompileTime) == int(Dynamic) ||
                             int(StrideType::OuterStrideAtCompileTime) == int(Derived::OuterStrideAtCompileTime),
          DerivedAlignment = int(evaluator<Derived>::Alignment),
          AlignmentMatch =
              (int(traits<PlainObjectType>::Alignment) == int(Unaligned)) || (DerivedAlignment >= int(Alignment)),
          ScalarTypeMatch = internal::is_same<typename PlainObjectType::Scalar, typename Derived::Scalar>::value,
          MatchAtCompileTime = HasDirectAccess && StorageOrderMatch && InnerStrideMatch && OuterStrideMatch &&
                               AlignmentMatch && ScalarTypeMatch
        };
        typedef std::conditional_t<MatchAtCompileTime, internal::true_type, internal::false_type> type;
      };
    };
    template <typename Derived>
    struct traits<RefBase<Derived>> : public traits<Derived> {};
  }  // namespace internal
  template <typename Derived>
  class RefBase : public MapBase<Derived> {
    typedef typename internal::traits<Derived>::PlainObjectType PlainObjectType;
    typedef typename internal::traits<Derived>::StrideType StrideType;

  public:
    typedef MapBase<Derived> Base;
    typedef typename Eigen::internal::traits<RefBase>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<RefBase>::type Nested;
    typedef typename Eigen::internal::traits<RefBase>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<RefBase>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<RefBase>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<RefBase>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<RefBase>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    constexpr inline Index innerStride() const {
      return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
    }
    constexpr inline Index outerStride() const {
      return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
             : IsVectorAtCompileTime                   ? this->size()
             : int(Flags) & RowMajorBit                ? this->cols()
                                                       : this->rows();
    }
    RefBase()
        : Base(0,
               RowsAtCompileTime == Dynamic ? 0 : RowsAtCompileTime,
               ColsAtCompileTime == Dynamic ? 0 : ColsAtCompileTime),
          m_stride(StrideType::OuterStrideAtCompileTime == Dynamic ? 0 : StrideType::OuterStrideAtCompileTime,
                   StrideType::InnerStrideAtCompileTime == Dynamic ? 0 : StrideType::InnerStrideAtCompileTime) {}
    using Base::operator=;
    inline RefBase& operator=(const RefBase& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline RefBase& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    RefBase(const RefBase&) = default;

  protected:
    typedef Stride<StrideType::OuterStrideAtCompileTime, StrideType::InnerStrideAtCompileTime> StrideBase;
    static constexpr Index resolveInnerStride(Index inner) { return inner == 0 ? 1 : inner; }
    static constexpr Index resolveOuterStride(
        Index inner, Index outer, Index rows, Index cols, bool isVectorAtCompileTime, bool isRowMajor) {
      return outer == 0 ? isVectorAtCompileTime ? inner * rows * cols
                          : isRowMajor          ? inner * cols
                                                : inner * rows
                        : outer;
    }
    template <typename Expression>
    bool construct(Expression& expr) {
      static_assert(((int(Eigen::internal::size_of_xpr_at_compile_time<PlainObjectType>::ret) == 0 &&
                      int(Eigen::internal::size_of_xpr_at_compile_time<Expression>::ret) == 0) ||
                     ((int(PlainObjectType::RowsAtCompileTime) == Eigen::Dynamic ||
                       int(Expression::RowsAtCompileTime) == Eigen::Dynamic ||
                       int(PlainObjectType::RowsAtCompileTime) == int(Expression::RowsAtCompileTime)) &&
                      (int(PlainObjectType::ColsAtCompileTime) == Eigen::Dynamic ||
                       int(Expression::ColsAtCompileTime) == Eigen::Dynamic ||
                       int(PlainObjectType::ColsAtCompileTime) == int(Expression::ColsAtCompileTime)))) ||
                        (PlainObjectType::IsVectorAtCompileTime &&
                         ((int(PlainObjectType::RowsAtCompileTime) == Eigen::Dynamic ||
                           int(Expression::ColsAtCompileTime) == Eigen::Dynamic ||
                           int(PlainObjectType::RowsAtCompileTime) == int(Expression::ColsAtCompileTime)) &&
                          (int(PlainObjectType::ColsAtCompileTime) == Eigen::Dynamic ||
                           int(Expression::RowsAtCompileTime) == Eigen::Dynamic ||
                           int(PlainObjectType::ColsAtCompileTime) == int(Expression::RowsAtCompileTime)))),
                    "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
      Index rows = expr.rows();
      Index cols = expr.cols();
      if (PlainObjectType::RowsAtCompileTime == 1) {
        (static_cast<bool>(expr.rows() == 1 || expr.cols() == 1)
             ? void(0)
             : __assert_fail("expr.rows()==1 || expr.cols()==1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Ref.h",
                             133,
                             __extension__ __PRETTY_FUNCTION__));
        rows = 1;
        cols = expr.size();
      } else if (PlainObjectType::ColsAtCompileTime == 1) {
        (static_cast<bool>(expr.rows() == 1 || expr.cols() == 1)
             ? void(0)
             : __assert_fail("expr.rows()==1 || expr.cols()==1",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Ref.h",
                             139,
                             __extension__ __PRETTY_FUNCTION__));
        rows = expr.size();
        cols = 1;
      }
      (static_cast<bool>((PlainObjectType::RowsAtCompileTime == Dynamic) ||
                         (PlainObjectType::RowsAtCompileTime == rows))
           ? void(0)
           : __assert_fail(
                 "(PlainObjectType::RowsAtCompileTime == Dynamic) || (PlainObjectType::RowsAtCompileTime == rows)",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/Ref.h",
                 145,
                 __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>((PlainObjectType::ColsAtCompileTime == Dynamic) ||
                         (PlainObjectType::ColsAtCompileTime == cols))
           ? void(0)
           : __assert_fail(
                 "(PlainObjectType::ColsAtCompileTime == Dynamic) || (PlainObjectType::ColsAtCompileTime == cols)",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/Ref.h",
                 147,
                 __extension__ __PRETTY_FUNCTION__));
      const bool transpose = PlainObjectType::IsVectorAtCompileTime && (rows != expr.rows());
      const bool row_major = ((PlainObjectType::Flags)&RowMajorBit) != 0;
      const bool expr_row_major = (Expression::Flags & RowMajorBit) != 0;
      const bool storage_differs = (row_major != expr_row_major);
      const bool swap_stride = (transpose != storage_differs);
      const Index expr_inner_actual = resolveInnerStride(expr.innerStride());
      const Index expr_outer_actual = resolveOuterStride(expr_inner_actual,
                                                         expr.outerStride(),
                                                         expr.rows(),
                                                         expr.cols(),
                                                         Expression::IsVectorAtCompileTime != 0,
                                                         expr_row_major);
      const bool row_vector = (rows == 1);
      const bool col_vector = (cols == 1);
      const Index inner_stride =
          ((!row_major && row_vector) || (row_major && col_vector))
              ? (StrideType::InnerStrideAtCompileTime > 0 ? Index(StrideType::InnerStrideAtCompileTime) : 1)
          : swap_stride ? expr_outer_actual
                        : expr_inner_actual;
      const Index outer_stride =
          ((!row_major && col_vector) || (row_major && row_vector))
              ? (StrideType::OuterStrideAtCompileTime > 0 ? Index(StrideType::OuterStrideAtCompileTime)
                                                          : rows * cols * inner_stride)
          : swap_stride ? expr_inner_actual
                        : expr_outer_actual;
      const bool inner_valid = (StrideType::InnerStrideAtCompileTime == Dynamic) ||
                               (resolveInnerStride(Index(StrideType::InnerStrideAtCompileTime)) == inner_stride);
      if (!inner_valid) {
        return false;
      }
      const bool outer_valid = (StrideType::OuterStrideAtCompileTime == Dynamic) ||
                               (resolveOuterStride(inner_stride,
                                                   Index(StrideType::OuterStrideAtCompileTime),
                                                   rows,
                                                   cols,
                                                   PlainObjectType::IsVectorAtCompileTime != 0,
                                                   row_major) == outer_stride);
      if (!outer_valid) {
        return false;
      }
      internal::construct_at<Base>(this, expr.data(), rows, cols);
      internal::construct_at(&m_stride,
                             (StrideType::OuterStrideAtCompileTime == 0) ? 0 : outer_stride,
                             (StrideType::InnerStrideAtCompileTime == 0) ? 0 : inner_stride);
      return true;
    }
    StrideBase m_stride;
  };
  template <typename PlainObjectType, int Options, typename StrideType>
  class Ref : public RefBase<Ref<PlainObjectType, Options, StrideType>> {
  private:
    typedef internal::traits<Ref> Traits;
    template <typename Derived>
    inline Ref(const PlainObjectBase<Derived>& expr,
               std::enable_if_t<bool(Traits::template match<Derived>::MatchAtCompileTime), Derived>* = 0);

  public:
    typedef RefBase<Ref> Base;
    typedef typename Eigen::internal::traits<Ref>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Ref>::type Nested;
    typedef typename Eigen::internal::traits<Ref>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Ref>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Ref>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Ref>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Ref>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    template <typename Derived>
    inline Ref(PlainObjectBase<Derived>& expr,
               std::enable_if_t<bool(Traits::template match<Derived>::MatchAtCompileTime), Derived>* = 0) {
      static_assert(bool(Traits::template match<Derived>::MatchAtCompileTime), "STORAGE_LAYOUT_DOES_NOT_MATCH");
      ;
      const bool success = Base::construct(expr.derived());
      Eigen::internal::ignore_unused_variable(success);
      (static_cast<bool>(success)
           ? void(0)
           : __assert_fail("success",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Ref.h",
                           306,
                           __extension__ __PRETTY_FUNCTION__));
    }
    template <typename Derived>
    inline Ref(const DenseBase<Derived>& expr,
               std::enable_if_t<bool(Traits::template match<Derived>::MatchAtCompileTime), Derived>* = 0) {
      static_assert(bool(internal::is_lvalue<Derived>::value), "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      static_assert(bool(Traits::template match<Derived>::MatchAtCompileTime), "STORAGE_LAYOUT_DOES_NOT_MATCH");
      ;
      static_assert(!Derived::IsPlainObjectBase, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      const bool success = Base::construct(expr.const_cast_derived());
      Eigen::internal::ignore_unused_variable(success);
      (static_cast<bool>(success)
           ? void(0)
           : __assert_fail("success",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Ref.h",
                           323,
                           __extension__ __PRETTY_FUNCTION__));
    }
    using Base::operator=;
    inline Ref& operator=(const Ref& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Ref& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Ref(const Ref&) = default;
  };
  template <typename TPlainObjectType, int Options, typename StrideType>
  class Ref<const TPlainObjectType, Options, StrideType>
      : public RefBase<Ref<const TPlainObjectType, Options, StrideType>> {
    typedef internal::traits<Ref> Traits;

  public:
    typedef RefBase<Ref> Base;
    typedef typename Eigen::internal::traits<Ref>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Ref>::type Nested;
    typedef typename Eigen::internal::traits<Ref>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Ref>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Ref>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Ref>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Ref>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    template <typename Derived>
    inline Ref(const DenseBase<Derived>& expr,
               std::enable_if_t<bool(Traits::template match<Derived>::ScalarTypeMatch), Derived>* = 0) {
      construct(expr.derived(), typename Traits::template match<Derived>::type());
    }
    inline Ref(const Ref& other) : Base(other) {}
    template <typename OtherRef>
    inline Ref(const RefBase<OtherRef>& other) {
      construct(other.derived(), typename Traits::template match<OtherRef>::type());
    }

  protected:
    template <typename Expression>
    void construct(const Expression& expr, internal::true_type) {
      if (!Base::construct(expr)) {
        construct(expr, internal::false_type());
      }
    }
    template <typename Expression>
    void construct(const Expression& expr, internal::false_type) {
      internal::call_assignment_no_alias(m_object, expr, internal::assign_op<Scalar, Scalar>());
      Base::construct(m_object);
    }

  protected:
    TPlainObjectType m_object;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
    struct traits<Block<XprType, BlockRows, BlockCols, InnerPanel>> : traits<XprType> {
      typedef typename traits<XprType>::Scalar Scalar;
      typedef typename traits<XprType>::StorageKind StorageKind;
      typedef typename traits<XprType>::XprKind XprKind;
      typedef typename ref_selector<XprType>::type XprTypeNested;
      typedef std::remove_reference_t<XprTypeNested> XprTypeNested_;
      enum {
        MatrixRows = traits<XprType>::RowsAtCompileTime,
        MatrixCols = traits<XprType>::ColsAtCompileTime,
        RowsAtCompileTime = MatrixRows == 0 ? 0 : BlockRows,
        ColsAtCompileTime = MatrixCols == 0 ? 0 : BlockCols,
        MaxRowsAtCompileTime = BlockRows == 0                 ? 0
                               : RowsAtCompileTime != Dynamic ? int(RowsAtCompileTime)
                                                              : int(traits<XprType>::MaxRowsAtCompileTime),
        MaxColsAtCompileTime = BlockCols == 0                 ? 0
                               : ColsAtCompileTime != Dynamic ? int(ColsAtCompileTime)
                                                              : int(traits<XprType>::MaxColsAtCompileTime),
        XprTypeIsRowMajor = (int(traits<XprType>::Flags) & RowMajorBit) != 0,
        IsRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? 1
                     : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
                                                                                : XprTypeIsRowMajor,
        HasSameStorageOrderAsXprType = (IsRowMajor == XprTypeIsRowMajor),
        InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
        InnerStrideAtCompileTime = HasSameStorageOrderAsXprType ? int(inner_stride_at_compile_time<XprType>::ret)
                                                                : int(outer_stride_at_compile_time<XprType>::ret),
        OuterStrideAtCompileTime = HasSameStorageOrderAsXprType ? int(outer_stride_at_compile_time<XprType>::ret)
                                                                : int(inner_stride_at_compile_time<XprType>::ret),
        FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
        FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
        Flags = (traits<XprType>::Flags & (DirectAccessBit | (InnerPanel ? CompressedAccessBit : 0))) | FlagsLvalueBit |
                FlagsRowMajorBit,
        Alignment = 0
      };
    };
    template <typename XprType,
              int BlockRows = Dynamic,
              int BlockCols = Dynamic,
              bool InnerPanel = false,
              bool HasDirectAccess = internal::has_direct_access<XprType>::ret>
    class BlockImpl_dense;
  }  // namespace internal
  template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel, typename StorageKind>
  class BlockImpl;
  template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  class Block
      : public BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> {
    typedef BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> Impl;

  public:
    typedef Impl Base;
    typedef typename Eigen::internal::traits<Block>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Block>::type Nested;
    typedef typename Eigen::internal::traits<Block>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Block>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Block>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Block>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Block>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    using Base::operator=;
    inline Block& operator=(const Block& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Block& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Block(const Block&) = default;
    typedef internal::remove_all_t<XprType> NestedExpression;
    inline Block(XprType& xpr, Index i) : Impl(xpr, i) {
      (static_cast<bool>((i >= 0) &&
                         (((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) && i < xpr.rows()) ||
                          ((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) && i < xpr.cols())))
           ? void(0)
           : __assert_fail("(i>=0) && ( ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && i<xpr.rows()) "
                           "||((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && i<xpr.cols()))",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Block.h",
                           124,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline Block(XprType& xpr, Index startRow, Index startCol) : Impl(xpr, startRow, startCol) {
      static_assert(RowsAtCompileTime != Dynamic && ColsAtCompileTime != Dynamic, "THIS_METHOD_IS_ONLY_FOR_FIXED_SIZE");
      (static_cast<bool>(startRow >= 0 && BlockRows >= 0 && startRow + BlockRows <= xpr.rows() && startCol >= 0 &&
                         BlockCols >= 0 && startCol + BlockCols <= xpr.cols())
           ? void(0)
           : __assert_fail("startRow >= 0 && BlockRows >= 0 && startRow + BlockRows <= xpr.rows() && startCol >= 0 && "
                           "BlockCols >= 0 && startCol + BlockCols <= xpr.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Block.h",
                           135,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline Block(XprType& xpr, Index startRow, Index startCol, Index blockRows, Index blockCols)
        : Impl(xpr, startRow, startCol, blockRows, blockCols) {
      (static_cast<bool>((RowsAtCompileTime == Dynamic || RowsAtCompileTime == blockRows) &&
                         (ColsAtCompileTime == Dynamic || ColsAtCompileTime == blockCols))
           ? void(0)
           : __assert_fail("(RowsAtCompileTime==Dynamic || RowsAtCompileTime==blockRows) && "
                           "(ColsAtCompileTime==Dynamic || ColsAtCompileTime==blockCols)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Block.h",
                           147,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(startRow >= 0 && blockRows >= 0 && startRow <= xpr.rows() - blockRows && startCol >= 0 &&
                         blockCols >= 0 && startCol <= xpr.cols() - blockCols)
           ? void(0)
           : __assert_fail("startRow >= 0 && blockRows >= 0 && startRow <= xpr.rows() - blockRows && startCol >= 0 && "
                           "blockCols >= 0 && startCol <= xpr.cols() - blockCols",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Block.h",
                           149,
                           __extension__ __PRETTY_FUNCTION__));
    }
  };
  template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  class BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, Dense>
      : public internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> {
    typedef internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> Impl;
    typedef typename XprType::StorageIndex StorageIndex;

  public:
    typedef Impl Base;
    using Base::operator=;
    inline BlockImpl& operator=(const BlockImpl& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline BlockImpl& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    BlockImpl(const BlockImpl&) = default;
    inline BlockImpl(XprType& xpr, Index i) : Impl(xpr, i) {}
    inline BlockImpl(XprType& xpr, Index startRow, Index startCol) : Impl(xpr, startRow, startCol) {}
    inline BlockImpl(XprType& xpr, Index startRow, Index startCol, Index blockRows, Index blockCols)
        : Impl(xpr, startRow, startCol, blockRows, blockCols) {}
  };
  namespace internal {
    template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel, bool HasDirectAccess>
    class BlockImpl_dense : public internal::dense_xpr_base<Block<XprType, BlockRows, BlockCols, InnerPanel>>::type {
      typedef Block<XprType, BlockRows, BlockCols, InnerPanel> BlockType;
      typedef typename internal::ref_selector<XprType>::non_const_type XprTypeNested;

    public:
      typedef typename internal::dense_xpr_base<BlockType>::type Base;
      typedef typename Eigen::internal::traits<BlockType>::Scalar Scalar;
      typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
      typedef typename Base::CoeffReturnType CoeffReturnType;
      typedef typename Eigen::internal::ref_selector<BlockType>::type Nested;
      typedef typename Eigen::internal::traits<BlockType>::StorageKind StorageKind;
      typedef typename Eigen::internal::traits<BlockType>::StorageIndex StorageIndex;
      enum CompileTimeTraits {
        RowsAtCompileTime = Eigen::internal::traits<BlockType>::RowsAtCompileTime,
        ColsAtCompileTime = Eigen::internal::traits<BlockType>::ColsAtCompileTime,
        Flags = Eigen::internal::traits<BlockType>::Flags,
        SizeAtCompileTime = Base::SizeAtCompileTime,
        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
        IsVectorAtCompileTime = Base::IsVectorAtCompileTime
      };
      using Base::const_cast_derived;
      using Base::derived;
      typedef typename Base::PacketScalar PacketScalar;
      using Base::operator=;
      inline BlockImpl_dense& operator=(const BlockImpl_dense& other) {
        Base::operator=(other);
        return *this;
      }
      template <typename OtherDerived>
      inline BlockImpl_dense& operator=(const DenseBase<OtherDerived>& other) {
        Base::operator=(other.derived());
        return *this;
      }
      BlockImpl_dense(const BlockImpl_dense&) = default;
      inline BlockImpl_dense(XprType& xpr, Index i)
          : m_xpr(xpr),
            m_startRow((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) ? i : 0),
            m_startCol((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) ? i : 0),
            m_blockRows(BlockRows == 1 ? 1 : xpr.rows()),
            m_blockCols(BlockCols == 1 ? 1 : xpr.cols()) {}
      inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol)
          : m_xpr(xpr), m_startRow(startRow), m_startCol(startCol), m_blockRows(BlockRows), m_blockCols(BlockCols) {}
      inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol, Index blockRows, Index blockCols)
          : m_xpr(xpr), m_startRow(startRow), m_startCol(startCol), m_blockRows(blockRows), m_blockCols(blockCols) {}
      inline Index rows() const { return m_blockRows.value(); }
      inline Index cols() const { return m_blockCols.value(); }
      inline Scalar& coeffRef(Index rowId, Index colId) {
        static_assert(Eigen::internal::is_lvalue<XprType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
        return m_xpr.coeffRef(rowId + m_startRow.value(), colId + m_startCol.value());
      }
      inline const Scalar& coeffRef(Index rowId, Index colId) const {
        return m_xpr.derived().coeffRef(rowId + m_startRow.value(), colId + m_startCol.value());
      }
      inline const CoeffReturnType coeff(Index rowId, Index colId) const {
        return m_xpr.coeff(rowId + m_startRow.value(), colId + m_startCol.value());
      }
      inline Scalar& coeffRef(Index index) {
        static_assert(Eigen::internal::is_lvalue<XprType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
        return m_xpr.coeffRef(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                              m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
      }
      inline const Scalar& coeffRef(Index index) const {
        return m_xpr.coeffRef(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                              m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
      }
      inline const CoeffReturnType coeff(Index index) const {
        return m_xpr.coeff(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                           m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
      }
      template <int LoadMode>
      inline PacketScalar packet(Index rowId, Index colId) const {
        return m_xpr.template packet<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value());
      }
      template <int LoadMode>
      inline void writePacket(Index rowId, Index colId, const PacketScalar& val) {
        m_xpr.template writePacket<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value(), val);
      }
      template <int LoadMode>
      inline PacketScalar packet(Index index) const {
        return m_xpr.template packet<Unaligned>(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                                                m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
      }
      template <int LoadMode>
      inline void writePacket(Index index, const PacketScalar& val) {
        m_xpr.template writePacket<Unaligned>(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                                              m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0),
                                              val);
      }
      inline const internal::remove_all_t<XprTypeNested>& nestedExpression() const { return m_xpr; }
      inline XprType& nestedExpression() { return m_xpr; }
      inline constexpr StorageIndex startRow() const noexcept { return m_startRow.value(); }
      inline constexpr StorageIndex startCol() const noexcept { return m_startCol.value(); }

    protected:
      XprTypeNested m_xpr;
      const internal::variable_if_dynamic<StorageIndex,
                                          (XprType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic>
          m_startRow;
      const internal::variable_if_dynamic<StorageIndex,
                                          (XprType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic>
          m_startCol;
      const internal::variable_if_dynamic<StorageIndex, RowsAtCompileTime> m_blockRows;
      const internal::variable_if_dynamic<StorageIndex, ColsAtCompileTime> m_blockCols;
    };
    template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
    class BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel, true>
        : public MapBase<Block<XprType, BlockRows, BlockCols, InnerPanel>> {
      typedef Block<XprType, BlockRows, BlockCols, InnerPanel> BlockType;
      typedef typename internal::ref_selector<XprType>::non_const_type XprTypeNested;
      enum { XprTypeIsRowMajor = (int(traits<XprType>::Flags) & RowMajorBit) != 0 };

    public:
      typedef MapBase<BlockType> Base;
      typedef typename Eigen::internal::traits<BlockType>::Scalar Scalar;
      typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
      typedef typename Base::CoeffReturnType CoeffReturnType;
      typedef typename Eigen::internal::ref_selector<BlockType>::type Nested;
      typedef typename Eigen::internal::traits<BlockType>::StorageKind StorageKind;
      typedef typename Eigen::internal::traits<BlockType>::StorageIndex StorageIndex;
      enum CompileTimeTraits {
        RowsAtCompileTime = Eigen::internal::traits<BlockType>::RowsAtCompileTime,
        ColsAtCompileTime = Eigen::internal::traits<BlockType>::ColsAtCompileTime,
        Flags = Eigen::internal::traits<BlockType>::Flags,
        SizeAtCompileTime = Base::SizeAtCompileTime,
        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
        IsVectorAtCompileTime = Base::IsVectorAtCompileTime
      };
      using Base::const_cast_derived;
      using Base::derived;
      typedef typename Base::PacketScalar PacketScalar;
      using Base::operator=;
      inline BlockImpl_dense& operator=(const BlockImpl_dense& other) {
        Base::operator=(other);
        return *this;
      }
      template <typename OtherDerived>
      inline BlockImpl_dense& operator=(const DenseBase<OtherDerived>& other) {
        Base::operator=(other.derived());
        return *this;
      }
      BlockImpl_dense(const BlockImpl_dense&) = default;
      inline BlockImpl_dense(XprType& xpr, Index i)
          : Base(xpr.data() +
                     i * (((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor)) ||
                                  ((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) && (XprTypeIsRowMajor))
                              ? xpr.innerStride()
                              : xpr.outerStride()),
                 BlockRows == 1 ? 1 : xpr.rows(),
                 BlockCols == 1 ? 1 : xpr.cols()),
            m_xpr(xpr),
            m_startRow((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) ? i : 0),
            m_startCol((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) ? i : 0) {
        init();
      }
      inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol)
          : Base(xpr.data() + xpr.innerStride() * (XprTypeIsRowMajor ? startCol : startRow) +
                 xpr.outerStride() * (XprTypeIsRowMajor ? startRow : startCol)),
            m_xpr(xpr),
            m_startRow(startRow),
            m_startCol(startCol) {
        init();
      }
      inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol, Index blockRows, Index blockCols)
          : Base(xpr.data() + xpr.innerStride() * (XprTypeIsRowMajor ? startCol : startRow) +
                     xpr.outerStride() * (XprTypeIsRowMajor ? startRow : startCol),
                 blockRows,
                 blockCols),
            m_xpr(xpr),
            m_startRow(startRow),
            m_startCol(startCol) {
        init();
      }
      inline const internal::remove_all_t<XprTypeNested>& nestedExpression() const noexcept { return m_xpr; }
      inline XprType& nestedExpression() { return m_xpr; }
      inline constexpr Index innerStride() const noexcept {
        return internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.innerStride() : m_xpr.outerStride();
      }
      inline constexpr Index outerStride() const noexcept {
        return internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.outerStride() : m_xpr.innerStride();
      }
      inline constexpr StorageIndex startRow() const noexcept { return m_startRow.value(); }
      inline constexpr StorageIndex startCol() const noexcept { return m_startCol.value(); }

    protected:
      inline BlockImpl_dense(XprType& xpr, const Scalar* data, Index blockRows, Index blockCols)
          : Base(data, blockRows, blockCols), m_xpr(xpr) {
        init();
      }

    protected:
      inline void init() {
        m_outerStride =
            internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.outerStride() : m_xpr.innerStride();
      }
      XprTypeNested m_xpr;
      const internal::variable_if_dynamic<StorageIndex,
                                          (XprType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic>
          m_startRow;
      const internal::variable_if_dynamic<StorageIndex,
                                          (XprType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic>
          m_startCol;
      Index m_outerStride;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename VectorType, int Size>
    struct traits<VectorBlock<VectorType, Size>>
        : public traits<Block<VectorType,
                              traits<VectorType>::Flags & RowMajorBit ? 1 : Size,
                              traits<VectorType>::Flags & RowMajorBit ? Size : 1>> {};
  }  // namespace internal
  template <typename VectorType, int Size>
  class VectorBlock : public Block<VectorType,
                                   internal::traits<VectorType>::Flags & RowMajorBit ? 1 : Size,
                                   internal::traits<VectorType>::Flags & RowMajorBit ? Size : 1> {
    typedef Block<VectorType,
                  internal::traits<VectorType>::Flags & RowMajorBit ? 1 : Size,
                  internal::traits<VectorType>::Flags & RowMajorBit ? Size : 1>
        Base;
    enum { IsColVector = !(internal::traits<VectorType>::Flags & RowMajorBit) };

  public:
    typedef typename Eigen::internal::traits<VectorBlock>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<VectorBlock>::type Nested;
    typedef typename Eigen::internal::traits<VectorBlock>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<VectorBlock>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<VectorBlock>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<VectorBlock>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<VectorBlock>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    static_assert(VectorBlock::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    using Base::operator=;
    inline VectorBlock(VectorType& vector, Index start, Index size)
        : Base(
              vector, IsColVector ? start : 0, IsColVector ? 0 : start, IsColVector ? size : 1, IsColVector ? 1 : size) {
    }
    inline VectorBlock(VectorType& vector, Index start)
        : Base(vector, IsColVector ? start : 0, IsColVector ? 0 : start) {}
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename XprType, typename RowIndices, typename ColIndices>
    struct traits<IndexedView<XprType, RowIndices, ColIndices>> : traits<XprType> {
      enum {
        RowsAtCompileTime = int(array_size<RowIndices>::value),
        ColsAtCompileTime = int(array_size<ColIndices>::value),
        MaxRowsAtCompileTime = RowsAtCompileTime,
        MaxColsAtCompileTime = ColsAtCompileTime,
        XprTypeIsRowMajor = (int(traits<XprType>::Flags) & RowMajorBit) != 0,
        IsRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? 1
                     : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
                                                                                : XprTypeIsRowMajor,
        RowIncr = int(get_compile_time_incr<RowIndices>::value),
        ColIncr = int(get_compile_time_incr<ColIndices>::value),
        InnerIncr = IsRowMajor ? ColIncr : RowIncr,
        OuterIncr = IsRowMajor ? RowIncr : ColIncr,
        HasSameStorageOrderAsXprType = (IsRowMajor == XprTypeIsRowMajor),
        XprInnerStride = HasSameStorageOrderAsXprType ? int(inner_stride_at_compile_time<XprType>::ret)
                                                      : int(outer_stride_at_compile_time<XprType>::ret),
        XprOuterstride = HasSameStorageOrderAsXprType ? int(outer_stride_at_compile_time<XprType>::ret)
                                                      : int(inner_stride_at_compile_time<XprType>::ret),
        InnerSize = XprTypeIsRowMajor ? ColsAtCompileTime : RowsAtCompileTime,
        IsBlockAlike = InnerIncr == 1 && OuterIncr == 1,
        IsInnerPannel =
            HasSameStorageOrderAsXprType &&
            is_same<AllRange<InnerSize>, std::conditional_t<XprTypeIsRowMajor, ColIndices, RowIndices>>::value,
        InnerStrideAtCompileTime =
            InnerIncr < 0 || InnerIncr == DynamicIndex || XprInnerStride == Dynamic || InnerIncr == UndefinedIncr
                ? Dynamic
                : XprInnerStride * InnerIncr,
        OuterStrideAtCompileTime =
            OuterIncr < 0 || OuterIncr == DynamicIndex || XprOuterstride == Dynamic || OuterIncr == UndefinedIncr
                ? Dynamic
                : XprOuterstride * OuterIncr,
        ReturnAsScalar = is_same<RowIndices, SingleRange>::value && is_same<ColIndices, SingleRange>::value,
        ReturnAsBlock = (!ReturnAsScalar) && IsBlockAlike,
        ReturnAsIndexedView = (!ReturnAsScalar) && (!ReturnAsBlock),
        DirectAccessMask =
            (int(InnerIncr) != UndefinedIncr && int(OuterIncr) != UndefinedIncr && InnerIncr >= 0 && OuterIncr >= 0)
                ? DirectAccessBit
                : 0,
        FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
        FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
        FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1) ? LinearAccessBit : 0,
        Flags = (traits<XprType>::Flags & (HereditaryBits | DirectAccessMask)) | FlagsLvalueBit | FlagsRowMajorBit |
                FlagsLinearAccessBit
      };
      typedef Block<XprType, RowsAtCompileTime, ColsAtCompileTime, IsInnerPannel> BlockType;
    };
  }  // namespace internal
  template <typename XprType, typename RowIndices, typename ColIndices, typename StorageKind>
  class IndexedViewImpl;
  template <typename XprType, typename RowIndices, typename ColIndices>
  class IndexedView
      : public IndexedViewImpl<XprType, RowIndices, ColIndices, typename internal::traits<XprType>::StorageKind> {
  public:
    typedef
        typename IndexedViewImpl<XprType, RowIndices, ColIndices, typename internal::traits<XprType>::StorageKind>::Base
            Base;
    typedef typename Eigen::internal::traits<IndexedView>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<IndexedView>::type Nested;
    typedef typename Eigen::internal::traits<IndexedView>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<IndexedView>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<IndexedView>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<IndexedView>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<IndexedView>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    using Base::operator=;
    inline IndexedView& operator=(const IndexedView& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline IndexedView& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    IndexedView(const IndexedView&) = default;
    typedef typename internal::ref_selector<XprType>::non_const_type MatrixTypeNested;
    typedef internal::remove_all_t<XprType> NestedExpression;
    template <typename T0, typename T1>
    IndexedView(XprType& xpr, const T0& rowIndices, const T1& colIndices)
        : m_xpr(xpr), m_rowIndices(rowIndices), m_colIndices(colIndices) {}
    Index rows() const { return internal::index_list_size(m_rowIndices); }
    Index cols() const { return internal::index_list_size(m_colIndices); }
    const internal::remove_all_t<XprType>& nestedExpression() const { return m_xpr; }
    std::remove_reference_t<XprType>& nestedExpression() { return m_xpr; }
    const RowIndices& rowIndices() const { return m_rowIndices; }
    const ColIndices& colIndices() const { return m_colIndices; }

  protected:
    MatrixTypeNested m_xpr;
    RowIndices m_rowIndices;
    ColIndices m_colIndices;
  };
  template <typename XprType, typename RowIndices, typename ColIndices, typename StorageKind>
  class IndexedViewImpl : public internal::generic_xpr_base<IndexedView<XprType, RowIndices, ColIndices>>::type {
  public:
    typedef typename internal::generic_xpr_base<IndexedView<XprType, RowIndices, ColIndices>>::type Base;
  };
  namespace internal {
    template <typename ArgType, typename RowIndices, typename ColIndices>
    struct unary_evaluator<IndexedView<ArgType, RowIndices, ColIndices>, IndexBased>
        : evaluator_base<IndexedView<ArgType, RowIndices, ColIndices>> {
      typedef IndexedView<ArgType, RowIndices, ColIndices> XprType;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        FlagsLinearAccessBit =
            (traits<XprType>::RowsAtCompileTime == 1 || traits<XprType>::ColsAtCompileTime == 1) ? LinearAccessBit : 0,
        FlagsRowMajorBit = traits<XprType>::FlagsRowMajorBit,
        Flags = (evaluator<ArgType>::Flags & (HereditaryBits & ~RowMajorBit)) | FlagsLinearAccessBit | FlagsRowMajorBit,
        Alignment = 0
      };
      explicit unary_evaluator(const XprType& xpr) : m_argImpl(xpr.nestedExpression()), m_xpr(xpr) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline CoeffReturnType coeff(Index row, Index col) const {
        (static_cast<bool>(m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() &&
                           m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols())
             ? void(0)
             : __assert_fail(
                   "m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() && "
                   "m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols()",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/IndexedView.h",
                   202,
                   __extension__ __PRETTY_FUNCTION__));
        return m_argImpl.coeff(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
      }
      inline Scalar& coeffRef(Index row, Index col) {
        (static_cast<bool>(m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() &&
                           m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols())
             ? void(0)
             : __assert_fail(
                   "m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() && "
                   "m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols()",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/IndexedView.h",
                   210,
                   __extension__ __PRETTY_FUNCTION__));
        return m_argImpl.coeffRef(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
      }
      inline Scalar& coeffRef(Index index) {
        static_assert(Eigen::internal::is_lvalue<XprType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
        Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
        Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
        (static_cast<bool>(m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() &&
                           m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols())
             ? void(0)
             : __assert_fail(
                   "m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() && "
                   "m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols()",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/IndexedView.h",
                   221,
                   __extension__ __PRETTY_FUNCTION__));
        return m_argImpl.coeffRef(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
      }
      inline const Scalar& coeffRef(Index index) const {
        Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
        Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
        (static_cast<bool>(m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() &&
                           m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols())
             ? void(0)
             : __assert_fail(
                   "m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() && "
                   "m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols()",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/IndexedView.h",
                   231,
                   __extension__ __PRETTY_FUNCTION__));
        return m_argImpl.coeffRef(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
      }
      inline const CoeffReturnType coeff(Index index) const {
        Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
        Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
        (static_cast<bool>(m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() &&
                           m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols())
             ? void(0)
             : __assert_fail(
                   "m_xpr.rowIndices()[row] >= 0 && m_xpr.rowIndices()[row] < m_xpr.nestedExpression().rows() && "
                   "m_xpr.colIndices()[col] >= 0 && m_xpr.colIndices()[col] < m_xpr.nestedExpression().cols()",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/IndexedView.h",
                   241,
                   __extension__ __PRETTY_FUNCTION__));
        return m_argImpl.coeff(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
      }

    protected:
      evaluator<ArgType> m_argImpl;
      const XprType& m_xpr;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename XprType, int Rows, int Cols, int Order>
    struct traits<Reshaped<XprType, Rows, Cols, Order>> : traits<XprType> {
      typedef typename traits<XprType>::Scalar Scalar;
      typedef typename traits<XprType>::StorageKind StorageKind;
      typedef typename traits<XprType>::XprKind XprKind;
      enum {
        MatrixRows = traits<XprType>::RowsAtCompileTime,
        MatrixCols = traits<XprType>::ColsAtCompileTime,
        RowsAtCompileTime = Rows,
        ColsAtCompileTime = Cols,
        MaxRowsAtCompileTime = Rows,
        MaxColsAtCompileTime = Cols,
        XpxStorageOrder = ((int(traits<XprType>::Flags) & RowMajorBit) == RowMajorBit) ? RowMajor : ColMajor,
        ReshapedStorageOrder = (RowsAtCompileTime == 1 && ColsAtCompileTime != 1)   ? RowMajor
                               : (ColsAtCompileTime == 1 && RowsAtCompileTime != 1) ? ColMajor
                                                                                    : XpxStorageOrder,
        HasSameStorageOrderAsXprType = (ReshapedStorageOrder == XpxStorageOrder),
        InnerSize = (ReshapedStorageOrder == int(RowMajor)) ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
        InnerStrideAtCompileTime =
            HasSameStorageOrderAsXprType ? int(inner_stride_at_compile_time<XprType>::ret) : Dynamic,
        OuterStrideAtCompileTime = Dynamic,
        HasDirectAccess = internal::has_direct_access<XprType>::ret && (Order == int(XpxStorageOrder)) &&
                          ((evaluator<XprType>::Flags & LinearAccessBit) == LinearAccessBit),
        MaskPacketAccessBit =
            (InnerSize == Dynamic || (InnerSize % packet_traits<Scalar>::size) == 0) && (InnerStrideAtCompileTime == 1)
                ? PacketAccessBit
                : 0,
        FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1) ? LinearAccessBit : 0,
        FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
        FlagsRowMajorBit = (ReshapedStorageOrder == int(RowMajor)) ? RowMajorBit : 0,
        FlagsDirectAccessBit = HasDirectAccess ? DirectAccessBit : 0,
        Flags0 = traits<XprType>::Flags & ((HereditaryBits & ~RowMajorBit) | MaskPacketAccessBit),
        Flags = (Flags0 | FlagsLinearAccessBit | FlagsLvalueBit | FlagsRowMajorBit | FlagsDirectAccessBit)
      };
    };
    template <typename XprType, int Rows, int Cols, int Order, bool HasDirectAccess>
    class ReshapedImpl_dense;
  }  // namespace internal
  template <typename XprType, int Rows, int Cols, int Order, typename StorageKind>
  class ReshapedImpl;
  template <typename XprType, int Rows, int Cols, int Order>
  class Reshaped : public ReshapedImpl<XprType, Rows, Cols, Order, typename internal::traits<XprType>::StorageKind> {
    typedef ReshapedImpl<XprType, Rows, Cols, Order, typename internal::traits<XprType>::StorageKind> Impl;

  public:
    typedef Impl Base;
    typedef typename Eigen::internal::traits<Reshaped>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Reshaped>::type Nested;
    typedef typename Eigen::internal::traits<Reshaped>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Reshaped>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Reshaped>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Reshaped>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Reshaped>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    using Base::operator=;
    inline Reshaped& operator=(const Reshaped& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Reshaped& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Reshaped(const Reshaped&) = default;
    inline Reshaped(XprType& xpr) : Impl(xpr) {
      static_assert(RowsAtCompileTime != Dynamic && ColsAtCompileTime != Dynamic, "THIS_METHOD_IS_ONLY_FOR_FIXED_SIZE");
      (static_cast<bool>(Rows * Cols == xpr.rows() * xpr.cols())
           ? void(0)
           : __assert_fail("Rows * Cols == xpr.rows() * xpr.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Reshaped.h",
                           114,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline Reshaped(XprType& xpr, Index reshapeRows, Index reshapeCols) : Impl(xpr, reshapeRows, reshapeCols) {
      (static_cast<bool>((RowsAtCompileTime == Dynamic || RowsAtCompileTime == reshapeRows) &&
                         (ColsAtCompileTime == Dynamic || ColsAtCompileTime == reshapeCols))
           ? void(0)
           : __assert_fail("(RowsAtCompileTime==Dynamic || RowsAtCompileTime==reshapeRows) && "
                           "(ColsAtCompileTime==Dynamic || ColsAtCompileTime==reshapeCols)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Reshaped.h",
                           125,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(reshapeRows * reshapeCols == xpr.rows() * xpr.cols())
           ? void(0)
           : __assert_fail("reshapeRows * reshapeCols == xpr.rows() * xpr.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Reshaped.h",
                           126,
                           __extension__ __PRETTY_FUNCTION__));
    }
  };
  template <typename XprType, int Rows, int Cols, int Order>
  class ReshapedImpl<XprType, Rows, Cols, Order, Dense>
      : public internal::ReshapedImpl_dense<XprType,
                                            Rows,
                                            Cols,
                                            Order,
                                            internal::traits<Reshaped<XprType, Rows, Cols, Order>>::HasDirectAccess> {
    typedef internal::ReshapedImpl_dense<XprType,
                                         Rows,
                                         Cols,
                                         Order,
                                         internal::traits<Reshaped<XprType, Rows, Cols, Order>>::HasDirectAccess>
        Impl;

  public:
    typedef Impl Base;
    using Base::operator=;
    inline ReshapedImpl& operator=(const ReshapedImpl& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline ReshapedImpl& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    ReshapedImpl(const ReshapedImpl&) = default;
    inline ReshapedImpl(XprType& xpr) : Impl(xpr) {}
    inline ReshapedImpl(XprType& xpr, Index reshapeRows, Index reshapeCols) : Impl(xpr, reshapeRows, reshapeCols) {}
  };
  namespace internal {
    template <typename XprType, int Rows, int Cols, int Order>
    class ReshapedImpl_dense<XprType, Rows, Cols, Order, false>
        : public internal::dense_xpr_base<Reshaped<XprType, Rows, Cols, Order>>::type {
      typedef Reshaped<XprType, Rows, Cols, Order> ReshapedType;

    public:
      typedef typename internal::dense_xpr_base<ReshapedType>::type Base;
      typedef typename Eigen::internal::traits<ReshapedType>::Scalar Scalar;
      typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
      typedef typename Base::CoeffReturnType CoeffReturnType;
      typedef typename Eigen::internal::ref_selector<ReshapedType>::type Nested;
      typedef typename Eigen::internal::traits<ReshapedType>::StorageKind StorageKind;
      typedef typename Eigen::internal::traits<ReshapedType>::StorageIndex StorageIndex;
      enum CompileTimeTraits {
        RowsAtCompileTime = Eigen::internal::traits<ReshapedType>::RowsAtCompileTime,
        ColsAtCompileTime = Eigen::internal::traits<ReshapedType>::ColsAtCompileTime,
        Flags = Eigen::internal::traits<ReshapedType>::Flags,
        SizeAtCompileTime = Base::SizeAtCompileTime,
        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
        IsVectorAtCompileTime = Base::IsVectorAtCompileTime
      };
      using Base::const_cast_derived;
      using Base::derived;
      typedef typename Base::PacketScalar PacketScalar;
      using Base::operator=;
      inline ReshapedImpl_dense& operator=(const ReshapedImpl_dense& other) {
        Base::operator=(other);
        return *this;
      }
      template <typename OtherDerived>
      inline ReshapedImpl_dense& operator=(const DenseBase<OtherDerived>& other) {
        Base::operator=(other.derived());
        return *this;
      }
      ReshapedImpl_dense(const ReshapedImpl_dense&) = default;
      typedef typename internal::ref_selector<XprType>::non_const_type MatrixTypeNested;
      typedef internal::remove_all_t<XprType> NestedExpression;
      class InnerIterator;
      inline ReshapedImpl_dense(XprType& xpr) : m_xpr(xpr), m_rows(Rows), m_cols(Cols) {}
      inline ReshapedImpl_dense(XprType& xpr, Index nRows, Index nCols) : m_xpr(xpr), m_rows(nRows), m_cols(nCols) {}
      Index rows() const { return m_rows; }
      Index cols() const { return m_cols; }
      const internal::remove_all_t<XprType>& nestedExpression() const { return m_xpr; }
      std::remove_reference_t<XprType>& nestedExpression() { return m_xpr; }

    protected:
      MatrixTypeNested m_xpr;
      const internal::variable_if_dynamic<Index, Rows> m_rows;
      const internal::variable_if_dynamic<Index, Cols> m_cols;
    };
    template <typename XprType, int Rows, int Cols, int Order>
    class ReshapedImpl_dense<XprType, Rows, Cols, Order, true> : public MapBase<Reshaped<XprType, Rows, Cols, Order>> {
      typedef Reshaped<XprType, Rows, Cols, Order> ReshapedType;
      typedef typename internal::ref_selector<XprType>::non_const_type XprTypeNested;

    public:
      typedef MapBase<ReshapedType> Base;
      typedef typename Eigen::internal::traits<ReshapedType>::Scalar Scalar;
      typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
      typedef typename Base::CoeffReturnType CoeffReturnType;
      typedef typename Eigen::internal::ref_selector<ReshapedType>::type Nested;
      typedef typename Eigen::internal::traits<ReshapedType>::StorageKind StorageKind;
      typedef typename Eigen::internal::traits<ReshapedType>::StorageIndex StorageIndex;
      enum CompileTimeTraits {
        RowsAtCompileTime = Eigen::internal::traits<ReshapedType>::RowsAtCompileTime,
        ColsAtCompileTime = Eigen::internal::traits<ReshapedType>::ColsAtCompileTime,
        Flags = Eigen::internal::traits<ReshapedType>::Flags,
        SizeAtCompileTime = Base::SizeAtCompileTime,
        MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
        IsVectorAtCompileTime = Base::IsVectorAtCompileTime
      };
      using Base::const_cast_derived;
      using Base::derived;
      typedef typename Base::PacketScalar PacketScalar;
      using Base::operator=;
      inline ReshapedImpl_dense& operator=(const ReshapedImpl_dense& other) {
        Base::operator=(other);
        return *this;
      }
      template <typename OtherDerived>
      inline ReshapedImpl_dense& operator=(const DenseBase<OtherDerived>& other) {
        Base::operator=(other.derived());
        return *this;
      }
      ReshapedImpl_dense(const ReshapedImpl_dense&) = default;
      inline ReshapedImpl_dense(XprType& xpr) : Base(xpr.data()), m_xpr(xpr) {}
      inline ReshapedImpl_dense(XprType& xpr, Index nRows, Index nCols) : Base(xpr.data(), nRows, nCols), m_xpr(xpr) {}
      const internal::remove_all_t<XprTypeNested>& nestedExpression() const { return m_xpr; }
      XprType& nestedExpression() { return m_xpr; }
      constexpr inline Index innerStride() const { return m_xpr.innerStride(); }
      constexpr inline Index outerStride() const {
        return ((Flags & RowMajorBit) == RowMajorBit) ? this->cols() : this->rows();
      }

    protected:
      XprTypeNested m_xpr;
    };
    template <typename ArgType, int Rows, int Cols, int Order, bool HasDirectAccess>
    struct reshaped_evaluator;
    template <typename ArgType, int Rows, int Cols, int Order>
    struct evaluator<Reshaped<ArgType, Rows, Cols, Order>>
        : reshaped_evaluator<ArgType, Rows, Cols, Order, traits<Reshaped<ArgType, Rows, Cols, Order>>::HasDirectAccess> {
      typedef Reshaped<ArgType, Rows, Cols, Order> XprType;
      typedef typename XprType::Scalar Scalar;
      typedef typename packet_traits<Scalar>::type PacketScalar;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        HasDirectAccess = traits<XprType>::HasDirectAccess,
        FlagsLinearAccessBit =
            (traits<XprType>::RowsAtCompileTime == 1 || traits<XprType>::ColsAtCompileTime == 1 || HasDirectAccess)
                ? LinearAccessBit
                : 0,
        FlagsRowMajorBit = (traits<XprType>::ReshapedStorageOrder == int(RowMajor)) ? RowMajorBit : 0,
        FlagsDirectAccessBit = HasDirectAccess ? DirectAccessBit : 0,
        Flags0 = evaluator<ArgType>::Flags & (HereditaryBits & ~RowMajorBit),
        Flags = Flags0 | FlagsLinearAccessBit | FlagsRowMajorBit | FlagsDirectAccessBit,
        PacketAlignment = unpacket_traits<PacketScalar>::alignment,
        Alignment = evaluator<ArgType>::Alignment
      };
      typedef reshaped_evaluator<ArgType, Rows, Cols, Order, HasDirectAccess> reshaped_evaluator_type;
      explicit evaluator(const XprType& xpr) : reshaped_evaluator_type(xpr) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
    };
    template <typename ArgType, int Rows, int Cols, int Order>
    struct reshaped_evaluator<ArgType, Rows, Cols, Order, false>
        : evaluator_base<Reshaped<ArgType, Rows, Cols, Order>> {
      typedef Reshaped<ArgType, Rows, Cols, Order> XprType;
      enum {
        CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
        Flags = (evaluator<ArgType>::Flags & (HereditaryBits)),
        Alignment = 0
      };
      explicit reshaped_evaluator(const XprType& xpr) : m_argImpl(xpr.nestedExpression()), m_xpr(xpr) {
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      typedef std::pair<Index, Index> RowCol;
      inline RowCol index_remap(Index rowId, Index colId) const {
        if (Order == ColMajor) {
          const Index nth_elem_idx = colId * m_xpr.rows() + rowId;
          return RowCol(nth_elem_idx % m_xpr.nestedExpression().rows(), nth_elem_idx / m_xpr.nestedExpression().rows());
        } else {
          const Index nth_elem_idx = colId + rowId * m_xpr.cols();
          return RowCol(nth_elem_idx / m_xpr.nestedExpression().cols(), nth_elem_idx % m_xpr.nestedExpression().cols());
        }
      }
      inline Scalar& coeffRef(Index rowId, Index colId) {
        static_assert(Eigen::internal::is_lvalue<XprType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
        const RowCol row_col = index_remap(rowId, colId);
        return m_argImpl.coeffRef(row_col.first, row_col.second);
      }
      inline const Scalar& coeffRef(Index rowId, Index colId) const {
        const RowCol row_col = index_remap(rowId, colId);
        return m_argImpl.coeffRef(row_col.first, row_col.second);
      }
      inline const CoeffReturnType coeff(Index rowId, Index colId) const {
        const RowCol row_col = index_remap(rowId, colId);
        return m_argImpl.coeff(row_col.first, row_col.second);
      }
      inline Scalar& coeffRef(Index index) {
        static_assert(Eigen::internal::is_lvalue<XprType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
        const RowCol row_col = index_remap(Rows == 1 ? 0 : index, Rows == 1 ? index : 0);
        return m_argImpl.coeffRef(row_col.first, row_col.second);
      }
      inline const Scalar& coeffRef(Index index) const {
        const RowCol row_col = index_remap(Rows == 1 ? 0 : index, Rows == 1 ? index : 0);
        return m_argImpl.coeffRef(row_col.first, row_col.second);
      }
      inline const CoeffReturnType coeff(Index index) const {
        const RowCol row_col = index_remap(Rows == 1 ? 0 : index, Rows == 1 ? index : 0);
        return m_argImpl.coeff(row_col.first, row_col.second);
      }

    protected:
      evaluator<ArgType> m_argImpl;
      const XprType& m_xpr;
    };
    template <typename ArgType, int Rows, int Cols, int Order>
    struct reshaped_evaluator<ArgType, Rows, Cols, Order, true>
        : mapbase_evaluator<Reshaped<ArgType, Rows, Cols, Order>,
                            typename Reshaped<ArgType, Rows, Cols, Order>::PlainObject> {
      typedef Reshaped<ArgType, Rows, Cols, Order> XprType;
      typedef typename XprType::Scalar Scalar;
      explicit reshaped_evaluator(const XprType& xpr) : mapbase_evaluator<XprType, typename XprType::PlainObject>(xpr) {
        (static_cast<bool>(((internal::UIntPtr(xpr.data()) % plain_enum_max(1, evaluator<XprType>::Alignment)) == 0) &&
                           "data is not aligned")
             ? void(0)
             : __assert_fail("((internal::UIntPtr(xpr.data()) % plain_enum_max(1, evaluator<XprType>::Alignment)) == "
                             "0) && \"data is not aligned\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Reshaped.h",
                             447,
                             __extension__ __PRETTY_FUNCTION__));
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType>
    struct traits<Transpose<MatrixType>> : public traits<MatrixType> {
      typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNestedPlain;
      enum {
        RowsAtCompileTime = MatrixType::ColsAtCompileTime,
        ColsAtCompileTime = MatrixType::RowsAtCompileTime,
        MaxRowsAtCompileTime = MatrixType::MaxColsAtCompileTime,
        MaxColsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
        FlagsLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
        Flags0 = traits<MatrixTypeNestedPlain>::Flags & ~(LvalueBit | NestByRefBit),
        Flags1 = Flags0 | FlagsLvalueBit,
        Flags = Flags1 ^ RowMajorBit,
        InnerStrideAtCompileTime = inner_stride_at_compile_time<MatrixType>::ret,
        OuterStrideAtCompileTime = outer_stride_at_compile_time<MatrixType>::ret
      };
    };
  }  // namespace internal
  template <typename MatrixType, typename StorageKind>
  class TransposeImpl;
  template <typename MatrixType>
  class Transpose : public TransposeImpl<MatrixType, typename internal::traits<MatrixType>::StorageKind> {
  public:
    typedef typename internal::ref_selector<MatrixType>::non_const_type MatrixTypeNested;
    typedef typename TransposeImpl<MatrixType, typename internal::traits<MatrixType>::StorageKind>::Base Base;
    typedef typename Eigen::internal::traits<Transpose>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Transpose>::type Nested;
    typedef typename Eigen::internal::traits<Transpose>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Transpose>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Transpose>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Transpose>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Transpose>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef internal::remove_all_t<MatrixType> NestedExpression;
    explicit inline Transpose(MatrixType& matrix) : m_matrix(matrix) {}
    using Base::operator=;
    inline Transpose& operator=(const Transpose& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Transpose& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Transpose(const Transpose&) = default;
    inline constexpr Index rows() const noexcept { return m_matrix.cols(); }
    inline constexpr Index cols() const noexcept { return m_matrix.rows(); }
    inline const internal::remove_all_t<MatrixTypeNested>& nestedExpression() const { return m_matrix; }
    inline std::remove_reference_t<MatrixTypeNested>& nestedExpression() { return m_matrix; }
    inline void resize(Index nrows, Index ncols) { m_matrix.resize(ncols, nrows); }

  protected:
    typename internal::ref_selector<MatrixType>::non_const_type m_matrix;
  };
  namespace internal {
    template <typename MatrixType, bool HasDirectAccess = has_direct_access<MatrixType>::ret>
    struct TransposeImpl_base {
      typedef typename dense_xpr_base<Transpose<MatrixType>>::type type;
    };
    template <typename MatrixType>
    struct TransposeImpl_base<MatrixType, false> {
      typedef typename dense_xpr_base<Transpose<MatrixType>>::type type;
    };
  }  // namespace internal
  template <typename XprType, typename StorageKind>
  class TransposeImpl : public internal::generic_xpr_base<Transpose<XprType>>::type {
  public:
    typedef typename internal::generic_xpr_base<Transpose<XprType>>::type Base;
  };
  template <typename MatrixType>
  class TransposeImpl<MatrixType, Dense> : public internal::TransposeImpl_base<MatrixType>::type {
  public:
    typedef typename internal::TransposeImpl_base<MatrixType>::type Base;
    using Base::coeffRef;
    typedef typename Eigen::internal::traits<Transpose<MatrixType>>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Transpose<MatrixType>>::type Nested;
    typedef typename Eigen::internal::traits<Transpose<MatrixType>>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Transpose<MatrixType>>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Transpose<MatrixType>>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Transpose<MatrixType>>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Transpose<MatrixType>>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    using Base::operator=;
    inline TransposeImpl& operator=(const TransposeImpl& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline TransposeImpl& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    TransposeImpl(const TransposeImpl&) = default;
    inline Index innerStride() const { return derived().nestedExpression().innerStride(); }
    inline Index outerStride() const { return derived().nestedExpression().outerStride(); }
    typedef std::conditional_t<internal::is_lvalue<MatrixType>::value, Scalar, const Scalar> ScalarWithConstIfNotLvalue;
    inline ScalarWithConstIfNotLvalue* data() { return derived().nestedExpression().data(); }
    inline const Scalar* data() const { return derived().nestedExpression().data(); }
    inline const Scalar& coeffRef(Index rowId, Index colId) const {
      return derived().nestedExpression().coeffRef(colId, rowId);
    }
    inline const Scalar& coeffRef(Index index) const { return derived().nestedExpression().coeffRef(index); }

  protected:
    TransposeImpl() = default;
    ~TransposeImpl() = default;
  };
  template <typename Derived>
  inline typename DenseBase<Derived>::TransposeReturnType DenseBase<Derived>::transpose() {
    return TransposeReturnType(derived());
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::ConstTransposeReturnType DenseBase<Derived>::transpose() const {
    return ConstTransposeReturnType(derived());
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::AdjointReturnType MatrixBase<Derived>::adjoint() const {
    return AdjointReturnType(this->transpose());
  }
  namespace internal {
    template <typename MatrixType,
              bool IsSquare = (MatrixType::RowsAtCompileTime == MatrixType::ColsAtCompileTime) &&
                              MatrixType::RowsAtCompileTime != Dynamic,
              bool MatchPacketSize = (int(MatrixType::RowsAtCompileTime) ==
                                      int(internal::packet_traits<typename MatrixType::Scalar>::size)) &&
                                     (internal::evaluator<MatrixType>::Flags & PacketAccessBit)>
    struct inplace_transpose_selector;
    template <typename MatrixType>
    struct inplace_transpose_selector<MatrixType, true, false> {
      static void run(MatrixType& m) {
        m.matrix().template triangularView<StrictlyUpper>().swap(
            m.matrix().transpose().template triangularView<StrictlyUpper>());
      }
    };
    template <typename MatrixType>
    struct inplace_transpose_selector<MatrixType, true, true> {
      static void run(MatrixType& m) {
        typedef typename MatrixType::Scalar Scalar;
        typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
        const Index PacketSize = internal::packet_traits<Scalar>::size;
        const Index Alignment = internal::evaluator<MatrixType>::Alignment;
        PacketBlock<Packet> A;
        for (Index i = 0; i < PacketSize; ++i)
          A.packet[i] = m.template packetByOuterInner<Alignment>(i, 0);
        internal::ptranspose(A);
        for (Index i = 0; i < PacketSize; ++i)
          m.template writePacket<Alignment>(m.rowIndexByOuterInner(i, 0), m.colIndexByOuterInner(i, 0), A.packet[i]);
      }
    };
    template <typename MatrixType, Index Alignment>
    void BlockedInPlaceTranspose(MatrixType& m) {
      typedef typename MatrixType::Scalar Scalar;
      typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
      const Index PacketSize = internal::packet_traits<Scalar>::size;
      (static_cast<bool>(m.rows() == m.cols())
           ? void(0)
           : __assert_fail("m.rows() == m.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Transpose.h",
                           270,
                           __extension__ __PRETTY_FUNCTION__));
      int row_start = 0;
      for (; row_start + PacketSize <= m.rows(); row_start += PacketSize) {
        for (int col_start = row_start; col_start + PacketSize <= m.cols(); col_start += PacketSize) {
          PacketBlock<Packet> A;
          if (row_start == col_start) {
            for (Index i = 0; i < PacketSize; ++i)
              A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i, col_start);
            internal::ptranspose(A);
            for (Index i = 0; i < PacketSize; ++i)
              m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start),
                                                m.colIndexByOuterInner(row_start + i, col_start),
                                                A.packet[i]);
          } else {
            PacketBlock<Packet> B;
            for (Index i = 0; i < PacketSize; ++i) {
              A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i, col_start);
              B.packet[i] = m.template packetByOuterInner<Alignment>(col_start + i, row_start);
            }
            internal::ptranspose(A);
            internal::ptranspose(B);
            for (Index i = 0; i < PacketSize; ++i) {
              m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start),
                                                m.colIndexByOuterInner(row_start + i, col_start),
                                                B.packet[i]);
              m.template writePacket<Alignment>(m.rowIndexByOuterInner(col_start + i, row_start),
                                                m.colIndexByOuterInner(col_start + i, row_start),
                                                A.packet[i]);
            }
          }
        }
      }
      for (Index row = row_start; row < m.rows(); ++row) {
        m.matrix().row(row).head(row).swap(m.matrix().col(row).head(row).transpose());
      }
    }
    template <typename MatrixType, bool MatchPacketSize>
    struct inplace_transpose_selector<MatrixType, false, MatchPacketSize> {
      static void run(MatrixType& m) {
        typedef typename MatrixType::Scalar Scalar;
        if (m.rows() == m.cols()) {
          const Index PacketSize = internal::packet_traits<Scalar>::size;
          if (!NumTraits<Scalar>::IsComplex && m.rows() >= PacketSize) {
            if ((m.rows() % PacketSize) == 0)
              BlockedInPlaceTranspose<MatrixType, internal::evaluator<MatrixType>::Alignment>(m);
            else
              BlockedInPlaceTranspose<MatrixType, Unaligned>(m);
          } else {
            m.matrix().template triangularView<StrictlyUpper>().swap(
                m.matrix().transpose().template triangularView<StrictlyUpper>());
          }
        } else {
          m = m.transpose().eval();
        }
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline void DenseBase<Derived>::transposeInPlace() {
    (static_cast<bool>((rows() == cols() || (RowsAtCompileTime == Dynamic && ColsAtCompileTime == Dynamic)) &&
                       "transposeInPlace() called on a non-square non-resizable matrix")
         ? void(0)
         : __assert_fail("(rows() == cols() || (RowsAtCompileTime == Dynamic && ColsAtCompileTime == Dynamic)) && "
                         "\"transposeInPlace() called on a non-square non-resizable matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Transpose.h",
                         349,
                         __extension__ __PRETTY_FUNCTION__));
    internal::inplace_transpose_selector<Derived>::run(derived());
  }
  template <typename Derived>
  inline void MatrixBase<Derived>::adjointInPlace() {
    derived() = adjoint().eval();
  }
  namespace internal {
    template <bool DestIsTransposed, typename OtherDerived>
    struct check_transpose_aliasing_compile_time_selector {
      enum { ret = bool(blas_traits<OtherDerived>::IsTransposed) != DestIsTransposed };
    };
    template <bool DestIsTransposed, typename BinOp, typename DerivedA, typename DerivedB>
    struct check_transpose_aliasing_compile_time_selector<DestIsTransposed, CwiseBinaryOp<BinOp, DerivedA, DerivedB>> {
      enum {
        ret = bool(blas_traits<DerivedA>::IsTransposed) != DestIsTransposed ||
              bool(blas_traits<DerivedB>::IsTransposed) != DestIsTransposed
      };
    };
    template <typename Scalar, bool DestIsTransposed, typename OtherDerived>
    struct check_transpose_aliasing_run_time_selector {
      static bool run(const Scalar* dest, const OtherDerived& src) {
        return (bool(blas_traits<OtherDerived>::IsTransposed) != DestIsTransposed) &&
               (dest != 0 && dest == (const Scalar*)extract_data(src));
      }
    };
    template <typename Scalar, bool DestIsTransposed, typename BinOp, typename DerivedA, typename DerivedB>
    struct check_transpose_aliasing_run_time_selector<Scalar, DestIsTransposed, CwiseBinaryOp<BinOp, DerivedA, DerivedB>> {
      static bool run(const Scalar* dest, const CwiseBinaryOp<BinOp, DerivedA, DerivedB>& src) {
        return ((blas_traits<DerivedA>::IsTransposed != DestIsTransposed) &&
                (dest != 0 && dest == (const Scalar*)extract_data(src.lhs()))) ||
               ((blas_traits<DerivedB>::IsTransposed != DestIsTransposed) &&
                (dest != 0 && dest == (const Scalar*)extract_data(src.rhs())));
      }
    };
    template <typename Derived,
              typename OtherDerived,
              bool MightHaveTransposeAliasing =
                  check_transpose_aliasing_compile_time_selector<blas_traits<Derived>::IsTransposed, OtherDerived>::ret>
    struct checkTransposeAliasing_impl {
      static void run(const Derived& dst, const OtherDerived& other) {
        (static_cast<bool>((!check_transpose_aliasing_run_time_selector<typename Derived::Scalar,
                                                                        blas_traits<Derived>::IsTransposed,
                                                                        OtherDerived>::run(extract_data(dst), other)) &&
                           "aliasing detected during transposition, use transposeInPlace() "
                           "or evaluate the rhs into a temporary using .eval()")
             ? void(0)
             : __assert_fail("(!check_transpose_aliasing_run_time_selector <typename "
                             "Derived::Scalar,blas_traits<Derived>::IsTransposed,OtherDerived> "
                             "::run(extract_data(dst), other)) && \"aliasing detected during transposition, use "
                             "transposeInPlace() \" \"or evaluate the rhs into a temporary using .eval()\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Transpose.h",
                             440,
                             __extension__ __PRETTY_FUNCTION__));
      }
    };
    template <typename Derived, typename OtherDerived>
    struct checkTransposeAliasing_impl<Derived, OtherDerived, false> {
      static void run(const Derived&, const OtherDerived&) {}
    };
    template <typename Dst, typename Src>
    void check_for_aliasing(const Dst& dst, const Src& src) {
      if ((!Dst::IsVectorAtCompileTime) && dst.rows() > 1 && dst.cols() > 1)
        internal::checkTransposeAliasing_impl<Dst, Src>::run(dst, src);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  class DiagonalBase : public EigenBase<Derived> {
  public:
    typedef typename internal::traits<Derived>::DiagonalVectorType DiagonalVectorType;
    typedef typename DiagonalVectorType::Scalar Scalar;
    typedef typename DiagonalVectorType::RealScalar RealScalar;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
    enum {
      RowsAtCompileTime = DiagonalVectorType::SizeAtCompileTime,
      ColsAtCompileTime = DiagonalVectorType::SizeAtCompileTime,
      MaxRowsAtCompileTime = DiagonalVectorType::MaxSizeAtCompileTime,
      MaxColsAtCompileTime = DiagonalVectorType::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = 0,
      Flags = NoPreferredStorageOrderBit
    };
    typedef Matrix<Scalar, RowsAtCompileTime, ColsAtCompileTime, 0, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        DenseMatrixType;
    typedef DenseMatrixType DenseType;
    typedef DiagonalMatrix<Scalar, DiagonalVectorType::SizeAtCompileTime, DiagonalVectorType::MaxSizeAtCompileTime>
        PlainObject;
    inline const Derived& derived() const { return *static_cast<const Derived*>(this); }
    inline Derived& derived() { return *static_cast<Derived*>(this); }
    DenseMatrixType toDenseMatrix() const { return derived(); }
    inline const DiagonalVectorType& diagonal() const { return derived().diagonal(); }
    inline DiagonalVectorType& diagonal() { return derived().diagonal(); }
    constexpr inline Index rows() const { return diagonal().size(); }
    constexpr inline Index cols() const { return diagonal().size(); }
    template <typename MatrixDerived>
    const Product<Derived, MatrixDerived, LazyProduct> operator*(const MatrixBase<MatrixDerived>& matrix) const {
      return Product<Derived, MatrixDerived, LazyProduct>(derived(), matrix.derived());
    }
    template <typename OtherDerived>
    using DiagonalProductReturnType = DiagonalWrapper<const CwiseBinaryOp<
        internal::scalar_product_op<typename internal::traits<DiagonalVectorType>::Scalar,
                                    typename internal::traits<typename OtherDerived::DiagonalVectorType>::Scalar>,
        const DiagonalVectorType,
        const typename OtherDerived::DiagonalVectorType>>;
    template <typename OtherDerived>
    const DiagonalProductReturnType<OtherDerived> operator*(const DiagonalBase<OtherDerived>& other) const {
      return diagonal().cwiseProduct(other.diagonal()).asDiagonal();
    }
    using DiagonalInverseReturnType =
        DiagonalWrapper<const CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const DiagonalVectorType>>;
    inline const DiagonalInverseReturnType inverse() const { return diagonal().cwiseInverse().asDiagonal(); }
    using DiagonalScaleReturnType = DiagonalWrapper<
        const CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<DiagonalVectorType>::Scalar, Scalar>,
                            const DiagonalVectorType,
                            const typename internal::plain_constant_type<DiagonalVectorType, Scalar>::type>>;
    inline const DiagonalScaleReturnType operator*(const Scalar& scalar) const {
      return (diagonal() * scalar).asDiagonal();
    }
    using ScaleDiagonalReturnType = DiagonalWrapper<
        const CwiseBinaryOp<internal::scalar_product_op<Scalar, typename internal::traits<DiagonalVectorType>::Scalar>,
                            const typename internal::plain_constant_type<DiagonalVectorType, Scalar>::type,
                            const DiagonalVectorType>>;
    friend inline const ScaleDiagonalReturnType operator*(const Scalar& scalar, const DiagonalBase& other) {
      return (scalar * other.diagonal()).asDiagonal();
    }
    template <typename OtherDerived>
    using DiagonalSumReturnType = DiagonalWrapper<const CwiseBinaryOp<
        internal::scalar_sum_op<typename internal::traits<DiagonalVectorType>::Scalar,
                                typename internal::traits<typename OtherDerived::DiagonalVectorType>::Scalar>,
        const DiagonalVectorType,
        const typename OtherDerived::DiagonalVectorType>>;
    template <typename OtherDerived>
    inline const DiagonalSumReturnType<OtherDerived> operator+(const DiagonalBase<OtherDerived>& other) const {
      return (diagonal() + other.diagonal()).asDiagonal();
    }
    template <typename OtherDerived>
    using DiagonalDifferenceReturnType = DiagonalWrapper<const CwiseBinaryOp<
        internal::scalar_difference_op<typename internal::traits<DiagonalVectorType>::Scalar,
                                       typename internal::traits<typename OtherDerived::DiagonalVectorType>::Scalar>,
        const DiagonalVectorType,
        const typename OtherDerived::DiagonalVectorType>>;
    template <typename OtherDerived>
    inline const DiagonalDifferenceReturnType<OtherDerived> operator-(const DiagonalBase<OtherDerived>& other) const {
      return (diagonal() - other.diagonal()).asDiagonal();
    }
  };
  namespace internal {
    template <typename Scalar_, int SizeAtCompileTime, int MaxSizeAtCompileTime>
    struct traits<DiagonalMatrix<Scalar_, SizeAtCompileTime, MaxSizeAtCompileTime>>
        : traits<Matrix<Scalar_, SizeAtCompileTime, SizeAtCompileTime, 0, MaxSizeAtCompileTime, MaxSizeAtCompileTime>> {
      typedef Matrix<Scalar_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1> DiagonalVectorType;
      typedef DiagonalShape StorageKind;
      enum { Flags = LvalueBit | NoPreferredStorageOrderBit | NestByRefBit };
    };
  }  // namespace internal
  template <typename Scalar_, int SizeAtCompileTime, int MaxSizeAtCompileTime>
  class DiagonalMatrix : public DiagonalBase<DiagonalMatrix<Scalar_, SizeAtCompileTime, MaxSizeAtCompileTime>> {
  public:
    typedef typename internal::traits<DiagonalMatrix>::DiagonalVectorType DiagonalVectorType;
    typedef const DiagonalMatrix& Nested;
    typedef Scalar_ Scalar;
    typedef typename internal::traits<DiagonalMatrix>::StorageKind StorageKind;
    typedef typename internal::traits<DiagonalMatrix>::StorageIndex StorageIndex;

  protected:
    DiagonalVectorType m_diagonal;

  public:
    inline const DiagonalVectorType& diagonal() const { return m_diagonal; }
    inline DiagonalVectorType& diagonal() { return m_diagonal; }
    inline DiagonalMatrix() {}
    explicit inline DiagonalMatrix(Index dim) : m_diagonal(dim) {}
    inline DiagonalMatrix(const Scalar& x, const Scalar& y) : m_diagonal(x, y) {}
    inline DiagonalMatrix(const Scalar& x, const Scalar& y, const Scalar& z) : m_diagonal(x, y, z) {}
    template <typename... ArgTypes>
    inline DiagonalMatrix(const Scalar& a0, const Scalar& a1, const Scalar& a2, const ArgTypes&... args)
        : m_diagonal(a0, a1, a2, args...) {}
    explicit inline DiagonalMatrix(const std::initializer_list<std::initializer_list<Scalar>>& list)
        : m_diagonal(list) {}
    explicit inline DiagonalMatrix(DiagonalVectorType&& diag) : m_diagonal(std::move(diag)) {}
    template <typename OtherDerived>
    inline DiagonalMatrix(const DiagonalBase<OtherDerived>& other) : m_diagonal(other.diagonal()) {}
    inline DiagonalMatrix(const DiagonalMatrix& other) : m_diagonal(other.diagonal()) {}
    template <typename OtherDerived>
    explicit inline DiagonalMatrix(const MatrixBase<OtherDerived>& other) : m_diagonal(other) {}
    template <typename OtherDerived>
    DiagonalMatrix& operator=(const DiagonalBase<OtherDerived>& other) {
      m_diagonal = other.diagonal();
      return *this;
    }
    DiagonalMatrix& operator=(const DiagonalMatrix& other) {
      m_diagonal = other.diagonal();
      return *this;
    }
    typedef DiagonalWrapper<const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, DiagonalVectorType>>
        InitializeReturnType;
    static const InitializeReturnType Zero() { return DiagonalVectorType::Zero().asDiagonal(); }
    static const InitializeReturnType Zero(Index size) { return DiagonalVectorType::Zero(size).asDiagonal(); }
    static const InitializeReturnType Identity() { return DiagonalVectorType::Ones().asDiagonal(); }
    static const InitializeReturnType Identity(Index size) { return DiagonalVectorType::Ones(size).asDiagonal(); }
    inline void resize(Index size) { m_diagonal.resize(size); }
    inline void setZero() { m_diagonal.setZero(); }
    inline void setZero(Index size) { m_diagonal.setZero(size); }
    inline void setIdentity() { m_diagonal.setOnes(); }
    inline void setIdentity(Index size) { m_diagonal.setOnes(size); }
  };
  namespace internal {
    template <typename DiagonalVectorType_>
    struct traits<DiagonalWrapper<DiagonalVectorType_>> {
      typedef DiagonalVectorType_ DiagonalVectorType;
      typedef typename DiagonalVectorType::Scalar Scalar;
      typedef typename DiagonalVectorType::StorageIndex StorageIndex;
      typedef DiagonalShape StorageKind;
      typedef typename traits<DiagonalVectorType>::XprKind XprKind;
      enum {
        RowsAtCompileTime = DiagonalVectorType::SizeAtCompileTime,
        ColsAtCompileTime = DiagonalVectorType::SizeAtCompileTime,
        MaxRowsAtCompileTime = DiagonalVectorType::MaxSizeAtCompileTime,
        MaxColsAtCompileTime = DiagonalVectorType::MaxSizeAtCompileTime,
        Flags = (traits<DiagonalVectorType>::Flags & LvalueBit) | NoPreferredStorageOrderBit
      };
    };
  }  // namespace internal
  template <typename DiagonalVectorType_>
  class DiagonalWrapper : public DiagonalBase<DiagonalWrapper<DiagonalVectorType_>>, internal::no_assignment_operator {
  public:
    typedef DiagonalVectorType_ DiagonalVectorType;
    typedef DiagonalWrapper Nested;
    explicit inline DiagonalWrapper(DiagonalVectorType& a_diagonal) : m_diagonal(a_diagonal) {}
    const DiagonalVectorType& diagonal() const { return m_diagonal; }

  protected:
    typename DiagonalVectorType::Nested m_diagonal;
  };
  template <typename Derived>
  inline const DiagonalWrapper<const Derived> MatrixBase<Derived>::asDiagonal() const {
    return DiagonalWrapper<const Derived>(derived());
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isDiagonal(const RealScalar& prec) const {
    if (cols() != rows())
      return false;
    RealScalar maxAbsOnDiagonal = static_cast<RealScalar>(-1);
    for (Index j = 0; j < cols(); ++j) {
      RealScalar absOnDiagonal = numext::abs(coeff(j, j));
      if (absOnDiagonal > maxAbsOnDiagonal)
        maxAbsOnDiagonal = absOnDiagonal;
    }
    for (Index j = 0; j < cols(); ++j)
      for (Index i = 0; i < j; ++i) {
        if (!internal::isMuchSmallerThan(coeff(i, j), maxAbsOnDiagonal, prec))
          return false;
        if (!internal::isMuchSmallerThan(coeff(j, i), maxAbsOnDiagonal, prec))
          return false;
      }
    return true;
  }
  namespace internal {
    template <>
    struct storage_kind_to_shape<DiagonalShape> {
      typedef DiagonalShape Shape;
    };
    struct Diagonal2Dense {};
    template <>
    struct AssignmentKind<DenseShape, DiagonalShape> {
      typedef Diagonal2Dense Kind;
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    struct Assignment<DstXprType, SrcXprType, Functor, Diagonal2Dense> {
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        dst.setZero();
        dst.diagonal() = src.diagonal();
      }
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::add_assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        dst.diagonal() += src.diagonal();
      }
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::sub_assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        dst.diagonal() -= src.diagonal();
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, int DiagIndex>
    struct traits<Diagonal<MatrixType, DiagIndex>> : traits<MatrixType> {
      typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNested_;
      typedef typename MatrixType::StorageKind StorageKind;
      enum {
        RowsAtCompileTime = (int(DiagIndex) == DynamicIndex || int(MatrixType::SizeAtCompileTime) == Dynamic)
                                ? Dynamic
                                : (plain_enum_min(MatrixType::RowsAtCompileTime - plain_enum_max(-DiagIndex, 0),
                                                  MatrixType::ColsAtCompileTime - plain_enum_max(DiagIndex, 0))),
        ColsAtCompileTime = 1,
        MaxRowsAtCompileTime =
            int(MatrixType::MaxSizeAtCompileTime) == Dynamic ? Dynamic
            : DiagIndex == DynamicIndex
                ? min_size_prefer_fixed(MatrixType::MaxRowsAtCompileTime, MatrixType::MaxColsAtCompileTime)
                : (plain_enum_min(MatrixType::MaxRowsAtCompileTime - plain_enum_max(-DiagIndex, 0),
                                  MatrixType::MaxColsAtCompileTime - plain_enum_max(DiagIndex, 0))),
        MaxColsAtCompileTime = 1,
        MaskLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
        Flags = (unsigned int)MatrixTypeNested_::Flags & (RowMajorBit | MaskLvalueBit | DirectAccessBit) & ~RowMajorBit,
        MatrixTypeOuterStride = outer_stride_at_compile_time<MatrixType>::ret,
        InnerStrideAtCompileTime = MatrixTypeOuterStride == Dynamic ? Dynamic : MatrixTypeOuterStride + 1,
        OuterStrideAtCompileTime = 0
      };
    };
  }  // namespace internal
  template <typename MatrixType, int DiagIndex_>
  class Diagonal : public internal::dense_xpr_base<Diagonal<MatrixType, DiagIndex_>>::type {
  public:
    enum { DiagIndex = DiagIndex_ };
    typedef typename internal::dense_xpr_base<Diagonal>::type Base;
    typedef typename Eigen::internal::traits<Diagonal>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Diagonal>::type Nested;
    typedef typename Eigen::internal::traits<Diagonal>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Diagonal>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Diagonal>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Diagonal>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Diagonal>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    explicit inline Diagonal(MatrixType& matrix, Index a_index = DiagIndex) : m_matrix(matrix), m_index(a_index) {
      (static_cast<bool>(a_index <= m_matrix.cols() && -a_index <= m_matrix.rows())
           ? void(0)
           : __assert_fail("a_index <= m_matrix.cols() && -a_index <= m_matrix.rows()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Diagonal.h",
                           77,
                           __extension__ __PRETTY_FUNCTION__));
    }
    using Base::operator=;
    inline Diagonal& operator=(const Diagonal& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Diagonal& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Diagonal(const Diagonal&) = default;
    inline Index rows() const {
      return m_index.value() < 0 ? numext::mini<Index>(m_matrix.cols(), m_matrix.rows() + m_index.value())
                                 : numext::mini<Index>(m_matrix.rows(), m_matrix.cols() - m_index.value());
    }
    constexpr inline Index cols() const noexcept { return 1; }
    constexpr inline Index innerStride() const noexcept { return m_matrix.outerStride() + 1; }
    constexpr inline Index outerStride() const noexcept { return 0; }
    typedef std::conditional_t<internal::is_lvalue<MatrixType>::value, Scalar, const Scalar> ScalarWithConstIfNotLvalue;
    inline ScalarWithConstIfNotLvalue* data() { return &(m_matrix.coeffRef(rowOffset(), colOffset())); }
    inline const Scalar* data() const { return &(m_matrix.coeffRef(rowOffset(), colOffset())); }
    inline Scalar& coeffRef(Index row, Index) {
      static_assert(Eigen::internal::is_lvalue<MatrixType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      return m_matrix.coeffRef(row + rowOffset(), row + colOffset());
    }
    inline const Scalar& coeffRef(Index row, Index) const {
      return m_matrix.coeffRef(row + rowOffset(), row + colOffset());
    }
    inline CoeffReturnType coeff(Index row, Index) const {
      return m_matrix.coeff(row + rowOffset(), row + colOffset());
    }
    inline Scalar& coeffRef(Index idx) {
      static_assert(Eigen::internal::is_lvalue<MatrixType>::value, "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      return m_matrix.coeffRef(idx + rowOffset(), idx + colOffset());
    }
    inline const Scalar& coeffRef(Index idx) const { return m_matrix.coeffRef(idx + rowOffset(), idx + colOffset()); }
    inline CoeffReturnType coeff(Index idx) const { return m_matrix.coeff(idx + rowOffset(), idx + colOffset()); }
    inline const internal::remove_all_t<typename MatrixType::Nested>& nestedExpression() const { return m_matrix; }
    inline Index index() const { return m_index.value(); }

  protected:
    typename internal::ref_selector<MatrixType>::non_const_type m_matrix;
    const internal::variable_if_dynamicindex<Index, DiagIndex> m_index;

  private:
    inline constexpr Index absDiagIndex() const noexcept {
      return m_index.value() > 0 ? m_index.value() : -m_index.value();
    }
    inline constexpr Index rowOffset() const noexcept { return m_index.value() > 0 ? 0 : -m_index.value(); }
    inline constexpr Index colOffset() const noexcept { return m_index.value() > 0 ? m_index.value() : 0; }
    template <int LoadMode>
    typename MatrixType::PacketReturnType packet(Index) const;
    template <int LoadMode>
    typename MatrixType::PacketReturnType packet(Index, Index) const;
  };
  template <typename Derived>
  inline typename MatrixBase<Derived>::DiagonalReturnType MatrixBase<Derived>::diagonal() {
    return DiagonalReturnType(derived());
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::ConstDiagonalReturnType MatrixBase<Derived>::diagonal() const {
    return ConstDiagonalReturnType(derived());
  }
  template <typename Derived>
  inline Diagonal<Derived, DynamicIndex> MatrixBase<Derived>::diagonal(Index index) {
    return Diagonal<Derived, DynamicIndex>(derived(), index);
  }
  template <typename Derived>
  inline const Diagonal<const Derived, DynamicIndex> MatrixBase<Derived>::diagonal(Index index) const {
    return Diagonal<const Derived, DynamicIndex>(derived(), index);
  }
  template <typename Derived>
  template <int Index_>
  inline Diagonal<Derived, Index_> MatrixBase<Derived>::diagonal() {
    return Diagonal<Derived, Index_>(derived());
  }
  template <typename Derived>
  template <int Index_>
  inline const Diagonal<const Derived, Index_> MatrixBase<Derived>::diagonal() const {
    return Diagonal<const Derived, Index_>(derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  template <typename DiagonalDerived>
  inline const Product<Derived, DiagonalDerived, LazyProduct> MatrixBase<Derived>::operator*(
      const DiagonalBase<DiagonalDerived>& a_diagonal) const {
    return Product<Derived, DiagonalDerived, LazyProduct>(derived(), a_diagonal.derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  class SkewSymmetricBase : public EigenBase<Derived> {
  public:
    typedef typename internal::traits<Derived>::SkewSymmetricVectorType SkewSymmetricVectorType;
    typedef typename SkewSymmetricVectorType::Scalar Scalar;
    typedef typename SkewSymmetricVectorType::RealScalar RealScalar;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
    enum {
      RowsAtCompileTime = SkewSymmetricVectorType::SizeAtCompileTime,
      ColsAtCompileTime = SkewSymmetricVectorType::SizeAtCompileTime,
      MaxRowsAtCompileTime = SkewSymmetricVectorType::MaxSizeAtCompileTime,
      MaxColsAtCompileTime = SkewSymmetricVectorType::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = 0,
      Flags = NoPreferredStorageOrderBit
    };
    typedef Matrix<Scalar, RowsAtCompileTime, ColsAtCompileTime, 0, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        DenseMatrixType;
    typedef DenseMatrixType DenseType;
    typedef SkewSymmetricMatrix3<Scalar> PlainObject;
    inline const Derived& derived() const { return *static_cast<const Derived*>(this); }
    inline Derived& derived() { return *static_cast<Derived*>(this); }
    DenseMatrixType toDenseMatrix() const { return derived(); }
    constexpr inline Scalar determinant() const { return 0; }
    PlainObject transpose() const { return (-vector()).asSkewSymmetric(); }
    DenseMatrixType exponential() const {
      DenseMatrixType retVal = DenseMatrixType::Identity();
      const SkewSymmetricVectorType& v = vector();
      if (v.isZero()) {
        return retVal;
      }
      const Scalar norm2 = v.squaredNorm();
      const Scalar norm = numext::sqrt(norm2);
      retVal += ((((1 - numext::cos(norm)) / norm2) * derived()) * derived()) +
                (numext::sin(norm) / norm) * derived().toDenseMatrix();
      return retVal;
    }
    inline const SkewSymmetricVectorType& vector() const { return derived().vector(); }
    inline SkewSymmetricVectorType& vector() { return derived().vector(); }
    constexpr inline Index rows() const { return 3; }
    constexpr inline Index cols() const { return 3; }
    template <typename MatrixDerived>
    Product<Derived, MatrixDerived, LazyProduct> operator*(const MatrixBase<MatrixDerived>& matrix) const {
      return Product<Derived, MatrixDerived, LazyProduct>(derived(), matrix.derived());
    }
    template <typename MatrixDerived>
    Product<Derived, MatrixDerived, LazyProduct> operator*(const SkewSymmetricBase<MatrixDerived>& matrix) const {
      return Product<Derived, MatrixDerived, LazyProduct>(derived(), matrix.derived());
    }
    template <typename OtherDerived>
    using SkewSymmetricProductReturnType = SkewSymmetricWrapper<const CwiseBinaryOp<
        internal::scalar_product_op<typename internal::traits<SkewSymmetricVectorType>::Scalar,
                                    typename internal::traits<typename OtherDerived::SkewSymmetricVectorType>::Scalar>,
        const SkewSymmetricVectorType,
        const typename OtherDerived::SkewSymmetricVectorType>>;
    template <typename OtherDerived>
    SkewSymmetricProductReturnType<OtherDerived> wedge(const SkewSymmetricBase<OtherDerived>& other) const {
      return vector().cross(other.vector()).asSkewSymmetric();
    }
    using SkewSymmetricScaleReturnType = SkewSymmetricWrapper<const CwiseBinaryOp<
        internal::scalar_product_op<typename internal::traits<SkewSymmetricVectorType>::Scalar, Scalar>,
        const SkewSymmetricVectorType,
        const typename internal::plain_constant_type<SkewSymmetricVectorType, Scalar>::type>>;
    inline SkewSymmetricScaleReturnType operator*(const Scalar& scalar) const {
      return (vector() * scalar).asSkewSymmetric();
    }
    using ScaleSkewSymmetricReturnType = SkewSymmetricWrapper<const CwiseBinaryOp<
        internal::scalar_product_op<Scalar, typename internal::traits<SkewSymmetricVectorType>::Scalar>,
        const typename internal::plain_constant_type<SkewSymmetricVectorType, Scalar>::type,
        const SkewSymmetricVectorType>>;
    friend inline ScaleSkewSymmetricReturnType operator*(const Scalar& scalar, const SkewSymmetricBase& other) {
      return (scalar * other.vector()).asSkewSymmetric();
    }
    template <typename OtherDerived>
    using SkewSymmetricSumReturnType = SkewSymmetricWrapper<const CwiseBinaryOp<
        internal::scalar_sum_op<typename internal::traits<SkewSymmetricVectorType>::Scalar,
                                typename internal::traits<typename OtherDerived::SkewSymmetricVectorType>::Scalar>,
        const SkewSymmetricVectorType,
        const typename OtherDerived::SkewSymmetricVectorType>>;
    template <typename OtherDerived>
    inline SkewSymmetricSumReturnType<OtherDerived> operator+(const SkewSymmetricBase<OtherDerived>& other) const {
      return (vector() + other.vector()).asSkewSymmetric();
    }
    template <typename OtherDerived>
    using SkewSymmetricDifferenceReturnType = SkewSymmetricWrapper<const CwiseBinaryOp<
        internal::scalar_difference_op<typename internal::traits<SkewSymmetricVectorType>::Scalar,
                                       typename internal::traits<typename OtherDerived::SkewSymmetricVectorType>::Scalar>,
        const SkewSymmetricVectorType,
        const typename OtherDerived::SkewSymmetricVectorType>>;
    template <typename OtherDerived>
    inline SkewSymmetricDifferenceReturnType<OtherDerived> operator-(
        const SkewSymmetricBase<OtherDerived>& other) const {
      return (vector() - other.vector()).asSkewSymmetric();
    }
  };
  namespace internal {
    template <typename Scalar_>
    struct traits<SkewSymmetricMatrix3<Scalar_>> : traits<Matrix<Scalar_, 3, 3, 0, 3, 3>> {
      typedef Matrix<Scalar_, 3, 1, 0, 3, 1> SkewSymmetricVectorType;
      typedef SkewSymmetricShape StorageKind;
      enum { Flags = LvalueBit | NoPreferredStorageOrderBit | NestByRefBit };
    };
  }  // namespace internal
  template <typename Scalar_>
  class SkewSymmetricMatrix3 : public SkewSymmetricBase<SkewSymmetricMatrix3<Scalar_>> {
  public:
    typedef typename internal::traits<SkewSymmetricMatrix3>::SkewSymmetricVectorType SkewSymmetricVectorType;
    typedef const SkewSymmetricMatrix3& Nested;
    typedef Scalar_ Scalar;
    typedef typename internal::traits<SkewSymmetricMatrix3>::StorageKind StorageKind;
    typedef typename internal::traits<SkewSymmetricMatrix3>::StorageIndex StorageIndex;

  protected:
    SkewSymmetricVectorType m_vector;

  public:
    inline const SkewSymmetricVectorType& vector() const { return m_vector; }
    inline SkewSymmetricVectorType& vector() { return m_vector; }
    inline SkewSymmetricMatrix3() {}
    inline SkewSymmetricMatrix3(const Scalar& x, const Scalar& y, const Scalar& z) : m_vector(x, y, z) {}
    explicit inline SkewSymmetricMatrix3(SkewSymmetricVectorType&& vec) : m_vector(std::move(vec)) {}
    template <typename OtherDerived>
    explicit inline SkewSymmetricMatrix3(const MatrixBase<OtherDerived>& other) : m_vector(other) {}
    template <typename OtherDerived>
    inline SkewSymmetricMatrix3(const SkewSymmetricBase<OtherDerived>& other) : m_vector(other.vector()) {}
    inline SkewSymmetricMatrix3(const SkewSymmetricMatrix3& other) : m_vector(other.vector()) {}
    template <typename OtherDerived>
    SkewSymmetricMatrix3& operator=(const SkewSymmetricBase<OtherDerived>& other) {
      m_vector = other.vector();
      return *this;
    }
    SkewSymmetricMatrix3& operator=(const SkewSymmetricMatrix3& other) {
      m_vector = other.vector();
      return *this;
    }
    typedef SkewSymmetricWrapper<const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, SkewSymmetricVectorType>>
        InitializeReturnType;
    static InitializeReturnType Zero() { return SkewSymmetricVectorType::Zero().asSkewSymmetric(); }
    inline void setZero() { m_vector.setZero(); }
  };
  namespace internal {
    template <typename SkewSymmetricVectorType_>
    struct traits<SkewSymmetricWrapper<SkewSymmetricVectorType_>> {
      typedef SkewSymmetricVectorType_ SkewSymmetricVectorType;
      typedef typename SkewSymmetricVectorType::Scalar Scalar;
      typedef typename SkewSymmetricVectorType::StorageIndex StorageIndex;
      typedef SkewSymmetricShape StorageKind;
      typedef typename traits<SkewSymmetricVectorType>::XprKind XprKind;
      enum {
        RowsAtCompileTime = SkewSymmetricVectorType::SizeAtCompileTime,
        ColsAtCompileTime = SkewSymmetricVectorType::SizeAtCompileTime,
        MaxRowsAtCompileTime = SkewSymmetricVectorType::MaxSizeAtCompileTime,
        MaxColsAtCompileTime = SkewSymmetricVectorType::MaxSizeAtCompileTime,
        Flags = (traits<SkewSymmetricVectorType>::Flags & LvalueBit) | NoPreferredStorageOrderBit
      };
    };
  }  // namespace internal
  template <typename SkewSymmetricVectorType_>
  class SkewSymmetricWrapper : public SkewSymmetricBase<SkewSymmetricWrapper<SkewSymmetricVectorType_>>,
                               internal::no_assignment_operator {
  public:
    typedef SkewSymmetricVectorType_ SkewSymmetricVectorType;
    typedef SkewSymmetricWrapper Nested;
    explicit inline SkewSymmetricWrapper(SkewSymmetricVectorType& a_vector) : m_vector(a_vector) {}
    const SkewSymmetricVectorType& vector() const { return m_vector; }

  protected:
    typename SkewSymmetricVectorType::Nested m_vector;
  };
  template <typename Derived>
  inline const SkewSymmetricWrapper<const Derived> MatrixBase<Derived>::asSkewSymmetric() const {
    return SkewSymmetricWrapper<const Derived>(derived());
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isSkewSymmetric(const RealScalar& prec) const {
    if (cols() != rows())
      return false;
    return (this->transpose() + *this).isZero(prec);
  }
  template <typename Derived>
  template <typename SkewDerived>
  inline const Product<Derived, SkewDerived, LazyProduct> MatrixBase<Derived>::operator*(
      const SkewSymmetricBase<SkewDerived>& skew) const {
    return Product<Derived, SkewDerived, LazyProduct>(derived(), skew.derived());
  }
  namespace internal {
    template <>
    struct storage_kind_to_shape<SkewSymmetricShape> {
      typedef SkewSymmetricShape Shape;
    };
    struct SkewSymmetric2Dense {};
    template <>
    struct AssignmentKind<DenseShape, SkewSymmetricShape> {
      typedef SkewSymmetric2Dense Kind;
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    struct Assignment<DstXprType, SrcXprType, Functor, SkewSymmetric2Dense> {
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        if ((dst.rows() != 3) || (dst.cols() != 3)) {
          dst.resize(3, 3);
        }
        dst.diagonal().setZero();
        const typename SrcXprType::SkewSymmetricVectorType v = src.vector();
        dst(0, 1) = -v(2);
        dst(1, 0) = v(2);
        dst(0, 2) = v(1);
        dst(2, 0) = -v(1);
        dst(1, 2) = -v(0);
        dst(2, 1) = v(0);
      }
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::add_assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        dst.vector() += src.vector();
      }
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::sub_assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>&) {
        dst.vector() -= src.vector();
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Func, typename Evaluator>
    struct redux_traits {
    public:
      typedef typename find_best_packet<typename Evaluator::Scalar, Evaluator::SizeAtCompileTime>::type PacketType;
      enum {
        PacketSize = unpacket_traits<PacketType>::size,
        InnerMaxSize = int(Evaluator::IsRowMajor) ? Evaluator::MaxColsAtCompileTime : Evaluator::MaxRowsAtCompileTime,
        OuterMaxSize = int(Evaluator::IsRowMajor) ? Evaluator::MaxRowsAtCompileTime : Evaluator::MaxColsAtCompileTime,
        SliceVectorizedWork = int(InnerMaxSize) == Dynamic   ? Dynamic
                              : int(OuterMaxSize) == Dynamic ? (int(InnerMaxSize) >= int(PacketSize) ? Dynamic : 0)
                                                             : (int(InnerMaxSize) / int(PacketSize)) * int(OuterMaxSize)
      };
      enum {
        MightVectorize = (int(Evaluator::Flags) & ActualPacketAccessBit) && (functor_traits<Func>::PacketAccess),
        MayLinearVectorize = bool(MightVectorize) && (int(Evaluator::Flags) & LinearAccessBit),
        MaySliceVectorize =
            bool(MightVectorize) && (int(SliceVectorizedWork) == Dynamic || int(SliceVectorizedWork) >= 3)
      };

    public:
      enum {
        Traversal = int(MayLinearVectorize)  ? int(LinearVectorizedTraversal)
                    : int(MaySliceVectorize) ? int(SliceVectorizedTraversal)
                                             : int(DefaultTraversal)
      };

    public:
      enum {
        Cost = Evaluator::SizeAtCompileTime == Dynamic
                   ? HugeCost
                   : int(Evaluator::SizeAtCompileTime) * int(Evaluator::CoeffReadCost) +
                         (Evaluator::SizeAtCompileTime - 1) * functor_traits<Func>::Cost,
        UnrollingLimit = 110 * (int(Traversal) == int(DefaultTraversal) ? 1 : int(PacketSize))
      };

    public:
      enum { Unrolling = Cost <= UnrollingLimit ? CompleteUnrolling : NoUnrolling };
    };
    template <typename Func, typename Evaluator, int Start, int Length>
    struct redux_novec_unroller {
      enum { HalfLength = Length / 2 };
      typedef typename Evaluator::Scalar Scalar;
      static inline Scalar run(const Evaluator& eval, const Func& func) {
        return func(redux_novec_unroller<Func, Evaluator, Start, HalfLength>::run(eval, func),
                    redux_novec_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::run(eval, func));
      }
    };
    template <typename Func, typename Evaluator, int Start>
    struct redux_novec_unroller<Func, Evaluator, Start, 1> {
      enum { outer = Start / Evaluator::InnerSizeAtCompileTime, inner = Start % Evaluator::InnerSizeAtCompileTime };
      typedef typename Evaluator::Scalar Scalar;
      static inline Scalar run(const Evaluator& eval, const Func&) { return eval.coeffByOuterInner(outer, inner); }
    };
    template <typename Func, typename Evaluator, int Start>
    struct redux_novec_unroller<Func, Evaluator, Start, 0> {
      typedef typename Evaluator::Scalar Scalar;
      static inline Scalar run(const Evaluator&, const Func&) { return Scalar(); }
    };
    template <typename Func, typename Evaluator, int Start, int Length>
    struct redux_vec_unroller {
      template <typename PacketType>
      static inline PacketType run(const Evaluator& eval, const Func& func) {
        enum { PacketSize = unpacket_traits<PacketType>::size, HalfLength = Length / 2 };
        return func.packetOp(
            redux_vec_unroller<Func, Evaluator, Start, HalfLength>::template run<PacketType>(eval, func),
            redux_vec_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::template run<PacketType>(
                eval, func));
      }
    };
    template <typename Func, typename Evaluator, int Start>
    struct redux_vec_unroller<Func, Evaluator, Start, 1> {
      template <typename PacketType>
      static inline PacketType run(const Evaluator& eval, const Func&) {
        enum {
          PacketSize = unpacket_traits<PacketType>::size,
          index = Start * PacketSize,
          outer = index / int(Evaluator::InnerSizeAtCompileTime),
          inner = index % int(Evaluator::InnerSizeAtCompileTime),
          alignment = Evaluator::Alignment
        };
        return eval.template packetByOuterInner<alignment, PacketType>(outer, inner);
      }
    };
    template <typename Func,
              typename Evaluator,
              int Traversal = redux_traits<Func, Evaluator>::Traversal,
              int Unrolling = redux_traits<Func, Evaluator>::Unrolling>
    struct redux_impl;
    template <typename Func, typename Evaluator>
    struct redux_impl<Func, Evaluator, DefaultTraversal, NoUnrolling> {
      typedef typename Evaluator::Scalar Scalar;
      template <typename XprType>
      static inline Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
        (static_cast<bool>(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix")
             ? void(0)
             : __assert_fail("xpr.rows()>0 && xpr.cols()>0 && \"you are using an empty matrix\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Redux.h",
                             202,
                             __extension__ __PRETTY_FUNCTION__));
        Scalar res = eval.coeffByOuterInner(0, 0);
        for (Index i = 1; i < xpr.innerSize(); ++i)
          res = func(res, eval.coeffByOuterInner(0, i));
        for (Index i = 1; i < xpr.outerSize(); ++i)
          for (Index j = 0; j < xpr.innerSize(); ++j)
            res = func(res, eval.coeffByOuterInner(i, j));
        return res;
      }
    };
    template <typename Func, typename Evaluator>
    struct redux_impl<Func, Evaluator, DefaultTraversal, CompleteUnrolling>
        : redux_novec_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> {
      typedef redux_novec_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> Base;
      typedef typename Evaluator::Scalar Scalar;
      template <typename XprType>
      static inline Scalar run(const Evaluator& eval, const Func& func, const XprType&) {
        return Base::run(eval, func);
      }
    };
    template <typename Func, typename Evaluator>
    struct redux_impl<Func, Evaluator, LinearVectorizedTraversal, NoUnrolling> {
      typedef typename Evaluator::Scalar Scalar;
      typedef typename redux_traits<Func, Evaluator>::PacketType PacketScalar;
      template <typename XprType>
      static Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
        const Index size = xpr.size();
        const Index packetSize = redux_traits<Func, Evaluator>::PacketSize;
        const int packetAlignment = unpacket_traits<PacketScalar>::alignment;
        enum {
          alignment0 = (bool(Evaluator::Flags & DirectAccessBit) && bool(packet_traits<Scalar>::AlignedOnScalar))
                           ? int(packetAlignment)
                           : int(Unaligned),
          alignment = plain_enum_max(alignment0, Evaluator::Alignment)
        };
        const Index alignedStart = internal::first_default_aligned(xpr);
        const Index alignedSize2 = ((size - alignedStart) / (2 * packetSize)) * (2 * packetSize);
        const Index alignedSize = ((size - alignedStart) / (packetSize)) * (packetSize);
        const Index alignedEnd2 = alignedStart + alignedSize2;
        const Index alignedEnd = alignedStart + alignedSize;
        Scalar res;
        if (alignedSize) {
          PacketScalar packet_res0 = eval.template packet<alignment, PacketScalar>(alignedStart);
          if (alignedSize > packetSize) {
            PacketScalar packet_res1 = eval.template packet<alignment, PacketScalar>(alignedStart + packetSize);
            for (Index index = alignedStart + 2 * packetSize; index < alignedEnd2; index += 2 * packetSize) {
              packet_res0 = func.packetOp(packet_res0, eval.template packet<alignment, PacketScalar>(index));
              packet_res1 =
                  func.packetOp(packet_res1, eval.template packet<alignment, PacketScalar>(index + packetSize));
            }
            packet_res0 = func.packetOp(packet_res0, packet_res1);
            if (alignedEnd > alignedEnd2)
              packet_res0 = func.packetOp(packet_res0, eval.template packet<alignment, PacketScalar>(alignedEnd2));
          }
          res = func.predux(packet_res0);
          for (Index index = 0; index < alignedStart; ++index)
            res = func(res, eval.coeff(index));
          for (Index index = alignedEnd; index < size; ++index)
            res = func(res, eval.coeff(index));
        } else {
          res = eval.coeff(0);
          for (Index index = 1; index < size; ++index)
            res = func(res, eval.coeff(index));
        }
        return res;
      }
    };
    template <typename Func, typename Evaluator, int Unrolling>
    struct redux_impl<Func, Evaluator, SliceVectorizedTraversal, Unrolling> {
      typedef typename Evaluator::Scalar Scalar;
      typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
      template <typename XprType>
      static Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
        (static_cast<bool>(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix")
             ? void(0)
             : __assert_fail("xpr.rows()>0 && xpr.cols()>0 && \"you are using an empty matrix\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Redux.h",
                             296,
                             __extension__ __PRETTY_FUNCTION__));
        const Index innerSize = xpr.innerSize();
        const Index outerSize = xpr.outerSize();
        enum { packetSize = redux_traits<Func, Evaluator>::PacketSize };
        const Index packetedInnerSize = ((innerSize) / packetSize) * packetSize;
        Scalar res;
        if (packetedInnerSize) {
          PacketType packet_res = eval.template packet<Unaligned, PacketType>(0, 0);
          for (Index j = 0; j < outerSize; ++j)
            for (Index i = (j == 0 ? packetSize : 0); i < packetedInnerSize; i += Index(packetSize))
              packet_res = func.packetOp(packet_res, eval.template packetByOuterInner<Unaligned, PacketType>(j, i));
          res = func.predux(packet_res);
          for (Index j = 0; j < outerSize; ++j)
            for (Index i = packetedInnerSize; i < innerSize; ++i)
              res = func(res, eval.coeffByOuterInner(j, i));
        } else {
          res = redux_impl<Func, Evaluator, DefaultTraversal, NoUnrolling>::run(eval, func, xpr);
        }
        return res;
      }
    };
    template <typename Func, typename Evaluator>
    struct redux_impl<Func, Evaluator, LinearVectorizedTraversal, CompleteUnrolling> {
      typedef typename Evaluator::Scalar Scalar;
      typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
      enum {
        PacketSize = redux_traits<Func, Evaluator>::PacketSize,
        Size = Evaluator::SizeAtCompileTime,
        VectorizedSize = (int(Size) / int(PacketSize)) * int(PacketSize)
      };
      template <typename XprType>
      static inline Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
        (static_cast<bool>(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix")
             ? void(0)
             : __assert_fail("xpr.rows()>0 && xpr.cols()>0 && \"you are using an empty matrix\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/Redux.h",
                             343,
                             __extension__ __PRETTY_FUNCTION__));
        if (VectorizedSize > 0) {
          Scalar res = func.predux(
              redux_vec_unroller<Func, Evaluator, 0, Size / PacketSize>::template run<PacketType>(eval, func));
          if (VectorizedSize != Size)
            res = func(res,
                       redux_novec_unroller<Func, Evaluator, VectorizedSize, Size - VectorizedSize>::run(eval, func));
          return res;
        } else {
          return redux_novec_unroller<Func, Evaluator, 0, Size>::run(eval, func);
        }
      }
    };
    template <typename XprType_>
    class redux_evaluator : public internal::evaluator<XprType_> {
      typedef internal::evaluator<XprType_> Base;

    public:
      typedef XprType_ XprType;
      inline explicit redux_evaluator(const XprType& xpr) : Base(xpr) {}
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      typedef typename XprType::PacketScalar PacketScalar;
      enum {
        MaxRowsAtCompileTime = XprType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = XprType::MaxColsAtCompileTime,
        Flags = Base::Flags & ~DirectAccessBit,
        IsRowMajor = XprType::IsRowMajor,
        SizeAtCompileTime = XprType::SizeAtCompileTime,
        InnerSizeAtCompileTime = XprType::InnerSizeAtCompileTime
      };
      inline CoeffReturnType coeffByOuterInner(Index outer, Index inner) const {
        return Base::coeff(IsRowMajor ? outer : inner, IsRowMajor ? inner : outer);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packetByOuterInner(Index outer, Index inner) const {
        return Base::template packet<LoadMode, PacketType>(IsRowMajor ? outer : inner, IsRowMajor ? inner : outer);
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename Func>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::redux(const Func& func) const {
    (static_cast<bool>(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix")
         ? void(0)
         : __assert_fail("this->rows()>0 && this->cols()>0 && \"you are using an empty matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Redux.h",
                         412,
                         __extension__ __PRETTY_FUNCTION__));
    typedef typename internal::redux_evaluator<Derived> ThisEvaluator;
    ThisEvaluator thisEval(derived());
    return internal::redux_impl<Func, ThisEvaluator>::run(thisEval, func, derived());
  }
  template <typename Derived>
  template <int NaNPropagation>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::minCoeff() const {
    return derived().redux(Eigen::internal::scalar_min_op<Scalar, Scalar, NaNPropagation>());
  }
  template <typename Derived>
  template <int NaNPropagation>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::maxCoeff() const {
    return derived().redux(Eigen::internal::scalar_max_op<Scalar, Scalar, NaNPropagation>());
  }
  template <typename Derived>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::sum() const {
    if (SizeAtCompileTime == 0 || (SizeAtCompileTime == Dynamic && size() == 0))
      return Scalar(0);
    return derived().redux(Eigen::internal::scalar_sum_op<Scalar, Scalar>());
  }
  template <typename Derived>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::mean() const {
    return Scalar(derived().redux(Eigen::internal::scalar_sum_op<Scalar, Scalar>())) / Scalar(this->size());
  }
  template <typename Derived>
  inline typename internal::traits<Derived>::Scalar DenseBase<Derived>::prod() const {
    if (SizeAtCompileTime == 0 || (SizeAtCompileTime == Dynamic && size() == 0))
      return Scalar(1);
    return derived().redux(Eigen::internal::scalar_product_op<Scalar>());
  }
  template <typename Derived>
  inline typename internal::traits<Derived>::Scalar MatrixBase<Derived>::trace() const {
    return derived().diagonal().sum();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Visitor,
              typename Derived,
              int UnrollCount,
              bool Vectorize = ((Derived::PacketAccess != 0) && functor_traits<Visitor>::PacketAccess)>
    struct visitor_impl;
    template <typename Visitor, typename Derived, int UnrollCount>
    struct visitor_impl<Visitor, Derived, UnrollCount, false> {
      enum {
        col = Derived::IsRowMajor ? (UnrollCount - 1) % Derived::ColsAtCompileTime
                                  : (UnrollCount - 1) / Derived::RowsAtCompileTime,
        row = Derived::IsRowMajor ? (UnrollCount - 1) / Derived::ColsAtCompileTime
                                  : (UnrollCount - 1) % Derived::RowsAtCompileTime
      };
      static inline void run(const Derived& mat, Visitor& visitor) {
        visitor_impl<Visitor, Derived, UnrollCount - 1>::run(mat, visitor);
        visitor(mat.coeff(row, col), row, col);
      }
    };
    template <typename Visitor, typename Derived>
    struct visitor_impl<Visitor, Derived, 1, false> {
      static inline void run(const Derived& mat, Visitor& visitor) { return visitor.init(mat.coeff(0, 0), 0, 0); }
    };
    template <typename Visitor, typename Derived>
    struct visitor_impl<Visitor, Derived, 0, false> {
      static inline void run(const Derived&, Visitor&) {}
    };
    template <typename Visitor, typename Derived>
    struct visitor_impl<Visitor, Derived, Dynamic, false> {
      static inline void run(const Derived& mat, Visitor& visitor) {
        visitor.init(mat.coeff(0, 0), 0, 0);
        if (Derived::IsRowMajor) {
          for (Index i = 1; i < mat.cols(); ++i) {
            visitor(mat.coeff(0, i), 0, i);
          }
          for (Index j = 1; j < mat.rows(); ++j) {
            for (Index i = 0; i < mat.cols(); ++i) {
              visitor(mat.coeff(j, i), j, i);
            }
          }
        } else {
          for (Index i = 1; i < mat.rows(); ++i) {
            visitor(mat.coeff(i, 0), i, 0);
          }
          for (Index j = 1; j < mat.cols(); ++j) {
            for (Index i = 0; i < mat.rows(); ++i) {
              visitor(mat.coeff(i, j), i, j);
            }
          }
        }
      }
    };
    template <typename Visitor, typename Derived, int UnrollSize>
    struct visitor_impl<Visitor, Derived, UnrollSize, true> {
      typedef typename Derived::Scalar Scalar;
      typedef typename packet_traits<Scalar>::type Packet;
      static inline void run(const Derived& mat, Visitor& visitor) {
        const Index PacketSize = packet_traits<Scalar>::size;
        visitor.init(mat.coeff(0, 0), 0, 0);
        if (Derived::IsRowMajor) {
          for (Index i = 0; i < mat.rows(); ++i) {
            Index j = i == 0 ? 1 : 0;
            for (; j + PacketSize - 1 < mat.cols(); j += PacketSize) {
              Packet p = mat.packet(i, j);
              visitor.packet(p, i, j);
            }
            for (; j < mat.cols(); ++j)
              visitor(mat.coeff(i, j), i, j);
          }
        } else {
          for (Index j = 0; j < mat.cols(); ++j) {
            Index i = j == 0 ? 1 : 0;
            for (; i + PacketSize - 1 < mat.rows(); i += PacketSize) {
              Packet p = mat.packet(i, j);
              visitor.packet(p, i, j);
            }
            for (; i < mat.rows(); ++i)
              visitor(mat.coeff(i, j), i, j);
          }
        }
      }
    };
    template <typename XprType>
    class visitor_evaluator {
    public:
      typedef internal::evaluator<XprType> Evaluator;
      enum {
        PacketAccess = Evaluator::Flags & PacketAccessBit,
        IsRowMajor = XprType::IsRowMajor,
        RowsAtCompileTime = XprType::RowsAtCompileTime,
        ColsAtCompileTime = XprType::ColsAtCompileTime,
        CoeffReadCost = Evaluator::CoeffReadCost
      };
      explicit visitor_evaluator(const XprType& xpr) : m_evaluator(xpr), m_xpr(xpr) {}
      typedef typename XprType::Scalar Scalar;
      typedef std::remove_const_t<typename XprType::CoeffReturnType> CoeffReturnType;
      typedef std::remove_const_t<typename XprType::PacketReturnType> PacketReturnType;
      constexpr Index rows() const noexcept { return m_xpr.rows(); }
      constexpr Index cols() const noexcept { return m_xpr.cols(); }
      constexpr Index size() const noexcept { return m_xpr.size(); }
      CoeffReturnType coeff(Index row, Index col) const { return m_evaluator.coeff(row, col); }
      PacketReturnType packet(Index row, Index col) const {
        return m_evaluator.template packet<Unaligned, PacketReturnType>(row, col);
      }

    protected:
      Evaluator m_evaluator;
      const XprType& m_xpr;
    };
  }  // namespace internal
  template <typename Derived>
  template <typename Visitor>
  void DenseBase<Derived>::visit(Visitor& visitor) const {
    if (size() == 0)
      return;
    typedef typename internal::visitor_evaluator<Derived> ThisEvaluator;
    ThisEvaluator thisEval(derived());
    enum {
      unroll = SizeAtCompileTime != Dynamic &&
               SizeAtCompileTime * int(ThisEvaluator::CoeffReadCost) +
                       (SizeAtCompileTime - 1) * int(internal::functor_traits<Visitor>::Cost) <=
                   110
    };
    return internal::visitor_impl < Visitor, ThisEvaluator,
           unroll ? int(SizeAtCompileTime) : Dynamic > ::run(thisEval, visitor);
  }
  namespace internal {
    template <typename Derived>
    struct coeff_visitor {
      coeff_visitor() : row(-1), col(-1), res(0) {}
      typedef typename Derived::Scalar Scalar;
      Index row, col;
      Scalar res;
      inline void init(const Scalar& value, Index i, Index j) {
        res = value;
        row = i;
        col = j;
      }
    };
    template <typename Scalar, int NaNPropagation, bool is_min = true>
    struct minmax_compare {
      typedef typename packet_traits<Scalar>::type Packet;
      static inline bool compare(Scalar a, Scalar b) { return a < b; }
      static inline Scalar predux(const Packet& p) { return predux_min<NaNPropagation>(p); }
    };
    template <typename Scalar, int NaNPropagation>
    struct minmax_compare<Scalar, NaNPropagation, false> {
      typedef typename packet_traits<Scalar>::type Packet;
      static inline bool compare(Scalar a, Scalar b) { return a > b; }
      static inline Scalar predux(const Packet& p) { return predux_max<NaNPropagation>(p); }
    };
    template <typename Derived, bool is_min, int NaNPropagation>
    struct minmax_coeff_visitor : coeff_visitor<Derived> {
      using Scalar = typename Derived::Scalar;
      using Packet = typename packet_traits<Scalar>::type;
      using Comparator = minmax_compare<Scalar, NaNPropagation, is_min>;
      inline void operator()(const Scalar& value, Index i, Index j) {
        if (Comparator::compare(value, this->res)) {
          this->res = value;
          this->row = i;
          this->col = j;
        }
      }
      inline void packet(const Packet& p, Index i, Index j) {
        const Index PacketSize = packet_traits<Scalar>::size;
        Scalar value = Comparator::predux(p);
        if (Comparator::compare(value, this->res)) {
          const Packet range = preverse(plset<Packet>(Scalar(1)));
          Packet mask = pcmp_eq(pset1<Packet>(value), p);
          Index max_idx = PacketSize - static_cast<Index>(predux_max(pand(range, mask)));
          this->res = value;
          this->row = Derived::IsRowMajor ? i : i + max_idx;
          ;
          this->col = Derived::IsRowMajor ? j + max_idx : j;
        }
      }
    };
    template <typename Derived, bool is_min>
    struct minmax_coeff_visitor<Derived, is_min, PropagateNumbers> : coeff_visitor<Derived> {
      typedef typename Derived::Scalar Scalar;
      using Packet = typename packet_traits<Scalar>::type;
      using Comparator = minmax_compare<Scalar, PropagateNumbers, is_min>;
      inline void operator()(const Scalar& value, Index i, Index j) {
        if ((!(numext::isnan)(value) && (numext::isnan)(this->res)) || Comparator::compare(value, this->res)) {
          this->res = value;
          this->row = i;
          this->col = j;
        }
      }
      inline void packet(const Packet& p, Index i, Index j) {
        const Index PacketSize = packet_traits<Scalar>::size;
        Scalar value = Comparator::predux(p);
        if ((!(numext::isnan)(value) && (numext::isnan)(this->res)) || Comparator::compare(value, this->res)) {
          const Packet range = preverse(plset<Packet>(Scalar(1)));
          Packet mask = pcmp_eq(pset1<Packet>(value), p);
          Index max_idx = PacketSize - static_cast<Index>(predux_max(pand(range, mask)));
          this->res = value;
          this->row = Derived::IsRowMajor ? i : i + max_idx;
          ;
          this->col = Derived::IsRowMajor ? j + max_idx : j;
        }
      }
    };
    template <typename Derived, bool is_min>
    struct minmax_coeff_visitor<Derived, is_min, PropagateNaN> : coeff_visitor<Derived> {
      typedef typename Derived::Scalar Scalar;
      using Packet = typename packet_traits<Scalar>::type;
      using Comparator = minmax_compare<Scalar, PropagateNaN, is_min>;
      inline void operator()(const Scalar& value, Index i, Index j) {
        const bool value_is_nan = (numext::isnan)(value);
        if ((value_is_nan && !(numext::isnan)(this->res)) || Comparator::compare(value, this->res)) {
          this->res = value;
          this->row = i;
          this->col = j;
        }
      }
      inline void packet(const Packet& p, Index i, Index j) {
        const Index PacketSize = packet_traits<Scalar>::size;
        Scalar value = Comparator::predux(p);
        const bool value_is_nan = (numext::isnan)(value);
        if ((value_is_nan && !(numext::isnan)(this->res)) || Comparator::compare(value, this->res)) {
          const Packet range = preverse(plset<Packet>(Scalar(1)));
          Packet mask = value_is_nan ? pnot(pcmp_eq(p, p)) : pcmp_eq(pset1<Packet>(value), p);
          Index max_idx = PacketSize - static_cast<Index>(predux_max(pand(range, mask)));
          this->res = value;
          this->row = Derived::IsRowMajor ? i : i + max_idx;
          ;
          this->col = Derived::IsRowMajor ? j + max_idx : j;
        }
      }
    };
    template <typename Scalar, bool is_min, int NaNPropagation>
    struct functor_traits<minmax_coeff_visitor<Scalar, is_min, NaNPropagation>> {
      enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = true };
    };
  }  // namespace internal
  template <typename Derived>
  template <int NaNPropagation, typename IndexType>
  typename internal::traits<Derived>::Scalar DenseBase<Derived>::minCoeff(IndexType* rowId, IndexType* colId) const {
    (static_cast<bool>(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix")
         ? void(0)
         : __assert_fail("this->rows()>0 && this->cols()>0 && \"you are using an empty matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Visitor.h",
                         368,
                         __extension__ __PRETTY_FUNCTION__));
    internal::minmax_coeff_visitor<Derived, true, NaNPropagation> minVisitor;
    this->visit(minVisitor);
    *rowId = minVisitor.row;
    if (colId)
      *colId = minVisitor.col;
    return minVisitor.res;
  }
  template <typename Derived>
  template <int NaNPropagation, typename IndexType>
  typename internal::traits<Derived>::Scalar DenseBase<Derived>::minCoeff(IndexType* index) const {
    (static_cast<bool>(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix")
         ? void(0)
         : __assert_fail("this->rows()>0 && this->cols()>0 && \"you are using an empty matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Visitor.h",
                         393,
                         __extension__ __PRETTY_FUNCTION__));
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    internal::minmax_coeff_visitor<Derived, true, NaNPropagation> minVisitor;
    this->visit(minVisitor);
    *index = IndexType((RowsAtCompileTime == 1) ? minVisitor.col : minVisitor.row);
    return minVisitor.res;
  }
  template <typename Derived>
  template <int NaNPropagation, typename IndexType>
  typename internal::traits<Derived>::Scalar DenseBase<Derived>::maxCoeff(IndexType* rowPtr, IndexType* colPtr) const {
    (static_cast<bool>(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix")
         ? void(0)
         : __assert_fail("this->rows()>0 && this->cols()>0 && \"you are using an empty matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Visitor.h",
                         419,
                         __extension__ __PRETTY_FUNCTION__));
    internal::minmax_coeff_visitor<Derived, false, NaNPropagation> maxVisitor;
    this->visit(maxVisitor);
    *rowPtr = maxVisitor.row;
    if (colPtr)
      *colPtr = maxVisitor.col;
    return maxVisitor.res;
  }
  template <typename Derived>
  template <int NaNPropagation, typename IndexType>
  typename internal::traits<Derived>::Scalar DenseBase<Derived>::maxCoeff(IndexType* index) const {
    (static_cast<bool>(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix")
         ? void(0)
         : __assert_fail("this->rows()>0 && this->cols()>0 && \"you are using an empty matrix\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/Visitor.h",
                         444,
                         __extension__ __PRETTY_FUNCTION__));
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    internal::minmax_coeff_visitor<Derived, false, NaNPropagation> maxVisitor;
    this->visit(maxVisitor);
    *index = (RowsAtCompileTime == 1) ? maxVisitor.col : maxVisitor.row;
    return maxVisitor.res;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived, typename OtherDerived, bool is_integer = NumTraits<typename Derived::Scalar>::IsInteger>
    struct isApprox_selector {
      static bool run(const Derived& x, const OtherDerived& y, const typename Derived::RealScalar& prec) {
        typename internal::nested_eval<Derived, 2>::type nested(x);
        typename internal::nested_eval<OtherDerived, 2>::type otherNested(y);
        return (nested - otherNested).cwiseAbs2().sum() <=
               prec * prec * numext::mini(nested.cwiseAbs2().sum(), otherNested.cwiseAbs2().sum());
      }
    };
    template <typename Derived, typename OtherDerived>
    struct isApprox_selector<Derived, OtherDerived, true> {
      static bool run(const Derived& x, const OtherDerived& y, const typename Derived::RealScalar&) {
        return x.matrix() == y.matrix();
      }
    };
    template <typename Derived, typename OtherDerived, bool is_integer = NumTraits<typename Derived::Scalar>::IsInteger>
    struct isMuchSmallerThan_object_selector {
      static bool run(const Derived& x, const OtherDerived& y, const typename Derived::RealScalar& prec) {
        return x.cwiseAbs2().sum() <= numext::abs2(prec) * y.cwiseAbs2().sum();
      }
    };
    template <typename Derived, typename OtherDerived>
    struct isMuchSmallerThan_object_selector<Derived, OtherDerived, true> {
      static bool run(const Derived& x, const OtherDerived&, const typename Derived::RealScalar&) {
        return x.matrix() == Derived::Zero(x.rows(), x.cols()).matrix();
      }
    };
    template <typename Derived, bool is_integer = NumTraits<typename Derived::Scalar>::IsInteger>
    struct isMuchSmallerThan_scalar_selector {
      static bool run(const Derived& x,
                      const typename Derived::RealScalar& y,
                      const typename Derived::RealScalar& prec) {
        return x.cwiseAbs2().sum() <= numext::abs2(prec * y);
      }
    };
    template <typename Derived>
    struct isMuchSmallerThan_scalar_selector<Derived, true> {
      static bool run(const Derived& x, const typename Derived::RealScalar&, const typename Derived::RealScalar&) {
        return x.matrix() == Derived::Zero(x.rows(), x.cols()).matrix();
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename OtherDerived>
  bool DenseBase<Derived>::isApprox(const DenseBase<OtherDerived>& other, const RealScalar& prec) const {
    return internal::isApprox_selector<Derived, OtherDerived>::run(derived(), other.derived(), prec);
  }
  template <typename Derived>
  bool DenseBase<Derived>::isMuchSmallerThan(const typename NumTraits<Scalar>::Real& other,
                                             const RealScalar& prec) const {
    return internal::isMuchSmallerThan_scalar_selector<Derived>::run(derived(), other, prec);
  }
  template <typename Derived>
  template <typename OtherDerived>
  bool DenseBase<Derived>::isMuchSmallerThan(const DenseBase<OtherDerived>& other, const RealScalar& prec) const {
    return internal::isMuchSmallerThan_object_selector<Derived, OtherDerived>::run(derived(), other.derived(), prec);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT>
    class generic_dense_assignment_kernel<DstEvaluatorTypeT,
                                          SrcEvaluatorTypeT,
                                          swap_assign_op<typename DstEvaluatorTypeT::Scalar>,
                                          Specialized>
        : public generic_dense_assignment_kernel<DstEvaluatorTypeT,
                                                 SrcEvaluatorTypeT,
                                                 swap_assign_op<typename DstEvaluatorTypeT::Scalar>,
                                                 BuiltIn> {
    protected:
      typedef generic_dense_assignment_kernel<DstEvaluatorTypeT,
                                              SrcEvaluatorTypeT,
                                              swap_assign_op<typename DstEvaluatorTypeT::Scalar>,
                                              BuiltIn>
          Base;
      using Base::m_dst;
      using Base::m_functor;
      using Base::m_src;

    public:
      typedef typename Base::Scalar Scalar;
      typedef typename Base::DstXprType DstXprType;
      typedef swap_assign_op<Scalar> Functor;
      inline generic_dense_assignment_kernel(DstEvaluatorTypeT& dst,
                                             const SrcEvaluatorTypeT& src,
                                             const Functor& func,
                                             DstXprType& dstExpr)
          : Base(dst, src, func, dstExpr) {}
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacket(Index row, Index col) {
        PacketType tmp = m_src.template packet<LoadMode, PacketType>(row, col);
        const_cast<SrcEvaluatorTypeT&>(m_src).template writePacket<LoadMode>(
            row, col, m_dst.template packet<StoreMode, PacketType>(row, col));
        m_dst.template writePacket<StoreMode>(row, col, tmp);
      }
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacket(Index index) {
        PacketType tmp = m_src.template packet<LoadMode, PacketType>(index);
        const_cast<SrcEvaluatorTypeT&>(m_src).template writePacket<LoadMode>(
            index, m_dst.template packet<StoreMode, PacketType>(index));
        m_dst.template writePacket<StoreMode>(index, tmp);
      }
      template <int StoreMode, int LoadMode, typename PacketType>
      inline void assignPacketByOuterInner(Index outer, Index inner) {
        Index row = Base::rowIndexByOuterInner(outer, inner);
        Index col = Base::colIndexByOuterInner(outer, inner);
        assignPacket<StoreMode, LoadMode, PacketType>(row, col);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename XprType>
  struct CommaInitializer {
    typedef typename XprType::Scalar Scalar;
    inline CommaInitializer(XprType& xpr, const Scalar& s) : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1) {
      (static_cast<bool>(m_xpr.rows() > 0 && m_xpr.cols() > 0 && "Cannot comma-initialize a 0x0 matrix (operator<<)")
           ? void(0)
           : __assert_fail(
                 "m_xpr.rows() > 0 && m_xpr.cols() > 0 && \"Cannot comma-initialize a 0x0 matrix (operator<<)\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Core/CommaInitializer.h",
                 39,
                 __extension__ __PRETTY_FUNCTION__));
      m_xpr.coeffRef(0, 0) = s;
    }
    template <typename OtherDerived>
    inline CommaInitializer(XprType& xpr, const DenseBase<OtherDerived>& other)
        : m_xpr(xpr), m_row(0), m_col(other.cols()), m_currentBlockRows(other.rows()) {
      (static_cast<bool>(m_xpr.rows() >= other.rows() && m_xpr.cols() >= other.cols() &&
                         "Cannot comma-initialize a 0x0 matrix (operator<<)")
           ? void(0)
           : __assert_fail("m_xpr.rows() >= other.rows() && m_xpr.cols() >= other.cols() && \"Cannot comma-initialize "
                           "a 0x0 matrix (operator<<)\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           49,
                           __extension__ __PRETTY_FUNCTION__));
      m_xpr.template block<OtherDerived::RowsAtCompileTime, OtherDerived::ColsAtCompileTime>(
          0, 0, other.rows(), other.cols()) = other;
    }
    inline CommaInitializer(const CommaInitializer& o)
        : m_xpr(o.m_xpr), m_row(o.m_row), m_col(o.m_col), m_currentBlockRows(o.m_currentBlockRows) {
      const_cast<CommaInitializer&>(o).m_row = m_xpr.rows();
      const_cast<CommaInitializer&>(o).m_col = m_xpr.cols();
      const_cast<CommaInitializer&>(o).m_currentBlockRows = 0;
    }
    CommaInitializer& operator,(const Scalar& s) {
      if (m_col == m_xpr.cols()) {
        m_row += m_currentBlockRows;
        m_col = 0;
        m_currentBlockRows = 1;
        (static_cast<bool>(m_row < m_xpr.rows() && "Too many rows passed to comma initializer (operator<<)")
             ? void(0)
             : __assert_fail("m_row<m_xpr.rows() && \"Too many rows passed to comma initializer (operator<<)\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/CommaInitializer.h",
                             75,
                             __extension__ __PRETTY_FUNCTION__));
      }
      (static_cast<bool>(m_col < m_xpr.cols() && "Too many coefficients passed to comma initializer (operator<<)")
           ? void(0)
           : __assert_fail("m_col<m_xpr.cols() && \"Too many coefficients passed to comma initializer (operator<<)\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           78,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_currentBlockRows == 1)
           ? void(0)
           : __assert_fail("m_currentBlockRows==1",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           79,
                           __extension__ __PRETTY_FUNCTION__));
      m_xpr.coeffRef(m_row, m_col++) = s;
      return *this;
    }
    template <typename OtherDerived>
    CommaInitializer& operator,(const DenseBase<OtherDerived>& other) {
      if (m_col == m_xpr.cols() && (other.cols() != 0 || other.rows() != m_currentBlockRows)) {
        m_row += m_currentBlockRows;
        m_col = 0;
        m_currentBlockRows = other.rows();
        (static_cast<bool>(m_row + m_currentBlockRows <= m_xpr.rows() &&
                           "Too many rows passed to comma initializer (operator<<)")
             ? void(0)
             : __assert_fail("m_row+m_currentBlockRows<=m_xpr.rows() && \"Too many rows passed to comma initializer "
                             "(operator<<)\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/CommaInitializer.h",
                             95,
                             __extension__ __PRETTY_FUNCTION__));
      }
      (static_cast<bool>((m_col + other.cols() <= m_xpr.cols()) &&
                         "Too many coefficients passed to comma initializer (operator<<)")
           ? void(0)
           : __assert_fail("(m_col + other.cols() <= m_xpr.cols()) && \"Too many coefficients passed to comma "
                           "initializer (operator<<)\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           98,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_currentBlockRows == other.rows())
           ? void(0)
           : __assert_fail("m_currentBlockRows==other.rows()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           99,
                           __extension__ __PRETTY_FUNCTION__));
      m_xpr.template block<OtherDerived::RowsAtCompileTime, OtherDerived::ColsAtCompileTime>(
          m_row, m_col, other.rows(), other.cols()) = other;
      m_col += other.cols();
      return *this;
    }
    inline ~CommaInitializer() { finished(); }
    inline XprType& finished() {
      (static_cast<bool>(((m_row + m_currentBlockRows) == m_xpr.rows() || m_xpr.cols() == 0) && m_col == m_xpr.cols() &&
                         "Too few coefficients passed to comma initializer (operator<<)")
           ? void(0)
           : __assert_fail("((m_row+m_currentBlockRows) == m_xpr.rows() || m_xpr.cols() == 0) && m_col == m_xpr.cols() "
                           "&& \"Too few coefficients passed to comma initializer (operator<<)\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/CommaInitializer.h",
                           126,
                           __extension__ __PRETTY_FUNCTION__));
      return m_xpr;
    }
    XprType& m_xpr;
    Index m_row;
    Index m_col;
    Index m_currentBlockRows;
  };
  template <typename Derived>
  inline CommaInitializer<Derived> DenseBase<Derived>::operator<<(const Scalar& s) {
    return CommaInitializer<Derived>(*static_cast<Derived*>(this), s);
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline CommaInitializer<Derived> DenseBase<Derived>::operator<<(const DenseBase<OtherDerived>& other) {
    return CommaInitializer<Derived>(*static_cast<Derived*>(this), other);
  }
}  // namespace Eigen

namespace Eigen {
  enum { Large = 2, Small = 3 };
  namespace internal {
    template <int Rows, int Cols, int Depth>
    struct product_type_selector;
    template <int Size, int MaxSize>
    struct product_size_category {
      enum {
        is_large = MaxSize == Dynamic || Size >= 8 || (Size == Dynamic && MaxSize >= 8),
        value = is_large    ? Large
                : Size == 1 ? 1
                            : Small
      };
    };
    template <typename Lhs, typename Rhs>
    struct product_type {
      typedef remove_all_t<Lhs> Lhs_;
      typedef remove_all_t<Rhs> Rhs_;
      enum {
        MaxRows = traits<Lhs_>::MaxRowsAtCompileTime,
        Rows = traits<Lhs_>::RowsAtCompileTime,
        MaxCols = traits<Rhs_>::MaxColsAtCompileTime,
        Cols = traits<Rhs_>::ColsAtCompileTime,
        MaxDepth = min_size_prefer_fixed(traits<Lhs_>::MaxColsAtCompileTime, traits<Rhs_>::MaxRowsAtCompileTime),
        Depth = min_size_prefer_fixed(traits<Lhs_>::ColsAtCompileTime, traits<Rhs_>::RowsAtCompileTime)
      };

    private:
      enum {
        rows_select = product_size_category<Rows, MaxRows>::value,
        cols_select = product_size_category<Cols, MaxCols>::value,
        depth_select = product_size_category<Depth, MaxDepth>::value
      };
      typedef product_type_selector<rows_select, cols_select, depth_select> selector;

    public:
      enum { value = selector::ret, ret = selector::ret };
    };
    template <int M, int N>
    struct product_type_selector<M, N, 1> {
      enum { ret = OuterProduct };
    };
    template <int M>
    struct product_type_selector<M, 1, 1> {
      enum { ret = LazyCoeffBasedProductMode };
    };
    template <int N>
    struct product_type_selector<1, N, 1> {
      enum { ret = LazyCoeffBasedProductMode };
    };
    template <int Depth>
    struct product_type_selector<1, 1, Depth> {
      enum { ret = InnerProduct };
    };
    template <>
    struct product_type_selector<1, 1, 1> {
      enum { ret = InnerProduct };
    };
    template <>
    struct product_type_selector<Small, 1, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<1, Small, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Small, Small, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Small, Small, 1> {
      enum { ret = LazyCoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Small, Large, 1> {
      enum { ret = LazyCoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Large, Small, 1> {
      enum { ret = LazyCoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<1, Large, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<1, Large, Large> {
      enum { ret = GemvProduct };
    };
    template <>
    struct product_type_selector<1, Small, Large> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Large, 1, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Large, 1, Large> {
      enum { ret = GemvProduct };
    };
    template <>
    struct product_type_selector<Small, 1, Large> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Small, Small, Large> {
      enum { ret = GemmProduct };
    };
    template <>
    struct product_type_selector<Large, Small, Large> {
      enum { ret = GemmProduct };
    };
    template <>
    struct product_type_selector<Small, Large, Large> {
      enum { ret = GemmProduct };
    };
    template <>
    struct product_type_selector<Large, Large, Large> {
      enum { ret = GemmProduct };
    };
    template <>
    struct product_type_selector<Large, Small, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Small, Large, Small> {
      enum { ret = CoeffBasedProductMode };
    };
    template <>
    struct product_type_selector<Large, Large, Small> {
      enum { ret = GemmProduct };
    };
  }  // namespace internal
  namespace internal {
    template <int Side, int StorageOrder, bool BlasCompatible>
    struct gemv_dense_selector;
  }
  namespace internal {
    template <typename Scalar, int Size, int MaxSize, bool Cond>
    struct gemv_static_vector_if;
    template <typename Scalar, int Size, int MaxSize>
    struct gemv_static_vector_if<Scalar, Size, MaxSize, false> {
      inline Scalar* data() {
        ;
        return 0;
      }
    };
    template <typename Scalar, int Size>
    struct gemv_static_vector_if<Scalar, Size, Dynamic, true> {
      inline Scalar* data() { return 0; }
    };
    template <typename Scalar, int Size, int MaxSize>
    struct gemv_static_vector_if<Scalar, Size, MaxSize, true> {
      enum {
        ForceAlignment = internal::packet_traits<Scalar>::Vectorizable,
        PacketSize = internal::packet_traits<Scalar>::size
      };
      internal::plain_array<Scalar,
                            internal::min_size_prefer_fixed(Size, MaxSize),
                            0,
                            internal::plain_enum_min(AlignedMax, PacketSize)>
          m_data;
      inline Scalar* data() { return m_data.array; }
    };
    template <int StorageOrder, bool BlasCompatible>
    struct gemv_dense_selector<OnTheLeft, StorageOrder, BlasCompatible> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        Transpose<Dest> destT(dest);
        enum { OtherStorageOrder = StorageOrder == RowMajor ? ColMajor : RowMajor };
        gemv_dense_selector<OnTheRight, OtherStorageOrder, BlasCompatible>::run(
            rhs.transpose(), lhs.transpose(), destT, alpha);
      }
    };
    template <>
    struct gemv_dense_selector<OnTheRight, ColMajor, true> {
      template <typename Lhs, typename Rhs, typename Dest>
      static inline void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        typedef typename Lhs::Scalar LhsScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef typename Dest::Scalar ResScalar;
        typedef internal::blas_traits<Lhs> LhsBlasTraits;
        typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
        typedef internal::blas_traits<Rhs> RhsBlasTraits;
        typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
        typedef Map<Matrix<ResScalar, Dynamic, 1>, plain_enum_min(AlignedMax, internal::packet_traits<ResScalar>::size)>
            MappedDest;
        ActualLhsType actualLhs = LhsBlasTraits::extract(lhs);
        ActualRhsType actualRhs = RhsBlasTraits::extract(rhs);
        ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
        typedef std::conditional_t<Dest::IsVectorAtCompileTime, Dest, typename Dest::ColXpr> ActualDest;
        enum {
          EvalToDestAtCompileTime = (ActualDest::InnerStrideAtCompileTime == 1),
          ComplexByReal = (NumTraits<LhsScalar>::IsComplex) && (!NumTraits<RhsScalar>::IsComplex),
          MightCannotUseDest = ((!EvalToDestAtCompileTime) || ComplexByReal) && (ActualDest::MaxSizeAtCompileTime != 0)
        };
        typedef const_blas_data_mapper<LhsScalar, Index, ColMajor> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, RowMajor> RhsMapper;
        RhsScalar compatibleAlpha = get_factor<ResScalar, RhsScalar>::run(actualAlpha);
        if (!MightCannotUseDest) {
          general_matrix_vector_product<Index,
                                        LhsScalar,
                                        LhsMapper,
                                        ColMajor,
                                        LhsBlasTraits::NeedToConjugate,
                                        RhsScalar,
                                        RhsMapper,
                                        RhsBlasTraits::NeedToConjugate>::run(actualLhs.rows(),
                                                                             actualLhs.cols(),
                                                                             LhsMapper(actualLhs.data(),
                                                                                       actualLhs.outerStride()),
                                                                             RhsMapper(actualRhs.data(),
                                                                                       actualRhs.innerStride()),
                                                                             dest.data(),
                                                                             1,
                                                                             compatibleAlpha);
        } else {
          gemv_static_vector_if<ResScalar,
                                ActualDest::SizeAtCompileTime,
                                ActualDest::MaxSizeAtCompileTime,
                                MightCannotUseDest>
              static_dest;
          const bool alphaIsCompatible = (!ComplexByReal) || (numext::is_exactly_zero(numext::imag(actualAlpha)));
          const bool evalToDest = EvalToDestAtCompileTime && alphaIsCompatible;
          Eigen::internal::check_size_for_overflow<ResScalar>(dest.size());
          ResScalar* actualDestPtr =
              (evalToDest ? dest.data() : static_dest.data()) != 0
                  ? (evalToDest ? dest.data() : static_dest.data())
                  : reinterpret_cast<ResScalar*>(
                        (sizeof(ResScalar) * dest.size() <= 131072)
                            ? reinterpret_cast<void*>(
                                  (internal::UIntPtr(__builtin_alloca(sizeof(ResScalar) * dest.size() + 64 - 1)) + 64 -
                                   1) &
                                  ~(std::size_t(64 - 1)))
                            : Eigen::internal::aligned_malloc(sizeof(ResScalar) * dest.size()));
          Eigen::internal::aligned_stack_memory_handler<ResScalar> actualDestPtr_stack_memory_destructor(
              (evalToDest ? dest.data() : static_dest.data()) == 0 ? actualDestPtr : 0,
              dest.size(),
              sizeof(ResScalar) * dest.size() > 131072);
          if (!evalToDest) {
            if (!alphaIsCompatible) {
              MappedDest(actualDestPtr, dest.size()).setZero();
              compatibleAlpha = RhsScalar(1);
            } else
              MappedDest(actualDestPtr, dest.size()) = dest;
          }
          general_matrix_vector_product<Index,
                                        LhsScalar,
                                        LhsMapper,
                                        ColMajor,
                                        LhsBlasTraits::NeedToConjugate,
                                        RhsScalar,
                                        RhsMapper,
                                        RhsBlasTraits::NeedToConjugate>::run(actualLhs.rows(),
                                                                             actualLhs.cols(),
                                                                             LhsMapper(actualLhs.data(),
                                                                                       actualLhs.outerStride()),
                                                                             RhsMapper(actualRhs.data(),
                                                                                       actualRhs.innerStride()),
                                                                             actualDestPtr,
                                                                             1,
                                                                             compatibleAlpha);
          if (!evalToDest) {
            if (!alphaIsCompatible)
              dest.matrix() += actualAlpha * MappedDest(actualDestPtr, dest.size());
            else
              dest = MappedDest(actualDestPtr, dest.size());
          }
        }
      }
    };
    template <>
    struct gemv_dense_selector<OnTheRight, RowMajor, true> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        typedef typename Lhs::Scalar LhsScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef typename Dest::Scalar ResScalar;
        typedef internal::blas_traits<Lhs> LhsBlasTraits;
        typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
        typedef internal::blas_traits<Rhs> RhsBlasTraits;
        typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
        typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
        std::add_const_t<ActualLhsType> actualLhs = LhsBlasTraits::extract(lhs);
        std::add_const_t<ActualRhsType> actualRhs = RhsBlasTraits::extract(rhs);
        ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
        enum {
          DirectlyUseRhs =
              ActualRhsTypeCleaned::InnerStrideAtCompileTime == 1 || ActualRhsTypeCleaned::MaxSizeAtCompileTime == 0
        };
        gemv_static_vector_if<RhsScalar,
                              ActualRhsTypeCleaned::SizeAtCompileTime,
                              ActualRhsTypeCleaned::MaxSizeAtCompileTime,
                              !DirectlyUseRhs>
            static_rhs;
        Eigen::internal::check_size_for_overflow<RhsScalar>(actualRhs.size());
        RhsScalar* actualRhsPtr =
            (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data()) != 0
                ? (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data())
                : reinterpret_cast<RhsScalar*>(
                      (sizeof(RhsScalar) * actualRhs.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * actualRhs.size() + 64 - 1)) +
                                 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * actualRhs.size()));
        Eigen::internal::aligned_stack_memory_handler<RhsScalar> actualRhsPtr_stack_memory_destructor(
            (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data()) == 0 ? actualRhsPtr : 0,
            actualRhs.size(),
            sizeof(RhsScalar) * actualRhs.size() > 131072);
        if (!DirectlyUseRhs) {
          Map<typename ActualRhsTypeCleaned::PlainObject>(actualRhsPtr, actualRhs.size()) = actualRhs;
        }
        typedef const_blas_data_mapper<LhsScalar, Index, RowMajor> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, ColMajor> RhsMapper;
        general_matrix_vector_product<Index,
                                      LhsScalar,
                                      LhsMapper,
                                      RowMajor,
                                      LhsBlasTraits::NeedToConjugate,
                                      RhsScalar,
                                      RhsMapper,
                                      RhsBlasTraits::NeedToConjugate>::run(actualLhs.rows(),
                                                                           actualLhs.cols(),
                                                                           LhsMapper(actualLhs.data(),
                                                                                     actualLhs.outerStride()),
                                                                           RhsMapper(actualRhsPtr, 1),
                                                                           dest.data(),
                                                                           dest.col(0).innerStride(),
                                                                           actualAlpha);
      }
    };
    template <>
    struct gemv_dense_selector<OnTheRight, ColMajor, false> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        static_assert((!nested_eval<Lhs, 1>::Evaluate),
                      "EIGEN_INTERNAL_COMPILATION_ERROR_OR_YOU_MADE_A_PROGRAMMING_MISTAKE");
        ;
        typename nested_eval<Rhs, 1>::type actual_rhs(rhs);
        const Index size = rhs.rows();
        for (Index k = 0; k < size; ++k)
          dest += (alpha * actual_rhs.coeff(k)) * lhs.col(k);
      }
    };
    template <>
    struct gemv_dense_selector<OnTheRight, RowMajor, false> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        static_assert((!nested_eval<Lhs, 1>::Evaluate),
                      "EIGEN_INTERNAL_COMPILATION_ERROR_OR_YOU_MADE_A_PROGRAMMING_MISTAKE");
        ;
        typename nested_eval<Rhs, Lhs::RowsAtCompileTime>::type actual_rhs(rhs);
        const Index rows = dest.rows();
        for (Index i = 0; i < rows; ++i)
          dest.coeffRef(i) += alpha * (lhs.row(i).cwiseProduct(actual_rhs.transpose())).sum();
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename OtherDerived>
  inline const Product<Derived, OtherDerived> MatrixBase<Derived>::operator*(
      const MatrixBase<OtherDerived>& other) const {
    enum {
      ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
                       int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
      AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
      SameSizes = ((int(Eigen::internal::size_of_xpr_at_compile_time<Derived>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<OtherDerived>::ret) == 0) ||
                   ((int(Derived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::RowsAtCompileTime) == int(OtherDerived::RowsAtCompileTime)) &&
                    (int(Derived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::ColsAtCompileTime) == int(OtherDerived::ColsAtCompileTime))))
    };
    static_assert(
        ProductIsValid || !(AreVectors && SameSizes),
        "INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS");
    static_assert(ProductIsValid || !(SameSizes && !AreVectors),
                  "INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION");
    static_assert(ProductIsValid || SameSizes, "INVALID_MATRIX_PRODUCT");
    return Product<Derived, OtherDerived>(derived(), other.derived());
  }
  template <typename Derived>
  template <typename OtherDerived>
  inline const Product<Derived, OtherDerived, LazyProduct> MatrixBase<Derived>::lazyProduct(
      const MatrixBase<OtherDerived>& other) const {
    enum {
      ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
                       int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
      AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
      SameSizes = ((int(Eigen::internal::size_of_xpr_at_compile_time<Derived>::ret) == 0 &&
                    int(Eigen::internal::size_of_xpr_at_compile_time<OtherDerived>::ret) == 0) ||
                   ((int(Derived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::RowsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::RowsAtCompileTime) == int(OtherDerived::RowsAtCompileTime)) &&
                    (int(Derived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(OtherDerived::ColsAtCompileTime) == Eigen::Dynamic ||
                     int(Derived::ColsAtCompileTime) == int(OtherDerived::ColsAtCompileTime))))
    };
    static_assert(
        ProductIsValid || !(AreVectors && SameSizes),
        "INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS");
    static_assert(ProductIsValid || !(SameSizes && !AreVectors),
                  "INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION");
    static_assert(ProductIsValid || SameSizes, "INVALID_MATRIX_PRODUCT");
    return Product<Derived, OtherDerived, LazyProduct>(derived(), other.derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Decomposition, typename RhsType, typename StorageKind>
  class SolveImpl;
  namespace internal {
    template <typename Decomposition, typename RhsType, typename StorageKind>
    struct solve_traits;
    template <typename Decomposition, typename RhsType>
    struct solve_traits<Decomposition, RhsType, Dense> {
      typedef typename make_proper_matrix_type<typename RhsType::Scalar,
                                               Decomposition::ColsAtCompileTime,
                                               RhsType::ColsAtCompileTime,
                                               RhsType::PlainObject::Options,
                                               Decomposition::MaxColsAtCompileTime,
                                               RhsType::MaxColsAtCompileTime>::type PlainObject;
    };
    template <typename Decomposition, typename RhsType>
    struct traits<Solve<Decomposition, RhsType>>
        : traits<typename solve_traits<Decomposition, RhsType, typename internal::traits<RhsType>::StorageKind>::
                     PlainObject> {
      typedef
          typename solve_traits<Decomposition, RhsType, typename internal::traits<RhsType>::StorageKind>::PlainObject
              PlainObject;
      typedef typename promote_index_type<typename Decomposition::StorageIndex, typename RhsType::StorageIndex>::type
          StorageIndex;
      typedef traits<PlainObject> BaseTraits;
      enum { Flags = BaseTraits::Flags & RowMajorBit, CoeffReadCost = HugeCost };
    };
  }  // namespace internal
  template <typename Decomposition, typename RhsType>
  class Solve : public SolveImpl<Decomposition, RhsType, typename internal::traits<RhsType>::StorageKind> {
  public:
    typedef typename internal::traits<Solve>::PlainObject PlainObject;
    typedef typename internal::traits<Solve>::StorageIndex StorageIndex;
    Solve(const Decomposition& dec, const RhsType& rhs) : m_dec(dec), m_rhs(rhs) {}
    constexpr Index rows() const noexcept { return m_dec.cols(); }
    constexpr Index cols() const noexcept { return m_rhs.cols(); }
    const Decomposition& dec() const { return m_dec; }
    const RhsType& rhs() const { return m_rhs; }

  protected:
    const Decomposition& m_dec;
    const typename internal::ref_selector<RhsType>::type m_rhs;
  };
  template <typename Decomposition, typename RhsType>
  class SolveImpl<Decomposition, RhsType, Dense> : public MatrixBase<Solve<Decomposition, RhsType>> {
    typedef Solve<Decomposition, RhsType> Derived;

  public:
    typedef MatrixBase<Solve<Decomposition, RhsType>> Base;
    typedef typename Eigen::internal::traits<Derived>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Derived>::type Nested;
    typedef typename Eigen::internal::traits<Derived>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Derived>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Derived>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Derived>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;

  private:
    Scalar coeff(Index row, Index col) const;
    Scalar coeff(Index i) const;
  };
  template <typename Decomposition, typename RhsType, typename StorageKind>
  class SolveImpl : public internal::generic_xpr_base<Solve<Decomposition, RhsType>, MatrixXpr, StorageKind>::type {
  public:
    typedef typename internal::generic_xpr_base<Solve<Decomposition, RhsType>, MatrixXpr, StorageKind>::type Base;
  };
  namespace internal {
    template <typename Decomposition, typename RhsType>
    struct evaluator<Solve<Decomposition, RhsType>>
        : public evaluator<typename Solve<Decomposition, RhsType>::PlainObject> {
      typedef Solve<Decomposition, RhsType> SolveType;
      typedef typename SolveType::PlainObject PlainObject;
      typedef evaluator<PlainObject> Base;
      enum { Flags = Base::Flags | EvalBeforeNestingBit };
      explicit evaluator(const SolveType& solve) : m_result(solve.rows(), solve.cols()) {
        internal::construct_at<Base>(this, m_result);
        solve.dec()._solve_impl(solve.rhs(), m_result);
      }

    protected:
      PlainObject m_result;
    };
    template <typename DstXprType, typename DecType, typename RhsType, typename Scalar>
    struct Assignment<DstXprType, Solve<DecType, RhsType>, internal::assign_op<Scalar, Scalar>, Dense2Dense> {
      typedef Solve<DecType, RhsType> SrcXprType;
      static void run(DstXprType& dst, const SrcXprType& src, const internal::assign_op<Scalar, Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        src.dec()._solve_impl(src.rhs(), dst);
      }
    };
    template <typename DstXprType, typename DecType, typename RhsType, typename Scalar>
    struct Assignment<DstXprType,
                      Solve<Transpose<const DecType>, RhsType>,
                      internal::assign_op<Scalar, Scalar>,
                      Dense2Dense> {
      typedef Solve<Transpose<const DecType>, RhsType> SrcXprType;
      static void run(DstXprType& dst, const SrcXprType& src, const internal::assign_op<Scalar, Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        src.dec().nestedExpression().template _solve_impl_transposed<false>(src.rhs(), dst);
      }
    };
    template <typename DstXprType, typename DecType, typename RhsType, typename Scalar>
    struct Assignment<
        DstXprType,
        Solve<CwiseUnaryOp<internal::scalar_conjugate_op<typename DecType::Scalar>, const Transpose<const DecType>>,
              RhsType>,
        internal::assign_op<Scalar, Scalar>,
        Dense2Dense> {
      typedef Solve<CwiseUnaryOp<internal::scalar_conjugate_op<typename DecType::Scalar>, const Transpose<const DecType>>,
                    RhsType>
          SrcXprType;
      static void run(DstXprType& dst, const SrcXprType& src, const internal::assign_op<Scalar, Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        src.dec().nestedExpression().nestedExpression().template _solve_impl_transposed<true>(src.rhs(), dst);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename XprType, typename StorageKind>
  class InverseImpl;
  namespace internal {
    template <typename XprType>
    struct traits<Inverse<XprType>> : traits<typename XprType::PlainObject> {
      typedef typename XprType::PlainObject PlainObject;
      typedef traits<PlainObject> BaseTraits;
      enum { Flags = BaseTraits::Flags & RowMajorBit };
    };
  }  // namespace internal
  template <typename XprType>
  class Inverse : public InverseImpl<XprType, typename internal::traits<XprType>::StorageKind> {
  public:
    typedef typename XprType::StorageIndex StorageIndex;
    typedef typename XprType::Scalar Scalar;
    typedef typename internal::ref_selector<XprType>::type XprTypeNested;
    typedef internal::remove_all_t<XprTypeNested> XprTypeNestedCleaned;
    typedef typename internal::ref_selector<Inverse>::type Nested;
    typedef internal::remove_all_t<XprType> NestedExpression;
    explicit Inverse(const XprType& xpr) : m_xpr(xpr) {}
    constexpr Index rows() const noexcept { return m_xpr.cols(); }
    constexpr Index cols() const noexcept { return m_xpr.rows(); }
    const XprTypeNestedCleaned& nestedExpression() const { return m_xpr; }

  protected:
    XprTypeNested m_xpr;
  };
  template <typename XprType, typename StorageKind>
  class InverseImpl : public internal::generic_xpr_base<Inverse<XprType>>::type {
  public:
    typedef typename internal::generic_xpr_base<Inverse<XprType>>::type Base;
    typedef typename XprType::Scalar Scalar;

  private:
    Scalar coeff(Index row, Index col) const;
    Scalar coeff(Index i) const;
  };
  namespace internal {
    template <typename ArgType>
    struct unary_evaluator<Inverse<ArgType>> : public evaluator<typename Inverse<ArgType>::PlainObject> {
      typedef Inverse<ArgType> InverseType;
      typedef typename InverseType::PlainObject PlainObject;
      typedef evaluator<PlainObject> Base;
      enum { Flags = Base::Flags | EvalBeforeNestingBit };
      unary_evaluator(const InverseType& inv_xpr) : m_result(inv_xpr.rows(), inv_xpr.cols()) {
        internal::construct_at<Base>(this, m_result);
        internal::call_assignment_no_alias(m_result, inv_xpr);
      }

    protected:
      PlainObject m_result;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived>
    struct solve_assertion {
      template <bool Transpose_, typename Rhs>
      static void run(const Derived& solver, const Rhs& b) {
        solver.template _check_solve_assertion<Transpose_>(b);
      }
    };
    template <typename Derived>
    struct solve_assertion<Transpose<Derived>> {
      typedef Transpose<Derived> type;
      template <bool Transpose_, typename Rhs>
      static void run(const type& transpose, const Rhs& b) {
        internal::solve_assertion<internal::remove_all_t<Derived>>::template run<true>(transpose.nestedExpression(), b);
      }
    };
    template <typename Scalar, typename Derived>
    struct solve_assertion<CwiseUnaryOp<Eigen::internal::scalar_conjugate_op<Scalar>, const Transpose<Derived>>> {
      typedef CwiseUnaryOp<Eigen::internal::scalar_conjugate_op<Scalar>, const Transpose<Derived>> type;
      template <bool Transpose_, typename Rhs>
      static void run(const type& adjoint, const Rhs& b) {
        internal::solve_assertion<internal::remove_all_t<Transpose<Derived>>>::template run<true>(
            adjoint.nestedExpression(), b);
      }
    };
  }  // namespace internal
  template <typename Derived>
  class SolverBase : public EigenBase<Derived> {
  public:
    typedef EigenBase<Derived> Base;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef Scalar CoeffReturnType;
    template <typename Derived_>
    friend struct internal::solve_assertion;
    enum {
      RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
      SizeAtCompileTime = (internal::size_of_xpr_at_compile_time<Derived>::ret),
      MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
      MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits<Derived>::MaxRowsAtCompileTime,
                                                            internal::traits<Derived>::MaxColsAtCompileTime),
      IsVectorAtCompileTime =
          internal::traits<Derived>::MaxRowsAtCompileTime == 1 || internal::traits<Derived>::MaxColsAtCompileTime == 1,
      NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0
                      : bool(IsVectorAtCompileTime)  ? 1
                                                     : 2
    };
    SolverBase() {}
    ~SolverBase() {}
    using Base::derived;
    template <typename Rhs>
    inline const Solve<Derived, Rhs> solve(const MatrixBase<Rhs>& b) const {
      internal::solve_assertion<internal::remove_all_t<Derived>>::template run<false>(derived(), b);
      return Solve<Derived, Rhs>(derived(), b.derived());
    }
    typedef Transpose<const Derived> ConstTransposeReturnType;
    inline const ConstTransposeReturnType transpose() const { return ConstTransposeReturnType(derived()); }
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, const ConstTransposeReturnType>,
                               const ConstTransposeReturnType>
        AdjointReturnType;
    inline const AdjointReturnType adjoint() const { return AdjointReturnType(derived().transpose()); }

  protected:
    template <bool Transpose_, typename Rhs>
    void _check_solve_assertion(const Rhs& b) const {
      ;
      (static_cast<bool>(derived().m_isInitialized && "Solver is not initialized.")
           ? void(0)
           : __assert_fail("derived().m_isInitialized && \"Solver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/SolverBase.h",
                           158,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>((Transpose_ ? derived().cols() : derived().rows()) == b.rows() &&
                         "SolverBase::solve(): invalid number of rows of the right hand side matrix b")
           ? void(0)
           : __assert_fail("(Transpose_?derived().cols():derived().rows())==b.rows() && \"SolverBase::solve(): invalid "
                           "number of rows of the right hand side matrix b\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/SolverBase.h",
                           159,
                           __extension__ __PRETTY_FUNCTION__));
    }
  };
  namespace internal {
    template <typename Derived>
    struct generic_xpr_base<Derived, MatrixXpr, SolverStorage> {
      typedef SolverBase<Derived> type;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    enum PermPermProduct_t { PermPermProduct };
  }
  template <typename Derived>
  class PermutationBase : public EigenBase<Derived> {
    typedef internal::traits<Derived> Traits;
    typedef EigenBase<Derived> Base;

  public:
    typedef typename Traits::IndicesType IndicesType;
    enum {
      Flags = Traits::Flags,
      RowsAtCompileTime = Traits::RowsAtCompileTime,
      ColsAtCompileTime = Traits::ColsAtCompileTime,
      MaxRowsAtCompileTime = Traits::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = Traits::MaxColsAtCompileTime
    };
    typedef typename Traits::StorageIndex StorageIndex;
    typedef Matrix<StorageIndex, RowsAtCompileTime, ColsAtCompileTime, 0, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        DenseMatrixType;
    typedef PermutationMatrix<IndicesType::SizeAtCompileTime, IndicesType::MaxSizeAtCompileTime, StorageIndex>
        PlainPermutationType;
    typedef PlainPermutationType PlainObject;
    using Base::derived;
    typedef Inverse<Derived> InverseReturnType;
    typedef void Scalar;
    template <typename OtherDerived>
    Derived& operator=(const PermutationBase<OtherDerived>& other) {
      indices() = other.indices();
      return derived();
    }
    template <typename OtherDerived>
    Derived& operator=(const TranspositionsBase<OtherDerived>& tr) {
      setIdentity(tr.size());
      for (Index k = size() - 1; k >= 0; --k)
        applyTranspositionOnTheRight(k, tr.coeff(k));
      return derived();
    }
    Derived& operator=(const PermutationBase& other) {
      indices() = other.indices();
      return derived();
    }
    inline Index rows() const { return Index(indices().size()); }
    inline Index cols() const { return Index(indices().size()); }
    inline Index size() const { return Index(indices().size()); }
    template <typename DenseDerived>
    void evalTo(MatrixBase<DenseDerived>& other) const {
      other.setZero();
      for (Index i = 0; i < rows(); ++i)
        other.coeffRef(indices().coeff(i), i) = typename DenseDerived::Scalar(1);
    }
    DenseMatrixType toDenseMatrix() const { return derived(); }
    const IndicesType& indices() const { return derived().indices(); }
    IndicesType& indices() { return derived().indices(); }
    inline void resize(Index newSize) { indices().resize(newSize); }
    void setIdentity() {
      StorageIndex n = StorageIndex(size());
      for (StorageIndex i = 0; i < n; ++i)
        indices().coeffRef(i) = i;
    }
    void setIdentity(Index newSize) {
      resize(newSize);
      setIdentity();
    }
    Derived& applyTranspositionOnTheLeft(Index i, Index j) {
      (static_cast<bool>(i >= 0 && j >= 0 && i < size() && j < size())
           ? void(0)
           : __assert_fail("i>=0 && j>=0 && i<size() && j<size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/PermutationMatrix.h",
                           181,
                           __extension__ __PRETTY_FUNCTION__));
      for (Index k = 0; k < size(); ++k) {
        if (indices().coeff(k) == i)
          indices().coeffRef(k) = StorageIndex(j);
        else if (indices().coeff(k) == j)
          indices().coeffRef(k) = StorageIndex(i);
      }
      return derived();
    }
    Derived& applyTranspositionOnTheRight(Index i, Index j) {
      (static_cast<bool>(i >= 0 && j >= 0 && i < size() && j < size())
           ? void(0)
           : __assert_fail("i>=0 && j>=0 && i<size() && j<size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/PermutationMatrix.h",
                           201,
                           __extension__ __PRETTY_FUNCTION__));
      numext::swap(indices().coeffRef(i), indices().coeffRef(j));
      return derived();
    }
    inline InverseReturnType inverse() const { return InverseReturnType(derived()); }
    inline InverseReturnType transpose() const { return InverseReturnType(derived()); }

  protected:
    template <typename OtherDerived>
    void assignTranspose(const PermutationBase<OtherDerived>& other) {
      for (Index i = 0; i < rows(); ++i)
        indices().coeffRef(other.indices().coeff(i)) = i;
    }
    template <typename Lhs, typename Rhs>
    void assignProduct(const Lhs& lhs, const Rhs& rhs) {
      (static_cast<bool>(lhs.cols() == rhs.rows())
           ? void(0)
           : __assert_fail("lhs.cols() == rhs.rows()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/PermutationMatrix.h",
                           236,
                           __extension__ __PRETTY_FUNCTION__));
      for (Index i = 0; i < rows(); ++i)
        indices().coeffRef(i) = lhs.indices().coeff(rhs.indices().coeff(i));
    }

  public:
    template <typename Other>
    inline PlainPermutationType operator*(const PermutationBase<Other>& other) const {
      return PlainPermutationType(internal::PermPermProduct, derived(), other.derived());
    }
    template <typename Other>
    inline PlainPermutationType operator*(const InverseImpl<Other, PermutationStorage>& other) const {
      return PlainPermutationType(internal::PermPermProduct, *this, other.eval());
    }
    template <typename Other>
    friend inline PlainPermutationType operator*(const InverseImpl<Other, PermutationStorage>& other,
                                                 const PermutationBase& perm) {
      return PlainPermutationType(internal::PermPermProduct, other.eval(), perm);
    }
    Index determinant() const {
      Index res = 1;
      Index n = size();
      Matrix<bool, RowsAtCompileTime, 1, 0, MaxRowsAtCompileTime> mask(n);
      mask.fill(false);
      Index r = 0;
      while (r < n) {
        while (r < n && mask[r])
          r++;
        if (r >= n)
          break;
        Index k0 = r++;
        mask.coeffRef(k0) = true;
        for (Index k = indices().coeff(k0); k != k0; k = indices().coeff(k)) {
          mask.coeffRef(k) = true;
          res = -res;
        }
      }
      return res;
    }

  protected:
  };
  namespace internal {
    template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_>
    struct traits<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>>
        : traits<
              Matrix<StorageIndex_, SizeAtCompileTime, SizeAtCompileTime, 0, MaxSizeAtCompileTime, MaxSizeAtCompileTime>> {
      typedef PermutationStorage StorageKind;
      typedef Matrix<StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1> IndicesType;
      typedef StorageIndex_ StorageIndex;
      typedef void Scalar;
    };
  }  // namespace internal
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_>
  class PermutationMatrix
      : public PermutationBase<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>> {
    typedef PermutationBase<PermutationMatrix> Base;
    typedef internal::traits<PermutationMatrix> Traits;

  public:
    typedef const PermutationMatrix& Nested;
    typedef typename Traits::IndicesType IndicesType;
    typedef typename Traits::StorageIndex StorageIndex;
    inline PermutationMatrix() {}
    explicit inline PermutationMatrix(Index size) : m_indices(size) { ; }
    template <typename OtherDerived>
    inline PermutationMatrix(const PermutationBase<OtherDerived>& other) : m_indices(other.indices()) {}
    inline PermutationMatrix(const PermutationMatrix& other) : m_indices(other.indices()) {}
    template <typename Other>
    explicit inline PermutationMatrix(const MatrixBase<Other>& indices) : m_indices(indices) {}
    template <typename Other>
    explicit PermutationMatrix(const TranspositionsBase<Other>& tr) : m_indices(tr.size()) {
      *this = tr;
    }
    template <typename Other>
    PermutationMatrix& operator=(const PermutationBase<Other>& other) {
      m_indices = other.indices();
      return *this;
    }
    template <typename Other>
    PermutationMatrix& operator=(const TranspositionsBase<Other>& tr) {
      return Base::operator=(tr.derived());
    }
    PermutationMatrix& operator=(const PermutationMatrix& other) {
      m_indices = other.m_indices;
      return *this;
    }
    const IndicesType& indices() const { return m_indices; }
    IndicesType& indices() { return m_indices; }
    template <typename Other>
    PermutationMatrix(const InverseImpl<Other, PermutationStorage>& other)
        : m_indices(other.derived().nestedExpression().size()) {
      ;
      StorageIndex end = StorageIndex(m_indices.size());
      for (StorageIndex i = 0; i < end; ++i)
        m_indices.coeffRef(other.derived().nestedExpression().indices().coeff(i)) = i;
    }
    template <typename Lhs, typename Rhs>
    PermutationMatrix(internal::PermPermProduct_t, const Lhs& lhs, const Rhs& rhs) : m_indices(lhs.indices().size()) {
      Base::assignProduct(lhs, rhs);
    }

  protected:
    IndicesType m_indices;
  };
  namespace internal {
    template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_>
    struct traits<Map<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess_>>
        : traits<
              Matrix<StorageIndex_, SizeAtCompileTime, SizeAtCompileTime, 0, MaxSizeAtCompileTime, MaxSizeAtCompileTime>> {
      typedef PermutationStorage StorageKind;
      typedef Map<const Matrix<StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1>, PacketAccess_>
          IndicesType;
      typedef StorageIndex_ StorageIndex;
      typedef void Scalar;
    };
  }  // namespace internal
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_>
  class Map<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess_>
      : public PermutationBase<
            Map<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess_>> {
    typedef PermutationBase<Map> Base;
    typedef internal::traits<Map> Traits;

  public:
    typedef typename Traits::IndicesType IndicesType;
    typedef typename IndicesType::Scalar StorageIndex;
    inline Map(const StorageIndex* indicesPtr) : m_indices(indicesPtr) {}
    inline Map(const StorageIndex* indicesPtr, Index size) : m_indices(indicesPtr, size) {}
    template <typename Other>
    Map& operator=(const PermutationBase<Other>& other) {
      return Base::operator=(other.derived());
    }
    template <typename Other>
    Map& operator=(const TranspositionsBase<Other>& tr) {
      return Base::operator=(tr.derived());
    }
    Map& operator=(const Map& other) {
      m_indices = other.m_indices;
      return *this;
    }
    const IndicesType& indices() const { return m_indices; }
    IndicesType& indices() { return m_indices; }

  protected:
    IndicesType m_indices;
  };
  template <typename IndicesType_>
  class TranspositionsWrapper;
  namespace internal {
    template <typename IndicesType_>
    struct traits<PermutationWrapper<IndicesType_>> {
      typedef PermutationStorage StorageKind;
      typedef void Scalar;
      typedef typename IndicesType_::Scalar StorageIndex;
      typedef IndicesType_ IndicesType;
      enum {
        RowsAtCompileTime = IndicesType_::SizeAtCompileTime,
        ColsAtCompileTime = IndicesType_::SizeAtCompileTime,
        MaxRowsAtCompileTime = IndicesType::MaxSizeAtCompileTime,
        MaxColsAtCompileTime = IndicesType::MaxSizeAtCompileTime,
        Flags = 0
      };
    };
  }  // namespace internal
  template <typename IndicesType_>
  class PermutationWrapper : public PermutationBase<PermutationWrapper<IndicesType_>> {
    typedef PermutationBase<PermutationWrapper> Base;
    typedef internal::traits<PermutationWrapper> Traits;

  public:
    typedef typename Traits::IndicesType IndicesType;
    inline PermutationWrapper(const IndicesType& indices) : m_indices(indices) {}
    const internal::remove_all_t<typename IndicesType::Nested>& indices() const { return m_indices; }

  protected:
    typename IndicesType::Nested m_indices;
  };
  template <typename MatrixDerived, typename PermutationDerived>
  const Product<MatrixDerived, PermutationDerived, AliasFreeProduct> operator*(
      const MatrixBase<MatrixDerived>& matrix, const PermutationBase<PermutationDerived>& permutation) {
    return Product<MatrixDerived, PermutationDerived, AliasFreeProduct>(matrix.derived(), permutation.derived());
  }
  template <typename PermutationDerived, typename MatrixDerived>
  const Product<PermutationDerived, MatrixDerived, AliasFreeProduct> operator*(
      const PermutationBase<PermutationDerived>& permutation, const MatrixBase<MatrixDerived>& matrix) {
    return Product<PermutationDerived, MatrixDerived, AliasFreeProduct>(permutation.derived(), matrix.derived());
  }
  template <typename PermutationType>
  class InverseImpl<PermutationType, PermutationStorage> : public EigenBase<Inverse<PermutationType>> {
    typedef typename PermutationType::PlainPermutationType PlainPermutationType;
    typedef internal::traits<PermutationType> PermTraits;

  protected:
    InverseImpl() {}

  public:
    typedef Inverse<PermutationType> InverseType;
    using EigenBase<Inverse<PermutationType>>::derived;
    typedef typename PermutationType::DenseMatrixType DenseMatrixType;
    enum {
      RowsAtCompileTime = PermTraits::RowsAtCompileTime,
      ColsAtCompileTime = PermTraits::ColsAtCompileTime,
      MaxRowsAtCompileTime = PermTraits::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = PermTraits::MaxColsAtCompileTime
    };
    template <typename DenseDerived>
    void evalTo(MatrixBase<DenseDerived>& other) const {
      other.setZero();
      for (Index i = 0; i < derived().rows(); ++i)
        other.coeffRef(i, derived().nestedExpression().indices().coeff(i)) = typename DenseDerived::Scalar(1);
    }
    PlainPermutationType eval() const { return derived(); }
    DenseMatrixType toDenseMatrix() const { return derived(); }
    template <typename OtherDerived>
    friend const Product<OtherDerived, InverseType, AliasFreeProduct> operator*(const MatrixBase<OtherDerived>& matrix,
                                                                                const InverseType& trPerm) {
      return Product<OtherDerived, InverseType, AliasFreeProduct>(matrix.derived(), trPerm.derived());
    }
    template <typename OtherDerived>
    const Product<InverseType, OtherDerived, AliasFreeProduct> operator*(const MatrixBase<OtherDerived>& matrix) const {
      return Product<InverseType, OtherDerived, AliasFreeProduct>(derived(), matrix.derived());
    }
  };
  template <typename Derived>
  const PermutationWrapper<const Derived> MatrixBase<Derived>::asPermutation() const {
    return derived();
  }
  namespace internal {
    template <>
    struct AssignmentKind<DenseShape, PermutationShape> {
      typedef EigenBase2EigenBase Kind;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  class TranspositionsBase {
    typedef internal::traits<Derived> Traits;

  public:
    typedef typename Traits::IndicesType IndicesType;
    typedef typename IndicesType::Scalar StorageIndex;
    typedef Eigen::Index Index;
    Derived& derived() { return *static_cast<Derived*>(this); }
    const Derived& derived() const { return *static_cast<const Derived*>(this); }
    template <typename OtherDerived>
    Derived& operator=(const TranspositionsBase<OtherDerived>& other) {
      indices() = other.indices();
      return derived();
    }
    Index size() const { return indices().size(); }
    Index rows() const { return indices().size(); }
    Index cols() const { return indices().size(); }
    inline const StorageIndex& coeff(Index i) const { return indices().coeff(i); }
    inline StorageIndex& coeffRef(Index i) { return indices().coeffRef(i); }
    inline const StorageIndex& operator()(Index i) const { return indices()(i); }
    inline StorageIndex& operator()(Index i) { return indices()(i); }
    inline const StorageIndex& operator[](Index i) const { return indices()(i); }
    inline StorageIndex& operator[](Index i) { return indices()(i); }
    const IndicesType& indices() const { return derived().indices(); }
    IndicesType& indices() { return derived().indices(); }
    inline void resize(Index newSize) { indices().resize(newSize); }
    void setIdentity() {
      for (StorageIndex i = 0; i < indices().size(); ++i)
        coeffRef(i) = i;
    }
    inline Transpose<TranspositionsBase> inverse() const { return Transpose<TranspositionsBase>(derived()); }
    inline Transpose<TranspositionsBase> transpose() const { return Transpose<TranspositionsBase>(derived()); }

  protected:
  };
  namespace internal {
    template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_>
    struct traits<Transpositions<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>>
        : traits<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>> {
      typedef Matrix<StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1> IndicesType;
      typedef TranspositionsStorage StorageKind;
    };
  }  // namespace internal
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_>
  class Transpositions
      : public TranspositionsBase<Transpositions<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>> {
    typedef internal::traits<Transpositions> Traits;

  public:
    typedef TranspositionsBase<Transpositions> Base;
    typedef typename Traits::IndicesType IndicesType;
    typedef typename IndicesType::Scalar StorageIndex;
    inline Transpositions() {}
    template <typename OtherDerived>
    inline Transpositions(const TranspositionsBase<OtherDerived>& other) : m_indices(other.indices()) {}
    template <typename Other>
    explicit inline Transpositions(const MatrixBase<Other>& indices) : m_indices(indices) {}
    template <typename OtherDerived>
    Transpositions& operator=(const TranspositionsBase<OtherDerived>& other) {
      return Base::operator=(other);
    }
    Transpositions& operator=(const Transpositions& other) {
      m_indices = other.m_indices;
      return *this;
    }
    inline Transpositions(Index size) : m_indices(size) {}
    const IndicesType& indices() const { return m_indices; }
    IndicesType& indices() { return m_indices; }

  protected:
    IndicesType m_indices;
  };
  namespace internal {
    template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_>
    struct traits<Map<Transpositions<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess_>>
        : traits<PermutationMatrix<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>> {
      typedef Map<const Matrix<StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1>, PacketAccess_>
          IndicesType;
      typedef StorageIndex_ StorageIndex;
      typedef TranspositionsStorage StorageKind;
    };
  }  // namespace internal
  template <int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess>
  class Map<Transpositions<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess>
      : public TranspositionsBase<
            Map<Transpositions<SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_>, PacketAccess>> {
    typedef internal::traits<Map> Traits;

  public:
    typedef TranspositionsBase<Map> Base;
    typedef typename Traits::IndicesType IndicesType;
    typedef typename IndicesType::Scalar StorageIndex;
    explicit inline Map(const StorageIndex* indicesPtr) : m_indices(indicesPtr) {}
    inline Map(const StorageIndex* indicesPtr, Index size) : m_indices(indicesPtr, size) {}
    template <typename OtherDerived>
    Map& operator=(const TranspositionsBase<OtherDerived>& other) {
      return Base::operator=(other);
    }
    Map& operator=(const Map& other) {
      m_indices = other.m_indices;
      return *this;
    }
    const IndicesType& indices() const { return m_indices; }
    IndicesType& indices() { return m_indices; }

  protected:
    IndicesType m_indices;
  };
  namespace internal {
    template <typename IndicesType_>
    struct traits<TranspositionsWrapper<IndicesType_>> : traits<PermutationWrapper<IndicesType_>> {
      typedef TranspositionsStorage StorageKind;
    };
  }  // namespace internal
  template <typename IndicesType_>
  class TranspositionsWrapper : public TranspositionsBase<TranspositionsWrapper<IndicesType_>> {
    typedef internal::traits<TranspositionsWrapper> Traits;

  public:
    typedef TranspositionsBase<TranspositionsWrapper> Base;
    typedef typename Traits::IndicesType IndicesType;
    typedef typename IndicesType::Scalar StorageIndex;
    explicit inline TranspositionsWrapper(IndicesType& indices) : m_indices(indices) {}
    template <typename OtherDerived>
    TranspositionsWrapper& operator=(const TranspositionsBase<OtherDerived>& other) {
      return Base::operator=(other);
    }
    const IndicesType& indices() const { return m_indices; }
    IndicesType& indices() { return m_indices; }

  protected:
    typename IndicesType::Nested m_indices;
  };
  template <typename MatrixDerived, typename TranspositionsDerived>
  const Product<MatrixDerived, TranspositionsDerived, AliasFreeProduct> operator*(
      const MatrixBase<MatrixDerived>& matrix, const TranspositionsBase<TranspositionsDerived>& transpositions) {
    return Product<MatrixDerived, TranspositionsDerived, AliasFreeProduct>(matrix.derived(), transpositions.derived());
  }
  template <typename TranspositionsDerived, typename MatrixDerived>
  const Product<TranspositionsDerived, MatrixDerived, AliasFreeProduct> operator*(
      const TranspositionsBase<TranspositionsDerived>& transpositions, const MatrixBase<MatrixDerived>& matrix) {
    return Product<TranspositionsDerived, MatrixDerived, AliasFreeProduct>(transpositions.derived(), matrix.derived());
  }
  namespace internal {
    template <typename Derived>
    struct traits<Transpose<TranspositionsBase<Derived>>> : traits<Derived> {};
  }  // namespace internal
  template <typename TranspositionsDerived>
  class Transpose<TranspositionsBase<TranspositionsDerived>> {
    typedef TranspositionsDerived TranspositionType;
    typedef typename TranspositionType::IndicesType IndicesType;

  public:
    explicit Transpose(const TranspositionType& t) : m_transpositions(t) {}
    constexpr Index size() const noexcept { return m_transpositions.size(); }
    constexpr Index rows() const noexcept { return m_transpositions.size(); }
    constexpr Index cols() const noexcept { return m_transpositions.size(); }
    template <typename OtherDerived>
    friend const Product<OtherDerived, Transpose, AliasFreeProduct> operator*(const MatrixBase<OtherDerived>& matrix,
                                                                              const Transpose& trt) {
      return Product<OtherDerived, Transpose, AliasFreeProduct>(matrix.derived(), trt);
    }
    template <typename OtherDerived>
    const Product<Transpose, OtherDerived, AliasFreeProduct> operator*(const MatrixBase<OtherDerived>& matrix) const {
      return Product<Transpose, OtherDerived, AliasFreeProduct>(*this, matrix.derived());
    }
    const TranspositionType& nestedExpression() const { return m_transpositions; }

  protected:
    const TranspositionType& m_transpositions;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <int Side, typename TriangularType, typename Rhs>
    struct triangular_solve_retval;
  }
  template <typename Derived>
  class TriangularBase : public EigenBase<Derived> {
  public:
    enum {
      Mode = internal::traits<Derived>::Mode,
      RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
      ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
      MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
      SizeAtCompileTime = (internal::size_of_xpr_at_compile_time<Derived>::ret),
      MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits<Derived>::MaxRowsAtCompileTime,
                                                            internal::traits<Derived>::MaxColsAtCompileTime)
    };
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename internal::traits<Derived>::StorageKind StorageKind;
    typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
    typedef typename internal::traits<Derived>::FullMatrixType DenseMatrixType;
    typedef DenseMatrixType DenseType;
    typedef Derived const& Nested;
    inline TriangularBase() {
      (static_cast<bool>(!((int(Mode) & int(UnitDiag)) && (int(Mode) & int(ZeroDiag))))
           ? void(0)
           : __assert_fail("!((int(Mode) & int(UnitDiag)) && (int(Mode) & int(ZeroDiag)))",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/TriangularMatrix.h",
                           57,
                           __extension__ __PRETTY_FUNCTION__));
    }
    constexpr inline Index rows() const noexcept { return derived().rows(); }
    constexpr inline Index cols() const noexcept { return derived().cols(); }
    constexpr inline Index outerStride() const noexcept { return derived().outerStride(); }
    constexpr inline Index innerStride() const noexcept { return derived().innerStride(); }
    void resize(Index rows, Index cols) {
      Eigen::internal::ignore_unused_variable(rows);
      ;
      Eigen::internal::ignore_unused_variable(cols);
      ;
      (static_cast<bool>(rows == this->rows() && cols == this->cols())
           ? void(0)
           : __assert_fail("rows==this->rows() && cols==this->cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/TriangularMatrix.h",
                           74,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline Scalar coeff(Index row, Index col) const { return derived().coeff(row, col); }
    inline Scalar& coeffRef(Index row, Index col) { return derived().coeffRef(row, col); }
    template <typename Other>
    inline void copyCoeff(Index row, Index col, Other& other) {
      derived().coeffRef(row, col) = other.coeff(row, col);
    }
    inline Scalar operator()(Index row, Index col) const {
      check_coordinates(row, col);
      return coeff(row, col);
    }
    inline Scalar& operator()(Index row, Index col) {
      check_coordinates(row, col);
      return coeffRef(row, col);
    }
    inline const Derived& derived() const { return *static_cast<const Derived*>(this); }
    inline Derived& derived() { return *static_cast<Derived*>(this); }
    template <typename DenseDerived>
    void evalTo(MatrixBase<DenseDerived>& other) const;
    template <typename DenseDerived>
    void evalToLazy(MatrixBase<DenseDerived>& other) const;
    DenseMatrixType toDenseMatrix() const {
      DenseMatrixType res(rows(), cols());
      evalToLazy(res);
      return res;
    }

  protected:
    void check_coordinates(Index row, Index col) const {
      ;
      ;
      (static_cast<bool>(col >= 0 && col < cols() && row >= 0 && row < rows())
           ? void(0)
           : __assert_fail("col>=0 && col<cols() && row>=0 && row<rows()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/TriangularMatrix.h",
                           132,
                           __extension__ __PRETTY_FUNCTION__));
      const int mode = int(Mode) & ~SelfAdjoint;
      ;
      (static_cast<bool>((mode == Upper && col >= row) || (mode == Lower && col <= row) ||
                         ((mode == StrictlyUpper || mode == UnitUpper) && col > row) ||
                         ((mode == StrictlyLower || mode == UnitLower) && col < row))
           ? void(0)
           : __assert_fail("(mode==Upper && col>=row) || (mode==Lower && col<=row) || ((mode==StrictlyUpper || "
                           "mode==UnitUpper) && col>row) || ((mode==StrictlyLower || mode==UnitLower) && col<row)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/TriangularMatrix.h",
                           138,
                           __extension__ __PRETTY_FUNCTION__));
    }
    void check_coordinates_internal(Index, Index) const {}
  };
  namespace internal {
    template <typename MatrixType, unsigned int Mode_>
    struct traits<TriangularView<MatrixType, Mode_>> : traits<MatrixType> {
      typedef typename ref_selector<MatrixType>::non_const_type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNestedNonRef;
      typedef remove_all_t<MatrixTypeNested> MatrixTypeNestedCleaned;
      typedef typename MatrixType::PlainObject FullMatrixType;
      typedef MatrixType ExpressionType;
      enum {
        Mode = Mode_,
        FlagsLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
        Flags = (MatrixTypeNestedCleaned::Flags & (HereditaryBits | FlagsLvalueBit) &
                 (~(PacketAccessBit | DirectAccessBit | LinearAccessBit)))
      };
    };
  }  // namespace internal
  template <typename MatrixType_, unsigned int Mode_, typename StorageKind>
  class TriangularViewImpl;
  template <typename MatrixType_, unsigned int Mode_>
  class TriangularView
      : public TriangularViewImpl<MatrixType_, Mode_, typename internal::traits<MatrixType_>::StorageKind> {
  public:
    typedef TriangularViewImpl<MatrixType_, Mode_, typename internal::traits<MatrixType_>::StorageKind> Base;
    typedef typename internal::traits<TriangularView>::Scalar Scalar;
    typedef MatrixType_ MatrixType;

  protected:
    typedef typename internal::traits<TriangularView>::MatrixTypeNested MatrixTypeNested;
    typedef typename internal::traits<TriangularView>::MatrixTypeNestedNonRef MatrixTypeNestedNonRef;
    typedef internal::remove_all_t<typename MatrixType::ConjugateReturnType> MatrixConjugateReturnType;
    typedef TriangularView<std::add_const_t<MatrixType>, Mode_> ConstTriangularView;

  public:
    typedef typename internal::traits<TriangularView>::StorageKind StorageKind;
    typedef typename internal::traits<TriangularView>::MatrixTypeNestedCleaned NestedExpression;
    enum {
      Mode = Mode_,
      Flags = internal::traits<TriangularView>::Flags,
      TransposeMode =
          (Mode & Upper ? Lower : 0) | (Mode & Lower ? Upper : 0) | (Mode & (UnitDiag)) | (Mode & (ZeroDiag)),
      IsVectorAtCompileTime = false
    };
    explicit inline TriangularView(MatrixType& matrix) : m_matrix(matrix) {}
    using Base::operator=;
    inline TriangularView& operator=(const TriangularView& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline TriangularView& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    TriangularView(const TriangularView&) = default;
    constexpr inline Index rows() const noexcept { return m_matrix.rows(); }
    constexpr inline Index cols() const noexcept { return m_matrix.cols(); }
    const NestedExpression& nestedExpression() const { return m_matrix; }
    NestedExpression& nestedExpression() { return m_matrix; }
    typedef TriangularView<const MatrixConjugateReturnType, Mode> ConjugateReturnType;
    inline const ConjugateReturnType conjugate() const { return ConjugateReturnType(m_matrix.conjugate()); }
    template <bool Cond>
    inline std::conditional_t<Cond, ConjugateReturnType, ConstTriangularView> conjugateIf() const {
      typedef std::conditional_t<Cond, ConjugateReturnType, ConstTriangularView> ReturnType;
      return ReturnType(m_matrix.template conjugateIf<Cond>());
    }
    typedef TriangularView<const typename MatrixType::AdjointReturnType, TransposeMode> AdjointReturnType;
    inline const AdjointReturnType adjoint() const { return AdjointReturnType(m_matrix.adjoint()); }
    typedef TriangularView<typename MatrixType::TransposeReturnType, TransposeMode> TransposeReturnType;
    template <class Dummy = int>
    inline TransposeReturnType transpose(
        std::enable_if_t<Eigen::internal::is_lvalue<MatrixType>::value, Dummy*> = nullptr) {
      typename MatrixType::TransposeReturnType tmp(m_matrix);
      return TransposeReturnType(tmp);
    }
    typedef TriangularView<const typename MatrixType::ConstTransposeReturnType, TransposeMode> ConstTransposeReturnType;
    inline const ConstTransposeReturnType transpose() const { return ConstTransposeReturnType(m_matrix.transpose()); }
    template <typename Other>
    inline const Solve<TriangularView, Other> solve(const MatrixBase<Other>& other) const {
      return Solve<TriangularView, Other>(*this, other.derived());
    }
    using Base::solve;
    SelfAdjointView<MatrixTypeNestedNonRef, Mode> selfadjointView() {
      static_assert((Mode & (UnitDiag | ZeroDiag)) == 0, "PROGRAMMING_ERROR");
      ;
      return SelfAdjointView<MatrixTypeNestedNonRef, Mode>(m_matrix);
    }
    const SelfAdjointView<MatrixTypeNestedNonRef, Mode> selfadjointView() const {
      static_assert((Mode & (UnitDiag | ZeroDiag)) == 0, "PROGRAMMING_ERROR");
      ;
      return SelfAdjointView<MatrixTypeNestedNonRef, Mode>(m_matrix);
    }
    Scalar determinant() const {
      if (Mode & UnitDiag)
        return 1;
      else if (Mode & ZeroDiag)
        return 0;
      else
        return m_matrix.diagonal().prod();
    }

  protected:
    MatrixTypeNested m_matrix;
  };
  template <typename MatrixType_, unsigned int Mode_>
  class TriangularViewImpl<MatrixType_, Mode_, Dense> : public TriangularBase<TriangularView<MatrixType_, Mode_>> {
  public:
    typedef TriangularView<MatrixType_, Mode_> TriangularViewType;
    typedef TriangularBase<TriangularViewType> Base;
    typedef typename internal::traits<TriangularViewType>::Scalar Scalar;
    typedef MatrixType_ MatrixType;
    typedef typename MatrixType::PlainObject DenseMatrixType;
    typedef DenseMatrixType PlainObject;

  public:
    using Base::derived;
    using Base::evalToLazy;
    typedef typename internal::traits<TriangularViewType>::StorageKind StorageKind;
    enum { Mode = Mode_, Flags = internal::traits<TriangularViewType>::Flags };
    inline Index outerStride() const { return derived().nestedExpression().outerStride(); }
    inline Index innerStride() const { return derived().nestedExpression().innerStride(); }
    template <typename Other>
    TriangularViewType& operator+=(const DenseBase<Other>& other) {
      internal::call_assignment_no_alias(
          derived(), other.derived(), internal::add_assign_op<Scalar, typename Other::Scalar>());
      return derived();
    }
    template <typename Other>
    TriangularViewType& operator-=(const DenseBase<Other>& other) {
      internal::call_assignment_no_alias(
          derived(), other.derived(), internal::sub_assign_op<Scalar, typename Other::Scalar>());
      return derived();
    }
    TriangularViewType& operator*=(const typename internal::traits<MatrixType>::Scalar& other) {
      return *this = derived().nestedExpression() * other;
    }
    TriangularViewType& operator/=(const typename internal::traits<MatrixType>::Scalar& other) {
      return *this = derived().nestedExpression() / other;
    }
    void fill(const Scalar& value) { setConstant(value); }
    TriangularViewType& setConstant(const Scalar& value) {
      return *this = MatrixType::Constant(derived().rows(), derived().cols(), value);
    }
    TriangularViewType& setZero() { return setConstant(Scalar(0)); }
    TriangularViewType& setOnes() { return setConstant(Scalar(1)); }
    inline Scalar coeff(Index row, Index col) const {
      Base::check_coordinates_internal(row, col);
      return derived().nestedExpression().coeff(row, col);
    }
    inline Scalar& coeffRef(Index row, Index col) {
      static_assert(Eigen::internal::is_lvalue<TriangularViewType>::value,
                    "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      Base::check_coordinates_internal(row, col);
      return derived().nestedExpression().coeffRef(row, col);
    }
    template <typename OtherDerived>
    TriangularViewType& operator=(const TriangularBase<OtherDerived>& other);
    template <typename OtherDerived>
    TriangularViewType& operator=(const MatrixBase<OtherDerived>& other);
    TriangularViewType& operator=(const TriangularViewImpl& other) {
      return *this = other.derived().nestedExpression();
    }
    template <typename OtherDerived>
    __attribute__((deprecated)) void lazyAssign(const TriangularBase<OtherDerived>& other);
    template <typename OtherDerived>
    __attribute__((deprecated)) void lazyAssign(const MatrixBase<OtherDerived>& other);
    template <typename OtherDerived>
    const Product<TriangularViewType, OtherDerived> operator*(const MatrixBase<OtherDerived>& rhs) const {
      return Product<TriangularViewType, OtherDerived>(derived(), rhs.derived());
    }
    template <typename OtherDerived>
    friend const Product<OtherDerived, TriangularViewType> operator*(const MatrixBase<OtherDerived>& lhs,
                                                                     const TriangularViewImpl& rhs) {
      return Product<OtherDerived, TriangularViewType>(lhs.derived(), rhs.derived());
    }
    template <int Side, typename Other>
    inline const internal::triangular_solve_retval<Side, TriangularViewType, Other> solve(
        const MatrixBase<Other>& other) const;
    template <int Side, typename OtherDerived>
    void solveInPlace(const MatrixBase<OtherDerived>& other) const;
    template <typename OtherDerived>
    void solveInPlace(const MatrixBase<OtherDerived>& other) const {
      return solveInPlace<OnTheLeft>(other);
    }
    template <typename OtherDerived>
    void swap(TriangularBase<OtherDerived> const& other) {
      static_assert(Eigen::internal::is_lvalue<OtherDerived>::value,
                    "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op<Scalar>());
    }
    template <typename OtherDerived>
    __attribute__((deprecated)) void swap(MatrixBase<OtherDerived> const& other) {
      static_assert(Eigen::internal::is_lvalue<OtherDerived>::value,
                    "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op<Scalar>());
    }
    template <typename RhsType, typename DstType>
    inline void _solve_impl(const RhsType& rhs, DstType& dst) const {
      if (!internal::is_same_dense(dst, rhs))
        dst = rhs;
      this->solveInPlace(dst);
    }
    template <typename ProductType>
    inline TriangularViewType& _assignProduct(const ProductType& prod, const Scalar& alpha, bool beta);

  protected:
    TriangularViewImpl(const TriangularViewImpl&) = default;
    TriangularViewImpl() = default;
    ~TriangularViewImpl() = default;
  };
  template <typename MatrixType, unsigned int Mode>
  template <typename OtherDerived>
  inline TriangularView<MatrixType, Mode>& TriangularViewImpl<MatrixType, Mode, Dense>::operator=(
      const MatrixBase<OtherDerived>& other) {
    internal::call_assignment_no_alias(
        derived(), other.derived(), internal::assign_op<Scalar, typename OtherDerived::Scalar>());
    return derived();
  }
  template <typename MatrixType, unsigned int Mode>
  template <typename OtherDerived>
  void TriangularViewImpl<MatrixType, Mode, Dense>::lazyAssign(const MatrixBase<OtherDerived>& other) {
    internal::call_assignment_no_alias(derived(), other.template triangularView<Mode>());
  }
  template <typename MatrixType, unsigned int Mode>
  template <typename OtherDerived>
  inline TriangularView<MatrixType, Mode>& TriangularViewImpl<MatrixType, Mode, Dense>::operator=(
      const TriangularBase<OtherDerived>& other) {
    (static_cast<bool>(Mode == int(OtherDerived::Mode))
         ? void(0)
         : __assert_fail("Mode == int(OtherDerived::Mode)",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/TriangularMatrix.h",
                         596,
                         __extension__ __PRETTY_FUNCTION__));
    internal::call_assignment(derived(), other.derived());
    return derived();
  }
  template <typename MatrixType, unsigned int Mode>
  template <typename OtherDerived>
  void TriangularViewImpl<MatrixType, Mode, Dense>::lazyAssign(const TriangularBase<OtherDerived>& other) {
    (static_cast<bool>(Mode == int(OtherDerived::Mode))
         ? void(0)
         : __assert_fail("Mode == int(OtherDerived::Mode)",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/TriangularMatrix.h",
                         605,
                         __extension__ __PRETTY_FUNCTION__));
    internal::call_assignment_no_alias(derived(), other.derived());
  }
  template <typename Derived>
  template <typename DenseDerived>
  void TriangularBase<Derived>::evalTo(MatrixBase<DenseDerived>& other) const {
    evalToLazy(other.derived());
  }
  template <typename Derived>
  template <unsigned int Mode>
  typename MatrixBase<Derived>::template TriangularViewReturnType<Mode>::Type MatrixBase<Derived>::triangularView() {
    return typename TriangularViewReturnType<Mode>::Type(derived());
  }
  template <typename Derived>
  template <unsigned int Mode>
  typename MatrixBase<Derived>::template ConstTriangularViewReturnType<Mode>::Type MatrixBase<Derived>::triangularView()
      const {
    return typename ConstTriangularViewReturnType<Mode>::Type(derived());
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isUpperTriangular(const RealScalar& prec) const {
    RealScalar maxAbsOnUpperPart = static_cast<RealScalar>(-1);
    for (Index j = 0; j < cols(); ++j) {
      Index maxi = numext::mini(j, rows() - 1);
      for (Index i = 0; i <= maxi; ++i) {
        RealScalar absValue = numext::abs(coeff(i, j));
        if (absValue > maxAbsOnUpperPart)
          maxAbsOnUpperPart = absValue;
      }
    }
    RealScalar threshold = maxAbsOnUpperPart * prec;
    for (Index j = 0; j < cols(); ++j)
      for (Index i = j + 1; i < rows(); ++i)
        if (numext::abs(coeff(i, j)) > threshold)
          return false;
    return true;
  }
  template <typename Derived>
  bool MatrixBase<Derived>::isLowerTriangular(const RealScalar& prec) const {
    RealScalar maxAbsOnLowerPart = static_cast<RealScalar>(-1);
    for (Index j = 0; j < cols(); ++j)
      for (Index i = j; i < rows(); ++i) {
        RealScalar absValue = numext::abs(coeff(i, j));
        if (absValue > maxAbsOnLowerPart)
          maxAbsOnLowerPart = absValue;
      }
    RealScalar threshold = maxAbsOnLowerPart * prec;
    for (Index j = 1; j < cols(); ++j) {
      Index maxi = numext::mini(j, rows() - 1);
      for (Index i = 0; i < maxi; ++i)
        if (numext::abs(coeff(i, j)) > threshold)
          return false;
    }
    return true;
  }
  namespace internal {
    template <typename MatrixType, unsigned int Mode>
    struct evaluator_traits<TriangularView<MatrixType, Mode>> {
      typedef typename storage_kind_to_evaluator_kind<typename MatrixType::StorageKind>::Kind Kind;
      typedef typename glue_shapes<typename evaluator_traits<MatrixType>::Shape, TriangularShape>::type Shape;
    };
    template <typename MatrixType, unsigned int Mode>
    struct unary_evaluator<TriangularView<MatrixType, Mode>, IndexBased>
        : evaluator<internal::remove_all_t<MatrixType>> {
      typedef TriangularView<MatrixType, Mode> XprType;
      typedef evaluator<internal::remove_all_t<MatrixType>> Base;
      unary_evaluator(const XprType& xpr) : Base(xpr.nestedExpression()) {}
    };
    struct Triangular2Triangular {};
    struct Triangular2Dense {};
    struct Dense2Triangular {};
    template <typename Kernel, unsigned int Mode, int UnrollCount, bool ClearOpposite>
    struct triangular_assignment_loop;
    template <int UpLo,
              int Mode,
              int SetOpposite,
              typename DstEvaluatorTypeT,
              typename SrcEvaluatorTypeT,
              typename Functor,
              int Version = Specialized>
    class triangular_dense_assignment_kernel
        : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> {
    protected:
      typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
      typedef typename Base::DstXprType DstXprType;
      typedef typename Base::SrcXprType SrcXprType;
      using Base::m_dst;
      using Base::m_functor;
      using Base::m_src;

    public:
      typedef typename Base::DstEvaluatorType DstEvaluatorType;
      typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
      typedef typename Base::Scalar Scalar;
      typedef typename Base::AssignmentTraits AssignmentTraits;
      triangular_dense_assignment_kernel(DstEvaluatorType& dst,
                                         const SrcEvaluatorType& src,
                                         const Functor& func,
                                         DstXprType& dstExpr)
          : Base(dst, src, func, dstExpr) {}
      using Base::assignCoeff;
      void assignDiagonalCoeff(Index id) {
        if (Mode == UnitDiag && SetOpposite)
          m_functor.assignCoeff(m_dst.coeffRef(id, id), Scalar(1));
        else if (Mode == ZeroDiag && SetOpposite)
          m_functor.assignCoeff(m_dst.coeffRef(id, id), Scalar(0));
        else if (Mode == 0)
          Base::assignCoeff(id, id);
      }
      void assignOppositeCoeff(Index row, Index col) {
        ;
        if (SetOpposite)
          m_functor.assignCoeff(m_dst.coeffRef(row, col), Scalar(0));
      }
    };
    template <int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType, typename Functor>
    inline void call_triangular_assignment_loop(DstXprType& dst, const SrcXprType& src, const Functor& func) {
      typedef evaluator<DstXprType> DstEvaluatorType;
      typedef evaluator<SrcXprType> SrcEvaluatorType;
      SrcEvaluatorType srcEvaluator(src);
      Index dstRows = src.rows();
      Index dstCols = src.cols();
      if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
        dst.resize(dstRows, dstCols);
      DstEvaluatorType dstEvaluator(dst);
      typedef triangular_dense_assignment_kernel<Mode&(Lower | Upper),
                                                 Mode&(UnitDiag | ZeroDiag | SelfAdjoint),
                                                 SetOpposite,
                                                 DstEvaluatorType,
                                                 SrcEvaluatorType,
                                                 Functor>
          Kernel;
      Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
      enum {
        unroll = DstXprType::SizeAtCompileTime != Dynamic && SrcEvaluatorType::CoeffReadCost < HugeCost &&
                 DstXprType::SizeAtCompileTime *
                         (int(DstEvaluatorType::CoeffReadCost) + int(SrcEvaluatorType::CoeffReadCost)) / 2 <=
                     110
      };
      triangular_assignment_loop<Kernel, Mode, unroll ? int(DstXprType::SizeAtCompileTime) : Dynamic, SetOpposite>::run(
          kernel);
    }
    template <int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType>
    inline void call_triangular_assignment_loop(DstXprType& dst, const SrcXprType& src) {
      call_triangular_assignment_loop<Mode, SetOpposite>(
          dst, src, internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>());
    }
    template <>
    struct AssignmentKind<TriangularShape, TriangularShape> {
      typedef Triangular2Triangular Kind;
    };
    template <>
    struct AssignmentKind<DenseShape, TriangularShape> {
      typedef Triangular2Dense Kind;
    };
    template <>
    struct AssignmentKind<TriangularShape, DenseShape> {
      typedef Dense2Triangular Kind;
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Triangular> {
      static void run(DstXprType& dst, const SrcXprType& src, const Functor& func) {
        (static_cast<bool>(int(DstXprType::Mode) == int(SrcXprType::Mode))
             ? void(0)
             : __assert_fail("int(DstXprType::Mode) == int(SrcXprType::Mode)",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/TriangularMatrix.h",
                             847,
                             __extension__ __PRETTY_FUNCTION__));
        call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
      }
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Dense> {
      static void run(DstXprType& dst, const SrcXprType& src, const Functor& func) {
        call_triangular_assignment_loop<SrcXprType::Mode, (int(SrcXprType::Mode) & int(SelfAdjoint)) == 0>(
            dst, src, func);
      }
    };
    template <typename DstXprType, typename SrcXprType, typename Functor>
    struct Assignment<DstXprType, SrcXprType, Functor, Dense2Triangular> {
      static void run(DstXprType& dst, const SrcXprType& src, const Functor& func) {
        call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
      }
    };
    template <typename Kernel, unsigned int Mode, int UnrollCount, bool SetOpposite>
    struct triangular_assignment_loop {
      typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
      typedef typename DstEvaluatorType::XprType DstXprType;
      enum {
        col = (UnrollCount - 1) / DstXprType::RowsAtCompileTime,
        row = (UnrollCount - 1) % DstXprType::RowsAtCompileTime
      };
      typedef typename Kernel::Scalar Scalar;
      static inline void run(Kernel& kernel) {
        triangular_assignment_loop<Kernel, Mode, UnrollCount - 1, SetOpposite>::run(kernel);
        if (row == col)
          kernel.assignDiagonalCoeff(row);
        else if (((Mode & Lower) && row > col) || ((Mode & Upper) && row < col))
          kernel.assignCoeff(row, col);
        else if (SetOpposite)
          kernel.assignOppositeCoeff(row, col);
      }
    };
    template <typename Kernel, unsigned int Mode, bool SetOpposite>
    struct triangular_assignment_loop<Kernel, Mode, 0, SetOpposite> {
      static inline void run(Kernel&) {}
    };
    template <typename Kernel, unsigned int Mode, bool SetOpposite>
    struct triangular_assignment_loop<Kernel, Mode, Dynamic, SetOpposite> {
      typedef typename Kernel::Scalar Scalar;
      static inline void run(Kernel& kernel) {
        for (Index j = 0; j < kernel.cols(); ++j) {
          Index maxi = numext::mini(j, kernel.rows());
          Index i = 0;
          if (((Mode & Lower) && SetOpposite) || (Mode & Upper)) {
            for (; i < maxi; ++i)
              if (Mode & Upper)
                kernel.assignCoeff(i, j);
              else
                kernel.assignOppositeCoeff(i, j);
          } else
            i = maxi;
          if (i < kernel.rows())
            kernel.assignDiagonalCoeff(i++);
          if (((Mode & Upper) && SetOpposite) || (Mode & Lower)) {
            for (; i < kernel.rows(); ++i)
              if (Mode & Lower)
                kernel.assignCoeff(i, j);
              else
                kernel.assignOppositeCoeff(i, j);
          }
        }
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename DenseDerived>
  void TriangularBase<Derived>::evalToLazy(MatrixBase<DenseDerived>& other) const {
    other.derived().resize(this->rows(), this->cols());
    internal::call_triangular_assignment_loop<Derived::Mode, (int(Derived::Mode) & int(SelfAdjoint)) == 0>(
        other.derived(), derived().nestedExpression());
  }
  namespace internal {
    template <typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, DefaultProduct>,
                      internal::assign_op<Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
                      Dense2Triangular> {
      typedef Product<Lhs, Rhs, DefaultProduct> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<Scalar, typename SrcXprType::Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        dst._assignProduct(src, Scalar(1), false);
      }
    };
    template <typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, DefaultProduct>,
                      internal::add_assign_op<Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
                      Dense2Triangular> {
      typedef Product<Lhs, Rhs, DefaultProduct> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::add_assign_op<Scalar, typename SrcXprType::Scalar>&) {
        dst._assignProduct(src, Scalar(1), true);
      }
    };
    template <typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, DefaultProduct>,
                      internal::sub_assign_op<Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
                      Dense2Triangular> {
      typedef Product<Lhs, Rhs, DefaultProduct> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::sub_assign_op<Scalar, typename SrcXprType::Scalar>&) {
        dst._assignProduct(src, Scalar(-1), true);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, unsigned int UpLo>
    struct traits<SelfAdjointView<MatrixType, UpLo>> : traits<MatrixType> {
      typedef typename ref_selector<MatrixType>::non_const_type MatrixTypeNested;
      typedef remove_all_t<MatrixTypeNested> MatrixTypeNestedCleaned;
      typedef MatrixType ExpressionType;
      typedef typename MatrixType::PlainObject FullMatrixType;
      enum {
        Mode = UpLo | SelfAdjoint,
        FlagsLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
        Flags = MatrixTypeNestedCleaned::Flags & (HereditaryBits | FlagsLvalueBit) &
                (~(PacketAccessBit | DirectAccessBit | LinearAccessBit))
      };
    };
  }  // namespace internal
  template <typename MatrixType_, unsigned int UpLo>
  class SelfAdjointView : public TriangularBase<SelfAdjointView<MatrixType_, UpLo>> {
  public:
    static_assert(UpLo == Lower || UpLo == Upper, "SELFADJOINTVIEW_ACCEPTS_UPPER_AND_LOWER_MODE_ONLY");
    typedef MatrixType_ MatrixType;
    typedef TriangularBase<SelfAdjointView> Base;
    typedef typename internal::traits<SelfAdjointView>::MatrixTypeNested MatrixTypeNested;
    typedef typename internal::traits<SelfAdjointView>::MatrixTypeNestedCleaned MatrixTypeNestedCleaned;
    typedef MatrixTypeNestedCleaned NestedExpression;
    typedef typename internal::traits<SelfAdjointView>::Scalar Scalar;
    typedef typename MatrixType::StorageIndex StorageIndex;
    typedef internal::remove_all_t<typename MatrixType::ConjugateReturnType> MatrixConjugateReturnType;
    typedef SelfAdjointView<std::add_const_t<MatrixType>, UpLo> ConstSelfAdjointView;
    enum {
      Mode = internal::traits<SelfAdjointView>::Mode,
      Flags = internal::traits<SelfAdjointView>::Flags,
      TransposeMode = ((int(Mode) & int(Upper)) ? Lower : 0) | ((int(Mode) & int(Lower)) ? Upper : 0)
    };
    typedef typename MatrixType::PlainObject PlainObject;
    explicit inline SelfAdjointView(MatrixType& matrix) : m_matrix(matrix) {}
    constexpr inline Index rows() const noexcept { return m_matrix.rows(); }
    constexpr inline Index cols() const noexcept { return m_matrix.cols(); }
    constexpr inline Index outerStride() const noexcept { return m_matrix.outerStride(); }
    constexpr inline Index innerStride() const noexcept { return m_matrix.innerStride(); }
    inline Scalar coeff(Index row, Index col) const {
      Base::check_coordinates_internal(row, col);
      return m_matrix.coeff(row, col);
    }
    inline Scalar& coeffRef(Index row, Index col) {
      static_assert(Eigen::internal::is_lvalue<SelfAdjointView>::value,
                    "THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY");
      ;
      Base::check_coordinates_internal(row, col);
      return m_matrix.coeffRef(row, col);
    }
    const MatrixTypeNestedCleaned& _expression() const { return m_matrix; }
    const MatrixTypeNestedCleaned& nestedExpression() const { return m_matrix; }
    MatrixTypeNestedCleaned& nestedExpression() { return m_matrix; }
    template <typename OtherDerived>
    const Product<SelfAdjointView, OtherDerived> operator*(const MatrixBase<OtherDerived>& rhs) const {
      return Product<SelfAdjointView, OtherDerived>(*this, rhs.derived());
    }
    template <typename OtherDerived>
    friend const Product<OtherDerived, SelfAdjointView> operator*(const MatrixBase<OtherDerived>& lhs,
                                                                  const SelfAdjointView& rhs) {
      return Product<OtherDerived, SelfAdjointView>(lhs.derived(), rhs);
    }
    friend const SelfAdjointView<
        const CwiseBinaryOp<internal::scalar_product_op<Scalar, typename internal::traits<MatrixType>::Scalar>,
                            const typename internal::plain_constant_type<MatrixType, Scalar>::type,
                            const MatrixType>,
        UpLo>
    operator*(const Scalar& s, const SelfAdjointView& mat) {
      return (s * mat.nestedExpression()).template selfadjointView<UpLo>();
    }
    template <typename DerivedU, typename DerivedV>
    SelfAdjointView& rankUpdate(const MatrixBase<DerivedU>& u,
                                const MatrixBase<DerivedV>& v,
                                const Scalar& alpha = Scalar(1));
    template <typename DerivedU>
    SelfAdjointView& rankUpdate(const MatrixBase<DerivedU>& u, const Scalar& alpha = Scalar(1));
    template <unsigned int TriMode>
    std::conditional_t<(TriMode & (Upper | Lower)) == (UpLo & (Upper | Lower)),
                       TriangularView<MatrixType, TriMode>,
                       TriangularView<typename MatrixType::AdjointReturnType, TriMode>>
    triangularView() const {
      std::conditional_t<(TriMode & (Upper | Lower)) == (UpLo & (Upper | Lower)),
                         MatrixType&,
                         typename MatrixType::ConstTransposeReturnType>
          tmp1(m_matrix);
      std::conditional_t<(TriMode & (Upper | Lower)) == (UpLo & (Upper | Lower)),
                         MatrixType&,
                         typename MatrixType::AdjointReturnType>
          tmp2(tmp1);
      return std::conditional_t<(TriMode & (Upper | Lower)) == (UpLo & (Upper | Lower)),
                                TriangularView<MatrixType, TriMode>,
                                TriangularView<typename MatrixType::AdjointReturnType, TriMode>>(tmp2);
    }
    typedef SelfAdjointView<const MatrixConjugateReturnType, UpLo> ConjugateReturnType;
    inline const ConjugateReturnType conjugate() const { return ConjugateReturnType(m_matrix.conjugate()); }
    template <bool Cond>
    inline std::conditional_t<Cond, ConjugateReturnType, ConstSelfAdjointView> conjugateIf() const {
      typedef std::conditional_t<Cond, ConjugateReturnType, ConstSelfAdjointView> ReturnType;
      return ReturnType(m_matrix.template conjugateIf<Cond>());
    }
    typedef SelfAdjointView<const typename MatrixType::AdjointReturnType, TransposeMode> AdjointReturnType;
    inline const AdjointReturnType adjoint() const { return AdjointReturnType(m_matrix.adjoint()); }
    typedef SelfAdjointView<typename MatrixType::TransposeReturnType, TransposeMode> TransposeReturnType;
    template <class Dummy = int>
    inline TransposeReturnType transpose(
        std::enable_if_t<Eigen::internal::is_lvalue<MatrixType>::value, Dummy*> = nullptr) {
      typename MatrixType::TransposeReturnType tmp(m_matrix);
      return TransposeReturnType(tmp);
    }
    typedef SelfAdjointView<const typename MatrixType::ConstTransposeReturnType, TransposeMode> ConstTransposeReturnType;
    inline const ConstTransposeReturnType transpose() const { return ConstTransposeReturnType(m_matrix.transpose()); }
    typename MatrixType::ConstDiagonalReturnType diagonal() const {
      return typename MatrixType::ConstDiagonalReturnType(m_matrix);
    }
    const LLT<PlainObject, UpLo> llt() const;
    const LDLT<PlainObject, UpLo> ldlt() const;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Matrix<RealScalar, internal::traits<MatrixType>::ColsAtCompileTime, 1> EigenvaluesReturnType;
    EigenvaluesReturnType eigenvalues() const;
    RealScalar operatorNorm() const;

  protected:
    MatrixTypeNested m_matrix;
  };
  namespace internal {
    template <typename MatrixType, unsigned int Mode>
    struct evaluator_traits<SelfAdjointView<MatrixType, Mode>> {
      typedef typename storage_kind_to_evaluator_kind<typename MatrixType::StorageKind>::Kind Kind;
      typedef SelfAdjointShape Shape;
    };
    template <int UpLo, int SetOpposite, typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version>
    class triangular_dense_assignment_kernel<UpLo,
                                             SelfAdjoint,
                                             SetOpposite,
                                             DstEvaluatorTypeT,
                                             SrcEvaluatorTypeT,
                                             Functor,
                                             Version>
        : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> {
    protected:
      typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
      typedef typename Base::DstXprType DstXprType;
      typedef typename Base::SrcXprType SrcXprType;
      using Base::m_dst;
      using Base::m_functor;
      using Base::m_src;

    public:
      typedef typename Base::DstEvaluatorType DstEvaluatorType;
      typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
      typedef typename Base::Scalar Scalar;
      typedef typename Base::AssignmentTraits AssignmentTraits;
      triangular_dense_assignment_kernel(DstEvaluatorType& dst,
                                         const SrcEvaluatorType& src,
                                         const Functor& func,
                                         DstXprType& dstExpr)
          : Base(dst, src, func, dstExpr) {}
      void assignCoeff(Index row, Index col) {
        ;
        Scalar tmp = m_src.coeff(row, col);
        m_functor.assignCoeff(m_dst.coeffRef(row, col), tmp);
        m_functor.assignCoeff(m_dst.coeffRef(col, row), numext::conj(tmp));
      }
      void assignDiagonalCoeff(Index id) { Base::assignCoeff(id, id); }
      void assignOppositeCoeff(Index, Index) { ; }
    };
  }  // namespace internal
  template <typename Derived>
  template <unsigned int UpLo>
  typename MatrixBase<Derived>::template ConstSelfAdjointViewReturnType<UpLo>::Type
  MatrixBase<Derived>::selfadjointView() const {
    return typename ConstSelfAdjointViewReturnType<UpLo>::Type(derived());
  }
  template <typename Derived>
  template <unsigned int UpLo>
  typename MatrixBase<Derived>::template SelfAdjointViewReturnType<UpLo>::Type MatrixBase<Derived>::selfadjointView() {
    return typename SelfAdjointViewReturnType<UpLo>::Type(derived());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    enum GEBPPacketSizeType { GEBPPacketFull = 0, GEBPPacketHalf, GEBPPacketQuarter };
    template <typename LhsScalar_,
              typename RhsScalar_,
              bool ConjLhs_ = false,
              bool ConjRhs_ = false,
              int Arch = Architecture::Target,
              int PacketSize_ = GEBPPacketFull>
    class gebp_traits;
    inline std::ptrdiff_t manage_caching_sizes_helper(std::ptrdiff_t a, std::ptrdiff_t b) { return a <= 0 ? b : a; }
    const std::ptrdiff_t defaultL1CacheSize = 32 * 1024;
    const std::ptrdiff_t defaultL2CacheSize = 256 * 1024;
    const std::ptrdiff_t defaultL3CacheSize = 2 * 1024 * 1024;
    struct CacheSizes {
      CacheSizes() : m_l1(-1), m_l2(-1), m_l3(-1) {
        int l1CacheSize, l2CacheSize, l3CacheSize;
        queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
        m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
        m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
        m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
      }
      std::ptrdiff_t m_l1;
      std::ptrdiff_t m_l2;
      std::ptrdiff_t m_l3;
    };
    inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3) {
      static CacheSizes m_cacheSizes;
      if (action == SetAction) {
        ;
        m_cacheSizes.m_l1 = *l1;
        m_cacheSizes.m_l2 = *l2;
        m_cacheSizes.m_l3 = *l3;
      } else if (action == GetAction) {
        ;
        *l1 = m_cacheSizes.m_l1;
        *l2 = m_cacheSizes.m_l2;
        *l3 = m_cacheSizes.m_l3;
      } else {
        ;
      }
    }
    template <typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
    void evaluateProductBlockingSizesHeuristic(Index& k, Index& m, Index& n, Index num_threads = 1) {
      typedef gebp_traits<LhsScalar, RhsScalar> Traits;
      std::ptrdiff_t l1, l2, l3;
      manage_caching_sizes(GetAction, &l1, &l2, &l3);
      if (num_threads > 1) {
        typedef typename Traits::ResScalar ResScalar;
        enum {
          kdiv = KcFactor * (Traits::mr * sizeof(LhsScalar) + Traits::nr * sizeof(RhsScalar)),
          ksub = Traits::mr * Traits::nr * sizeof(ResScalar),
          kr = 8,
          mr = Traits::mr,
          nr = Traits::nr
        };
        const Index k_cache = numext::maxi<Index>(kr, (numext::mini<Index>)((l1 - ksub) / kdiv, 320));
        if (k_cache < k) {
          k = k_cache - (k_cache % kr);
          ;
        }
        const Index n_cache = (l2 - l1) / (nr * sizeof(RhsScalar) * k);
        const Index n_per_thread = numext::div_ceil(n, num_threads);
        if (n_cache <= n_per_thread) {
          ;
          n = n_cache - (n_cache % nr);
          ;
        } else {
          n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
        }
        if (l3 > l2) {
          const Index m_cache = (l3 - l2) / (sizeof(LhsScalar) * k * num_threads);
          const Index m_per_thread = numext::div_ceil(m, num_threads);
          if (m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
            m = m_cache - (m_cache % mr);
            ;
          } else {
            m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
          }
        }
      } else {
        if ((numext::maxi)(k, (numext::maxi)(m, n)) < 48)
          return;
        typedef typename Traits::ResScalar ResScalar;
        enum {
          k_peeling = 8,
          k_div = KcFactor * (Traits::mr * sizeof(LhsScalar) + Traits::nr * sizeof(RhsScalar)),
          k_sub = Traits::mr * Traits::nr * sizeof(ResScalar)
        };
        const Index max_kc = numext::maxi<Index>(((l1 - k_sub) / k_div) & (~(k_peeling - 1)), 1);
        const Index old_k = k;
        if (k > max_kc) {
          k = (k % max_kc) == 0 ? max_kc
                                : max_kc - k_peeling * ((max_kc - 1 - (k % max_kc)) / (k_peeling * (k / max_kc + 1)));
          ;
        }
        const Index actual_l2 = 1572864;
        Index max_nc;
        const Index lhs_bytes = m * k * sizeof(LhsScalar);
        const Index remaining_l1 = l1 - k_sub - lhs_bytes;
        if (remaining_l1 >= Index(Traits::nr * sizeof(RhsScalar)) * k) {
          max_nc = remaining_l1 / (k * sizeof(RhsScalar));
        } else {
          max_nc = (3 * actual_l2) / (2 * 2 * max_kc * sizeof(RhsScalar));
        }
        Index nc = numext::mini<Index>(actual_l2 / (2 * k * sizeof(RhsScalar)), max_nc) & (~(Traits::nr - 1));
        if (n > nc) {
          n = (n % nc) == 0 ? nc : (nc - Traits::nr * ((nc - (n % nc)) / (Traits::nr * (n / nc + 1))));
        } else if (old_k == k) {
          Index problem_size = k * n * sizeof(LhsScalar);
          Index actual_lm = actual_l2;
          Index max_mc = m;
          if (problem_size <= 1024) {
            actual_lm = l1;
          } else if (l3 != 0 && problem_size <= 32768) {
            actual_lm = l2;
            max_mc = (numext::mini<Index>)(576, max_mc);
          }
          Index mc = (numext::mini<Index>)(actual_lm / (3 * k * sizeof(LhsScalar)), max_mc);
          if (mc > Traits::mr)
            mc -= mc % Traits::mr;
          else if (mc == 0)
            return;
          m = (m % mc) == 0 ? mc : (mc - Traits::mr * ((mc - (m % mc)) / (Traits::mr * (m / mc + 1))));
        }
      }
    }
    template <typename Index>
    inline bool useSpecificBlockingSizes(Index& k, Index& m, Index& n) {
      Eigen::internal::ignore_unused_variable(k);
      Eigen::internal::ignore_unused_variable(m);
      Eigen::internal::ignore_unused_variable(n);
      return false;
    }
    template <typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
    void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1) {
      if (!useSpecificBlockingSizes(k, m, n)) {
        evaluateProductBlockingSizesHeuristic<LhsScalar, RhsScalar, KcFactor, Index>(k, m, n, num_threads);
      }
    }
    template <typename LhsScalar, typename RhsScalar, typename Index>
    inline void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1) {
      computeProductBlockingSizes<LhsScalar, RhsScalar, 1, Index>(k, m, n, num_threads);
    }
    template <typename RhsPacket, typename RhsPacketx4, int registers_taken>
    struct RhsPanelHelper {
    private:
      static constexpr int remaining_registers = (std::max)(int((2 * sizeof(void*))) - registers_taken, 0);

    public:
      typedef std::conditional_t<remaining_registers >= 4, RhsPacketx4, RhsPacket> type;
    };
    template <typename Packet>
    struct QuadPacket {
      Packet B_0, B1, B2, B3;
      const Packet& get(const FixedInt<0>&) const { return B_0; }
      const Packet& get(const FixedInt<1>&) const { return B1; }
      const Packet& get(const FixedInt<2>&) const { return B2; }
      const Packet& get(const FixedInt<3>&) const { return B3; }
    };
    template <int N, typename T1, typename T2, typename T3>
    struct packet_conditional {
      typedef T3 type;
    };
    template <typename T1, typename T2, typename T3>
    struct packet_conditional<GEBPPacketFull, T1, T2, T3> {
      typedef T1 type;
    };
    template <typename T1, typename T2, typename T3>
    struct packet_conditional<GEBPPacketHalf, T1, T2, T3> {
      typedef T2 type;
    };
    template <typename LhsScalar_, typename RhsScalar_, bool ConjLhs_, bool ConjRhs_, int Arch, int PacketSize_>
    class gebp_traits {
    public:
      typedef LhsScalar_ LhsScalar;
      typedef RhsScalar_ RhsScalar;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<LhsScalar>::type,
                                          typename packet_traits<LhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<LhsScalar>::half>::half>::type
          LhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<RhsScalar>::type,
                                          typename packet_traits<RhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<RhsScalar>::half>::half>::type
          RhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<ResScalar>::type,
                                          typename packet_traits<ResScalar>::half,
                                          typename unpacket_traits<typename packet_traits<ResScalar>::half>::half>::type
          ResPacket_;
      enum {
        ConjLhs = ConjLhs_,
        ConjRhs = ConjRhs_,
        Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable,
        LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
        RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
        ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
        NumberOfRegisters = (2 * sizeof(void*)),
        nr = 4,
        default_mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * LhsPacketSize,
        mr = default_mr,
        LhsProgress = LhsPacketSize,
        RhsProgress = 1
      };
      typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
      typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
      typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
      typedef LhsPacket LhsPacket4Packing;
      typedef QuadPacket<RhsPacket> RhsPacketx4;
      typedef ResPacket AccPacket;
      inline void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
      template <typename RhsPacketType>
      inline void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
        dest = pset1<RhsPacketType>(*b);
      }
      inline void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
        pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
      }
      template <typename RhsPacketType>
      inline void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
        loadRhs(b, dest);
      }
      inline void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
      inline void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const { dest = ploadquad<RhsPacket>(b); }
      template <typename LhsPacketType>
      inline void loadLhs(const LhsScalar* a, LhsPacketType& dest) const {
        dest = pload<LhsPacketType>(a);
      }
      template <typename LhsPacketType>
      inline void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
        dest = ploadu<LhsPacketType>(a);
      }
      template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketType& b,
                       AccPacketType& c,
                       RhsPacketType& tmp,
                       const LaneIdType&) const {
        conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
        tmp = b;
        tmp = cj.pmul(a, tmp);
        c = padd(c, tmp);
      }
      template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketx4& b,
                       AccPacketType& c,
                       RhsPacket& tmp,
                       const LaneIdType& lane) const {
        madd(a, b.get(lane), c, tmp, lane);
      }
      inline void acc(const AccPacket& c, const ResPacket& alpha, ResPacket& r) const { r = pmadd(c, alpha, r); }
      template <typename ResPacketHalf>
      inline void acc(const ResPacketHalf& c, const ResPacketHalf& alpha, ResPacketHalf& r) const {
        r = pmadd(c, alpha, r);
      }
    };
    template <typename RealScalar, bool ConjLhs_, int Arch, int PacketSize_>
    class gebp_traits<std::complex<RealScalar>, RealScalar, ConjLhs_, false, Arch, PacketSize_> {
    public:
      typedef std::complex<RealScalar> LhsScalar;
      typedef RealScalar RhsScalar;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<LhsScalar>::type,
                                          typename packet_traits<LhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<LhsScalar>::half>::half>::type
          LhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<RhsScalar>::type,
                                          typename packet_traits<RhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<RhsScalar>::half>::half>::type
          RhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<ResScalar>::type,
                                          typename packet_traits<ResScalar>::half,
                                          typename unpacket_traits<typename packet_traits<ResScalar>::half>::half>::type
          ResPacket_;
      enum {
        ConjLhs = ConjLhs_,
        ConjRhs = false,
        Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable,
        LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
        RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
        ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
        NumberOfRegisters = (2 * sizeof(void*)),
        nr = 4,
        mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * LhsPacketSize,
        LhsProgress = LhsPacketSize,
        RhsProgress = 1
      };
      typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
      typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
      typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
      typedef LhsPacket LhsPacket4Packing;
      typedef QuadPacket<RhsPacket> RhsPacketx4;
      typedef ResPacket AccPacket;
      inline void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
      template <typename RhsPacketType>
      inline void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
        dest = pset1<RhsPacketType>(*b);
      }
      inline void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
        pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
      }
      template <typename RhsPacketType>
      inline void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
        loadRhs(b, dest);
      }
      inline void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
      inline void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const {
        loadRhsQuad_impl(b, dest, std::conditional_t<RhsPacketSize == 16, true_type, false_type>());
      }
      inline void loadRhsQuad_impl(const RhsScalar* b, RhsPacket& dest, const true_type&) const {
        RhsScalar tmp[4] = {b[0], b[0], b[1], b[1]};
        dest = ploadquad<RhsPacket>(tmp);
      }
      inline void loadRhsQuad_impl(const RhsScalar* b, RhsPacket& dest, const false_type&) const {
        ;
        dest = pset1<RhsPacket>(*b);
      }
      inline void loadLhs(const LhsScalar* a, LhsPacket& dest) const { dest = pload<LhsPacket>(a); }
      template <typename LhsPacketType>
      inline void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
        dest = ploadu<LhsPacketType>(a);
      }
      template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketType& b,
                       AccPacketType& c,
                       RhsPacketType& tmp,
                       const LaneIdType&) const {
        madd_impl(a, b, c, tmp, std::conditional_t<Vectorizable, true_type, false_type>());
      }
      template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType>
      inline void madd_impl(const LhsPacketType& a,
                            const RhsPacketType& b,
                            AccPacketType& c,
                            RhsPacketType& tmp,
                            const true_type&) const {
        tmp = b;
        tmp = pmul(a.v, tmp);
        c.v = padd(c.v, tmp);
      }
      inline void madd_impl(const LhsScalar& a, const RhsScalar& b, ResScalar& c, RhsScalar&, const false_type&) const {
        c += a * b;
      }
      template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketx4& b,
                       AccPacketType& c,
                       RhsPacket& tmp,
                       const LaneIdType& lane) const {
        madd(a, b.get(lane), c, tmp, lane);
      }
      template <typename ResPacketType, typename AccPacketType>
      inline void acc(const AccPacketType& c, const ResPacketType& alpha, ResPacketType& r) const {
        conj_helper<ResPacketType, ResPacketType, ConjLhs, false> cj;
        r = cj.pmadd(c, alpha, r);
      }

    protected:
    };
    template <typename Packet>
    struct DoublePacket {
      Packet first;
      Packet second;
    };
    template <typename Packet>
    DoublePacket<Packet> padd(const DoublePacket<Packet>& a, const DoublePacket<Packet>& b) {
      DoublePacket<Packet> res;
      res.first = padd(a.first, b.first);
      res.second = padd(a.second, b.second);
      return res;
    }
    template <typename Packet>
    const DoublePacket<Packet>& predux_half_dowto4(const DoublePacket<Packet>& a,
                                                   std::enable_if_t<unpacket_traits<Packet>::size <= 8>* = 0) {
      return a;
    }
    template <typename Packet>
    DoublePacket<typename unpacket_traits<Packet>::half> predux_half_dowto4(
        const DoublePacket<Packet>& a, std::enable_if_t<unpacket_traits<Packet>::size == 16>* = 0) {
      DoublePacket<typename unpacket_traits<Packet>::half> res;
      typedef std::complex<typename unpacket_traits<Packet>::type> Cplx;
      typedef typename packet_traits<Cplx>::type CplxPacket;
      res.first = predux_half_dowto4(CplxPacket(a.first)).v;
      res.second = predux_half_dowto4(CplxPacket(a.second)).v;
      return res;
    }
    template <typename Scalar, typename RealPacket>
    void loadQuadToDoublePacket(const Scalar* b,
                                DoublePacket<RealPacket>& dest,
                                std::enable_if_t<unpacket_traits<RealPacket>::size <= 8>* = 0) {
      dest.first = pset1<RealPacket>(numext::real(*b));
      dest.second = pset1<RealPacket>(numext::imag(*b));
    }
    template <typename Scalar, typename RealPacket>
    void loadQuadToDoublePacket(const Scalar* b,
                                DoublePacket<RealPacket>& dest,
                                std::enable_if_t<unpacket_traits<RealPacket>::size == 16>* = 0) {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      RealScalar r[4] = {numext::real(b[0]), numext::real(b[0]), numext::real(b[1]), numext::real(b[1])};
      RealScalar i[4] = {numext::imag(b[0]), numext::imag(b[0]), numext::imag(b[1]), numext::imag(b[1])};
      dest.first = ploadquad<RealPacket>(r);
      dest.second = ploadquad<RealPacket>(i);
    }
    template <typename Packet>
    struct unpacket_traits<DoublePacket<Packet>> {
      typedef DoublePacket<typename unpacket_traits<Packet>::half> half;
    };
    template <typename RealScalar, bool ConjLhs_, bool ConjRhs_, int Arch, int PacketSize_>
    class gebp_traits<std::complex<RealScalar>, std::complex<RealScalar>, ConjLhs_, ConjRhs_, Arch, PacketSize_> {
    public:
      typedef std::complex<RealScalar> Scalar;
      typedef std::complex<RealScalar> LhsScalar;
      typedef std::complex<RealScalar> RhsScalar;
      typedef std::complex<RealScalar> ResScalar;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<LhsScalar>::type,
                                          typename packet_traits<LhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<LhsScalar>::half>::half>::type
          LhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<RhsScalar>::type,
                                          typename packet_traits<RhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<RhsScalar>::half>::half>::type
          RhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<ResScalar>::type,
                                          typename packet_traits<ResScalar>::half,
                                          typename unpacket_traits<typename packet_traits<ResScalar>::half>::half>::type
          ResPacket_;
      typedef
          typename packet_conditional<PacketSize_,
                                      typename packet_traits<RealScalar>::type,
                                      typename packet_traits<RealScalar>::half,
                                      typename unpacket_traits<typename packet_traits<RealScalar>::half>::half>::type
              RealPacket;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<Scalar>::type,
                                          typename packet_traits<Scalar>::half,
                                          typename unpacket_traits<typename packet_traits<Scalar>::half>::half>::type
          ScalarPacket;
      enum {
        ConjLhs = ConjLhs_,
        ConjRhs = ConjRhs_,
        Vectorizable = unpacket_traits<RealPacket>::vectorizable && unpacket_traits<ScalarPacket>::vectorizable,
        ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
        LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
        RhsPacketSize = Vectorizable ? unpacket_traits<RhsScalar>::size : 1,
        RealPacketSize = Vectorizable ? unpacket_traits<RealPacket>::size : 1,
        nr = 4,
        mr = ResPacketSize,
        LhsProgress = ResPacketSize,
        RhsProgress = 1
      };
      typedef DoublePacket<RealPacket> DoublePacketType;
      typedef std::conditional_t<Vectorizable, ScalarPacket, Scalar> LhsPacket4Packing;
      typedef std::conditional_t<Vectorizable, RealPacket, Scalar> LhsPacket;
      typedef std::conditional_t<Vectorizable, DoublePacketType, Scalar> RhsPacket;
      typedef std::conditional_t<Vectorizable, ScalarPacket, Scalar> ResPacket;
      typedef std::conditional_t<Vectorizable, DoublePacketType, Scalar> AccPacket;
      typedef QuadPacket<RhsPacket> RhsPacketx4;
      inline void initAcc(Scalar& p) { p = Scalar(0); }
      inline void initAcc(DoublePacketType& p) {
        p.first = pset1<RealPacket>(RealScalar(0));
        p.second = pset1<RealPacket>(RealScalar(0));
      }
      inline void loadRhs(const RhsScalar* b, ScalarPacket& dest) const { dest = pset1<ScalarPacket>(*b); }
      template <typename RealPacketType>
      inline void loadRhs(const RhsScalar* b, DoublePacket<RealPacketType>& dest) const {
        dest.first = pset1<RealPacketType>(numext::real(*b));
        dest.second = pset1<RealPacketType>(numext::imag(*b));
      }
      inline void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
        loadRhs(b, dest.B_0);
        loadRhs(b + 1, dest.B1);
        loadRhs(b + 2, dest.B2);
        loadRhs(b + 3, dest.B3);
      }
      inline void updateRhs(const RhsScalar* b, ScalarPacket& dest) const { loadRhs(b, dest); }
      template <typename RealPacketType>
      inline void updateRhs(const RhsScalar* b, DoublePacket<RealPacketType>& dest) const {
        loadRhs(b, dest);
      }
      inline void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
      inline void loadRhsQuad(const RhsScalar* b, ResPacket& dest) const { loadRhs(b, dest); }
      inline void loadRhsQuad(const RhsScalar* b, DoublePacketType& dest) const { loadQuadToDoublePacket(b, dest); }
      inline void loadLhs(const LhsScalar* a, LhsPacket& dest) const {
        dest = pload<LhsPacket>((const typename unpacket_traits<LhsPacket>::type*)(a));
      }
      template <typename LhsPacketType>
      inline void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
        dest = ploadu<LhsPacketType>((const typename unpacket_traits<LhsPacketType>::type*)(a));
      }
      template <typename LhsPacketType,
                typename RhsPacketType,
                typename ResPacketType,
                typename TmpType,
                typename LaneIdType>
      inline std::enable_if_t<!is_same<RhsPacketType, RhsPacketx4>::value> madd(const LhsPacketType& a,
                                                                                const RhsPacketType& b,
                                                                                DoublePacket<ResPacketType>& c,
                                                                                TmpType&,
                                                                                const LaneIdType&) const {
        c.first = padd(pmul(a, b.first), c.first);
        c.second = padd(pmul(a, b.second), c.second);
      }
      template <typename LaneIdType>
      inline void madd(const LhsPacket& a, const RhsPacket& b, ResPacket& c, RhsPacket&, const LaneIdType&) const {
        c = cj.pmadd(a, b, c);
      }
      template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketx4& b,
                       AccPacketType& c,
                       RhsPacket& tmp,
                       const LaneIdType& lane) const {
        madd(a, b.get(lane), c, tmp, lane);
      }
      inline void acc(const Scalar& c, const Scalar& alpha, Scalar& r) const { r += alpha * c; }
      template <typename RealPacketType, typename ResPacketType>
      inline void acc(const DoublePacket<RealPacketType>& c, const ResPacketType& alpha, ResPacketType& r) const {
        ResPacketType tmp;
        if ((!ConjLhs) && (!ConjRhs)) {
          tmp = pcplxflip(pconj(ResPacketType(c.second)));
          tmp = padd(ResPacketType(c.first), tmp);
        } else if ((!ConjLhs) && (ConjRhs)) {
          tmp = pconj(pcplxflip(ResPacketType(c.second)));
          tmp = padd(ResPacketType(c.first), tmp);
        } else if ((ConjLhs) && (!ConjRhs)) {
          tmp = pcplxflip(ResPacketType(c.second));
          tmp = padd(pconj(ResPacketType(c.first)), tmp);
        } else if ((ConjLhs) && (ConjRhs)) {
          tmp = pcplxflip(ResPacketType(c.second));
          tmp = psub(pconj(ResPacketType(c.first)), tmp);
        }
        r = pmadd(tmp, alpha, r);
      }

    protected:
      conj_helper<LhsScalar, RhsScalar, ConjLhs, ConjRhs> cj;
    };
    template <typename RealScalar, bool ConjRhs_, int Arch, int PacketSize_>
    class gebp_traits<RealScalar, std::complex<RealScalar>, false, ConjRhs_, Arch, PacketSize_> {
    public:
      typedef std::complex<RealScalar> Scalar;
      typedef RealScalar LhsScalar;
      typedef Scalar RhsScalar;
      typedef Scalar ResScalar;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<LhsScalar>::type,
                                          typename packet_traits<LhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<LhsScalar>::half>::half>::type
          LhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<RhsScalar>::type,
                                          typename packet_traits<RhsScalar>::half,
                                          typename unpacket_traits<typename packet_traits<RhsScalar>::half>::half>::type
          RhsPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<ResScalar>::type,
                                          typename packet_traits<ResScalar>::half,
                                          typename unpacket_traits<typename packet_traits<ResScalar>::half>::half>::type
          ResPacket_;
      typedef
          typename packet_conditional<PacketSize_,
                                      typename packet_traits<RealScalar>::type,
                                      typename packet_traits<RealScalar>::half,
                                      typename unpacket_traits<typename packet_traits<RealScalar>::half>::half>::type
              RealPacket_;
      typedef typename packet_conditional<PacketSize_,
                                          typename packet_traits<Scalar>::type,
                                          typename packet_traits<Scalar>::half,
                                          typename unpacket_traits<typename packet_traits<Scalar>::half>::half>::type
          ScalarPacket_;
      enum {
        ConjLhs = false,
        ConjRhs = ConjRhs_,
        Vectorizable = unpacket_traits<RealPacket_>::vectorizable && unpacket_traits<ScalarPacket_>::vectorizable,
        LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
        RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
        ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
        NumberOfRegisters = (2 * sizeof(void*)),
        nr = 4,
        mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * ResPacketSize,
        LhsProgress = ResPacketSize,
        RhsProgress = 1
      };
      typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
      typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
      typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
      typedef LhsPacket LhsPacket4Packing;
      typedef QuadPacket<RhsPacket> RhsPacketx4;
      typedef ResPacket AccPacket;
      inline void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
      template <typename RhsPacketType>
      inline void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
        dest = pset1<RhsPacketType>(*b);
      }
      inline void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
        pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
      }
      template <typename RhsPacketType>
      inline void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
        loadRhs(b, dest);
      }
      inline void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
      inline void loadLhs(const LhsScalar* a, LhsPacket& dest) const { dest = ploaddup<LhsPacket>(a); }
      inline void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const { dest = ploadquad<RhsPacket>(b); }
      template <typename LhsPacketType>
      inline void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
        dest = ploaddup<LhsPacketType>(a);
      }
      template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketType& b,
                       AccPacketType& c,
                       RhsPacketType& tmp,
                       const LaneIdType&) const {
        madd_impl(a, b, c, tmp, std::conditional_t<Vectorizable, true_type, false_type>());
      }
      template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType>
      inline void madd_impl(const LhsPacketType& a,
                            const RhsPacketType& b,
                            AccPacketType& c,
                            RhsPacketType& tmp,
                            const true_type&) const {
        tmp = b;
        tmp.v = pmul(a, tmp.v);
        c = padd(c, tmp);
      }
      inline void madd_impl(const LhsScalar& a, const RhsScalar& b, ResScalar& c, RhsScalar&, const false_type&) const {
        c += a * b;
      }
      template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
      inline void madd(const LhsPacketType& a,
                       const RhsPacketx4& b,
                       AccPacketType& c,
                       RhsPacket& tmp,
                       const LaneIdType& lane) const {
        madd(a, b.get(lane), c, tmp, lane);
      }
      template <typename ResPacketType, typename AccPacketType>
      inline void acc(const AccPacketType& c, const ResPacketType& alpha, ResPacketType& r) const {
        conj_helper<ResPacketType, ResPacketType, false, ConjRhs> cj;
        r = cj.pmadd(alpha, c, r);
      }

    protected:
    };
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              typename DataMapper,
              int mr,
              int nr,
              bool ConjugateLhs,
              bool ConjugateRhs>
    struct gebp_kernel {
      typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
      typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target, GEBPPacketHalf>
          HalfTraits;
      typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target, GEBPPacketQuarter>
          QuarterTraits;
      typedef typename Traits::ResScalar ResScalar;
      typedef typename Traits::LhsPacket LhsPacket;
      typedef typename Traits::RhsPacket RhsPacket;
      typedef typename Traits::ResPacket ResPacket;
      typedef typename Traits::AccPacket AccPacket;
      typedef typename Traits::RhsPacketx4 RhsPacketx4;
      typedef typename RhsPanelHelper<RhsPacket, RhsPacketx4, 15>::type RhsPanel15;
      typedef typename RhsPanelHelper<RhsPacket, RhsPacketx4, 27>::type RhsPanel27;
      typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
      typedef typename SwappedTraits::ResScalar SResScalar;
      typedef typename SwappedTraits::LhsPacket SLhsPacket;
      typedef typename SwappedTraits::RhsPacket SRhsPacket;
      typedef typename SwappedTraits::ResPacket SResPacket;
      typedef typename SwappedTraits::AccPacket SAccPacket;
      typedef typename HalfTraits::LhsPacket LhsPacketHalf;
      typedef typename HalfTraits::RhsPacket RhsPacketHalf;
      typedef typename HalfTraits::ResPacket ResPacketHalf;
      typedef typename HalfTraits::AccPacket AccPacketHalf;
      typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
      typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
      typedef typename QuarterTraits::ResPacket ResPacketQuarter;
      typedef typename QuarterTraits::AccPacket AccPacketQuarter;
      typedef typename DataMapper::LinearMapper LinearMapper;
      enum {
        Vectorizable = Traits::Vectorizable,
        LhsProgress = Traits::LhsProgress,
        LhsProgressHalf = HalfTraits::LhsProgress,
        LhsProgressQuarter = QuarterTraits::LhsProgress,
        RhsProgress = Traits::RhsProgress,
        RhsProgressHalf = HalfTraits::RhsProgress,
        RhsProgressQuarter = QuarterTraits::RhsProgress,
        ResPacketSize = Traits::ResPacketSize
      };
      __attribute__((noinline)) void operator()(const DataMapper& res,
                                                const LhsScalar* blockA,
                                                const RhsScalar* blockB,
                                                Index rows,
                                                Index depth,
                                                Index cols,
                                                ResScalar alpha,
                                                Index strideA = -1,
                                                Index strideB = -1,
                                                Index offsetA = 0,
                                                Index offsetB = 0);
    };
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              typename DataMapper,
              int mr,
              int nr,
              bool ConjugateLhs,
              bool ConjugateRhs,
              int SwappedLhsProgress =
                  gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target>::LhsProgress>
    struct last_row_process_16_packets {
      typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
      typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
      typedef typename Traits::ResScalar ResScalar;
      typedef typename SwappedTraits::LhsPacket SLhsPacket;
      typedef typename SwappedTraits::RhsPacket SRhsPacket;
      typedef typename SwappedTraits::ResPacket SResPacket;
      typedef typename SwappedTraits::AccPacket SAccPacket;
      inline void operator()(const DataMapper& res,
                             SwappedTraits& straits,
                             const LhsScalar* blA,
                             const RhsScalar* blB,
                             Index depth,
                             const Index endk,
                             Index i,
                             Index j2,
                             ResScalar alpha,
                             SAccPacket& C0) {
        Eigen::internal::ignore_unused_variable(res);
        ;
        Eigen::internal::ignore_unused_variable(straits);
        ;
        Eigen::internal::ignore_unused_variable(blA);
        ;
        Eigen::internal::ignore_unused_variable(blB);
        ;
        Eigen::internal::ignore_unused_variable(depth);
        ;
        Eigen::internal::ignore_unused_variable(endk);
        ;
        Eigen::internal::ignore_unused_variable(i);
        ;
        Eigen::internal::ignore_unused_variable(j2);
        ;
        Eigen::internal::ignore_unused_variable(alpha);
        ;
        Eigen::internal::ignore_unused_variable(C0);
        ;
      }
    };
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              typename DataMapper,
              int mr,
              int nr,
              bool ConjugateLhs,
              bool ConjugateRhs>
    struct last_row_process_16_packets<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs, 16> {
      typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
      typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
      typedef typename Traits::ResScalar ResScalar;
      typedef typename SwappedTraits::LhsPacket SLhsPacket;
      typedef typename SwappedTraits::RhsPacket SRhsPacket;
      typedef typename SwappedTraits::ResPacket SResPacket;
      typedef typename SwappedTraits::AccPacket SAccPacket;
      inline void operator()(const DataMapper& res,
                             SwappedTraits& straits,
                             const LhsScalar* blA,
                             const RhsScalar* blB,
                             Index depth,
                             const Index endk,
                             Index i,
                             Index j2,
                             ResScalar alpha,
                             SAccPacket& C0) {
        typedef typename unpacket_traits<typename unpacket_traits<SResPacket>::half>::half SResPacketQuarter;
        typedef typename unpacket_traits<typename unpacket_traits<SLhsPacket>::half>::half SLhsPacketQuarter;
        typedef typename unpacket_traits<typename unpacket_traits<SRhsPacket>::half>::half SRhsPacketQuarter;
        typedef typename unpacket_traits<typename unpacket_traits<SAccPacket>::half>::half SAccPacketQuarter;
        SResPacketQuarter R = res.template gatherPacket<SResPacketQuarter>(i, j2);
        SResPacketQuarter alphav = pset1<SResPacketQuarter>(alpha);
        if (depth - endk > 0) {
          SAccPacketQuarter c0 = predux_half_dowto4(predux_half_dowto4(C0));
          for (Index kk = endk; kk < depth; kk++) {
            SLhsPacketQuarter a0;
            SRhsPacketQuarter b0;
            straits.loadLhsUnaligned(blB, a0);
            straits.loadRhs(blA, b0);
            straits.madd(a0, b0, c0, b0, fix<0>);
            blB += SwappedTraits::LhsProgress / 4;
            blA += 1;
          }
          straits.acc(c0, alphav, R);
        } else {
          straits.acc(predux_half_dowto4(predux_half_dowto4(C0)), alphav, R);
        }
        res.scatterPacket(i, j2, R);
      }
    };
    template <int nr,
              Index LhsProgress,
              Index RhsProgress,
              typename LhsScalar,
              typename RhsScalar,
              typename ResScalar,
              typename AccPacket,
              typename LhsPacket,
              typename RhsPacket,
              typename ResPacket,
              typename GEBPTraits,
              typename LinearMapper,
              typename DataMapper>
    struct lhs_process_one_packet {
      typedef typename GEBPTraits::RhsPacketx4 RhsPacketx4;
      inline void peeled_kc_onestep(Index K,
                                    const LhsScalar* blA,
                                    const RhsScalar* blB,
                                    GEBPTraits traits,
                                    LhsPacket* A0,
                                    RhsPacketx4* rhs_panel,
                                    RhsPacket* T0,
                                    AccPacket* C0,
                                    AccPacket* C1,
                                    AccPacket* C2,
                                    AccPacket* C3) {
        __asm__(
            "#"
            "begin step of gebp micro kernel 1X4");
        __asm__(
            "#"
            "Note: these asm comments work around bug 935!");
        traits.loadLhs(&blA[(0 + 1 * K) * LhsProgress], *A0);
        traits.loadRhs(&blB[(0 + 4 * K) * RhsProgress], *rhs_panel);
        traits.madd(*A0, *rhs_panel, *C0, *T0, fix<0>);
        traits.madd(*A0, *rhs_panel, *C1, *T0, fix<1>);
        traits.madd(*A0, *rhs_panel, *C2, *T0, fix<2>);
        traits.madd(*A0, *rhs_panel, *C3, *T0, fix<3>);
        __asm__(
            "#"
            "end step of gebp micro kernel 1X4");
      }
      inline void operator()(const DataMapper& res,
                             const LhsScalar* blockA,
                             const RhsScalar* blockB,
                             ResScalar alpha,
                             Index peelStart,
                             Index peelEnd,
                             Index strideA,
                             Index strideB,
                             Index offsetA,
                             Index offsetB,
                             int prefetch_res_offset,
                             Index peeled_kc,
                             Index pk,
                             Index cols,
                             Index depth,
                             Index packet_cols4) {
        GEBPTraits traits;
        Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
        for (Index i = peelStart; i < peelEnd; i += LhsProgress) {
          for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
            const LhsScalar* blA = &blockA[i * strideA + offsetA * (LhsProgress)];
            prefetch(&blA[0]);
            AccPacket C0, C1, C2, C3;
            traits.initAcc(C0);
            traits.initAcc(C1);
            traits.initAcc(C2);
            traits.initAcc(C3);
            AccPacket D0, D1, D2, D3;
            traits.initAcc(D0);
            traits.initAcc(D1);
            traits.initAcc(D2);
            traits.initAcc(D3);
            LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
            LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
            LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
            LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
            r0.prefetch(prefetch_res_offset);
            r1.prefetch(prefetch_res_offset);
            r2.prefetch(prefetch_res_offset);
            r3.prefetch(prefetch_res_offset);
            const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
            prefetch(&blB[0]);
            LhsPacket A0, A1;
            for (Index k = 0; k < peeled_kc; k += pk) {
              __asm__(
                  "#"
                  "begin gebp micro kernel 1/half/quarterX4");
              RhsPacketx4 rhs_panel;
              RhsPacket T0;
              internal::prefetch(blB + (48 + 0));
              peeled_kc_onestep(0, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
              peeled_kc_onestep(1, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
              peeled_kc_onestep(2, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
              peeled_kc_onestep(3, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
              internal::prefetch(blB + (48 + 16));
              peeled_kc_onestep(4, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
              peeled_kc_onestep(5, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
              peeled_kc_onestep(6, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
              peeled_kc_onestep(7, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
              blB += pk * 4 * RhsProgress;
              blA += pk * LhsProgress;
              __asm__(
                  "#"
                  "end gebp micro kernel 1/half/quarterX4");
            }
            C0 = padd(C0, D0);
            C1 = padd(C1, D1);
            C2 = padd(C2, D2);
            C3 = padd(C3, D3);
            for (Index k = peeled_kc; k < depth; k++) {
              RhsPacketx4 rhs_panel;
              RhsPacket T0;
              peeled_kc_onestep(0, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
              blB += 4 * RhsProgress;
              blA += LhsProgress;
            }
            ResPacket R0, R1;
            ResPacket alphav = pset1<ResPacket>(alpha);
            R0 = r0.template loadPacket<ResPacket>(0);
            R1 = r1.template loadPacket<ResPacket>(0);
            traits.acc(C0, alphav, R0);
            traits.acc(C1, alphav, R1);
            r0.storePacket(0, R0);
            r1.storePacket(0, R1);
            R0 = r2.template loadPacket<ResPacket>(0);
            R1 = r3.template loadPacket<ResPacket>(0);
            traits.acc(C2, alphav, R0);
            traits.acc(C3, alphav, R1);
            r2.storePacket(0, R0);
            r3.storePacket(0, R1);
          }
          for (Index j2 = packet_cols4; j2 < cols; j2++) {
            const LhsScalar* blA = &blockA[i * strideA + offsetA * (LhsProgress)];
            prefetch(&blA[0]);
            AccPacket C0;
            traits.initAcc(C0);
            LinearMapper r0 = res.getLinearMapper(i, j2);
            const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
            LhsPacket A0;
            for (Index k = 0; k < peeled_kc; k += pk) {
              __asm__(
                  "#"
                  "begin gebp micro kernel 1/half/quarterX1");
              RhsPacket B_0;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 0) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 1) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 1) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 2) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 2) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 3) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 3) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 4) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 4) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 5) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 5) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 6) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 6) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 7) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 7) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              blB += pk * RhsProgress;
              blA += pk * LhsProgress;
              __asm__(
                  "#"
                  "end gebp micro kernel 1/half/quarterX1");
            }
            for (Index k = peeled_kc; k < depth; k++) {
              RhsPacket B_0;
              do {
                __asm__(
                    "#"
                    "begin step of gebp micro kernel 1/half/quarterX1");
                __asm__(
                    "#"
                    "Note: these asm comments work around bug 935!");
                traits.loadLhsUnaligned(&blA[(0 + 1 * 0) * LhsProgress], A0);
                traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                traits.madd(A0, B_0, C0, B_0, fix<0>);
                __asm__(
                    "#"
                    "end step of gebp micro kernel 1/half/quarterX1");
              } while (false);
              ;
              blB += RhsProgress;
              blA += LhsProgress;
            }
            ResPacket R0;
            ResPacket alphav = pset1<ResPacket>(alpha);
            R0 = r0.template loadPacket<ResPacket>(0);
            traits.acc(C0, alphav, R0);
            r0.storePacket(0, R0);
          }
        }
      }
    };
    template <int nr,
              Index LhsProgress,
              Index RhsProgress,
              typename LhsScalar,
              typename RhsScalar,
              typename ResScalar,
              typename AccPacket,
              typename LhsPacket,
              typename RhsPacket,
              typename ResPacket,
              typename GEBPTraits,
              typename LinearMapper,
              typename DataMapper>
    struct lhs_process_fraction_of_packet : lhs_process_one_packet<nr,
                                                                   LhsProgress,
                                                                   RhsProgress,
                                                                   LhsScalar,
                                                                   RhsScalar,
                                                                   ResScalar,
                                                                   AccPacket,
                                                                   LhsPacket,
                                                                   RhsPacket,
                                                                   ResPacket,
                                                                   GEBPTraits,
                                                                   LinearMapper,
                                                                   DataMapper> {
      inline void peeled_kc_onestep(Index K,
                                    const LhsScalar* blA,
                                    const RhsScalar* blB,
                                    GEBPTraits traits,
                                    LhsPacket* A0,
                                    RhsPacket* B_0,
                                    RhsPacket* B1,
                                    RhsPacket* B2,
                                    RhsPacket* B3,
                                    AccPacket* C0,
                                    AccPacket* C1,
                                    AccPacket* C2,
                                    AccPacket* C3) {
        __asm__(
            "#"
            "begin step of gebp micro kernel 1X4");
        __asm__(
            "#"
            "Note: these asm comments work around bug 935!");
        traits.loadLhsUnaligned(&blA[(0 + 1 * K) * (LhsProgress)], *A0);
        traits.broadcastRhs(&blB[(0 + 4 * K) * RhsProgress], *B_0, *B1, *B2, *B3);
        traits.madd(*A0, *B_0, *C0, *B_0);
        traits.madd(*A0, *B1, *C1, *B1);
        traits.madd(*A0, *B2, *C2, *B2);
        traits.madd(*A0, *B3, *C3, *B3);
        __asm__(
            "#"
            "end step of gebp micro kernel 1X4");
      }
    };
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              typename DataMapper,
              int mr,
              int nr,
              bool ConjugateLhs,
              bool ConjugateRhs>
    __attribute__((noinline)) void
    gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs>::operator()(
        const DataMapper& res,
        const LhsScalar* blockA,
        const RhsScalar* blockB,
        Index rows,
        Index depth,
        Index cols,
        ResScalar alpha,
        Index strideA,
        Index strideB,
        Index offsetA,
        Index offsetB) {
      Traits traits;
      SwappedTraits straits;
      if (strideA == -1)
        strideA = depth;
      if (strideB == -1)
        strideB = depth;
      conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
      Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
      Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
      const Index peeled_mc3 = mr >= 3 * Traits::LhsProgress ? (rows / (3 * LhsProgress)) * (3 * LhsProgress) : 0;
      const Index peeled_mc2 = mr >= 2 * Traits::LhsProgress
                                   ? peeled_mc3 + ((rows - peeled_mc3) / (2 * LhsProgress)) * (2 * LhsProgress)
                                   : 0;
      const Index peeled_mc1 = mr >= 1 * Traits::LhsProgress
                                   ? peeled_mc2 + ((rows - peeled_mc2) / (1 * LhsProgress)) * (1 * LhsProgress)
                                   : 0;
      const Index peeled_mc_half =
          mr >= LhsProgressHalf ? peeled_mc1 + ((rows - peeled_mc1) / (LhsProgressHalf)) * (LhsProgressHalf) : 0;
      const Index peeled_mc_quarter =
          mr >= LhsProgressQuarter
              ? peeled_mc_half + ((rows - peeled_mc_half) / (LhsProgressQuarter)) * (LhsProgressQuarter)
              : 0;
      enum { pk = 8 };
      const Index peeled_kc = depth & ~(pk - 1);
      const int prefetch_res_offset = 32 / sizeof(ResScalar);
      if (mr >= 3 * Traits::LhsProgress) {
        const Index l1 = defaultL1CacheSize;
        const Index actual_panel_rows =
            (3 * LhsProgress) * std::max<Index>(1,
                                                ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
                                                 (depth * sizeof(LhsScalar) * 3 * LhsProgress)));
        for (Index i1 = 0; i1 < peeled_mc3; i1 += actual_panel_rows) {
          const Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc3);
          for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
            for (Index i = i1; i < actual_panel_end; i += 3 * LhsProgress) {
              const LhsScalar* blA = &blockA[i * strideA + offsetA * (3 * LhsProgress)];
              prefetch(&blA[0]);
              AccPacket C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11;
              traits.initAcc(C0);
              traits.initAcc(C1);
              traits.initAcc(C2);
              traits.initAcc(C3);
              traits.initAcc(C4);
              traits.initAcc(C5);
              traits.initAcc(C6);
              traits.initAcc(C7);
              traits.initAcc(C8);
              traits.initAcc(C9);
              traits.initAcc(C10);
              traits.initAcc(C11);
              LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
              LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
              LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
              LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
              r0.prefetch(0);
              r1.prefetch(0);
              r2.prefetch(0);
              r3.prefetch(0);
              const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
              prefetch(&blB[0]);
              LhsPacket A0, A1;
              for (Index k = 0; k < peeled_kc; k += pk) {
                __asm__(
                    "#"
                    "begin gebp micro kernel 3pX4");
                RhsPanel15 rhs_panel;
                RhsPacket T0;
                LhsPacket A2;
                internal::prefetch(blB);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 0 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 0 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 0) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 0) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 1 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 1 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 1) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 1) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 1) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 1) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 1) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 1) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 1) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 2 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 2 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 2) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 2) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 2) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 2) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 2) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 2) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 2) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 3 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 3 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 3) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 3) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 3) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 3) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 3) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 3) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 3) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 4 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 4 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 4) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 4) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 4) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 4) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 4) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 4) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 4) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 5 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 5 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 5) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 5) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 5) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 5) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 5) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 5) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 5) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 6 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 6 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 6) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 6) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 6) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 6) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 6) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 6) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 6) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 7 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 7 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 7) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 7) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 7) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 7) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 7) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 7) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 7) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                blB += pk * 4 * RhsProgress;
                blA += pk * 3 * Traits::LhsProgress;
                __asm__(
                    "#"
                    "end gebp micro kernel 3pX4");
              }
              for (Index k = peeled_kc; k < depth; k++) {
                RhsPanel15 rhs_panel;
                RhsPacket T0;
                LhsPacket A2;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX4");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  internal::prefetch(blA + (3 * 0 + 16) * LhsProgress);
                  if (0 || 0) {
                    internal::prefetch(blB + (4 * 0 + 16) * RhsProgress);
                  }
                  traits.loadLhs(&blA[(0 + 3 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 0) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 0) * LhsProgress], A2);
                  traits.loadRhs(blB + (0 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A2, rhs_panel, C8, T0, fix<0>);
                  traits.updateRhs(blB + (1 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A2, rhs_panel, C9, T0, fix<1>);
                  traits.updateRhs(blB + (2 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A2, rhs_panel, C10, T0, fix<2>);
                  traits.updateRhs(blB + (3 + 4 * 0) * Traits::RhsProgress, rhs_panel);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  traits.madd(A2, rhs_panel, C11, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX4");
                } while (false);
                blB += 4 * RhsProgress;
                blA += 3 * Traits::LhsProgress;
              }
              ResPacket R0, R1, R2;
              ResPacket alphav = pset1<ResPacket>(alpha);
              R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r0.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
              traits.acc(C0, alphav, R0);
              traits.acc(C4, alphav, R1);
              traits.acc(C8, alphav, R2);
              r0.storePacket(0 * Traits::ResPacketSize, R0);
              r0.storePacket(1 * Traits::ResPacketSize, R1);
              r0.storePacket(2 * Traits::ResPacketSize, R2);
              R0 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r1.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
              traits.acc(C1, alphav, R0);
              traits.acc(C5, alphav, R1);
              traits.acc(C9, alphav, R2);
              r1.storePacket(0 * Traits::ResPacketSize, R0);
              r1.storePacket(1 * Traits::ResPacketSize, R1);
              r1.storePacket(2 * Traits::ResPacketSize, R2);
              R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r2.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
              traits.acc(C2, alphav, R0);
              traits.acc(C6, alphav, R1);
              traits.acc(C10, alphav, R2);
              r2.storePacket(0 * Traits::ResPacketSize, R0);
              r2.storePacket(1 * Traits::ResPacketSize, R1);
              r2.storePacket(2 * Traits::ResPacketSize, R2);
              R0 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r3.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
              traits.acc(C3, alphav, R0);
              traits.acc(C7, alphav, R1);
              traits.acc(C11, alphav, R2);
              r3.storePacket(0 * Traits::ResPacketSize, R0);
              r3.storePacket(1 * Traits::ResPacketSize, R1);
              r3.storePacket(2 * Traits::ResPacketSize, R2);
            }
          }
          for (Index j2 = packet_cols4; j2 < cols; j2++) {
            for (Index i = i1; i < actual_panel_end; i += 3 * LhsProgress) {
              const LhsScalar* blA = &blockA[i * strideA + offsetA * (3 * Traits::LhsProgress)];
              prefetch(&blA[0]);
              AccPacket C0, C4, C8;
              traits.initAcc(C0);
              traits.initAcc(C4);
              traits.initAcc(C8);
              LinearMapper r0 = res.getLinearMapper(i, j2);
              r0.prefetch(0);
              const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
              LhsPacket A0, A1, A2;
              for (Index k = 0; k < peeled_kc; k += pk) {
                __asm__(
                    "#"
                    "begin gebp micro kernel 3pX1");
                RhsPacket B_0;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 0) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 0) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 1) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 1) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 1) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 1) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 2) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 2) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 2) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 2) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 3) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 3) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 3) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 3) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 4) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 4) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 4) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 4) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 5) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 5) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 5) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 5) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 6) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 6) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 6) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 6) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 7) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 7) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 7) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 7) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                blB += int(pk) * int(RhsProgress);
                blA += int(pk) * 3 * int(Traits::LhsProgress);
                __asm__(
                    "#"
                    "end gebp micro kernel 3pX1");
              }
              for (Index k = peeled_kc; k < depth; k++) {
                RhsPacket B_0;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 3pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 3 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 3 * 0) * LhsProgress], A1);
                  traits.loadLhs(&blA[(2 + 3 * 0) * LhsProgress], A2);
                  traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B_0, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  traits.madd(A2, B_0, C8, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 3pX1");
                } while (false);
                blB += RhsProgress;
                blA += 3 * Traits::LhsProgress;
              }
              ResPacket R0, R1, R2;
              ResPacket alphav = pset1<ResPacket>(alpha);
              R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r0.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
              traits.acc(C0, alphav, R0);
              traits.acc(C4, alphav, R1);
              traits.acc(C8, alphav, R2);
              r0.storePacket(0 * Traits::ResPacketSize, R0);
              r0.storePacket(1 * Traits::ResPacketSize, R1);
              r0.storePacket(2 * Traits::ResPacketSize, R2);
            }
          }
        }
      }
      if (mr >= 2 * Traits::LhsProgress) {
        const Index l1 = defaultL1CacheSize;
        Index actual_panel_rows =
            (2 * LhsProgress) * std::max<Index>(1,
                                                ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
                                                 (depth * sizeof(LhsScalar) * 2 * LhsProgress)));
        for (Index i1 = peeled_mc3; i1 < peeled_mc2; i1 += actual_panel_rows) {
          Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc2);
          for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
            for (Index i = i1; i < actual_panel_end; i += 2 * LhsProgress) {
              const LhsScalar* blA = &blockA[i * strideA + offsetA * (2 * Traits::LhsProgress)];
              prefetch(&blA[0]);
              AccPacket C0, C1, C2, C3, C4, C5, C6, C7;
              traits.initAcc(C0);
              traits.initAcc(C1);
              traits.initAcc(C2);
              traits.initAcc(C3);
              traits.initAcc(C4);
              traits.initAcc(C5);
              traits.initAcc(C6);
              traits.initAcc(C7);
              LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
              LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
              LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
              LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
              r0.prefetch(prefetch_res_offset);
              r1.prefetch(prefetch_res_offset);
              r2.prefetch(prefetch_res_offset);
              r3.prefetch(prefetch_res_offset);
              const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
              prefetch(&blB[0]);
              LhsPacket A0, A1;
              for (Index k = 0; k < peeled_kc; k += pk) {
                __asm__(
                    "#"
                    "begin gebp micro kernel 2pX4");
                RhsPacketx4 rhs_panel;
                RhsPacket T0;
                internal::prefetch(blB + (48 + 0));
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 0) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 0) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 1) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 1) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 1) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 2) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 2) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 2) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 3) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 3) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 3) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                internal::prefetch(blB + (48 + 16));
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 4) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 4) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 4) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 5) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 5) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 5) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 6) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 6) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 6) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 7) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 7) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 7) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                blB += pk * 4 * RhsProgress;
                blA += pk * (2 * Traits::LhsProgress);
                __asm__(
                    "#"
                    "end gebp micro kernel 2pX4");
              }
              for (Index k = peeled_kc; k < depth; k++) {
                RhsPacketx4 rhs_panel;
                RhsPacket T0;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX4");
                  traits.loadLhs(&blA[(0 + 2 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 0) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4 * 0) * RhsProgress], rhs_panel);
                  traits.madd(A0, rhs_panel, C0, T0, fix<0>);
                  traits.madd(A1, rhs_panel, C4, T0, fix<0>);
                  traits.madd(A0, rhs_panel, C1, T0, fix<1>);
                  traits.madd(A1, rhs_panel, C5, T0, fix<1>);
                  traits.madd(A0, rhs_panel, C2, T0, fix<2>);
                  traits.madd(A1, rhs_panel, C6, T0, fix<2>);
                  traits.madd(A0, rhs_panel, C3, T0, fix<3>);
                  traits.madd(A1, rhs_panel, C7, T0, fix<3>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX4");
                } while (false);
                blB += 4 * RhsProgress;
                blA += 2 * Traits::LhsProgress;
              }
              ResPacket R0, R1, R2, R3;
              ResPacket alphav = pset1<ResPacket>(alpha);
              R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R3 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              traits.acc(C0, alphav, R0);
              traits.acc(C4, alphav, R1);
              traits.acc(C1, alphav, R2);
              traits.acc(C5, alphav, R3);
              r0.storePacket(0 * Traits::ResPacketSize, R0);
              r0.storePacket(1 * Traits::ResPacketSize, R1);
              r1.storePacket(0 * Traits::ResPacketSize, R2);
              r1.storePacket(1 * Traits::ResPacketSize, R3);
              R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              R2 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R3 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              traits.acc(C2, alphav, R0);
              traits.acc(C6, alphav, R1);
              traits.acc(C3, alphav, R2);
              traits.acc(C7, alphav, R3);
              r2.storePacket(0 * Traits::ResPacketSize, R0);
              r2.storePacket(1 * Traits::ResPacketSize, R1);
              r3.storePacket(0 * Traits::ResPacketSize, R2);
              r3.storePacket(1 * Traits::ResPacketSize, R3);
            }
          }
          for (Index j2 = packet_cols4; j2 < cols; j2++) {
            for (Index i = i1; i < actual_panel_end; i += 2 * LhsProgress) {
              const LhsScalar* blA = &blockA[i * strideA + offsetA * (2 * Traits::LhsProgress)];
              prefetch(&blA[0]);
              AccPacket C0, C4;
              traits.initAcc(C0);
              traits.initAcc(C4);
              LinearMapper r0 = res.getLinearMapper(i, j2);
              r0.prefetch(prefetch_res_offset);
              const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
              LhsPacket A0, A1;
              for (Index k = 0; k < peeled_kc; k += pk) {
                __asm__(
                    "#"
                    "begin gebp micro kernel 2pX1");
                RhsPacket B_0, B1;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 0) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 1) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 1) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 1) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 2) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 2) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 2) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 3) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 3) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 3) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 4) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 4) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 4) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 5) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 5) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 5) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 6) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 6) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 6) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 7) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 7) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 7) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                blB += int(pk) * int(RhsProgress);
                blA += int(pk) * 2 * int(Traits::LhsProgress);
                __asm__(
                    "#"
                    "end gebp micro kernel 2pX1");
              }
              for (Index k = peeled_kc; k < depth; k++) {
                RhsPacket B_0, B1;
                do {
                  __asm__(
                      "#"
                      "begin step of gebp micro kernel 2pX1");
                  __asm__(
                      "#"
                      "Note: these asm comments work around bug 935!");
                  traits.loadLhs(&blA[(0 + 2 * 0) * LhsProgress], A0);
                  traits.loadLhs(&blA[(1 + 2 * 0) * LhsProgress], A1);
                  traits.loadRhs(&blB[(0 + 0) * RhsProgress], B_0);
                  traits.madd(A0, B_0, C0, B1, fix<0>);
                  traits.madd(A1, B_0, C4, B_0, fix<0>);
                  __asm__(
                      "#"
                      "end step of gebp micro kernel 2pX1");
                } while (false);
                blB += RhsProgress;
                blA += 2 * Traits::LhsProgress;
              }
              ResPacket R0, R1;
              ResPacket alphav = pset1<ResPacket>(alpha);
              R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
              R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
              traits.acc(C0, alphav, R0);
              traits.acc(C4, alphav, R1);
              r0.storePacket(0 * Traits::ResPacketSize, R0);
              r0.storePacket(1 * Traits::ResPacketSize, R1);
            }
          }
        }
      }
      if (mr >= 1 * Traits::LhsProgress) {
        lhs_process_one_packet<nr,
                               LhsProgress,
                               RhsProgress,
                               LhsScalar,
                               RhsScalar,
                               ResScalar,
                               AccPacket,
                               LhsPacket,
                               RhsPacket,
                               ResPacket,
                               Traits,
                               LinearMapper,
                               DataMapper>
            p;
        p(res,
          blockA,
          blockB,
          alpha,
          peeled_mc2,
          peeled_mc1,
          strideA,
          strideB,
          offsetA,
          offsetB,
          prefetch_res_offset,
          peeled_kc,
          pk,
          cols,
          depth,
          packet_cols4);
      }
      if ((LhsProgressHalf < LhsProgress) && mr >= LhsProgressHalf) {
        lhs_process_fraction_of_packet<nr,
                                       LhsProgressHalf,
                                       RhsProgressHalf,
                                       LhsScalar,
                                       RhsScalar,
                                       ResScalar,
                                       AccPacketHalf,
                                       LhsPacketHalf,
                                       RhsPacketHalf,
                                       ResPacketHalf,
                                       HalfTraits,
                                       LinearMapper,
                                       DataMapper>
            p;
        p(res,
          blockA,
          blockB,
          alpha,
          peeled_mc1,
          peeled_mc_half,
          strideA,
          strideB,
          offsetA,
          offsetB,
          prefetch_res_offset,
          peeled_kc,
          pk,
          cols,
          depth,
          packet_cols4);
      }
      if ((LhsProgressQuarter < LhsProgressHalf) && mr >= LhsProgressQuarter) {
        lhs_process_fraction_of_packet<nr,
                                       LhsProgressQuarter,
                                       RhsProgressQuarter,
                                       LhsScalar,
                                       RhsScalar,
                                       ResScalar,
                                       AccPacketQuarter,
                                       LhsPacketQuarter,
                                       RhsPacketQuarter,
                                       ResPacketQuarter,
                                       QuarterTraits,
                                       LinearMapper,
                                       DataMapper>
            p;
        p(res,
          blockA,
          blockB,
          alpha,
          peeled_mc_half,
          peeled_mc_quarter,
          strideA,
          strideB,
          offsetA,
          offsetB,
          prefetch_res_offset,
          peeled_kc,
          pk,
          cols,
          depth,
          packet_cols4);
      }
      if (peeled_mc_quarter < rows) {
        for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
          for (Index i = peeled_mc_quarter; i < rows; i += 1) {
            const LhsScalar* blA = &blockA[i * strideA + offsetA];
            prefetch(&blA[0]);
            const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
            const int SResPacketHalfSize = unpacket_traits<typename unpacket_traits<SResPacket>::half>::size;
            const int SResPacketQuarterSize =
                unpacket_traits<typename unpacket_traits<typename unpacket_traits<SResPacket>::half>::half>::size;
            if ((SwappedTraits::LhsProgress % 4) == 0 && (SwappedTraits::LhsProgress <= 16) &&
                (SwappedTraits::LhsProgress != 8 || SResPacketHalfSize == nr) &&
                (SwappedTraits::LhsProgress != 16 || SResPacketQuarterSize == nr)) {
              SAccPacket C0, C1, C2, C3;
              straits.initAcc(C0);
              straits.initAcc(C1);
              straits.initAcc(C2);
              straits.initAcc(C3);
              const Index spk = (std::max)(1, SwappedTraits::LhsProgress / 4);
              const Index endk = (depth / spk) * spk;
              const Index endk4 = (depth / (spk * 4)) * (spk * 4);
              Index k = 0;
              for (; k < endk4; k += 4 * spk) {
                SLhsPacket A0, A1;
                SRhsPacket B_0, B_1;
                straits.loadLhsUnaligned(blB + 0 * SwappedTraits::LhsProgress, A0);
                straits.loadLhsUnaligned(blB + 1 * SwappedTraits::LhsProgress, A1);
                straits.loadRhsQuad(blA + 0 * spk, B_0);
                straits.loadRhsQuad(blA + 1 * spk, B_1);
                straits.madd(A0, B_0, C0, B_0, fix<0>);
                straits.madd(A1, B_1, C1, B_1, fix<0>);
                straits.loadLhsUnaligned(blB + 2 * SwappedTraits::LhsProgress, A0);
                straits.loadLhsUnaligned(blB + 3 * SwappedTraits::LhsProgress, A1);
                straits.loadRhsQuad(blA + 2 * spk, B_0);
                straits.loadRhsQuad(blA + 3 * spk, B_1);
                straits.madd(A0, B_0, C2, B_0, fix<0>);
                straits.madd(A1, B_1, C3, B_1, fix<0>);
                blB += 4 * SwappedTraits::LhsProgress;
                blA += 4 * spk;
              }
              C0 = padd(padd(C0, C1), padd(C2, C3));
              for (; k < endk; k += spk) {
                SLhsPacket A0;
                SRhsPacket B_0;
                straits.loadLhsUnaligned(blB, A0);
                straits.loadRhsQuad(blA, B_0);
                straits.madd(A0, B_0, C0, B_0, fix<0>);
                blB += SwappedTraits::LhsProgress;
                blA += spk;
              }
              if (SwappedTraits::LhsProgress == 8) {
                typedef std::conditional_t<SwappedTraits::LhsProgress >= 8,
                                           typename unpacket_traits<SResPacket>::half,
                                           SResPacket>
                    SResPacketHalf;
                typedef std::conditional_t<SwappedTraits::LhsProgress >= 8,
                                           typename unpacket_traits<SLhsPacket>::half,
                                           SLhsPacket>
                    SLhsPacketHalf;
                typedef std::conditional_t<SwappedTraits::LhsProgress >= 8,
                                           typename unpacket_traits<SRhsPacket>::half,
                                           SRhsPacket>
                    SRhsPacketHalf;
                typedef std::conditional_t<SwappedTraits::LhsProgress >= 8,
                                           typename unpacket_traits<SAccPacket>::half,
                                           SAccPacket>
                    SAccPacketHalf;
                SResPacketHalf R = res.template gatherPacket<SResPacketHalf>(i, j2);
                SResPacketHalf alphav = pset1<SResPacketHalf>(alpha);
                if (depth - endk > 0) {
                  SLhsPacketHalf a0;
                  SRhsPacketHalf b0;
                  straits.loadLhsUnaligned(blB, a0);
                  straits.loadRhs(blA, b0);
                  SAccPacketHalf c0 = predux_half_dowto4(C0);
                  straits.madd(a0, b0, c0, b0, fix<0>);
                  straits.acc(c0, alphav, R);
                } else {
                  straits.acc(predux_half_dowto4(C0), alphav, R);
                }
                res.scatterPacket(i, j2, R);
              } else if (SwappedTraits::LhsProgress == 16) {
                last_row_process_16_packets<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs>
                    p;
                p(res, straits, blA, blB, depth, endk, i, j2, alpha, C0);
              } else {
                SResPacket R = res.template gatherPacket<SResPacket>(i, j2);
                SResPacket alphav = pset1<SResPacket>(alpha);
                straits.acc(C0, alphav, R);
                res.scatterPacket(i, j2, R);
              }
            } else {
              ResScalar C0(0), C1(0), C2(0), C3(0);
              for (Index k = 0; k < depth; k++) {
                LhsScalar A0;
                RhsScalar B_0, B_1;
                A0 = blA[k];
                B_0 = blB[0];
                B_1 = blB[1];
                C0 = cj.pmadd(A0, B_0, C0);
                C1 = cj.pmadd(A0, B_1, C1);
                B_0 = blB[2];
                B_1 = blB[3];
                C2 = cj.pmadd(A0, B_0, C2);
                C3 = cj.pmadd(A0, B_1, C3);
                blB += 4;
              }
              res(i, j2 + 0) += alpha * C0;
              res(i, j2 + 1) += alpha * C1;
              res(i, j2 + 2) += alpha * C2;
              res(i, j2 + 3) += alpha * C3;
            }
          }
        }
        for (Index j2 = packet_cols4; j2 < cols; j2++) {
          for (Index i = peeled_mc_quarter; i < rows; i += 1) {
            const LhsScalar* blA = &blockA[i * strideA + offsetA];
            prefetch(&blA[0]);
            ResScalar C0(0);
            const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
            for (Index k = 0; k < depth; k++) {
              LhsScalar A0 = blA[k];
              RhsScalar B_0 = blB[k];
              C0 = cj.pmadd(A0, B_0, C0);
            }
            res(i, j2) += alpha * C0;
          }
        }
      }
    }
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int Pack1,
              int Pack2,
              typename Packet,
              bool Conjugate,
              bool PanelMode>
    struct gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, ColMajor, Conjugate, PanelMode> {
      typedef typename DataMapper::LinearMapper LinearMapper;
      __attribute__((noinline)) void operator()(
          Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride = 0, Index offset = 0);
    };
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int Pack1,
              int Pack2,
              typename Packet,
              bool Conjugate,
              bool PanelMode>
    __attribute__((noinline)) void
    gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, ColMajor, Conjugate, PanelMode>::operator()(
        Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride, Index offset) {
      typedef typename unpacket_traits<Packet>::half HalfPacket;
      typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
      enum {
        PacketSize = unpacket_traits<Packet>::size,
        HalfPacketSize = unpacket_traits<HalfPacket>::size,
        QuarterPacketSize = unpacket_traits<QuarterPacket>::size,
        HasHalf = (int)HalfPacketSize < (int)PacketSize,
        HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize
      };
      __asm__(
          "#"
          "EIGEN PRODUCT PACK LHS");
      Eigen::internal::ignore_unused_variable(stride);
      ;
      Eigen::internal::ignore_unused_variable(offset);
      ;
      (static_cast<bool>(((!PanelMode) && stride == 0 && offset == 0) ||
                         (PanelMode && stride >= depth && offset <= stride))
           ? void(0)
           : __assert_fail("((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/products/GeneralBlockPanelKernel.h",
                           2776,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(((Pack1 % PacketSize) == 0 && Pack1 <= 4 * PacketSize) || (Pack1 <= 4))
           ? void(0)
           : __assert_fail("((Pack1%PacketSize)==0 && Pack1<=4*PacketSize) || (Pack1<=4)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/products/GeneralBlockPanelKernel.h",
                           2777,
                           __extension__ __PRETTY_FUNCTION__));
      conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
      Index count = 0;
      const Index peeled_mc3 = Pack1 >= 3 * PacketSize ? (rows / (3 * PacketSize)) * (3 * PacketSize) : 0;
      const Index peeled_mc2 =
          Pack1 >= 2 * PacketSize ? peeled_mc3 + ((rows - peeled_mc3) / (2 * PacketSize)) * (2 * PacketSize) : 0;
      const Index peeled_mc1 =
          Pack1 >= 1 * PacketSize ? peeled_mc2 + ((rows - peeled_mc2) / (1 * PacketSize)) * (1 * PacketSize) : 0;
      const Index peeled_mc_half =
          Pack1 >= HalfPacketSize ? peeled_mc1 + ((rows - peeled_mc1) / (HalfPacketSize)) * (HalfPacketSize) : 0;
      const Index peeled_mc_quarter =
          Pack1 >= QuarterPacketSize ? (rows / (QuarterPacketSize)) * (QuarterPacketSize) : 0;
      const Index last_lhs_progress = rows > peeled_mc_quarter ? (rows - peeled_mc_quarter) & ~1 : 0;
      const Index peeled_mc0 = Pack2 >= PacketSize              ? peeled_mc_quarter
                               : Pack2 > 1 && last_lhs_progress ? (rows / last_lhs_progress) * last_lhs_progress
                                                                : 0;
      Index i = 0;
      if (Pack1 >= 3 * PacketSize) {
        for (; i < peeled_mc3; i += 3 * PacketSize) {
          if (PanelMode)
            count += (3 * PacketSize) * offset;
          for (Index k = 0; k < depth; k++) {
            Packet A, B, C;
            A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
            B = lhs.template loadPacket<Packet>(i + 1 * PacketSize, k);
            C = lhs.template loadPacket<Packet>(i + 2 * PacketSize, k);
            pstore(blockA + count, cj.pconj(A));
            count += PacketSize;
            pstore(blockA + count, cj.pconj(B));
            count += PacketSize;
            pstore(blockA + count, cj.pconj(C));
            count += PacketSize;
          }
          if (PanelMode)
            count += (3 * PacketSize) * (stride - offset - depth);
        }
      }
      if (Pack1 >= 2 * PacketSize) {
        for (; i < peeled_mc2; i += 2 * PacketSize) {
          if (PanelMode)
            count += (2 * PacketSize) * offset;
          for (Index k = 0; k < depth; k++) {
            Packet A, B;
            A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
            B = lhs.template loadPacket<Packet>(i + 1 * PacketSize, k);
            pstore(blockA + count, cj.pconj(A));
            count += PacketSize;
            pstore(blockA + count, cj.pconj(B));
            count += PacketSize;
          }
          if (PanelMode)
            count += (2 * PacketSize) * (stride - offset - depth);
        }
      }
      if (Pack1 >= 1 * PacketSize) {
        for (; i < peeled_mc1; i += 1 * PacketSize) {
          if (PanelMode)
            count += (1 * PacketSize) * offset;
          for (Index k = 0; k < depth; k++) {
            Packet A;
            A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
            pstore(blockA + count, cj.pconj(A));
            count += PacketSize;
          }
          if (PanelMode)
            count += (1 * PacketSize) * (stride - offset - depth);
        }
      }
      if (HasHalf && Pack1 >= HalfPacketSize) {
        for (; i < peeled_mc_half; i += HalfPacketSize) {
          if (PanelMode)
            count += (HalfPacketSize)*offset;
          for (Index k = 0; k < depth; k++) {
            HalfPacket A;
            A = lhs.template loadPacket<HalfPacket>(i + 0 * (HalfPacketSize), k);
            pstoreu(blockA + count, cj.pconj(A));
            count += HalfPacketSize;
          }
          if (PanelMode)
            count += (HalfPacketSize) * (stride - offset - depth);
        }
      }
      if (HasQuarter && Pack1 >= QuarterPacketSize) {
        for (; i < peeled_mc_quarter; i += QuarterPacketSize) {
          if (PanelMode)
            count += (QuarterPacketSize)*offset;
          for (Index k = 0; k < depth; k++) {
            QuarterPacket A;
            A = lhs.template loadPacket<QuarterPacket>(i + 0 * (QuarterPacketSize), k);
            pstoreu(blockA + count, cj.pconj(A));
            count += QuarterPacketSize;
          }
          if (PanelMode)
            count += (QuarterPacketSize) * (stride - offset - depth);
        }
      }
      if (Pack2 < PacketSize && Pack2 > 1) {
        for (; i < peeled_mc0; i += last_lhs_progress) {
          if (PanelMode)
            count += last_lhs_progress * offset;
          for (Index k = 0; k < depth; k++)
            for (Index w = 0; w < last_lhs_progress; w++)
              blockA[count++] = cj(lhs(i + w, k));
          if (PanelMode)
            count += last_lhs_progress * (stride - offset - depth);
        }
      }
      for (; i < rows; i++) {
        if (PanelMode)
          count += offset;
        for (Index k = 0; k < depth; k++)
          blockA[count++] = cj(lhs(i, k));
        if (PanelMode)
          count += (stride - offset - depth);
      }
    }
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int Pack1,
              int Pack2,
              typename Packet,
              bool Conjugate,
              bool PanelMode>
    struct gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, RowMajor, Conjugate, PanelMode> {
      typedef typename DataMapper::LinearMapper LinearMapper;
      __attribute__((noinline)) void operator()(
          Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride = 0, Index offset = 0);
    };
    template <typename Scalar,
              typename Index,
              typename DataMapper,
              int Pack1,
              int Pack2,
              typename Packet,
              bool Conjugate,
              bool PanelMode>
    __attribute__((noinline)) void
    gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, RowMajor, Conjugate, PanelMode>::operator()(
        Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride, Index offset) {
      typedef typename unpacket_traits<Packet>::half HalfPacket;
      typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
      enum {
        PacketSize = unpacket_traits<Packet>::size,
        HalfPacketSize = unpacket_traits<HalfPacket>::size,
        QuarterPacketSize = unpacket_traits<QuarterPacket>::size,
        HasHalf = (int)HalfPacketSize < (int)PacketSize,
        HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize
      };
      __asm__(
          "#"
          "EIGEN PRODUCT PACK LHS");
      Eigen::internal::ignore_unused_variable(stride);
      ;
      Eigen::internal::ignore_unused_variable(offset);
      ;
      (static_cast<bool>(((!PanelMode) && stride == 0 && offset == 0) ||
                         (PanelMode && stride >= depth && offset <= stride))
           ? void(0)
           : __assert_fail("((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/products/GeneralBlockPanelKernel.h",
                           2932,
                           __extension__ __PRETTY_FUNCTION__));
      conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
      Index count = 0;
      bool gone_half = false, gone_quarter = false, gone_last = false;
      Index i = 0;
      Index pack = Pack1;
      Index psize = PacketSize;
      while (pack > 0) {
        Index remaining_rows = rows - i;
        Index peeled_mc = gone_last ? Pack2 > 1 ? (rows / pack) * pack : 0 : i + (remaining_rows / pack) * pack;
        Index starting_pos = i;
        for (; i < peeled_mc; i += pack) {
          if (PanelMode)
            count += pack * offset;
          Index k = 0;
          if (pack >= psize && psize >= QuarterPacketSize) {
            const Index peeled_k = (depth / psize) * psize;
            for (; k < peeled_k; k += psize) {
              for (Index m = 0; m < pack; m += psize) {
                if (psize == PacketSize) {
                  PacketBlock<Packet> kernel;
                  for (Index p = 0; p < psize; ++p)
                    kernel.packet[p] = lhs.template loadPacket<Packet>(i + p + m, k);
                  ptranspose(kernel);
                  for (Index p = 0; p < psize; ++p)
                    pstore(blockA + count + m + (pack)*p, cj.pconj(kernel.packet[p]));
                } else if (HasHalf && psize == HalfPacketSize) {
                  gone_half = true;
                  PacketBlock<HalfPacket> kernel_half;
                  for (Index p = 0; p < psize; ++p)
                    kernel_half.packet[p] = lhs.template loadPacket<HalfPacket>(i + p + m, k);
                  ptranspose(kernel_half);
                  for (Index p = 0; p < psize; ++p)
                    pstore(blockA + count + m + (pack)*p, cj.pconj(kernel_half.packet[p]));
                } else if (HasQuarter && psize == QuarterPacketSize) {
                  gone_quarter = true;
                  PacketBlock<QuarterPacket> kernel_quarter;
                  for (Index p = 0; p < psize; ++p)
                    kernel_quarter.packet[p] = lhs.template loadPacket<QuarterPacket>(i + p + m, k);
                  ptranspose(kernel_quarter);
                  for (Index p = 0; p < psize; ++p)
                    pstore(blockA + count + m + (pack)*p, cj.pconj(kernel_quarter.packet[p]));
                }
              }
              count += psize * pack;
            }
          }
          for (; k < depth; k++) {
            Index w = 0;
            for (; w < pack - 3; w += 4) {
              Scalar a(cj(lhs(i + w + 0, k))), b(cj(lhs(i + w + 1, k))), c(cj(lhs(i + w + 2, k))),
                  d(cj(lhs(i + w + 3, k)));
              blockA[count++] = a;
              blockA[count++] = b;
              blockA[count++] = c;
              blockA[count++] = d;
            }
            if (pack % 4)
              for (; w < pack; ++w)
                blockA[count++] = cj(lhs(i + w, k));
          }
          if (PanelMode)
            count += pack * (stride - offset - depth);
        }
        pack -= psize;
        Index left = rows - i;
        if (pack <= 0) {
          if (!gone_last && (starting_pos == i || left >= psize / 2 || left >= psize / 4) &&
              ((psize / 2 == HalfPacketSize && HasHalf && !gone_half) ||
               (psize / 2 == QuarterPacketSize && HasQuarter && !gone_quarter))) {
            psize /= 2;
            pack = psize;
            continue;
          }
          if (Pack2 < PacketSize && !gone_last) {
            gone_last = true;
            psize = pack = left & ~1;
          }
        }
      }
      for (; i < rows; i++) {
        if (PanelMode)
          count += offset;
        for (Index k = 0; k < depth; k++)
          blockA[count++] = cj(lhs(i, k));
        if (PanelMode)
          count += (stride - offset - depth);
      }
    }
    template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
    struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode> {
      typedef typename packet_traits<Scalar>::type Packet;
      typedef typename DataMapper::LinearMapper LinearMapper;
      enum { PacketSize = packet_traits<Scalar>::size };
      __attribute__((noinline)) void operator()(
          Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride = 0, Index offset = 0);
    };
    template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
    __attribute__((noinline)) void
    gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>::operator()(
        Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride, Index offset) {
      __asm__(
          "#"
          "EIGEN PRODUCT PACK RHS COLMAJOR");
      Eigen::internal::ignore_unused_variable(stride);
      ;
      Eigen::internal::ignore_unused_variable(offset);
      ;
      (static_cast<bool>(((!PanelMode) && stride == 0 && offset == 0) ||
                         (PanelMode && stride >= depth && offset <= stride))
           ? void(0)
           : __assert_fail("((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride)",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/products/GeneralBlockPanelKernel.h",
                           3060,
                           __extension__ __PRETTY_FUNCTION__));
      conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
      Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
      Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
      Index count = 0;
      const Index peeled_k = (depth / PacketSize) * PacketSize;
      if (nr >= 4) {
        for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
          if (PanelMode)
            count += 4 * offset;
          const LinearMapper dm0 = rhs.getLinearMapper(0, j2 + 0);
          const LinearMapper dm1 = rhs.getLinearMapper(0, j2 + 1);
          const LinearMapper dm2 = rhs.getLinearMapper(0, j2 + 2);
          const LinearMapper dm3 = rhs.getLinearMapper(0, j2 + 3);
          Index k = 0;
          if ((PacketSize % 4) == 0) {
            for (; k < peeled_k; k += PacketSize) {
              PacketBlock<Packet, (PacketSize % 4) == 0 ? 4 : PacketSize> kernel;
              kernel.packet[0] = dm0.template loadPacket<Packet>(k);
              kernel.packet[1 % PacketSize] = dm1.template loadPacket<Packet>(k);
              kernel.packet[2 % PacketSize] = dm2.template loadPacket<Packet>(k);
              kernel.packet[3 % PacketSize] = dm3.template loadPacket<Packet>(k);
              ptranspose(kernel);
              pstoreu(blockB + count + 0 * PacketSize, cj.pconj(kernel.packet[0]));
              pstoreu(blockB + count + 1 * PacketSize, cj.pconj(kernel.packet[1 % PacketSize]));
              pstoreu(blockB + count + 2 * PacketSize, cj.pconj(kernel.packet[2 % PacketSize]));
              pstoreu(blockB + count + 3 * PacketSize, cj.pconj(kernel.packet[3 % PacketSize]));
              count += 4 * PacketSize;
            }
          }
          for (; k < depth; k++) {
            blockB[count + 0] = cj(dm0(k));
            blockB[count + 1] = cj(dm1(k));
            blockB[count + 2] = cj(dm2(k));
            blockB[count + 3] = cj(dm3(k));
            count += 4;
          }
          if (PanelMode)
            count += 4 * (stride - offset - depth);
        }
      }
      for (Index j2 = packet_cols4; j2 < cols; ++j2) {
        if (PanelMode)
          count += offset;
        const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
        for (Index k = 0; k < depth; k++) {
          blockB[count] = cj(dm0(k));
          count += 1;
        }
        if (PanelMode)
          count += (stride - offset - depth);
      }
    }
    template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
    struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, RowMajor, Conjugate, PanelMode> {
      typedef typename packet_traits<Scalar>::type Packet;
      typedef typename unpacket_traits<Packet>::half HalfPacket;
      typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
      typedef typename DataMapper::LinearMapper LinearMapper;
      enum {
        PacketSize = packet_traits<Scalar>::size,
        HalfPacketSize = unpacket_traits<HalfPacket>::size,
        QuarterPacketSize = unpacket_traits<QuarterPacket>::size
      };
      __attribute__((noinline)) void operator()(
          Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride = 0, Index offset = 0) {
        __asm__(
            "#"
            "EIGEN PRODUCT PACK RHS ROWMAJOR");
        Eigen::internal::ignore_unused_variable(stride);
        ;
        Eigen::internal::ignore_unused_variable(offset);
        ;
        (static_cast<bool>(((!PanelMode) && stride == 0 && offset == 0) ||
                           (PanelMode && stride >= depth && offset <= stride))
             ? void(0)
             : __assert_fail(
                   "((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride)",
                   "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                   "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                   "Core/products/GeneralBlockPanelKernel.h",
                   3255,
                   __extension__ __PRETTY_FUNCTION__));
        const bool HasHalf = (int)HalfPacketSize < (int)PacketSize;
        const bool HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize;
        conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
        Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
        Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
        Index count = 0;
        if (nr >= 4) {
          for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
            if (PanelMode)
              count += 4 * offset;
            for (Index k = 0; k < depth; k++) {
              if (PacketSize == 4) {
                Packet A = rhs.template loadPacket<Packet>(k, j2);
                pstoreu(blockB + count, cj.pconj(A));
                count += PacketSize;
              } else if (HasHalf && HalfPacketSize == 4) {
                HalfPacket A = rhs.template loadPacket<HalfPacket>(k, j2);
                pstoreu(blockB + count, cj.pconj(A));
                count += HalfPacketSize;
              } else if (HasQuarter && QuarterPacketSize == 4) {
                QuarterPacket A = rhs.template loadPacket<QuarterPacket>(k, j2);
                pstoreu(blockB + count, cj.pconj(A));
                count += QuarterPacketSize;
              } else {
                const LinearMapper dm0 = rhs.getLinearMapper(k, j2);
                blockB[count + 0] = cj(dm0(0));
                blockB[count + 1] = cj(dm0(1));
                blockB[count + 2] = cj(dm0(2));
                blockB[count + 3] = cj(dm0(3));
                count += 4;
              }
            }
            if (PanelMode)
              count += 4 * (stride - offset - depth);
          }
        }
        for (Index j2 = packet_cols4; j2 < cols; ++j2) {
          if (PanelMode)
            count += offset;
          for (Index k = 0; k < depth; k++) {
            blockB[count] = cj(rhs(k, j2));
            count += 1;
          }
          if (PanelMode)
            count += stride - offset - depth;
        }
      }
    };
  }  // namespace internal
  inline std::ptrdiff_t l1CacheSize() {
    std::ptrdiff_t l1, l2, l3;
    internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
    return l1;
  }
  inline std::ptrdiff_t l2CacheSize() {
    std::ptrdiff_t l1, l2, l3;
    internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
    return l2;
  }
  inline std::ptrdiff_t l3CacheSize() {
    std::ptrdiff_t l1, l2, l3;
    internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
    return l3;
  }
  inline void setCpuCacheSizes(std::ptrdiff_t l1, std::ptrdiff_t l2, std::ptrdiff_t l3) {
    internal::manage_caching_sizes(SetAction, &l1, &l2, &l3);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    inline void manage_multi_threading(Action action, int* v) {
      static int m_maxThreads = -1;
      Eigen::internal::ignore_unused_variable(m_maxThreads);
      if (action == SetAction) {
        ;
        m_maxThreads = *v;
      } else if (action == GetAction) {
        ;
        *v = 1;
      } else {
        ;
      }
    }
  }  // namespace internal
  inline void initParallel() {
    int nbt;
    internal::manage_multi_threading(GetAction, &nbt);
    std::ptrdiff_t l1, l2, l3;
    internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
  }
  inline int nbThreads() {
    int ret;
    internal::manage_multi_threading(GetAction, &ret);
    return ret;
  }
  inline void setNbThreads(int v) { internal::manage_multi_threading(SetAction, &v); }
  namespace internal {
    template <typename Index>
    struct GemmParallelInfo {
      GemmParallelInfo() : lhs_start(0), lhs_length(0) {}
      Index lhs_start;
      Index lhs_length;
    };
    template <bool Condition, typename Functor, typename Index>
    void parallelize_gemm(const Functor& func, Index rows, Index cols, Index depth, bool transpose) {
      Eigen::internal::ignore_unused_variable(depth);
      ;
      Eigen::internal::ignore_unused_variable(transpose);
      ;
      func(0, rows, 0, cols);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Lhs, typename Rhs, int Options>
    struct evaluator<Product<Lhs, Rhs, Options>> : public product_evaluator<Product<Lhs, Rhs, Options>> {
      typedef Product<Lhs, Rhs, Options> XprType;
      typedef product_evaluator<XprType> Base;
      inline explicit evaluator(const XprType& xpr) : Base(xpr) {}
    };
    template <typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
    struct evaluator_assume_aliasing<CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
                                                   const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
                                                   const Product<Lhs, Rhs, DefaultProduct>>> {
      static const bool value = true;
    };
    template <typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
    struct evaluator<CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
                                   const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
                                   const Product<Lhs, Rhs, DefaultProduct>>>
        : public evaluator<
              Product<CwiseBinaryOp<internal::scalar_product_op<Scalar1, typename internal::traits<Lhs>::Scalar>,
                                    const typename internal::plain_constant_type<Lhs, Scalar1>::type,
                                    const Lhs>,
                      Rhs,
                      DefaultProduct>> {
      typedef CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
                            const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
                            const Product<Lhs, Rhs, DefaultProduct>>
          XprType;
      typedef evaluator<
          Product<CwiseBinaryOp<internal::scalar_product_op<Scalar1, typename internal::traits<Lhs>::Scalar>,
                                const typename internal::plain_constant_type<Lhs, Scalar1>::type,
                                const Lhs>,
                  Rhs,
                  DefaultProduct>>
          Base;
      inline explicit evaluator(const XprType& xpr)
          : Base(xpr.lhs().functor().m_other * xpr.rhs().lhs() * xpr.rhs().rhs()) {}
    };
    template <typename Lhs, typename Rhs, int DiagIndex>
    struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex>>
        : public evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>> {
      typedef Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> XprType;
      typedef evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>> Base;
      inline explicit evaluator(const XprType& xpr)
          : Base(Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>(
                Product<Lhs, Rhs, LazyProduct>(xpr.nestedExpression().lhs(), xpr.nestedExpression().rhs()),
                xpr.index())) {}
    };
    template <typename Lhs,
              typename Rhs,
              typename LhsShape = typename evaluator_traits<Lhs>::Shape,
              typename RhsShape = typename evaluator_traits<Rhs>::Shape,
              int ProductType = internal::product_type<Lhs, Rhs>::value>
    struct generic_product_impl;
    template <typename Lhs, typename Rhs>
    struct evaluator_assume_aliasing<Product<Lhs, Rhs, DefaultProduct>> {
      static const bool value = true;
    };
    template <typename Lhs, typename Rhs, int Options, int ProductTag, typename LhsShape, typename RhsShape>
    struct product_evaluator<Product<Lhs, Rhs, Options>, ProductTag, LhsShape, RhsShape>
        : public evaluator<typename Product<Lhs, Rhs, Options>::PlainObject> {
      typedef Product<Lhs, Rhs, Options> XprType;
      typedef typename XprType::PlainObject PlainObject;
      typedef evaluator<PlainObject> Base;
      enum { Flags = Base::Flags | EvalBeforeNestingBit };
      inline explicit product_evaluator(const XprType& xpr) : m_result(xpr.rows(), xpr.cols()) {
        internal::construct_at<Base>(this, m_result);
        generic_product_impl<Lhs, Rhs, LhsShape, RhsShape, ProductTag>::evalTo(m_result, xpr.lhs(), xpr.rhs());
      }

    protected:
      PlainObject m_result;
    };
    template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, Options>,
                      internal::assign_op<Scalar, Scalar>,
                      Dense2Dense,
                      std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
      typedef Product<Lhs, Rhs, Options> SrcXprType;
      static inline void run(DstXprType& dst, const SrcXprType& src, const internal::assign_op<Scalar, Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        generic_product_impl<Lhs, Rhs>::evalTo(dst, src.lhs(), src.rhs());
      }
    };
    template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, Options>,
                      internal::add_assign_op<Scalar, Scalar>,
                      Dense2Dense,
                      std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
      typedef Product<Lhs, Rhs, Options> SrcXprType;
      static inline void run(DstXprType& dst, const SrcXprType& src, const internal::add_assign_op<Scalar, Scalar>&) {
        (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
             ? void(0)
             : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/ProductEvaluators.h",
                             163,
                             __extension__ __PRETTY_FUNCTION__));
        generic_product_impl<Lhs, Rhs>::addTo(dst, src.lhs(), src.rhs());
      }
    };
    template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
    struct Assignment<DstXprType,
                      Product<Lhs, Rhs, Options>,
                      internal::sub_assign_op<Scalar, Scalar>,
                      Dense2Dense,
                      std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
      typedef Product<Lhs, Rhs, Options> SrcXprType;
      static inline void run(DstXprType& dst, const SrcXprType& src, const internal::sub_assign_op<Scalar, Scalar>&) {
        (static_cast<bool>(dst.rows() == src.rows() && dst.cols() == src.cols())
             ? void(0)
             : __assert_fail("dst.rows() == src.rows() && dst.cols() == src.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/ProductEvaluators.h",
                             178,
                             __extension__ __PRETTY_FUNCTION__));
        generic_product_impl<Lhs, Rhs>::subTo(dst, src.lhs(), src.rhs());
      }
    };
    template <typename DstXprType,
              typename Lhs,
              typename Rhs,
              typename AssignFunc,
              typename Scalar,
              typename ScalarBis,
              typename Plain>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_product_op<ScalarBis, Scalar>,
                                    const CwiseNullaryOp<internal::scalar_constant_op<ScalarBis>, Plain>,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      AssignFunc,
                      Dense2Dense> {
      typedef CwiseBinaryOp<internal::scalar_product_op<ScalarBis, Scalar>,
                            const CwiseNullaryOp<internal::scalar_constant_op<ScalarBis>, Plain>,
                            const Product<Lhs, Rhs, DefaultProduct>>
          SrcXprType;
      static inline void run(DstXprType& dst, const SrcXprType& src, const AssignFunc& func) {
        call_assignment_no_alias(dst, (src.lhs().functor().m_other * src.rhs().lhs()) * src.rhs().rhs(), func);
      }
    };
    template <typename OtherXpr, typename Lhs, typename Rhs>
    struct evaluator_assume_aliasing<
        CwiseBinaryOp<
            internal::scalar_sum_op<typename OtherXpr::Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
            const OtherXpr,
            const Product<Lhs, Rhs, DefaultProduct>>,
        DenseShape> {
      static const bool value = true;
    };
    template <typename OtherXpr, typename Lhs, typename Rhs>
    struct evaluator_assume_aliasing<
        CwiseBinaryOp<internal::scalar_difference_op<typename OtherXpr::Scalar,
                                                     typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
                      const OtherXpr,
                      const Product<Lhs, Rhs, DefaultProduct>>,
        DenseShape> {
      static const bool value = true;
    };
    template <typename DstXprType, typename OtherXpr, typename ProductType, typename Func1, typename Func2>
    struct assignment_from_xpr_op_product {
      template <typename SrcXprType, typename InitialFunc>
      static inline void run(DstXprType& dst, const SrcXprType& src, const InitialFunc&) {
        call_assignment_no_alias(dst, src.lhs(), Func1());
        call_assignment_no_alias(dst, src.rhs(), Func2());
      }
    };
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_sum_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::assign_op<DstScalar, OtherScalar>,
                                                                    internal::add_assign_op<DstScalar, ProdScalar>> {};
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_sum_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::add_assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::add_assign_op<DstScalar, OtherScalar>,
                                                                    internal::add_assign_op<DstScalar, ProdScalar>> {};
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_sum_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::sub_assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::sub_assign_op<DstScalar, OtherScalar>,
                                                                    internal::sub_assign_op<DstScalar, ProdScalar>> {};
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_difference_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::assign_op<DstScalar, OtherScalar>,
                                                                    internal::sub_assign_op<DstScalar, ProdScalar>> {};
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_difference_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::add_assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::add_assign_op<DstScalar, OtherScalar>,
                                                                    internal::sub_assign_op<DstScalar, ProdScalar>> {};
    template <typename DstXprType,
              typename OtherXpr,
              typename Lhs,
              typename Rhs,
              typename DstScalar,
              typename SrcScalar,
              typename OtherScalar,
              typename ProdScalar>
    struct Assignment<DstXprType,
                      CwiseBinaryOp<internal::scalar_difference_op<OtherScalar, ProdScalar>,
                                    const OtherXpr,
                                    const Product<Lhs, Rhs, DefaultProduct>>,
                      internal::sub_assign_op<DstScalar, SrcScalar>,
                      Dense2Dense> : assignment_from_xpr_op_product<DstXprType,
                                                                    OtherXpr,
                                                                    Product<Lhs, Rhs, DefaultProduct>,
                                                                    internal::sub_assign_op<DstScalar, OtherScalar>,
                                                                    internal::add_assign_op<DstScalar, ProdScalar>> {};
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, InnerProduct> {
      template <typename Dst>
      static inline void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        dst.coeffRef(0, 0) = (lhs.transpose().cwiseProduct(rhs)).sum();
      }
      template <typename Dst>
      static inline void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        dst.coeffRef(0, 0) += (lhs.transpose().cwiseProduct(rhs)).sum();
      }
      template <typename Dst>
      static inline void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        dst.coeffRef(0, 0) -= (lhs.transpose().cwiseProduct(rhs)).sum();
      }
    };
    template <typename Dst, typename Lhs, typename Rhs, typename Func>
    void outer_product_selector_run(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Func& func, const false_type&) {
      evaluator<Rhs> rhsEval(rhs);
      Eigen::internal::local_nested_eval_wrapper<Lhs, Rhs::SizeAtCompileTime> actual_lhs_wrapper(
          lhs,
          reinterpret_cast<typename Lhs::Scalar*>(
              ((Eigen::internal::local_nested_eval_wrapper<Lhs, Rhs::SizeAtCompileTime>::NeedExternalBuffer) &&
               ((sizeof(typename Lhs::Scalar) * lhs.size()) <= 131072))
                  ? reinterpret_cast<void*>(
                        (internal::UIntPtr(__builtin_alloca(sizeof(typename Lhs::Scalar) * lhs.size() + 64 - 1)) + 64 -
                         1) &
                        ~(std::size_t(64 - 1)))
                  : 0));
      typename Eigen::internal::local_nested_eval_wrapper<Lhs, Rhs::SizeAtCompileTime>::ObjectType actual_lhs(
          actual_lhs_wrapper.object);
      const Index cols = dst.cols();
      for (Index j = 0; j < cols; ++j)
        func(dst.col(j), rhsEval.coeff(Index(0), j) * actual_lhs);
    }
    template <typename Dst, typename Lhs, typename Rhs, typename Func>
    void outer_product_selector_run(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Func& func, const true_type&) {
      evaluator<Lhs> lhsEval(lhs);
      Eigen::internal::local_nested_eval_wrapper<Rhs, Lhs::SizeAtCompileTime> actual_rhs_wrapper(
          rhs,
          reinterpret_cast<typename Rhs::Scalar*>(
              ((Eigen::internal::local_nested_eval_wrapper<Rhs, Lhs::SizeAtCompileTime>::NeedExternalBuffer) &&
               ((sizeof(typename Rhs::Scalar) * rhs.size()) <= 131072))
                  ? reinterpret_cast<void*>(
                        (internal::UIntPtr(__builtin_alloca(sizeof(typename Rhs::Scalar) * rhs.size() + 64 - 1)) + 64 -
                         1) &
                        ~(std::size_t(64 - 1)))
                  : 0));
      typename Eigen::internal::local_nested_eval_wrapper<Rhs, Lhs::SizeAtCompileTime>::ObjectType actual_rhs(
          actual_rhs_wrapper.object);
      const Index rows = dst.rows();
      for (Index i = 0; i < rows; ++i)
        func(dst.row(i), lhsEval.coeff(i, Index(0)) * actual_rhs);
    }
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, OuterProduct> {
      template <typename T>
      struct is_row_major
          : std::conditional_t<(int(T::Flags) & RowMajorBit), internal::true_type, internal::false_type> {};
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      struct set {
        template <typename Dst, typename Src>
        void operator()(const Dst& dst, const Src& src) const {
          dst.const_cast_derived() = src;
        }
      };
      struct add {
        template <typename Dst, typename Src>
        void operator()(const Dst& dst, const Src& src) const {
          dst.const_cast_derived() += src;
        }
      };
      struct sub {
        template <typename Dst, typename Src>
        void operator()(const Dst& dst, const Src& src) const {
          dst.const_cast_derived() -= src;
        }
      };
      struct adds {
        Scalar m_scale;
        explicit adds(const Scalar& s) : m_scale(s) {}
        template <typename Dst, typename Src>
        void operator()(const Dst& dst, const Src& src) const {
          dst.const_cast_derived() += m_scale * src;
        }
      };
      template <typename Dst>
      static inline void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        internal::outer_product_selector_run(dst, lhs, rhs, set(), is_row_major<Dst>());
      }
      template <typename Dst>
      static inline void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        internal::outer_product_selector_run(dst, lhs, rhs, add(), is_row_major<Dst>());
      }
      template <typename Dst>
      static inline void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        internal::outer_product_selector_run(dst, lhs, rhs, sub(), is_row_major<Dst>());
      }
      template <typename Dst>
      static inline void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        internal::outer_product_selector_run(dst, lhs, rhs, adds(alpha), is_row_major<Dst>());
      }
    };
    template <typename Lhs, typename Rhs, typename Derived>
    struct generic_product_impl_base {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dst>
      static inline void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        dst.setZero();
        scaleAndAddTo(dst, lhs, rhs, Scalar(1));
      }
      template <typename Dst>
      static inline void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        scaleAndAddTo(dst, lhs, rhs, Scalar(1));
      }
      template <typename Dst>
      static inline void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        scaleAndAddTo(dst, lhs, rhs, Scalar(-1));
      }
      template <typename Dst>
      static inline void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        Derived::scaleAndAddTo(dst, lhs, rhs, alpha);
      }
    };
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemvProduct>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemvProduct>> {
      typedef typename nested_eval<Lhs, 1>::type LhsNested;
      typedef typename nested_eval<Rhs, 1>::type RhsNested;
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      enum { Side = Lhs::IsVectorAtCompileTime ? OnTheLeft : OnTheRight };
      typedef internal::remove_all_t<std::conditional_t<int(Side) == OnTheRight, LhsNested, RhsNested>> MatrixType;
      template <typename Dest>
      static inline void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        if (lhs.rows() == 1 && rhs.cols() == 1) {
          dst.coeffRef(0, 0) += alpha * lhs.row(0).conjugate().dot(rhs.col(0));
          return;
        }
        LhsNested actual_lhs(lhs);
        RhsNested actual_rhs(rhs);
        internal::gemv_dense_selector<Side,
                                      (int(MatrixType::Flags) & RowMajorBit) ? RowMajor : ColMajor,
                                      bool(internal::blas_traits<MatrixType>::HasUsableDirectAccess)>::run(actual_lhs,
                                                                                                           actual_rhs,
                                                                                                           dst,
                                                                                                           alpha);
      }
    };
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dst>
      static inline void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::assign_op<typename Dst::Scalar, Scalar>());
      }
      template <typename Dst>
      static inline void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::add_assign_op<typename Dst::Scalar, Scalar>());
      }
      template <typename Dst>
      static inline void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::sub_assign_op<typename Dst::Scalar, Scalar>());
      }
      template <typename Dst, typename Func>
      static inline void eval_dynamic(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Func& func) {
        enum {
          HasScalarFactor = blas_traits<Lhs>::HasScalarFactor || blas_traits<Rhs>::HasScalarFactor,
          ConjLhs = blas_traits<Lhs>::NeedToConjugate,
          ConjRhs = blas_traits<Rhs>::NeedToConjugate
        };
        Scalar actualAlpha = combine_scalar_factors<Scalar>(lhs, rhs);
        eval_dynamic_impl(dst,
                          blas_traits<Lhs>::extract(lhs).template conjugateIf<ConjLhs>(),
                          blas_traits<Rhs>::extract(rhs).template conjugateIf<ConjRhs>(),
                          func,
                          actualAlpha,
                          std::conditional_t<HasScalarFactor, true_type, false_type>());
      }

    protected:
      template <typename Dst, typename LhsT, typename RhsT, typename Func, typename Scalar>
      static inline void eval_dynamic_impl(
          Dst& dst, const LhsT& lhs, const RhsT& rhs, const Func& func, const Scalar& s, false_type) {
        Eigen::internal::ignore_unused_variable(s);
        ;
        ;
        call_restricted_packet_assignment_no_alias(dst, lhs.lazyProduct(rhs), func);
      }
      template <typename Dst, typename LhsT, typename RhsT, typename Func, typename Scalar>
      static inline void eval_dynamic_impl(
          Dst& dst, const LhsT& lhs, const RhsT& rhs, const Func& func, const Scalar& s, true_type) {
        call_restricted_packet_assignment_no_alias(dst, s * lhs.lazyProduct(rhs), func);
      }
    };
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, LazyCoeffBasedProductMode>
        : generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> {};
    template <int Traversal, int UnrollingIndex, typename Lhs, typename Rhs, typename RetScalar>
    struct etor_product_coeff_impl;
    template <int StorageOrder, int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl;
    template <typename Lhs, typename Rhs, int ProductTag>
    struct product_evaluator<Product<Lhs, Rhs, LazyProduct>, ProductTag, DenseShape, DenseShape>
        : evaluator_base<Product<Lhs, Rhs, LazyProduct>> {
      typedef Product<Lhs, Rhs, LazyProduct> XprType;
      typedef typename XprType::Scalar Scalar;
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline explicit product_evaluator(const XprType& xpr)
          : m_lhs(xpr.lhs()), m_rhs(xpr.rhs()), m_lhsImpl(m_lhs), m_rhsImpl(m_rhs), m_innerDim(xpr.lhs().cols()) {
        static_assert((NumTraits<Scalar>::MulCost) >= 0 && (NumTraits<Scalar>::MulCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((NumTraits<Scalar>::AddCost) >= 0 && (NumTraits<Scalar>::AddCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename internal::nested_eval<Lhs, Rhs::ColsAtCompileTime>::type LhsNested;
      typedef typename internal::nested_eval<Rhs, Lhs::RowsAtCompileTime>::type RhsNested;
      typedef internal::remove_all_t<LhsNested> LhsNestedCleaned;
      typedef internal::remove_all_t<RhsNested> RhsNestedCleaned;
      typedef evaluator<LhsNestedCleaned> LhsEtorType;
      typedef evaluator<RhsNestedCleaned> RhsEtorType;
      enum {
        RowsAtCompileTime = LhsNestedCleaned::RowsAtCompileTime,
        ColsAtCompileTime = RhsNestedCleaned::ColsAtCompileTime,
        InnerSize = min_size_prefer_fixed(LhsNestedCleaned::ColsAtCompileTime, RhsNestedCleaned::RowsAtCompileTime),
        MaxRowsAtCompileTime = LhsNestedCleaned::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = RhsNestedCleaned::MaxColsAtCompileTime
      };
      typedef typename find_best_packet<Scalar, RowsAtCompileTime>::type LhsVecPacketType;
      typedef typename find_best_packet<Scalar, ColsAtCompileTime>::type RhsVecPacketType;
      enum {
        LhsCoeffReadCost = LhsEtorType::CoeffReadCost,
        RhsCoeffReadCost = RhsEtorType::CoeffReadCost,
        CoeffReadCost = InnerSize == 0 ? NumTraits<Scalar>::ReadCost
                        : InnerSize == Dynamic
                            ? HugeCost
                            : InnerSize * (NumTraits<Scalar>::MulCost + int(LhsCoeffReadCost) + int(RhsCoeffReadCost)) +
                                  (InnerSize - 1) * NumTraits<Scalar>::AddCost,
        Unroll = CoeffReadCost <= 110,
        LhsFlags = LhsEtorType::Flags,
        RhsFlags = RhsEtorType::Flags,
        LhsRowMajor = LhsFlags & RowMajorBit,
        RhsRowMajor = RhsFlags & RowMajorBit,
        LhsVecPacketSize = unpacket_traits<LhsVecPacketType>::size,
        RhsVecPacketSize = unpacket_traits<RhsVecPacketType>::size,
        LhsAlignment =
            plain_enum_min(LhsEtorType::Alignment, LhsVecPacketSize* int(sizeof(typename LhsNestedCleaned::Scalar))),
        RhsAlignment =
            plain_enum_min(RhsEtorType::Alignment, RhsVecPacketSize* int(sizeof(typename RhsNestedCleaned::Scalar))),
        SameType = is_same<typename LhsNestedCleaned::Scalar, typename RhsNestedCleaned::Scalar>::value,
        CanVectorizeRhs = bool(RhsRowMajor) && (RhsFlags & PacketAccessBit) && (ColsAtCompileTime != 1),
        CanVectorizeLhs = (!LhsRowMajor) && (LhsFlags & PacketAccessBit) && (RowsAtCompileTime != 1),
        EvalToRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1) ? 1
                         : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1)
                             ? 0
                             : (bool(RhsRowMajor) && !CanVectorizeLhs),
        Flags = ((int(LhsFlags) | int(RhsFlags)) & HereditaryBits & ~RowMajorBit) | (EvalToRowMajor ? RowMajorBit : 0) |
                (SameType && (CanVectorizeLhs || CanVectorizeRhs) ? PacketAccessBit : 0) |
                (XprType::IsVectorAtCompileTime ? LinearAccessBit : 0),
        LhsOuterStrideBytes =
            int(LhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename LhsNestedCleaned::Scalar)),
        RhsOuterStrideBytes =
            int(RhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename RhsNestedCleaned::Scalar)),
        Alignment = bool(CanVectorizeLhs)
                        ? (LhsOuterStrideBytes <= 0 || (int(LhsOuterStrideBytes) % plain_enum_max(1, LhsAlignment)) != 0
                               ? 0
                               : LhsAlignment)
                    : bool(CanVectorizeRhs)
                        ? (RhsOuterStrideBytes <= 0 || (int(RhsOuterStrideBytes) % plain_enum_max(1, RhsAlignment)) != 0
                               ? 0
                               : RhsAlignment)
                        : 0,
        CanVectorizeInner = SameType && LhsRowMajor && (!RhsRowMajor) &&
                            (int(LhsFlags) & int(RhsFlags) & ActualPacketAccessBit) &&
                            (int(InnerSize) % packet_traits<Scalar>::size == 0)
      };
      inline const CoeffReturnType coeff(Index row, Index col) const {
        return (m_lhs.row(row).transpose().cwiseProduct(m_rhs.col(col))).sum();
      }
      inline const CoeffReturnType coeff(Index index) const {
        const Index row = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? 0 : index;
        const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? index : 0;
        return (m_lhs.row(row).transpose().cwiseProduct(m_rhs.col(col))).sum();
      }
      template <int LoadMode, typename PacketType>
      inline const PacketType packet(Index row, Index col) const {
        PacketType res;
        typedef etor_product_packet_impl<bool(int(Flags) & RowMajorBit) ? RowMajor : ColMajor,
                                         Unroll ? int(InnerSize) : Dynamic,
                                         LhsEtorType,
                                         RhsEtorType,
                                         PacketType,
                                         LoadMode>
            PacketImpl;
        PacketImpl::run(row, col, m_lhsImpl, m_rhsImpl, m_innerDim, res);
        return res;
      }
      template <int LoadMode, typename PacketType>
      inline const PacketType packet(Index index) const {
        const Index row = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? 0 : index;
        const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? index : 0;
        return packet<LoadMode, PacketType>(row, col);
      }

    protected:
      add_const_on_value_type_t<LhsNested> m_lhs;
      add_const_on_value_type_t<RhsNested> m_rhs;
      LhsEtorType m_lhsImpl;
      RhsEtorType m_rhsImpl;
      Index m_innerDim;
    };
    template <typename Lhs, typename Rhs>
    struct product_evaluator<Product<Lhs, Rhs, DefaultProduct>, LazyCoeffBasedProductMode, DenseShape, DenseShape>
        : product_evaluator<Product<Lhs, Rhs, LazyProduct>, CoeffBasedProductMode, DenseShape, DenseShape> {
      typedef Product<Lhs, Rhs, DefaultProduct> XprType;
      typedef Product<Lhs, Rhs, LazyProduct> BaseProduct;
      typedef product_evaluator<BaseProduct, CoeffBasedProductMode, DenseShape, DenseShape> Base;
      enum { Flags = Base::Flags | EvalBeforeNestingBit };
      inline explicit product_evaluator(const XprType& xpr) : Base(BaseProduct(xpr.lhs(), xpr.rhs())) {}
    };
    template <int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<RowMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res) {
        etor_product_packet_impl<RowMajor, UnrollingIndex - 1, Lhs, Rhs, Packet, LoadMode>::run(
            row, col, lhs, rhs, innerDim, res);
        res = pmadd(pset1<Packet>(lhs.coeff(row, Index(UnrollingIndex - 1))),
                    rhs.template packet<LoadMode, Packet>(Index(UnrollingIndex - 1), col),
                    res);
      }
    };
    template <int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<ColMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res) {
        etor_product_packet_impl<ColMajor, UnrollingIndex - 1, Lhs, Rhs, Packet, LoadMode>::run(
            row, col, lhs, rhs, innerDim, res);
        res = pmadd(lhs.template packet<LoadMode, Packet>(row, Index(UnrollingIndex - 1)),
                    pset1<Packet>(rhs.coeff(Index(UnrollingIndex - 1), col)),
                    res);
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<RowMajor, 1, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index, Packet& res) {
        res = pmul(pset1<Packet>(lhs.coeff(row, Index(0))), rhs.template packet<LoadMode, Packet>(Index(0), col));
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<ColMajor, 1, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index, Packet& res) {
        res = pmul(lhs.template packet<LoadMode, Packet>(row, Index(0)), pset1<Packet>(rhs.coeff(Index(0), col)));
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<RowMajor, 0, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index, Index, const Lhs&, const Rhs&, Index, Packet& res) {
        res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<ColMajor, 0, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index, Index, const Lhs&, const Rhs&, Index, Packet& res) {
        res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<RowMajor, Dynamic, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res) {
        res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
        for (Index i = 0; i < innerDim; ++i)
          res = pmadd(pset1<Packet>(lhs.coeff(row, i)), rhs.template packet<LoadMode, Packet>(i, col), res);
      }
    };
    template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
    struct etor_product_packet_impl<ColMajor, Dynamic, Lhs, Rhs, Packet, LoadMode> {
      static inline void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res) {
        res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
        for (Index i = 0; i < innerDim; ++i)
          res = pmadd(lhs.template packet<LoadMode, Packet>(row, i), pset1<Packet>(rhs.coeff(i, col)), res);
      }
    };
    template <int Mode, bool LhsIsTriangular, typename Lhs, bool LhsIsVector, typename Rhs, bool RhsIsVector>
    struct triangular_product_impl;
    template <typename Lhs, typename Rhs, int ProductTag>
    struct generic_product_impl<Lhs, Rhs, TriangularShape, DenseShape, ProductTag>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, TriangularShape, DenseShape, ProductTag>> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dest>
      static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        triangular_product_impl<Lhs::Mode, true, typename Lhs::MatrixType, false, Rhs, Rhs::ColsAtCompileTime == 1>::run(
            dst, lhs.nestedExpression(), rhs, alpha);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag>
    struct generic_product_impl<Lhs, Rhs, DenseShape, TriangularShape, ProductTag>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, TriangularShape, ProductTag>> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dest>
      static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        triangular_product_impl<Rhs::Mode, false, Lhs, Lhs::RowsAtCompileTime == 1, typename Rhs::MatrixType, false>::run(
            dst, lhs, rhs.nestedExpression(), alpha);
      }
    };
    template <typename Lhs, int LhsMode, bool LhsIsVector, typename Rhs, int RhsMode, bool RhsIsVector>
    struct selfadjoint_product_impl;
    template <typename Lhs, typename Rhs, int ProductTag>
    struct generic_product_impl<Lhs, Rhs, SelfAdjointShape, DenseShape, ProductTag>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, SelfAdjointShape, DenseShape, ProductTag>> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dest>
      static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        selfadjoint_product_impl<typename Lhs::MatrixType, Lhs::Mode, false, Rhs, 0, Rhs::IsVectorAtCompileTime>::run(
            dst, lhs.nestedExpression(), rhs, alpha);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag>
    struct generic_product_impl<Lhs, Rhs, DenseShape, SelfAdjointShape, ProductTag>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, SelfAdjointShape, ProductTag>> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      template <typename Dest>
      static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
        selfadjoint_product_impl<Lhs, 0, Lhs::IsVectorAtCompileTime, typename Rhs::MatrixType, Rhs::Mode, false>::run(
            dst, lhs, rhs.nestedExpression(), alpha);
      }
    };
    template <typename MatrixType, typename DiagonalType, typename Derived, int ProductOrder>
    struct diagonal_product_evaluator_base : evaluator_base<Derived> {
      typedef
          typename ScalarBinaryOpTraits<typename MatrixType::Scalar, typename DiagonalType::Scalar>::ReturnType Scalar;

    public:
      enum {
        CoeffReadCost = int(NumTraits<Scalar>::MulCost) + int(evaluator<MatrixType>::CoeffReadCost) +
                        int(evaluator<DiagonalType>::CoeffReadCost),
        MatrixFlags = evaluator<MatrixType>::Flags,
        DiagFlags = evaluator<DiagonalType>::Flags,
        StorageOrder_ = (Derived::MaxRowsAtCompileTime == 1 && Derived::MaxColsAtCompileTime != 1)   ? RowMajor
                        : (Derived::MaxColsAtCompileTime == 1 && Derived::MaxRowsAtCompileTime != 1) ? ColMajor
                        : MatrixFlags & RowMajorBit                                                  ? RowMajor
                                                                                                     : ColMajor,
        SameStorageOrder_ = StorageOrder_ == (MatrixFlags & RowMajorBit ? RowMajor : ColMajor),
        ScalarAccessOnDiag_ = !((int(StorageOrder_) == ColMajor && int(ProductOrder) == OnTheLeft) ||
                                (int(StorageOrder_) == RowMajor && int(ProductOrder) == OnTheRight)),
        SameTypes_ = is_same<typename MatrixType::Scalar, typename DiagonalType::Scalar>::value,
        Vectorizable_ = bool(int(MatrixFlags) & PacketAccessBit) && SameTypes_ &&
                        (SameStorageOrder_ || (MatrixFlags & LinearAccessBit) == LinearAccessBit) &&
                        (ScalarAccessOnDiag_ || (bool(int(DiagFlags) & PacketAccessBit))),
        LinearAccessMask_ =
            (MatrixType::RowsAtCompileTime == 1 || MatrixType::ColsAtCompileTime == 1) ? LinearAccessBit : 0,
        Flags = ((HereditaryBits | LinearAccessMask_) & (unsigned int)(MatrixFlags)) |
                (Vectorizable_ ? PacketAccessBit : 0),
        Alignment = evaluator<MatrixType>::Alignment,
        AsScalarProduct = (DiagonalType::SizeAtCompileTime == 1) ||
                          (DiagonalType::SizeAtCompileTime == Dynamic && MatrixType::RowsAtCompileTime == 1 &&
                           ProductOrder == OnTheLeft) ||
                          (DiagonalType::SizeAtCompileTime == Dynamic && MatrixType::ColsAtCompileTime == 1 &&
                           ProductOrder == OnTheRight)
      };
      diagonal_product_evaluator_base(const MatrixType& mat, const DiagonalType& diag)
          : m_diagImpl(diag), m_matImpl(mat) {
        static_assert((NumTraits<Scalar>::MulCost) >= 0 && (NumTraits<Scalar>::MulCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      inline const Scalar coeff(Index idx) const {
        if (AsScalarProduct)
          return m_diagImpl.coeff(0) * m_matImpl.coeff(idx);
        else
          return m_diagImpl.coeff(idx) * m_matImpl.coeff(idx);
      }

    protected:
      template <int LoadMode, typename PacketType>
      inline PacketType packet_impl(Index row, Index col, Index id, internal::true_type) const {
        return internal::pmul(m_matImpl.template packet<LoadMode, PacketType>(row, col),
                              internal::pset1<PacketType>(m_diagImpl.coeff(id)));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet_impl(Index row, Index col, Index id, internal::false_type) const {
        enum {
          InnerSize = (MatrixType::Flags & RowMajorBit) ? MatrixType::ColsAtCompileTime : MatrixType::RowsAtCompileTime,
          DiagonalPacketLoadMode = plain_enum_min(
              LoadMode, ((InnerSize % 16) == 0) ? int(Aligned16) : int(evaluator<DiagonalType>::Alignment))
        };
        return internal::pmul(m_matImpl.template packet<LoadMode, PacketType>(row, col),
                              m_diagImpl.template packet<DiagonalPacketLoadMode, PacketType>(id));
      }
      evaluator<DiagonalType> m_diagImpl;
      evaluator<MatrixType> m_matImpl;
    };
    template <typename Lhs, typename Rhs, int ProductKind, int ProductTag>
    struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DiagonalShape, DenseShape>
        : diagonal_product_evaluator_base<Rhs,
                                          typename Lhs::DiagonalVectorType,
                                          Product<Lhs, Rhs, LazyProduct>,
                                          OnTheLeft> {
      typedef diagonal_product_evaluator_base<Rhs,
                                              typename Lhs::DiagonalVectorType,
                                              Product<Lhs, Rhs, LazyProduct>,
                                              OnTheLeft>
          Base;
      using Base::coeff;
      using Base::m_diagImpl;
      using Base::m_matImpl;
      typedef typename Base::Scalar Scalar;
      typedef Product<Lhs, Rhs, ProductKind> XprType;
      typedef typename XprType::PlainObject PlainObject;
      typedef typename Lhs::DiagonalVectorType DiagonalType;
      enum { StorageOrder = Base::StorageOrder_ };
      explicit product_evaluator(const XprType& xpr) : Base(xpr.rhs(), xpr.lhs().diagonal()) {}
      inline const Scalar coeff(Index row, Index col) const {
        return m_diagImpl.coeff(row) * m_matImpl.coeff(row, col);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return this->template packet_impl<LoadMode, PacketType>(
            row,
            col,
            row,
            std::conditional_t<int(StorageOrder) == RowMajor, internal::true_type, internal::false_type>());
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index idx) const {
        return packet<LoadMode, PacketType>(int(StorageOrder) == ColMajor ? idx : 0,
                                            int(StorageOrder) == ColMajor ? 0 : idx);
      }
    };
    template <typename Lhs, typename Rhs, int ProductKind, int ProductTag>
    struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DenseShape, DiagonalShape>
        : diagonal_product_evaluator_base<Lhs,
                                          typename Rhs::DiagonalVectorType,
                                          Product<Lhs, Rhs, LazyProduct>,
                                          OnTheRight> {
      typedef diagonal_product_evaluator_base<Lhs,
                                              typename Rhs::DiagonalVectorType,
                                              Product<Lhs, Rhs, LazyProduct>,
                                              OnTheRight>
          Base;
      using Base::coeff;
      using Base::m_diagImpl;
      using Base::m_matImpl;
      typedef typename Base::Scalar Scalar;
      typedef Product<Lhs, Rhs, ProductKind> XprType;
      typedef typename XprType::PlainObject PlainObject;
      enum { StorageOrder = Base::StorageOrder_ };
      explicit product_evaluator(const XprType& xpr) : Base(xpr.lhs(), xpr.rhs().diagonal()) {}
      inline const Scalar coeff(Index row, Index col) const {
        return m_matImpl.coeff(row, col) * m_diagImpl.coeff(col);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index row, Index col) const {
        return this->template packet_impl<LoadMode, PacketType>(
            row,
            col,
            col,
            std::conditional_t<int(StorageOrder) == ColMajor, internal::true_type, internal::false_type>());
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index idx) const {
        return packet<LoadMode, PacketType>(int(StorageOrder) == ColMajor ? idx : 0,
                                            int(StorageOrder) == ColMajor ? 0 : idx);
      }
    };
    template <typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
    struct permutation_matrix_product;
    template <typename ExpressionType, int Side, bool Transposed>
    struct permutation_matrix_product<ExpressionType, Side, Transposed, DenseShape> {
      typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
      typedef remove_all_t<MatrixType> MatrixTypeCleaned;
      template <typename Dest, typename PermutationType>
      static inline void run(Dest& dst, const PermutationType& perm, const ExpressionType& xpr) {
        MatrixType mat(xpr);
        const Index n = Side == OnTheLeft ? mat.rows() : mat.cols();
        if (is_same_dense(dst, mat)) {
          Matrix<bool, PermutationType::RowsAtCompileTime, 1, 0, PermutationType::MaxRowsAtCompileTime> mask(
              perm.size());
          mask.fill(false);
          Index r = 0;
          while (r < perm.size()) {
            while (r < perm.size() && mask[r])
              r++;
            if (r >= perm.size())
              break;
            Index k0 = r++;
            Index kPrev = k0;
            mask.coeffRef(k0) = true;
            for (Index k = perm.indices().coeff(k0); k != k0; k = perm.indices().coeff(k)) {
              Block<Dest,
                    Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime,
                    Side == OnTheRight ? 1 : Dest::ColsAtCompileTime>(dst, k)
                  .swap(Block < Dest,
                        Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime,
                        Side == OnTheRight
                            ? 1
                            : Dest::ColsAtCompileTime > (dst, ((Side == OnTheLeft) ^ Transposed) ? k0 : kPrev));
              mask.coeffRef(k) = true;
              kPrev = k;
            }
          }
        } else {
          for (Index i = 0; i < n; ++i) {
            Block<Dest,
                  Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime,
                  Side == OnTheRight ? 1 : Dest::ColsAtCompileTime>(
                dst,
                ((Side == OnTheLeft) ^ Transposed)
                    ? perm.indices().coeff(i)
                    : i) = Block < const MatrixTypeCleaned,
                      Side == OnTheLeft ? 1 : MatrixTypeCleaned::RowsAtCompileTime,
                      Side == OnTheRight ? 1
                                         : MatrixTypeCleaned::ColsAtCompileTime >
                                               (mat, ((Side == OnTheRight) ^ Transposed) ? perm.indices().coeff(i) : i);
          }
        }
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, PermutationShape, MatrixShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        permutation_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, MatrixShape, PermutationShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        permutation_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Inverse<Lhs>, Rhs, PermutationShape, MatrixShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs) {
        permutation_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Inverse<Rhs>, MatrixShape, PermutationShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs) {
        permutation_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
      }
    };
    template <typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
    struct transposition_matrix_product {
      typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
      typedef remove_all_t<MatrixType> MatrixTypeCleaned;
      template <typename Dest, typename TranspositionType>
      static inline void run(Dest& dst, const TranspositionType& tr, const ExpressionType& xpr) {
        MatrixType mat(xpr);
        typedef typename TranspositionType::StorageIndex StorageIndex;
        const Index size = tr.size();
        StorageIndex j = 0;
        if (!is_same_dense(dst, mat))
          dst = mat;
        for (Index k = (Transposed ? size - 1 : 0); Transposed ? k >= 0 : k < size; Transposed ? --k : ++k)
          if (Index(j = tr.coeff(k)) != k) {
            if (Side == OnTheLeft)
              dst.row(k).swap(dst.row(j));
            else if (Side == OnTheRight)
              dst.col(k).swap(dst.col(j));
          }
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, TranspositionsShape, MatrixShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        transposition_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, MatrixShape, TranspositionsShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        transposition_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Transpose<Lhs>, Rhs, TranspositionsShape, MatrixShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs) {
        transposition_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Transpose<Rhs>, MatrixShape, TranspositionsShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs) {
        transposition_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, SkewSymmetricShape, MatrixShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        generic_product_impl<typename Lhs::DenseMatrixType, Rhs, DenseShape, MatrixShape, ProductTag>::evalTo(
            dst, lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
    struct generic_product_impl<Lhs, Rhs, MatrixShape, SkewSymmetricShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        generic_product_impl<Lhs, typename Rhs::DenseMatrixType, MatrixShape, DenseShape, ProductTag>::evalTo(
            dst, lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int ProductTag>
    struct generic_product_impl<Lhs, Rhs, SkewSymmetricShape, SkewSymmetricShape, ProductTag> {
      template <typename Dest>
      static inline void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
        generic_product_impl<typename Lhs::DenseMatrixType,
                             typename Rhs::DenseMatrixType,
                             DenseShape,
                             DenseShape,
                             ProductTag>::evalTo(dst, lhs, rhs);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    enum GEMVPacketSizeType { GEMVPacketFull = 0, GEMVPacketHalf, GEMVPacketQuarter };
    template <int N, typename T1, typename T2, typename T3>
    struct gemv_packet_cond {
      typedef T3 type;
    };
    template <typename T1, typename T2, typename T3>
    struct gemv_packet_cond<GEMVPacketFull, T1, T2, T3> {
      typedef T1 type;
    };
    template <typename T1, typename T2, typename T3>
    struct gemv_packet_cond<GEMVPacketHalf, T1, T2, T3> {
      typedef T2 type;
    };
    template <typename LhsScalar, typename RhsScalar, int PacketSize_ = GEMVPacketFull>
    class gemv_traits {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      typedef typename gemv_packet_cond<PacketSize_,
                                        typename packet_traits<LhsScalar>::type,
                                        typename packet_traits<LhsScalar>::half,
                                        typename unpacket_traits<typename packet_traits<LhsScalar>::half>::half>::type
          LhsPacket_;
      typedef typename gemv_packet_cond<PacketSize_,
                                        typename packet_traits<RhsScalar>::type,
                                        typename packet_traits<RhsScalar>::half,
                                        typename unpacket_traits<typename packet_traits<RhsScalar>::half>::half>::type
          RhsPacket_;
      typedef typename gemv_packet_cond<PacketSize_,
                                        typename packet_traits<ResScalar>::type,
                                        typename packet_traits<ResScalar>::half,
                                        typename unpacket_traits<typename packet_traits<ResScalar>::half>::half>::type
          ResPacket_;

    public:
      enum {
        Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable &&
                       int(unpacket_traits<LhsPacket_>::size) == int(unpacket_traits<RhsPacket_>::size),
        LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
        RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
        ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1
      };
      typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
      typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
      typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
    };
    template <typename Index,
              typename LhsScalar,
              typename LhsMapper,
              bool ConjugateLhs,
              typename RhsScalar,
              typename RhsMapper,
              bool ConjugateRhs,
              int Version>
    struct general_matrix_vector_product<Index,
                                         LhsScalar,
                                         LhsMapper,
                                         ColMajor,
                                         ConjugateLhs,
                                         RhsScalar,
                                         RhsMapper,
                                         ConjugateRhs,
                                         Version> {
      typedef gemv_traits<LhsScalar, RhsScalar> Traits;
      typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketHalf> HalfTraits;
      typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketQuarter> QuarterTraits;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      typedef typename Traits::LhsPacket LhsPacket;
      typedef typename Traits::RhsPacket RhsPacket;
      typedef typename Traits::ResPacket ResPacket;
      typedef typename HalfTraits::LhsPacket LhsPacketHalf;
      typedef typename HalfTraits::RhsPacket RhsPacketHalf;
      typedef typename HalfTraits::ResPacket ResPacketHalf;
      typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
      typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
      typedef typename QuarterTraits::ResPacket ResPacketQuarter;
      __attribute__((noinline)) static void run(Index rows,
                                                Index cols,
                                                const LhsMapper& lhs,
                                                const RhsMapper& rhs,
                                                ResScalar* res,
                                                Index resIncr,
                                                RhsScalar alpha);
    };
    template <typename Index,
              typename LhsScalar,
              typename LhsMapper,
              bool ConjugateLhs,
              typename RhsScalar,
              typename RhsMapper,
              bool ConjugateRhs,
              int Version>
    __attribute__((noinline)) void general_matrix_vector_product<Index,
                                                                 LhsScalar,
                                                                 LhsMapper,
                                                                 ColMajor,
                                                                 ConjugateLhs,
                                                                 RhsScalar,
                                                                 RhsMapper,
                                                                 ConjugateRhs,
                                                                 Version>::run(Index rows,
                                                                               Index cols,
                                                                               const LhsMapper& alhs,
                                                                               const RhsMapper& rhs,
                                                                               ResScalar* res,
                                                                               Index resIncr,
                                                                               RhsScalar alpha) {
      Eigen::internal::ignore_unused_variable(resIncr);
      ;
      ;
      LhsMapper lhs(alhs);
      conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
      conj_helper<LhsPacket, RhsPacket, ConjugateLhs, ConjugateRhs> pcj;
      conj_helper<LhsPacketHalf, RhsPacketHalf, ConjugateLhs, ConjugateRhs> pcj_half;
      conj_helper<LhsPacketQuarter, RhsPacketQuarter, ConjugateLhs, ConjugateRhs> pcj_quarter;
      const Index lhsStride = lhs.stride();
      enum {
        LhsAlignment = Unaligned,
        ResPacketSize = Traits::ResPacketSize,
        ResPacketSizeHalf = HalfTraits::ResPacketSize,
        ResPacketSizeQuarter = QuarterTraits::ResPacketSize,
        LhsPacketSize = Traits::LhsPacketSize,
        HasHalf = (int)ResPacketSizeHalf < (int)ResPacketSize,
        HasQuarter = (int)ResPacketSizeQuarter < (int)ResPacketSizeHalf
      };
      const Index n8 = rows - 8 * ResPacketSize + 1;
      const Index n4 = rows - 4 * ResPacketSize + 1;
      const Index n3 = rows - 3 * ResPacketSize + 1;
      const Index n2 = rows - 2 * ResPacketSize + 1;
      const Index n1 = rows - 1 * ResPacketSize + 1;
      const Index n_half = rows - 1 * ResPacketSizeHalf + 1;
      const Index n_quarter = rows - 1 * ResPacketSizeQuarter + 1;
      const Index block_cols = cols < 128 ? cols : (lhsStride * sizeof(LhsScalar) < 32000 ? 16 : 4);
      ResPacket palpha = pset1<ResPacket>(alpha);
      ResPacketHalf palpha_half = pset1<ResPacketHalf>(alpha);
      ResPacketQuarter palpha_quarter = pset1<ResPacketQuarter>(alpha);
      for (Index j2 = 0; j2 < cols; j2 += block_cols) {
        Index jend = numext::mini(j2 + block_cols, cols);
        Index i = 0;
        for (; i < n8; i += ResPacketSize * 8) {
          ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
                    c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0)),
                    c4 = pset1<ResPacket>(ResScalar(0)), c5 = pset1<ResPacket>(ResScalar(0)),
                    c6 = pset1<ResPacket>(ResScalar(0)), c7 = pset1<ResPacket>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
            c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
            c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
            c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
            c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 3, j), b0, c3);
            c4 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 4, j), b0, c4);
            c5 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 5, j), b0, c5);
            c6 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 6, j), b0, c6);
            c7 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 7, j), b0, c7);
          }
          pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
          pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
          pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
          pstoreu(res + i + ResPacketSize * 3, pmadd(c3, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 3)));
          pstoreu(res + i + ResPacketSize * 4, pmadd(c4, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 4)));
          pstoreu(res + i + ResPacketSize * 5, pmadd(c5, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 5)));
          pstoreu(res + i + ResPacketSize * 6, pmadd(c6, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 6)));
          pstoreu(res + i + ResPacketSize * 7, pmadd(c7, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 7)));
        }
        if (i < n4) {
          ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
                    c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
            c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
            c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
            c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
            c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 3, j), b0, c3);
          }
          pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
          pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
          pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
          pstoreu(res + i + ResPacketSize * 3, pmadd(c3, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 3)));
          i += ResPacketSize * 4;
        }
        if (i < n3) {
          ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
                    c2 = pset1<ResPacket>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
            c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
            c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
            c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
          }
          pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
          pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
          pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
          i += ResPacketSize * 3;
        }
        if (i < n2) {
          ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
            c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
            c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
          }
          pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
          pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
          i += ResPacketSize * 2;
        }
        if (i < n1) {
          ResPacket c0 = pset1<ResPacket>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
            c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
          }
          pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
          i += ResPacketSize;
        }
        if (HasHalf && i < n_half) {
          ResPacketHalf c0 = pset1<ResPacketHalf>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacketHalf b0 = pset1<RhsPacketHalf>(rhs(j, 0));
            c0 = pcj_half.pmadd(lhs.template load<LhsPacketHalf, LhsAlignment>(i + 0, j), b0, c0);
          }
          pstoreu(res + i + ResPacketSizeHalf * 0,
                  pmadd(c0, palpha_half, ploadu<ResPacketHalf>(res + i + ResPacketSizeHalf * 0)));
          i += ResPacketSizeHalf;
        }
        if (HasQuarter && i < n_quarter) {
          ResPacketQuarter c0 = pset1<ResPacketQuarter>(ResScalar(0));
          for (Index j = j2; j < jend; j += 1) {
            RhsPacketQuarter b0 = pset1<RhsPacketQuarter>(rhs(j, 0));
            c0 = pcj_quarter.pmadd(lhs.template load<LhsPacketQuarter, LhsAlignment>(i + 0, j), b0, c0);
          }
          pstoreu(res + i + ResPacketSizeQuarter * 0,
                  pmadd(c0, palpha_quarter, ploadu<ResPacketQuarter>(res + i + ResPacketSizeQuarter * 0)));
          i += ResPacketSizeQuarter;
        }
        for (; i < rows; ++i) {
          ResScalar c0(0);
          for (Index j = j2; j < jend; j += 1)
            c0 += cj.pmul(lhs(i, j), rhs(j, 0));
          res[i] += alpha * c0;
        }
      }
    }
    template <typename Index,
              typename LhsScalar,
              typename LhsMapper,
              bool ConjugateLhs,
              typename RhsScalar,
              typename RhsMapper,
              bool ConjugateRhs,
              int Version>
    struct general_matrix_vector_product<Index,
                                         LhsScalar,
                                         LhsMapper,
                                         RowMajor,
                                         ConjugateLhs,
                                         RhsScalar,
                                         RhsMapper,
                                         ConjugateRhs,
                                         Version> {
      typedef gemv_traits<LhsScalar, RhsScalar> Traits;
      typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketHalf> HalfTraits;
      typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketQuarter> QuarterTraits;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      typedef typename Traits::LhsPacket LhsPacket;
      typedef typename Traits::RhsPacket RhsPacket;
      typedef typename Traits::ResPacket ResPacket;
      typedef typename HalfTraits::LhsPacket LhsPacketHalf;
      typedef typename HalfTraits::RhsPacket RhsPacketHalf;
      typedef typename HalfTraits::ResPacket ResPacketHalf;
      typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
      typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
      typedef typename QuarterTraits::ResPacket ResPacketQuarter;
      __attribute__((noinline)) static void run(Index rows,
                                                Index cols,
                                                const LhsMapper& lhs,
                                                const RhsMapper& rhs,
                                                ResScalar* res,
                                                Index resIncr,
                                                ResScalar alpha);
    };
    template <typename Index,
              typename LhsScalar,
              typename LhsMapper,
              bool ConjugateLhs,
              typename RhsScalar,
              typename RhsMapper,
              bool ConjugateRhs,
              int Version>
    __attribute__((noinline)) void general_matrix_vector_product<Index,
                                                                 LhsScalar,
                                                                 LhsMapper,
                                                                 RowMajor,
                                                                 ConjugateLhs,
                                                                 RhsScalar,
                                                                 RhsMapper,
                                                                 ConjugateRhs,
                                                                 Version>::run(Index rows,
                                                                               Index cols,
                                                                               const LhsMapper& alhs,
                                                                               const RhsMapper& rhs,
                                                                               ResScalar* res,
                                                                               Index resIncr,
                                                                               ResScalar alpha) {
      LhsMapper lhs(alhs);
      ;
      conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
      conj_helper<LhsPacket, RhsPacket, ConjugateLhs, ConjugateRhs> pcj;
      conj_helper<LhsPacketHalf, RhsPacketHalf, ConjugateLhs, ConjugateRhs> pcj_half;
      conj_helper<LhsPacketQuarter, RhsPacketQuarter, ConjugateLhs, ConjugateRhs> pcj_quarter;
      const Index n8 = lhs.stride() * sizeof(LhsScalar) > 32000 ? 0 : rows - 7;
      const Index n4 = rows - 3;
      const Index n2 = rows - 1;
      enum {
        LhsAlignment = Unaligned,
        ResPacketSize = Traits::ResPacketSize,
        ResPacketSizeHalf = HalfTraits::ResPacketSize,
        ResPacketSizeQuarter = QuarterTraits::ResPacketSize,
        LhsPacketSize = Traits::LhsPacketSize,
        LhsPacketSizeHalf = HalfTraits::LhsPacketSize,
        LhsPacketSizeQuarter = QuarterTraits::LhsPacketSize,
        HasHalf = (int)ResPacketSizeHalf < (int)ResPacketSize,
        HasQuarter = (int)ResPacketSizeQuarter < (int)ResPacketSizeHalf
      };
      Index i = 0;
      for (; i < n8; i += 8) {
        ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
                  c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0)),
                  c4 = pset1<ResPacket>(ResScalar(0)), c5 = pset1<ResPacket>(ResScalar(0)),
                  c6 = pset1<ResPacket>(ResScalar(0)), c7 = pset1<ResPacket>(ResScalar(0));
        Index j = 0;
        for (; j + LhsPacketSize <= cols; j += LhsPacketSize) {
          RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
          c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
          c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
          c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 2, j), b0, c2);
          c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 3, j), b0, c3);
          c4 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 4, j), b0, c4);
          c5 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 5, j), b0, c5);
          c6 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 6, j), b0, c6);
          c7 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 7, j), b0, c7);
        }
        ResScalar cc0 = predux(c0);
        ResScalar cc1 = predux(c1);
        ResScalar cc2 = predux(c2);
        ResScalar cc3 = predux(c3);
        ResScalar cc4 = predux(c4);
        ResScalar cc5 = predux(c5);
        ResScalar cc6 = predux(c6);
        ResScalar cc7 = predux(c7);
        for (; j < cols; ++j) {
          RhsScalar b0 = rhs(j, 0);
          cc0 += cj.pmul(lhs(i + 0, j), b0);
          cc1 += cj.pmul(lhs(i + 1, j), b0);
          cc2 += cj.pmul(lhs(i + 2, j), b0);
          cc3 += cj.pmul(lhs(i + 3, j), b0);
          cc4 += cj.pmul(lhs(i + 4, j), b0);
          cc5 += cj.pmul(lhs(i + 5, j), b0);
          cc6 += cj.pmul(lhs(i + 6, j), b0);
          cc7 += cj.pmul(lhs(i + 7, j), b0);
        }
        res[(i + 0) * resIncr] += alpha * cc0;
        res[(i + 1) * resIncr] += alpha * cc1;
        res[(i + 2) * resIncr] += alpha * cc2;
        res[(i + 3) * resIncr] += alpha * cc3;
        res[(i + 4) * resIncr] += alpha * cc4;
        res[(i + 5) * resIncr] += alpha * cc5;
        res[(i + 6) * resIncr] += alpha * cc6;
        res[(i + 7) * resIncr] += alpha * cc7;
      }
      for (; i < n4; i += 4) {
        ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
                  c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0));
        Index j = 0;
        for (; j + LhsPacketSize <= cols; j += LhsPacketSize) {
          RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
          c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
          c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
          c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 2, j), b0, c2);
          c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 3, j), b0, c3);
        }
        ResScalar cc0 = predux(c0);
        ResScalar cc1 = predux(c1);
        ResScalar cc2 = predux(c2);
        ResScalar cc3 = predux(c3);
        for (; j < cols; ++j) {
          RhsScalar b0 = rhs(j, 0);
          cc0 += cj.pmul(lhs(i + 0, j), b0);
          cc1 += cj.pmul(lhs(i + 1, j), b0);
          cc2 += cj.pmul(lhs(i + 2, j), b0);
          cc3 += cj.pmul(lhs(i + 3, j), b0);
        }
        res[(i + 0) * resIncr] += alpha * cc0;
        res[(i + 1) * resIncr] += alpha * cc1;
        res[(i + 2) * resIncr] += alpha * cc2;
        res[(i + 3) * resIncr] += alpha * cc3;
      }
      for (; i < n2; i += 2) {
        ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0));
        Index j = 0;
        for (; j + LhsPacketSize <= cols; j += LhsPacketSize) {
          RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
          c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
          c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
        }
        ResScalar cc0 = predux(c0);
        ResScalar cc1 = predux(c1);
        for (; j < cols; ++j) {
          RhsScalar b0 = rhs(j, 0);
          cc0 += cj.pmul(lhs(i + 0, j), b0);
          cc1 += cj.pmul(lhs(i + 1, j), b0);
        }
        res[(i + 0) * resIncr] += alpha * cc0;
        res[(i + 1) * resIncr] += alpha * cc1;
      }
      for (; i < rows; ++i) {
        ResPacket c0 = pset1<ResPacket>(ResScalar(0));
        ResPacketHalf c0_h = pset1<ResPacketHalf>(ResScalar(0));
        ResPacketQuarter c0_q = pset1<ResPacketQuarter>(ResScalar(0));
        Index j = 0;
        for (; j + LhsPacketSize <= cols; j += LhsPacketSize) {
          RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
          c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i, j), b0, c0);
        }
        ResScalar cc0 = predux(c0);
        if (HasHalf) {
          for (; j + LhsPacketSizeHalf <= cols; j += LhsPacketSizeHalf) {
            RhsPacketHalf b0 = rhs.template load<RhsPacketHalf, Unaligned>(j, 0);
            c0_h = pcj_half.pmadd(lhs.template load<LhsPacketHalf, LhsAlignment>(i, j), b0, c0_h);
          }
          cc0 += predux(c0_h);
        }
        if (HasQuarter) {
          for (; j + LhsPacketSizeQuarter <= cols; j += LhsPacketSizeQuarter) {
            RhsPacketQuarter b0 = rhs.template load<RhsPacketQuarter, Unaligned>(j, 0);
            c0_q = pcj_quarter.pmadd(lhs.template load<LhsPacketQuarter, LhsAlignment>(i, j), b0, c0_q);
          }
          cc0 += predux(c0_q);
        }
        for (; j < cols; ++j) {
          cc0 += cj.pmul(lhs(i, j), rhs(j, 0));
        }
        res[i * resIncr] += alpha * cc0;
      }
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename LhsScalar_, typename RhsScalar_>
    class level3_blocking;
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    struct general_matrix_matrix_product<Index,
                                         LhsScalar,
                                         LhsStorageOrder,
                                         ConjugateLhs,
                                         RhsScalar,
                                         RhsStorageOrder,
                                         ConjugateRhs,
                                         RowMajor,
                                         ResInnerStride> {
      typedef gebp_traits<RhsScalar, LhsScalar> Traits;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      static inline void run(Index rows,
                             Index cols,
                             Index depth,
                             const LhsScalar* lhs,
                             Index lhsStride,
                             const RhsScalar* rhs,
                             Index rhsStride,
                             ResScalar* res,
                             Index resIncr,
                             Index resStride,
                             ResScalar alpha,
                             level3_blocking<RhsScalar, LhsScalar>& blocking,
                             GemmParallelInfo<Index>* info = 0) {
        general_matrix_matrix_product<Index,
                                      RhsScalar,
                                      RhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                      ConjugateRhs,
                                      LhsScalar,
                                      LhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                      ConjugateLhs,
                                      ColMajor,
                                      ResInnerStride>::run(cols,
                                                           rows,
                                                           depth,
                                                           rhs,
                                                           rhsStride,
                                                           lhs,
                                                           lhsStride,
                                                           res,
                                                           resIncr,
                                                           resStride,
                                                           alpha,
                                                           blocking,
                                                           info);
      }
    };
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    struct general_matrix_matrix_product<Index,
                                         LhsScalar,
                                         LhsStorageOrder,
                                         ConjugateLhs,
                                         RhsScalar,
                                         RhsStorageOrder,
                                         ConjugateRhs,
                                         ColMajor,
                                         ResInnerStride> {
      typedef gebp_traits<LhsScalar, RhsScalar> Traits;
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      static void run(Index rows,
                      Index cols,
                      Index depth,
                      const LhsScalar* _lhs,
                      Index lhsStride,
                      const RhsScalar* _rhs,
                      Index rhsStride,
                      ResScalar* _res,
                      Index resIncr,
                      Index resStride,
                      ResScalar alpha,
                      level3_blocking<LhsScalar, RhsScalar>& blocking,
                      GemmParallelInfo<Index>* info = 0) {
        typedef const_blas_data_mapper<LhsScalar, Index, LhsStorageOrder> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, RhsStorageOrder> RhsMapper;
        typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
        LhsMapper lhs(_lhs, lhsStride);
        RhsMapper rhs(_rhs, rhsStride);
        ResMapper res(_res, resStride, resIncr);
        Index kc = blocking.kc();
        Index mc = (std::min)(rows, blocking.mc());
        Index nc = (std::min)(cols, blocking.nc());
        gemm_pack_lhs<LhsScalar,
                      Index,
                      LhsMapper,
                      Traits::mr,
                      Traits::LhsProgress,
                      typename Traits::LhsPacket4Packing,
                      LhsStorageOrder>
            pack_lhs;
        gemm_pack_rhs<RhsScalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
        gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp;
        {
          Eigen::internal::ignore_unused_variable(info);
          ;
          std::size_t sizeA = kc * mc;
          std::size_t sizeB = kc * nc;
          Eigen::internal::check_size_for_overflow<LhsScalar>(sizeA);
          LhsScalar* blockA =
              (blocking.blockA()) != 0
                  ? (blocking.blockA())
                  : reinterpret_cast<LhsScalar*>(
                        (sizeof(LhsScalar) * sizeA <= 131072)
                            ? reinterpret_cast<void*>(
                                  (internal::UIntPtr(__builtin_alloca(sizeof(LhsScalar) * sizeA + 64 - 1)) + 64 - 1) &
                                  ~(std::size_t(64 - 1)))
                            : Eigen::internal::aligned_malloc(sizeof(LhsScalar) * sizeA));
          Eigen::internal::aligned_stack_memory_handler<LhsScalar> blockA_stack_memory_destructor(
              (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(LhsScalar) * sizeA > 131072);
          Eigen::internal::check_size_for_overflow<RhsScalar>(sizeB);
          RhsScalar* blockB =
              (blocking.blockB()) != 0
                  ? (blocking.blockB())
                  : reinterpret_cast<RhsScalar*>(
                        (sizeof(RhsScalar) * sizeB <= 131072)
                            ? reinterpret_cast<void*>(
                                  (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * sizeB + 64 - 1)) + 64 - 1) &
                                  ~(std::size_t(64 - 1)))
                            : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * sizeB));
          Eigen::internal::aligned_stack_memory_handler<RhsScalar> blockB_stack_memory_destructor(
              (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(RhsScalar) * sizeB > 131072);
          const bool pack_rhs_once = mc != rows && kc == depth && nc == cols;
          for (Index i2 = 0; i2 < rows; i2 += mc) {
            const Index actual_mc = (std::min)(i2 + mc, rows) - i2;
            for (Index k2 = 0; k2 < depth; k2 += kc) {
              const Index actual_kc = (std::min)(k2 + kc, depth) - k2;
              pack_lhs(blockA, lhs.getSubMapper(i2, k2), actual_kc, actual_mc);
              for (Index j2 = 0; j2 < cols; j2 += nc) {
                const Index actual_nc = (std::min)(j2 + nc, cols) - j2;
                if ((!pack_rhs_once) || i2 == 0)
                  pack_rhs(blockB, rhs.getSubMapper(k2, j2), actual_kc, actual_nc);
                gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
              }
            }
          }
        }
      }
    };
    template <typename Scalar, typename Index, typename Gemm, typename Lhs, typename Rhs, typename Dest, typename BlockingType>
    struct gemm_functor {
      gemm_functor(const Lhs& lhs, const Rhs& rhs, Dest& dest, const Scalar& actualAlpha, BlockingType& blocking)
          : m_lhs(lhs), m_rhs(rhs), m_dest(dest), m_actualAlpha(actualAlpha), m_blocking(blocking) {}
      void initParallelSession(Index num_threads) const {
        m_blocking.initParallel(m_lhs.rows(), m_rhs.cols(), m_lhs.cols(), num_threads);
        m_blocking.allocateA();
      }
      void operator()(Index row, Index rows, Index col = 0, Index cols = -1, GemmParallelInfo<Index>* info = 0) const {
        if (cols == -1)
          cols = m_rhs.cols();
        Gemm::run(rows,
                  cols,
                  m_lhs.cols(),
                  &m_lhs.coeffRef(row, 0),
                  m_lhs.outerStride(),
                  &m_rhs.coeffRef(0, col),
                  m_rhs.outerStride(),
                  (Scalar*)&(m_dest.coeffRef(row, col)),
                  m_dest.innerStride(),
                  m_dest.outerStride(),
                  m_actualAlpha,
                  m_blocking,
                  info);
      }
      typedef typename Gemm::Traits Traits;

    protected:
      const Lhs& m_lhs;
      const Rhs& m_rhs;
      Dest& m_dest;
      Scalar m_actualAlpha;
      BlockingType& m_blocking;
    };
    template <int StorageOrder,
              typename LhsScalar,
              typename RhsScalar,
              int MaxRows,
              int MaxCols,
              int MaxDepth,
              int KcFactor = 1,
              bool FiniteAtCompileTime = MaxRows != Dynamic && MaxCols != Dynamic && MaxDepth != Dynamic>
    class gemm_blocking_space;
    template <typename LhsScalar_, typename RhsScalar_>
    class level3_blocking {
      typedef LhsScalar_ LhsScalar;
      typedef RhsScalar_ RhsScalar;

    protected:
      LhsScalar* m_blockA;
      RhsScalar* m_blockB;
      Index m_mc;
      Index m_nc;
      Index m_kc;

    public:
      level3_blocking() : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0) {}
      inline Index mc() const { return m_mc; }
      inline Index nc() const { return m_nc; }
      inline Index kc() const { return m_kc; }
      inline LhsScalar* blockA() { return m_blockA; }
      inline RhsScalar* blockB() { return m_blockB; }
    };
    template <int StorageOrder, typename LhsScalar_, typename RhsScalar_, int MaxRows, int MaxCols, int MaxDepth, int KcFactor>
    class gemm_blocking_space<StorageOrder, LhsScalar_, RhsScalar_, MaxRows, MaxCols, MaxDepth, KcFactor, true>
        : public level3_blocking<std::conditional_t<StorageOrder == RowMajor, RhsScalar_, LhsScalar_>,
                                 std::conditional_t<StorageOrder == RowMajor, LhsScalar_, RhsScalar_>> {
      enum {
        Transpose = StorageOrder == RowMajor,
        ActualRows = Transpose ? MaxCols : MaxRows,
        ActualCols = Transpose ? MaxRows : MaxCols
      };
      typedef std::conditional_t<Transpose, RhsScalar_, LhsScalar_> LhsScalar;
      typedef std::conditional_t<Transpose, LhsScalar_, RhsScalar_> RhsScalar;
      enum { SizeA = ActualRows * MaxDepth, SizeB = ActualCols * MaxDepth };
      alignas(16) char m_staticA[SizeA * sizeof(LhsScalar) + 64 - 1];
      alignas(16) char m_staticB[SizeB * sizeof(RhsScalar) + 64 - 1];

    public:
      gemm_blocking_space(Index, Index, Index, Index, bool) {
        this->m_mc = ActualRows;
        this->m_nc = ActualCols;
        this->m_kc = MaxDepth;
        this->m_blockA = reinterpret_cast<LhsScalar*>((internal::UIntPtr(m_staticA) + (64 - 1)) & ~std::size_t(64 - 1));
        this->m_blockB = reinterpret_cast<RhsScalar*>((internal::UIntPtr(m_staticB) + (64 - 1)) & ~std::size_t(64 - 1));
      }
      void initParallel(Index, Index, Index, Index) {}
      inline void allocateA() {}
      inline void allocateB() {}
      inline void allocateAll() {}
    };
    template <int StorageOrder, typename LhsScalar_, typename RhsScalar_, int MaxRows, int MaxCols, int MaxDepth, int KcFactor>
    class gemm_blocking_space<StorageOrder, LhsScalar_, RhsScalar_, MaxRows, MaxCols, MaxDepth, KcFactor, false>
        : public level3_blocking<std::conditional_t<StorageOrder == RowMajor, RhsScalar_, LhsScalar_>,
                                 std::conditional_t<StorageOrder == RowMajor, LhsScalar_, RhsScalar_>> {
      enum { Transpose = StorageOrder == RowMajor };
      typedef std::conditional_t<Transpose, RhsScalar_, LhsScalar_> LhsScalar;
      typedef std::conditional_t<Transpose, LhsScalar_, RhsScalar_> RhsScalar;
      Index m_sizeA;
      Index m_sizeB;

    public:
      gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking) {
        this->m_mc = Transpose ? cols : rows;
        this->m_nc = Transpose ? rows : cols;
        this->m_kc = depth;
        if (l3_blocking) {
          computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
        } else {
          Index n = this->m_nc;
          computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, this->m_mc, n, num_threads);
        }
        m_sizeA = this->m_mc * this->m_kc;
        m_sizeB = this->m_kc * this->m_nc;
      }
      void initParallel(Index rows, Index cols, Index depth, Index num_threads) {
        this->m_mc = Transpose ? cols : rows;
        this->m_nc = Transpose ? rows : cols;
        this->m_kc = depth;
        ;
        Index m = this->m_mc;
        computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, m, this->m_nc, num_threads);
        m_sizeA = this->m_mc * this->m_kc;
        m_sizeB = this->m_kc * this->m_nc;
      }
      void allocateA() {
        if (this->m_blockA == 0)
          this->m_blockA = aligned_new<LhsScalar>(m_sizeA);
      }
      void allocateB() {
        if (this->m_blockB == 0)
          this->m_blockB = aligned_new<RhsScalar>(m_sizeB);
      }
      void allocateAll() {
        allocateA();
        allocateB();
      }
      ~gemm_blocking_space() {
        aligned_delete(this->m_blockA, m_sizeA);
        aligned_delete(this->m_blockB, m_sizeB);
      }
    };
  }  // namespace internal
  namespace internal {
    template <typename Lhs, typename Rhs>
    struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemmProduct>
        : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemmProduct>> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      typedef typename Lhs::Scalar LhsScalar;
      typedef typename Rhs::Scalar RhsScalar;
      typedef internal::blas_traits<Lhs> LhsBlasTraits;
      typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
      typedef internal::remove_all_t<ActualLhsType> ActualLhsTypeCleaned;
      typedef internal::blas_traits<Rhs> RhsBlasTraits;
      typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
      typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
      enum { MaxDepthAtCompileTime = min_size_prefer_fixed(Lhs::MaxColsAtCompileTime, Rhs::MaxRowsAtCompileTime) };
      typedef generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> lazyproduct;
      template <typename Dst>
      static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        if ((rhs.rows() + dst.rows() + dst.cols()) < 20 && rhs.rows() > 0)
          lazyproduct::eval_dynamic(dst, lhs, rhs, internal::assign_op<typename Dst::Scalar, Scalar>());
        else {
          dst.setZero();
          scaleAndAddTo(dst, lhs, rhs, Scalar(1));
        }
      }
      template <typename Dst>
      static void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        if ((rhs.rows() + dst.rows() + dst.cols()) < 20 && rhs.rows() > 0)
          lazyproduct::eval_dynamic(dst, lhs, rhs, internal::add_assign_op<typename Dst::Scalar, Scalar>());
        else
          scaleAndAddTo(dst, lhs, rhs, Scalar(1));
      }
      template <typename Dst>
      static void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
        if ((rhs.rows() + dst.rows() + dst.cols()) < 20 && rhs.rows() > 0)
          lazyproduct::eval_dynamic(dst, lhs, rhs, internal::sub_assign_op<typename Dst::Scalar, Scalar>());
        else
          scaleAndAddTo(dst, lhs, rhs, Scalar(-1));
      }
      template <typename Dest>
      static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
        (static_cast<bool>(dst.rows() == a_lhs.rows() && dst.cols() == a_rhs.cols())
             ? void(0)
             : __assert_fail("dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/products/GeneralMatrixMatrix.h",
                             471,
                             __extension__ __PRETTY_FUNCTION__));
        if (a_lhs.cols() == 0 || a_lhs.rows() == 0 || a_rhs.cols() == 0)
          return;
        if (dst.cols() == 1) {
          typename Dest::ColXpr dst_vec(dst.col(0));
          return internal::generic_product_impl<Lhs, typename Rhs::ConstColXpr, DenseShape, DenseShape, GemvProduct>::
              scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
        } else if (dst.rows() == 1) {
          typename Dest::RowXpr dst_vec(dst.row(0));
          return internal::generic_product_impl<typename Lhs::ConstRowXpr, Rhs, DenseShape, DenseShape, GemvProduct>::
              scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
        }
        add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
        add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
        Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
        typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                              LhsScalar,
                                              RhsScalar,
                                              Dest::MaxRowsAtCompileTime,
                                              Dest::MaxColsAtCompileTime,
                                              MaxDepthAtCompileTime>
            BlockingType;
        typedef internal::gemm_functor<
            Scalar,
            Index,
            internal::general_matrix_matrix_product<Index,
                                                    LhsScalar,
                                                    (ActualLhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                                    bool(LhsBlasTraits::NeedToConjugate),
                                                    RhsScalar,
                                                    (ActualRhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                                    bool(RhsBlasTraits::NeedToConjugate),
                                                    (Dest::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                                    Dest::InnerStrideAtCompileTime>,
            ActualLhsTypeCleaned,
            ActualRhsTypeCleaned,
            Dest,
            BlockingType>
            GemmFunctor;
        BlockingType blocking(dst.rows(), dst.cols(), lhs.cols(), 1, true);
        internal::parallelize_gemm<(Dest::MaxRowsAtCompileTime > 32 || Dest::MaxRowsAtCompileTime == Dynamic)>(
            GemmFunctor(lhs, rhs, dst, actualAlpha, blocking),
            a_lhs.rows(),
            a_rhs.cols(),
            a_lhs.cols(),
            Dest::Flags & RowMajorBit);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename LhsScalar, typename RhsScalar, typename Index, int Side, int Mode, bool Conjugate, int StorageOrder>
    struct triangular_solve_vector;
    template <typename Scalar,
              typename Index,
              int Side,
              int Mode,
              bool Conjugate,
              int TriStorageOrder,
              int OtherStorageOrder,
              int OtherInnerStride>
    struct triangular_solve_matrix;
    template <typename Lhs, typename Rhs, int Side>
    class trsolve_traits {
    private:
      enum { RhsIsVectorAtCompileTime = (Side == OnTheLeft ? Rhs::ColsAtCompileTime : Rhs::RowsAtCompileTime) == 1 };

    public:
      enum {
        Unrolling = (RhsIsVectorAtCompileTime && Rhs::SizeAtCompileTime != Dynamic && Rhs::SizeAtCompileTime <= 8)
                        ? CompleteUnrolling
                        : NoUnrolling,
        RhsVectors = RhsIsVectorAtCompileTime ? 1 : Dynamic
      };
    };
    template <typename Lhs,
              typename Rhs,
              int Side,
              int Mode,
              int Unrolling = trsolve_traits<Lhs, Rhs, Side>::Unrolling,
              int RhsVectors = trsolve_traits<Lhs, Rhs, Side>::RhsVectors>
    struct triangular_solver_selector;
    template <typename Lhs, typename Rhs, int Side, int Mode>
    struct triangular_solver_selector<Lhs, Rhs, Side, Mode, NoUnrolling, 1> {
      typedef typename Lhs::Scalar LhsScalar;
      typedef typename Rhs::Scalar RhsScalar;
      typedef blas_traits<Lhs> LhsProductTraits;
      typedef typename LhsProductTraits::ExtractType ActualLhsType;
      typedef Map<Matrix<RhsScalar, Dynamic, 1>, Aligned> MappedRhs;
      static void run(const Lhs& lhs, Rhs& rhs) {
        ActualLhsType actualLhs = LhsProductTraits::extract(lhs);
        bool useRhsDirectly = Rhs::InnerStrideAtCompileTime == 1 || rhs.innerStride() == 1;
        Eigen::internal::check_size_for_overflow<RhsScalar>(rhs.size());
        RhsScalar* actualRhs =
            ((useRhsDirectly ? rhs.data() : 0)) != 0
                ? ((useRhsDirectly ? rhs.data() : 0))
                : reinterpret_cast<RhsScalar*>(
                      (sizeof(RhsScalar) * rhs.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * rhs.size() + 64 - 1)) + 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * rhs.size()));
        Eigen::internal::aligned_stack_memory_handler<RhsScalar> actualRhs_stack_memory_destructor(
            ((useRhsDirectly ? rhs.data() : 0)) == 0 ? actualRhs : 0,
            rhs.size(),
            sizeof(RhsScalar) * rhs.size() > 131072);
        if (!useRhsDirectly)
          MappedRhs(actualRhs, rhs.size()) = rhs;
        triangular_solve_vector<LhsScalar,
                                RhsScalar,
                                Index,
                                Side,
                                Mode,
                                LhsProductTraits::NeedToConjugate,
                                (int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor>::run(actualLhs.cols(),
                                                                                            actualLhs.data(),
                                                                                            actualLhs.outerStride(),
                                                                                            actualRhs);
        if (!useRhsDirectly)
          rhs = MappedRhs(actualRhs, rhs.size());
      }
    };
    template <typename Lhs, typename Rhs, int Side, int Mode>
    struct triangular_solver_selector<Lhs, Rhs, Side, Mode, NoUnrolling, Dynamic> {
      typedef typename Rhs::Scalar Scalar;
      typedef blas_traits<Lhs> LhsProductTraits;
      typedef typename LhsProductTraits::DirectLinearAccessType ActualLhsType;
      static void run(const Lhs& lhs, Rhs& rhs) {
        add_const_on_value_type_t<ActualLhsType> actualLhs = LhsProductTraits::extract(lhs);
        const Index size = lhs.rows();
        const Index othersize = Side == OnTheLeft ? rhs.cols() : rhs.rows();
        typedef internal::gemm_blocking_space<(Rhs::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                              Scalar,
                                              Scalar,
                                              Rhs::MaxRowsAtCompileTime,
                                              Rhs::MaxColsAtCompileTime,
                                              Lhs::MaxRowsAtCompileTime,
                                              4>
            BlockingType;
        BlockingType blocking(rhs.rows(), rhs.cols(), size, 1, false);
        triangular_solve_matrix<Scalar,
                                Index,
                                Side,
                                Mode,
                                LhsProductTraits::NeedToConjugate,
                                (int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor,
                                (Rhs::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                Rhs::InnerStrideAtCompileTime>::run(size,
                                                                    othersize,
                                                                    &actualLhs.coeffRef(0, 0),
                                                                    actualLhs.outerStride(),
                                                                    &rhs.coeffRef(0, 0),
                                                                    rhs.innerStride(),
                                                                    rhs.outerStride(),
                                                                    blocking);
      }
    };
    template <typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size, bool Stop = LoopIndex == Size>
    struct triangular_solver_unroller;
    template <typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
    struct triangular_solver_unroller<Lhs, Rhs, Mode, LoopIndex, Size, false> {
      enum {
        IsLower = ((Mode & Lower) == Lower),
        DiagIndex = IsLower ? LoopIndex : Size - LoopIndex - 1,
        StartIndex = IsLower ? 0 : DiagIndex + 1
      };
      static void run(const Lhs& lhs, Rhs& rhs) {
        if (LoopIndex > 0)
          rhs.coeffRef(DiagIndex) -= lhs.row(DiagIndex)
                                         .template segment<LoopIndex>(StartIndex)
                                         .transpose()
                                         .cwiseProduct(rhs.template segment<LoopIndex>(StartIndex))
                                         .sum();
        if (!(Mode & UnitDiag))
          rhs.coeffRef(DiagIndex) /= lhs.coeff(DiagIndex, DiagIndex);
        triangular_solver_unroller<Lhs, Rhs, Mode, LoopIndex + 1, Size>::run(lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
    struct triangular_solver_unroller<Lhs, Rhs, Mode, LoopIndex, Size, true> {
      static void run(const Lhs&, Rhs&) {}
    };
    template <typename Lhs, typename Rhs, int Mode>
    struct triangular_solver_selector<Lhs, Rhs, OnTheLeft, Mode, CompleteUnrolling, 1> {
      static void run(const Lhs& lhs, Rhs& rhs) {
        triangular_solver_unroller<Lhs, Rhs, Mode, 0, Rhs::SizeAtCompileTime>::run(lhs, rhs);
      }
    };
    template <typename Lhs, typename Rhs, int Mode>
    struct triangular_solver_selector<Lhs, Rhs, OnTheRight, Mode, CompleteUnrolling, 1> {
      static void run(const Lhs& lhs, Rhs& rhs) {
        Transpose<const Lhs> trLhs(lhs);
        Transpose<Rhs> trRhs(rhs);
        triangular_solver_unroller<Transpose<const Lhs>,
                                   Transpose<Rhs>,
                                   ((Mode & Upper) == Upper ? Lower : Upper) | (Mode & UnitDiag),
                                   0,
                                   Rhs::SizeAtCompileTime>::run(trLhs, trRhs);
      }
    };
  }  // namespace internal
  template <typename MatrixType, unsigned int Mode>
  template <int Side, typename OtherDerived>
  void TriangularViewImpl<MatrixType, Mode, Dense>::solveInPlace(const MatrixBase<OtherDerived>& _other) const {
    OtherDerived& other = _other.const_cast_derived();
    (static_cast<bool>(derived().cols() == derived().rows() &&
                       ((Side == OnTheLeft && derived().cols() == other.rows()) ||
                        (Side == OnTheRight && derived().cols() == other.cols())))
         ? void(0)
         : __assert_fail("derived().cols() == derived().rows() && ((Side==OnTheLeft && derived().cols() == "
                         "other.rows()) || (Side==OnTheRight && derived().cols() == other.cols()))",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/SolveTriangular.h",
                         172,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>((!(int(Mode) & int(ZeroDiag))) && bool(int(Mode) & (int(Upper) | int(Lower))))
         ? void(0)
         : __assert_fail("(!(int(Mode) & int(ZeroDiag))) && bool(int(Mode) & (int(Upper) | int(Lower)))",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/SolveTriangular.h",
                         173,
                         __extension__ __PRETTY_FUNCTION__));
    if (derived().cols() == 0)
      return;
    enum {
      copy = (internal::traits<OtherDerived>::Flags & RowMajorBit) && OtherDerived::IsVectorAtCompileTime &&
             OtherDerived::SizeAtCompileTime != 1
    };
    typedef std::conditional_t<copy, typename internal::plain_matrix_type_column_major<OtherDerived>::type, OtherDerived&>
        OtherCopy;
    OtherCopy otherCopy(other);
    internal::triangular_solver_selector<MatrixType, std::remove_reference_t<OtherCopy>, Side, Mode>::run(
        derived().nestedExpression(), otherCopy);
    if (copy)
      other = otherCopy;
  }
  template <typename Derived, unsigned int Mode>
  template <int Side, typename Other>
  const internal::triangular_solve_retval<Side, TriangularView<Derived, Mode>, Other>
  TriangularViewImpl<Derived, Mode, Dense>::solve(const MatrixBase<Other>& other) const {
    return internal::triangular_solve_retval<Side, TriangularViewType, Other>(derived(), other.derived());
  }
  namespace internal {
    template <int Side, typename TriangularType, typename Rhs>
    struct traits<triangular_solve_retval<Side, TriangularType, Rhs>> {
      typedef typename internal::plain_matrix_type_column_major<Rhs>::type ReturnType;
    };
    template <int Side, typename TriangularType, typename Rhs>
    struct triangular_solve_retval : public ReturnByValue<triangular_solve_retval<Side, TriangularType, Rhs>> {
      typedef remove_all_t<typename Rhs::Nested> RhsNestedCleaned;
      typedef ReturnByValue<triangular_solve_retval> Base;
      triangular_solve_retval(const TriangularType& tri, const Rhs& rhs) : m_triangularMatrix(tri), m_rhs(rhs) {}
      inline constexpr Index rows() const noexcept { return m_rhs.rows(); }
      inline constexpr Index cols() const noexcept { return m_rhs.cols(); }
      template <typename Dest>
      inline void evalTo(Dest& dst) const {
        if (!is_same_dense(dst, m_rhs))
          dst = m_rhs;
        m_triangularMatrix.template solveInPlace<Side>(dst);
      }

    protected:
      const TriangularType& m_triangularMatrix;
      typename Rhs::Nested m_rhs;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar, typename Index, int StorageOrder, int UpLo, bool ConjLhs, bool ConjRhs>
  struct selfadjoint_rank1_update;
  namespace internal {
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              int mr,
              int nr,
              bool ConjLhs,
              bool ConjRhs,
              int ResInnerStride,
              int UpLo>
    struct tribb_kernel;
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResStorageOrder,
              int ResInnerStride,
              int UpLo,
              int Version = Specialized>
    struct general_matrix_matrix_triangular_product;
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int UpLo,
              int Version>
    struct general_matrix_matrix_triangular_product<Index,
                                                    LhsScalar,
                                                    LhsStorageOrder,
                                                    ConjugateLhs,
                                                    RhsScalar,
                                                    RhsStorageOrder,
                                                    ConjugateRhs,
                                                    RowMajor,
                                                    ResInnerStride,
                                                    UpLo,
                                                    Version> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      static inline void run(Index size,
                             Index depth,
                             const LhsScalar* lhs,
                             Index lhsStride,
                             const RhsScalar* rhs,
                             Index rhsStride,
                             ResScalar* res,
                             Index resIncr,
                             Index resStride,
                             const ResScalar& alpha,
                             level3_blocking<RhsScalar, LhsScalar>& blocking) {
        general_matrix_matrix_triangular_product<Index,
                                                 RhsScalar,
                                                 RhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                                 ConjugateRhs,
                                                 LhsScalar,
                                                 LhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                                 ConjugateLhs,
                                                 ColMajor,
                                                 ResInnerStride,
                                                 UpLo == Lower ? Upper : Lower>::run(size,
                                                                                     depth,
                                                                                     rhs,
                                                                                     rhsStride,
                                                                                     lhs,
                                                                                     lhsStride,
                                                                                     res,
                                                                                     resIncr,
                                                                                     resStride,
                                                                                     alpha,
                                                                                     blocking);
      }
    };
    template <typename Index,
              typename LhsScalar,
              int LhsStorageOrder,
              bool ConjugateLhs,
              typename RhsScalar,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int UpLo,
              int Version>
    struct general_matrix_matrix_triangular_product<Index,
                                                    LhsScalar,
                                                    LhsStorageOrder,
                                                    ConjugateLhs,
                                                    RhsScalar,
                                                    RhsStorageOrder,
                                                    ConjugateRhs,
                                                    ColMajor,
                                                    ResInnerStride,
                                                    UpLo,
                                                    Version> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      static inline void run(Index size,
                             Index depth,
                             const LhsScalar* _lhs,
                             Index lhsStride,
                             const RhsScalar* _rhs,
                             Index rhsStride,
                             ResScalar* _res,
                             Index resIncr,
                             Index resStride,
                             const ResScalar& alpha,
                             level3_blocking<LhsScalar, RhsScalar>& blocking) {
        typedef gebp_traits<LhsScalar, RhsScalar> Traits;
        typedef const_blas_data_mapper<LhsScalar, Index, LhsStorageOrder> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, RhsStorageOrder> RhsMapper;
        typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
        LhsMapper lhs(_lhs, lhsStride);
        RhsMapper rhs(_rhs, rhsStride);
        ResMapper res(_res, resStride, resIncr);
        Index kc = blocking.kc();
        Index mc = (std::min)(size, blocking.mc());
        if (mc > Traits::nr)
          mc = (mc / Traits::nr) * Traits::nr;
        std::size_t sizeA = kc * mc;
        std::size_t sizeB = kc * size;
        Eigen::internal::check_size_for_overflow<LhsScalar>(sizeA);
        LhsScalar* blockA =
            (blocking.blockA()) != 0
                ? (blocking.blockA())
                : reinterpret_cast<LhsScalar*>(
                      (sizeof(LhsScalar) * sizeA <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(LhsScalar) * sizeA + 64 - 1)) + 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(LhsScalar) * sizeA));
        Eigen::internal::aligned_stack_memory_handler<LhsScalar> blockA_stack_memory_destructor(
            (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(LhsScalar) * sizeA > 131072);
        Eigen::internal::check_size_for_overflow<RhsScalar>(sizeB);
        RhsScalar* blockB =
            (blocking.blockB()) != 0
                ? (blocking.blockB())
                : reinterpret_cast<RhsScalar*>(
                      (sizeof(RhsScalar) * sizeB <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * sizeB + 64 - 1)) + 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * sizeB));
        Eigen::internal::aligned_stack_memory_handler<RhsScalar> blockB_stack_memory_destructor(
            (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(RhsScalar) * sizeB > 131072);
        gemm_pack_lhs<LhsScalar,
                      Index,
                      LhsMapper,
                      Traits::mr,
                      Traits::LhsProgress,
                      typename Traits::LhsPacket4Packing,
                      LhsStorageOrder>
            pack_lhs;
        gemm_pack_rhs<RhsScalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
        gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp;
        tribb_kernel<LhsScalar, RhsScalar, Index, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs, ResInnerStride, UpLo>
            sybb;
        for (Index k2 = 0; k2 < depth; k2 += kc) {
          const Index actual_kc = (std::min)(k2 + kc, depth) - k2;
          pack_rhs(blockB, rhs.getSubMapper(k2, 0), actual_kc, size);
          for (Index i2 = 0; i2 < size; i2 += mc) {
            const Index actual_mc = (std::min)(i2 + mc, size) - i2;
            pack_lhs(blockA, lhs.getSubMapper(i2, k2), actual_kc, actual_mc);
            if (UpLo == Lower)
              gebp(res.getSubMapper(i2, 0),
                   blockA,
                   blockB,
                   actual_mc,
                   actual_kc,
                   (std::min)(size, i2),
                   alpha,
                   -1,
                   -1,
                   0,
                   0);
            sybb(_res + resStride * i2 + resIncr * i2,
                 resIncr,
                 resStride,
                 blockA,
                 blockB + actual_kc * i2,
                 actual_mc,
                 actual_kc,
                 alpha);
            if (UpLo == Upper) {
              Index j2 = i2 + actual_mc;
              gebp(res.getSubMapper(i2, j2),
                   blockA,
                   blockB + actual_kc * j2,
                   actual_mc,
                   actual_kc,
                   (std::max)(Index(0), size - j2),
                   alpha,
                   -1,
                   -1,
                   0,
                   0);
            }
          }
        }
      }
    };
    template <typename LhsScalar,
              typename RhsScalar,
              typename Index,
              int mr,
              int nr,
              bool ConjLhs,
              bool ConjRhs,
              int ResInnerStride,
              int UpLo>
    struct tribb_kernel {
      typedef gebp_traits<LhsScalar, RhsScalar, ConjLhs, ConjRhs> Traits;
      typedef typename Traits::ResScalar ResScalar;
      enum { BlockSize = meta_least_common_multiple<plain_enum_max(mr, nr), plain_enum_min(mr, nr)>::ret };
      void operator()(ResScalar* _res,
                      Index resIncr,
                      Index resStride,
                      const LhsScalar* blockA,
                      const RhsScalar* blockB,
                      Index size,
                      Index depth,
                      const ResScalar& alpha) {
        typedef blas_data_mapper<ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
        typedef blas_data_mapper<ResScalar, Index, ColMajor, Unaligned> BufferMapper;
        ResMapper res(_res, resStride, resIncr);
        gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, mr, nr, ConjLhs, ConjRhs> gebp_kernel1;
        gebp_kernel<LhsScalar, RhsScalar, Index, BufferMapper, mr, nr, ConjLhs, ConjRhs> gebp_kernel2;
        Matrix<ResScalar, BlockSize, BlockSize, ColMajor> buffer(
            (internal::constructor_without_unaligned_array_assert()));
        for (Index j = 0; j < size; j += BlockSize) {
          Index actualBlockSize = std::min<Index>(BlockSize, size - j);
          const RhsScalar* actual_b = blockB + j * depth;
          if (UpLo == Upper)
            gebp_kernel1(res.getSubMapper(0, j), blockA, actual_b, j, depth, actualBlockSize, alpha, -1, -1, 0, 0);
          {
            Index i = j;
            buffer.setZero();
            gebp_kernel2(BufferMapper(buffer.data(), BlockSize),
                         blockA + depth * i,
                         actual_b,
                         actualBlockSize,
                         depth,
                         actualBlockSize,
                         alpha,
                         -1,
                         -1,
                         0,
                         0);
            for (Index j1 = 0; j1 < actualBlockSize; ++j1) {
              typename ResMapper::LinearMapper r = res.getLinearMapper(i, j + j1);
              for (Index i1 = UpLo == Lower ? j1 : 0; UpLo == Lower ? i1 < actualBlockSize : i1 <= j1; ++i1)
                r(i1) += buffer(i1, j1);
            }
          }
          if (UpLo == Lower) {
            Index i = j + actualBlockSize;
            gebp_kernel1(res.getSubMapper(i, j),
                         blockA + depth * i,
                         actual_b,
                         size - i,
                         depth,
                         actualBlockSize,
                         alpha,
                         -1,
                         -1,
                         0,
                         0);
          }
        }
      }
    };
  }  // namespace internal
  template <typename MatrixType, typename ProductType, int UpLo, bool IsOuterProduct>
  struct general_product_to_triangular_selector;
  template <typename MatrixType, typename ProductType, int UpLo>
  struct general_product_to_triangular_selector<MatrixType, ProductType, UpLo, true> {
    static void run(MatrixType& mat, const ProductType& prod, const typename MatrixType::Scalar& alpha, bool beta) {
      typedef typename MatrixType::Scalar Scalar;
      typedef internal::remove_all_t<typename ProductType::LhsNested> Lhs;
      typedef internal::blas_traits<Lhs> LhsBlasTraits;
      typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhs;
      typedef internal::remove_all_t<ActualLhs> ActualLhs_;
      internal::add_const_on_value_type_t<ActualLhs> actualLhs = LhsBlasTraits::extract(prod.lhs());
      typedef internal::remove_all_t<typename ProductType::RhsNested> Rhs;
      typedef internal::blas_traits<Rhs> RhsBlasTraits;
      typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhs;
      typedef internal::remove_all_t<ActualRhs> ActualRhs_;
      internal::add_const_on_value_type_t<ActualRhs> actualRhs = RhsBlasTraits::extract(prod.rhs());
      Scalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(prod.lhs().derived()) *
                           RhsBlasTraits::extractScalarFactor(prod.rhs().derived());
      if (!beta)
        mat.template triangularView<UpLo>().setZero();
      enum {
        StorageOrder = (internal::traits<MatrixType>::Flags & RowMajorBit) ? RowMajor : ColMajor,
        UseLhsDirectly = ActualLhs_::InnerStrideAtCompileTime == 1,
        UseRhsDirectly = ActualRhs_::InnerStrideAtCompileTime == 1
      };
      internal::gemv_static_vector_if<Scalar, Lhs::SizeAtCompileTime, Lhs::MaxSizeAtCompileTime, !UseLhsDirectly>
          static_lhs;
      Eigen::internal::check_size_for_overflow<Scalar>(actualLhs.size());
      Scalar* actualLhsPtr =
          ((UseLhsDirectly ? const_cast<Scalar*>(actualLhs.data()) : static_lhs.data())) != 0
              ? ((UseLhsDirectly ? const_cast<Scalar*>(actualLhs.data()) : static_lhs.data()))
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * actualLhs.size() <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * actualLhs.size() + 64 - 1)) + 64 -
                               1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * actualLhs.size()));
      Eigen::internal::aligned_stack_memory_handler<Scalar> actualLhsPtr_stack_memory_destructor(
          ((UseLhsDirectly ? const_cast<Scalar*>(actualLhs.data()) : static_lhs.data())) == 0 ? actualLhsPtr : 0,
          actualLhs.size(),
          sizeof(Scalar) * actualLhs.size() > 131072);
      if (!UseLhsDirectly)
        Map<typename ActualLhs_::PlainObject>(actualLhsPtr, actualLhs.size()) = actualLhs;
      internal::gemv_static_vector_if<Scalar, Rhs::SizeAtCompileTime, Rhs::MaxSizeAtCompileTime, !UseRhsDirectly>
          static_rhs;
      Eigen::internal::check_size_for_overflow<Scalar>(actualRhs.size());
      Scalar* actualRhsPtr =
          ((UseRhsDirectly ? const_cast<Scalar*>(actualRhs.data()) : static_rhs.data())) != 0
              ? ((UseRhsDirectly ? const_cast<Scalar*>(actualRhs.data()) : static_rhs.data()))
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * actualRhs.size() <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * actualRhs.size() + 64 - 1)) + 64 -
                               1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * actualRhs.size()));
      Eigen::internal::aligned_stack_memory_handler<Scalar> actualRhsPtr_stack_memory_destructor(
          ((UseRhsDirectly ? const_cast<Scalar*>(actualRhs.data()) : static_rhs.data())) == 0 ? actualRhsPtr : 0,
          actualRhs.size(),
          sizeof(Scalar) * actualRhs.size() > 131072);
      if (!UseRhsDirectly)
        Map<typename ActualRhs_::PlainObject>(actualRhsPtr, actualRhs.size()) = actualRhs;
      selfadjoint_rank1_update<Scalar,
                               Index,
                               StorageOrder,
                               UpLo,
                               LhsBlasTraits::NeedToConjugate && NumTraits<Scalar>::IsComplex,
                               RhsBlasTraits::NeedToConjugate && NumTraits<Scalar>::IsComplex>::run(actualLhs.size(),
                                                                                                    mat.data(),
                                                                                                    mat.outerStride(),
                                                                                                    actualLhsPtr,
                                                                                                    actualRhsPtr,
                                                                                                    actualAlpha);
    }
  };
  template <typename MatrixType, typename ProductType, int UpLo>
  struct general_product_to_triangular_selector<MatrixType, ProductType, UpLo, false> {
    static void run(MatrixType& mat, const ProductType& prod, const typename MatrixType::Scalar& alpha, bool beta) {
      typedef internal::remove_all_t<typename ProductType::LhsNested> Lhs;
      typedef internal::blas_traits<Lhs> LhsBlasTraits;
      typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhs;
      typedef internal::remove_all_t<ActualLhs> ActualLhs_;
      internal::add_const_on_value_type_t<ActualLhs> actualLhs = LhsBlasTraits::extract(prod.lhs());
      typedef internal::remove_all_t<typename ProductType::RhsNested> Rhs;
      typedef internal::blas_traits<Rhs> RhsBlasTraits;
      typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhs;
      typedef internal::remove_all_t<ActualRhs> ActualRhs_;
      internal::add_const_on_value_type_t<ActualRhs> actualRhs = RhsBlasTraits::extract(prod.rhs());
      typename ProductType::Scalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(prod.lhs().derived()) *
                                                 RhsBlasTraits::extractScalarFactor(prod.rhs().derived());
      if (!beta)
        mat.template triangularView<UpLo>().setZero();
      enum {
        IsRowMajor = (internal::traits<MatrixType>::Flags & RowMajorBit) ? 1 : 0,
        LhsIsRowMajor = ActualLhs_::Flags & RowMajorBit ? 1 : 0,
        RhsIsRowMajor = ActualRhs_::Flags & RowMajorBit ? 1 : 0,
        SkipDiag = (UpLo & (UnitDiag | ZeroDiag)) != 0
      };
      Index size = mat.cols();
      if (SkipDiag)
        size--;
      Index depth = actualLhs.cols();
      typedef internal::gemm_blocking_space<IsRowMajor ? RowMajor : ColMajor,
                                            typename Lhs::Scalar,
                                            typename Rhs::Scalar,
                                            MatrixType::MaxColsAtCompileTime,
                                            MatrixType::MaxColsAtCompileTime,
                                            ActualRhs_::MaxColsAtCompileTime>
          BlockingType;
      BlockingType blocking(size, size, depth, 1, false);
      internal::general_matrix_matrix_triangular_product<
          Index,
          typename Lhs::Scalar,
          LhsIsRowMajor ? RowMajor : ColMajor,
          LhsBlasTraits::NeedToConjugate,
          typename Rhs::Scalar,
          RhsIsRowMajor ? RowMajor : ColMajor,
          RhsBlasTraits::NeedToConjugate,
          IsRowMajor ? RowMajor : ColMajor,
          MatrixType::InnerStrideAtCompileTime,
          UpLo&(Lower | Upper)>::run(size,
                                     depth,
                                     &actualLhs.coeffRef(SkipDiag && (UpLo & Lower) == Lower ? 1 : 0, 0),
                                     actualLhs.outerStride(),
                                     &actualRhs.coeffRef(0, SkipDiag && (UpLo & Upper) == Upper ? 1 : 0),
                                     actualRhs.outerStride(),
                                     mat.data() +
                                         (SkipDiag ? (bool(IsRowMajor) != ((UpLo & Lower) == Lower) ? mat.innerStride()
                                                                                                    : mat.outerStride())
                                                   : 0),
                                     mat.innerStride(),
                                     mat.outerStride(),
                                     actualAlpha,
                                     blocking);
    }
  };
  template <typename MatrixType, unsigned int UpLo>
  template <typename ProductType>
  TriangularView<MatrixType, UpLo>& TriangularViewImpl<MatrixType, UpLo, Dense>::_assignProduct(const ProductType& prod,
                                                                                                const Scalar& alpha,
                                                                                                bool beta) {
    static_assert((UpLo & UnitDiag) == 0, "WRITING_TO_TRIANGULAR_PART_WITH_UNIT_DIAGONAL_IS_NOT_SUPPORTED");
    ;
    (static_cast<bool>(derived().nestedExpression().rows() == prod.rows() && derived().cols() == prod.cols())
         ? void(0)
         : __assert_fail("derived().nestedExpression().rows() == prod.rows() && derived().cols() == prod.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h",
                         315,
                         __extension__ __PRETTY_FUNCTION__));
    general_product_to_triangular_selector<MatrixType, ProductType, UpLo, internal::traits<ProductType>::InnerSize == 1>::
        run(derived().nestedExpression().const_cast_derived(), prod, alpha, beta);
    return derived();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar,
              typename Index,
              int StorageOrder,
              int UpLo,
              bool ConjugateLhs,
              bool ConjugateRhs,
              int Version = Specialized>
    struct selfadjoint_matrix_vector_product;
    template <typename Scalar, typename Index, int StorageOrder, int UpLo, bool ConjugateLhs, bool ConjugateRhs, int Version>
    struct selfadjoint_matrix_vector_product {
      static __attribute__((noinline)) void run(
          Index size, const Scalar* lhs, Index lhsStride, const Scalar* rhs, Scalar* res, Scalar alpha);
    };
    template <typename Scalar, typename Index, int StorageOrder, int UpLo, bool ConjugateLhs, bool ConjugateRhs, int Version>
    __attribute__((noinline)) void
    selfadjoint_matrix_vector_product<Scalar, Index, StorageOrder, UpLo, ConjugateLhs, ConjugateRhs, Version>::run(
        Index size, const Scalar* lhs, Index lhsStride, const Scalar* rhs, Scalar* res, Scalar alpha) {
      typedef typename packet_traits<Scalar>::type Packet;
      typedef typename NumTraits<Scalar>::Real RealScalar;
      const Index PacketSize = sizeof(Packet) / sizeof(Scalar);
      enum {
        IsRowMajor = StorageOrder == RowMajor ? 1 : 0,
        IsLower = UpLo == Lower ? 1 : 0,
        FirstTriangular = IsRowMajor == IsLower
      };
      conj_helper<Scalar, Scalar, NumTraits<Scalar>::IsComplex && logical_xor(ConjugateLhs, IsRowMajor), ConjugateRhs>
          cj0;
      conj_helper<Scalar, Scalar, NumTraits<Scalar>::IsComplex && logical_xor(ConjugateLhs, !IsRowMajor), ConjugateRhs>
          cj1;
      conj_helper<RealScalar, Scalar, false, ConjugateRhs> cjd;
      conj_helper<Packet, Packet, NumTraits<Scalar>::IsComplex && logical_xor(ConjugateLhs, IsRowMajor), ConjugateRhs>
          pcj0;
      conj_helper<Packet, Packet, NumTraits<Scalar>::IsComplex && logical_xor(ConjugateLhs, !IsRowMajor), ConjugateRhs>
          pcj1;
      Scalar cjAlpha = ConjugateRhs ? numext::conj(alpha) : alpha;
      Index bound = numext::maxi(Index(0), size - 8) & 0xfffffffe;
      if (FirstTriangular)
        bound = size - bound;
      for (Index j = FirstTriangular ? bound : 0; j < (FirstTriangular ? size : bound); j += 2) {
        const Scalar* __restrict A0 = lhs + j * lhsStride;
        const Scalar* __restrict A1 = lhs + (j + 1) * lhsStride;
        Scalar t0 = cjAlpha * rhs[j];
        Packet ptmp0 = pset1<Packet>(t0);
        Scalar t1 = cjAlpha * rhs[j + 1];
        Packet ptmp1 = pset1<Packet>(t1);
        Scalar t2(0);
        Packet ptmp2 = pset1<Packet>(t2);
        Scalar t3(0);
        Packet ptmp3 = pset1<Packet>(t3);
        Index starti = FirstTriangular ? 0 : j + 2;
        Index endi = FirstTriangular ? j : size;
        Index alignedStart = (starti) + internal::first_default_aligned(&res[starti], endi - starti);
        Index alignedEnd = alignedStart + ((endi - alignedStart) / (PacketSize)) * (PacketSize);
        res[j] += cjd.pmul(numext::real(A0[j]), t0);
        res[j + 1] += cjd.pmul(numext::real(A1[j + 1]), t1);
        if (FirstTriangular) {
          res[j] += cj0.pmul(A1[j], t1);
          t3 += cj1.pmul(A1[j], rhs[j]);
        } else {
          res[j + 1] += cj0.pmul(A0[j + 1], t0);
          t2 += cj1.pmul(A0[j + 1], rhs[j + 1]);
        }
        for (Index i = starti; i < alignedStart; ++i) {
          res[i] += cj0.pmul(A0[i], t0) + cj0.pmul(A1[i], t1);
          t2 += cj1.pmul(A0[i], rhs[i]);
          t3 += cj1.pmul(A1[i], rhs[i]);
        }
        const Scalar* __restrict a0It = A0 + alignedStart;
        const Scalar* __restrict a1It = A1 + alignedStart;
        const Scalar* __restrict rhsIt = rhs + alignedStart;
        Scalar* __restrict resIt = res + alignedStart;
        for (Index i = alignedStart; i < alignedEnd; i += PacketSize) {
          Packet A0i = ploadu<Packet>(a0It);
          a0It += PacketSize;
          Packet A1i = ploadu<Packet>(a1It);
          a1It += PacketSize;
          Packet Bi = ploadu<Packet>(rhsIt);
          rhsIt += PacketSize;
          Packet Xi = pload<Packet>(resIt);
          Xi = pcj0.pmadd(A0i, ptmp0, pcj0.pmadd(A1i, ptmp1, Xi));
          ptmp2 = pcj1.pmadd(A0i, Bi, ptmp2);
          ptmp3 = pcj1.pmadd(A1i, Bi, ptmp3);
          pstore(resIt, Xi);
          resIt += PacketSize;
        }
        for (Index i = alignedEnd; i < endi; i++) {
          res[i] += cj0.pmul(A0[i], t0) + cj0.pmul(A1[i], t1);
          t2 += cj1.pmul(A0[i], rhs[i]);
          t3 += cj1.pmul(A1[i], rhs[i]);
        }
        res[j] += alpha * (t2 + predux(ptmp2));
        res[j + 1] += alpha * (t3 + predux(ptmp3));
      }
      for (Index j = FirstTriangular ? 0 : bound; j < (FirstTriangular ? bound : size); j++) {
        const Scalar* __restrict A0 = lhs + j * lhsStride;
        Scalar t1 = cjAlpha * rhs[j];
        Scalar t2(0);
        res[j] += cjd.pmul(numext::real(A0[j]), t1);
        for (Index i = FirstTriangular ? 0 : j + 1; i < (FirstTriangular ? j : size); i++) {
          res[i] += cj0.pmul(A0[i], t1);
          t2 += cj1.pmul(A0[i], rhs[i]);
        }
        res[j] += alpha * t2;
      }
    }
  }  // namespace internal
  namespace internal {
    template <typename Lhs, int LhsMode, typename Rhs>
    struct selfadjoint_product_impl<Lhs, LhsMode, false, Rhs, 0, true> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      typedef internal::blas_traits<Lhs> LhsBlasTraits;
      typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
      typedef internal::remove_all_t<ActualLhsType> ActualLhsTypeCleaned;
      typedef internal::blas_traits<Rhs> RhsBlasTraits;
      typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
      typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
      enum { LhsUpLo = LhsMode & (Upper | Lower) };
      template <typename Dest>
      static void run(Dest& dest, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
        typedef typename Dest::Scalar ResScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef Map<Matrix<ResScalar, Dynamic, 1>, plain_enum_min(AlignedMax, internal::packet_traits<ResScalar>::size)>
            MappedDest;
        (static_cast<bool>(dest.rows() == a_lhs.rows() && dest.cols() == a_rhs.cols())
             ? void(0)
             : __assert_fail("dest.rows()==a_lhs.rows() && dest.cols()==a_rhs.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/products/SelfadjointMatrixVector.h",
                             188,
                             __extension__ __PRETTY_FUNCTION__));
        add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
        add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
        Scalar actualAlpha =
            alpha * LhsBlasTraits::extractScalarFactor(a_lhs) * RhsBlasTraits::extractScalarFactor(a_rhs);
        enum {
          EvalToDest = (Dest::InnerStrideAtCompileTime == 1),
          UseRhs = (ActualRhsTypeCleaned::InnerStrideAtCompileTime == 1)
        };
        internal::gemv_static_vector_if<ResScalar, Dest::SizeAtCompileTime, Dest::MaxSizeAtCompileTime, !EvalToDest>
            static_dest;
        internal::gemv_static_vector_if<RhsScalar,
                                        ActualRhsTypeCleaned::SizeAtCompileTime,
                                        ActualRhsTypeCleaned::MaxSizeAtCompileTime,
                                        !UseRhs>
            static_rhs;
        Eigen::internal::check_size_for_overflow<ResScalar>(dest.size());
        ResScalar* actualDestPtr =
            (EvalToDest ? dest.data() : static_dest.data()) != 0
                ? (EvalToDest ? dest.data() : static_dest.data())
                : reinterpret_cast<ResScalar*>(
                      (sizeof(ResScalar) * dest.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(ResScalar) * dest.size() + 64 - 1)) + 64 -
                                 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(ResScalar) * dest.size()));
        Eigen::internal::aligned_stack_memory_handler<ResScalar> actualDestPtr_stack_memory_destructor(
            (EvalToDest ? dest.data() : static_dest.data()) == 0 ? actualDestPtr : 0,
            dest.size(),
            sizeof(ResScalar) * dest.size() > 131072);
        Eigen::internal::check_size_for_overflow<RhsScalar>(rhs.size());
        RhsScalar* actualRhsPtr =
            (UseRhs ? const_cast<RhsScalar*>(rhs.data()) : static_rhs.data()) != 0
                ? (UseRhs ? const_cast<RhsScalar*>(rhs.data()) : static_rhs.data())
                : reinterpret_cast<RhsScalar*>(
                      (sizeof(RhsScalar) * rhs.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * rhs.size() + 64 - 1)) + 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * rhs.size()));
        Eigen::internal::aligned_stack_memory_handler<RhsScalar> actualRhsPtr_stack_memory_destructor(
            (UseRhs ? const_cast<RhsScalar*>(rhs.data()) : static_rhs.data()) == 0 ? actualRhsPtr : 0,
            rhs.size(),
            sizeof(RhsScalar) * rhs.size() > 131072);
        if (!EvalToDest) {
          MappedDest(actualDestPtr, dest.size()) = dest;
        }
        if (!UseRhs) {
          Map<typename ActualRhsTypeCleaned::PlainObject>(actualRhsPtr, rhs.size()) = rhs;
        }
        internal::selfadjoint_matrix_vector_product<
            Scalar,
            Index,
            (internal::traits<ActualLhsTypeCleaned>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            int(LhsUpLo),
            bool(LhsBlasTraits::NeedToConjugate),
            bool(RhsBlasTraits::NeedToConjugate)>::run(lhs.rows(),
                                                       &lhs.coeffRef(0, 0),
                                                       lhs.outerStride(),
                                                       actualRhsPtr,
                                                       actualDestPtr,
                                                       actualAlpha);
        if (!EvalToDest)
          dest = MappedDest(actualDestPtr, dest.size());
      }
    };
    template <typename Lhs, typename Rhs, int RhsMode>
    struct selfadjoint_product_impl<Lhs, 0, true, Rhs, RhsMode, false> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      enum { RhsUpLo = RhsMode & (Upper | Lower) };
      template <typename Dest>
      static void run(Dest& dest, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
        Transpose<Dest> destT(dest);
        selfadjoint_product_impl<Transpose<const Rhs>,
                                 int(RhsUpLo) == Upper ? Lower : Upper,
                                 false,
                                 Transpose<const Lhs>,
                                 0,
                                 true>::run(destT, a_rhs.transpose(), a_lhs.transpose(), alpha);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar, typename Index, int Pack1, int Pack2_dummy, int StorageOrder>
    struct symm_pack_lhs {
      template <int BlockRows>
      inline void pack(Scalar* blockA,
                       const const_blas_data_mapper<Scalar, Index, StorageOrder>& lhs,
                       Index cols,
                       Index i,
                       Index& count) {
        for (Index k = 0; k < i; k++)
          for (Index w = 0; w < BlockRows; w++)
            blockA[count++] = lhs(i + w, k);
        Index h = 0;
        for (Index k = i; k < i + BlockRows; k++) {
          for (Index w = 0; w < h; w++)
            blockA[count++] = numext::conj(lhs(k, i + w));
          blockA[count++] = numext::real(lhs(k, k));
          for (Index w = h + 1; w < BlockRows; w++)
            blockA[count++] = lhs(i + w, k);
          ++h;
        }
        for (Index k = i + BlockRows; k < cols; k++)
          for (Index w = 0; w < BlockRows; w++)
            blockA[count++] = numext::conj(lhs(k, i + w));
      }
      void operator()(Scalar* blockA, const Scalar* _lhs, Index lhsStride, Index cols, Index rows) {
        typedef typename unpacket_traits<typename packet_traits<Scalar>::type>::half HalfPacket;
        typedef typename unpacket_traits<typename unpacket_traits<typename packet_traits<Scalar>::type>::half>::half
            QuarterPacket;
        enum {
          PacketSize = packet_traits<Scalar>::size,
          HalfPacketSize = unpacket_traits<HalfPacket>::size,
          QuarterPacketSize = unpacket_traits<QuarterPacket>::size,
          HasHalf = (int)HalfPacketSize < (int)PacketSize,
          HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize
        };
        const_blas_data_mapper<Scalar, Index, StorageOrder> lhs(_lhs, lhsStride);
        Index count = 0;
        const Index peeled_mc3 = Pack1 >= 3 * PacketSize ? (rows / (3 * PacketSize)) * (3 * PacketSize) : 0;
        const Index peeled_mc2 =
            Pack1 >= 2 * PacketSize ? peeled_mc3 + ((rows - peeled_mc3) / (2 * PacketSize)) * (2 * PacketSize) : 0;
        const Index peeled_mc1 =
            Pack1 >= 1 * PacketSize ? peeled_mc2 + ((rows - peeled_mc2) / (1 * PacketSize)) * (1 * PacketSize) : 0;
        const Index peeled_mc_half =
            Pack1 >= HalfPacketSize ? peeled_mc1 + ((rows - peeled_mc1) / (HalfPacketSize)) * (HalfPacketSize) : 0;
        const Index peeled_mc_quarter =
            Pack1 >= QuarterPacketSize
                ? peeled_mc_half + ((rows - peeled_mc_half) / (QuarterPacketSize)) * (QuarterPacketSize)
                : 0;
        if (Pack1 >= 3 * PacketSize)
          for (Index i = 0; i < peeled_mc3; i += 3 * PacketSize)
            pack<3 * PacketSize>(blockA, lhs, cols, i, count);
        if (Pack1 >= 2 * PacketSize)
          for (Index i = peeled_mc3; i < peeled_mc2; i += 2 * PacketSize)
            pack<2 * PacketSize>(blockA, lhs, cols, i, count);
        if (Pack1 >= 1 * PacketSize)
          for (Index i = peeled_mc2; i < peeled_mc1; i += 1 * PacketSize)
            pack<1 * PacketSize>(blockA, lhs, cols, i, count);
        if (HasHalf && Pack1 >= HalfPacketSize)
          for (Index i = peeled_mc1; i < peeled_mc_half; i += HalfPacketSize)
            pack<HalfPacketSize>(blockA, lhs, cols, i, count);
        if (HasQuarter && Pack1 >= QuarterPacketSize)
          for (Index i = peeled_mc_half; i < peeled_mc_quarter; i += QuarterPacketSize)
            pack<QuarterPacketSize>(blockA, lhs, cols, i, count);
        for (Index i = peeled_mc_quarter; i < rows; i++) {
          for (Index k = 0; k < i; k++)
            blockA[count++] = lhs(i, k);
          blockA[count++] = numext::real(lhs(i, i));
          for (Index k = i + 1; k < cols; k++)
            blockA[count++] = numext::conj(lhs(k, i));
        }
      }
    };
    template <typename Scalar, typename Index, int nr, int StorageOrder>
    struct symm_pack_rhs {
      enum { PacketSize = packet_traits<Scalar>::size };
      void operator()(Scalar* blockB, const Scalar* _rhs, Index rhsStride, Index rows, Index cols, Index k2) {
        Index end_k = k2 + rows;
        Index count = 0;
        const_blas_data_mapper<Scalar, Index, StorageOrder> rhs(_rhs, rhsStride);
        Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
        Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
        for (Index j2 = 0; j2 < k2; j2 += nr) {
          for (Index k = k2; k < end_k; k++) {
            blockB[count + 0] = rhs(k, j2 + 0);
            blockB[count + 1] = rhs(k, j2 + 1);
            if (nr >= 4) {
              blockB[count + 2] = rhs(k, j2 + 2);
              blockB[count + 3] = rhs(k, j2 + 3);
            }
            if (nr >= 8) {
              blockB[count + 4] = rhs(k, j2 + 4);
              blockB[count + 5] = rhs(k, j2 + 5);
              blockB[count + 6] = rhs(k, j2 + 6);
              blockB[count + 7] = rhs(k, j2 + 7);
            }
            count += nr;
          }
        }
        Index end8 = nr >= 8 ? (std::min)(k2 + rows, packet_cols8) : k2;
        if (nr >= 8) {
          for (Index j2 = k2; j2 < end8; j2 += 8) {
            for (Index k = k2; k < j2; k++) {
              blockB[count + 0] = numext::conj(rhs(j2 + 0, k));
              blockB[count + 1] = numext::conj(rhs(j2 + 1, k));
              blockB[count + 2] = numext::conj(rhs(j2 + 2, k));
              blockB[count + 3] = numext::conj(rhs(j2 + 3, k));
              blockB[count + 4] = numext::conj(rhs(j2 + 4, k));
              blockB[count + 5] = numext::conj(rhs(j2 + 5, k));
              blockB[count + 6] = numext::conj(rhs(j2 + 6, k));
              blockB[count + 7] = numext::conj(rhs(j2 + 7, k));
              count += 8;
            }
            Index h = 0;
            for (Index k = j2; k < j2 + 8; k++) {
              for (Index w = 0; w < h; ++w)
                blockB[count + w] = rhs(k, j2 + w);
              blockB[count + h] = numext::real(rhs(k, k));
              for (Index w = h + 1; w < 8; ++w)
                blockB[count + w] = numext::conj(rhs(j2 + w, k));
              count += 8;
              ++h;
            }
            for (Index k = j2 + 8; k < end_k; k++) {
              blockB[count + 0] = rhs(k, j2 + 0);
              blockB[count + 1] = rhs(k, j2 + 1);
              blockB[count + 2] = rhs(k, j2 + 2);
              blockB[count + 3] = rhs(k, j2 + 3);
              blockB[count + 4] = rhs(k, j2 + 4);
              blockB[count + 5] = rhs(k, j2 + 5);
              blockB[count + 6] = rhs(k, j2 + 6);
              blockB[count + 7] = rhs(k, j2 + 7);
              count += 8;
            }
          }
        }
        if (nr >= 4) {
          for (Index j2 = end8; j2 < (std::min)(k2 + rows, packet_cols4); j2 += 4) {
            for (Index k = k2; k < j2; k++) {
              blockB[count + 0] = numext::conj(rhs(j2 + 0, k));
              blockB[count + 1] = numext::conj(rhs(j2 + 1, k));
              blockB[count + 2] = numext::conj(rhs(j2 + 2, k));
              blockB[count + 3] = numext::conj(rhs(j2 + 3, k));
              count += 4;
            }
            Index h = 0;
            for (Index k = j2; k < j2 + 4; k++) {
              for (Index w = 0; w < h; ++w)
                blockB[count + w] = rhs(k, j2 + w);
              blockB[count + h] = numext::real(rhs(k, k));
              for (Index w = h + 1; w < 4; ++w)
                blockB[count + w] = numext::conj(rhs(j2 + w, k));
              count += 4;
              ++h;
            }
            for (Index k = j2 + 4; k < end_k; k++) {
              blockB[count + 0] = rhs(k, j2 + 0);
              blockB[count + 1] = rhs(k, j2 + 1);
              blockB[count + 2] = rhs(k, j2 + 2);
              blockB[count + 3] = rhs(k, j2 + 3);
              count += 4;
            }
          }
        }
        if (nr >= 8) {
          for (Index j2 = k2 + rows; j2 < packet_cols8; j2 += 8) {
            for (Index k = k2; k < end_k; k++) {
              blockB[count + 0] = numext::conj(rhs(j2 + 0, k));
              blockB[count + 1] = numext::conj(rhs(j2 + 1, k));
              blockB[count + 2] = numext::conj(rhs(j2 + 2, k));
              blockB[count + 3] = numext::conj(rhs(j2 + 3, k));
              blockB[count + 4] = numext::conj(rhs(j2 + 4, k));
              blockB[count + 5] = numext::conj(rhs(j2 + 5, k));
              blockB[count + 6] = numext::conj(rhs(j2 + 6, k));
              blockB[count + 7] = numext::conj(rhs(j2 + 7, k));
              count += 8;
            }
          }
        }
        if (nr >= 4) {
          for (Index j2 = (std::max)(packet_cols8, k2 + rows); j2 < packet_cols4; j2 += 4) {
            for (Index k = k2; k < end_k; k++) {
              blockB[count + 0] = numext::conj(rhs(j2 + 0, k));
              blockB[count + 1] = numext::conj(rhs(j2 + 1, k));
              blockB[count + 2] = numext::conj(rhs(j2 + 2, k));
              blockB[count + 3] = numext::conj(rhs(j2 + 3, k));
              count += 4;
            }
          }
        }
        for (Index j2 = packet_cols4; j2 < cols; ++j2) {
          Index half = (std::min)(end_k, j2);
          for (Index k = k2; k < half; k++) {
            blockB[count] = numext::conj(rhs(j2, k));
            count += 1;
          }
          if (half == j2 && half < k2 + rows) {
            blockB[count] = numext::real(rhs(j2, j2));
            count += 1;
          } else
            half--;
          for (Index k = half + 1; k < k2 + rows; k++) {
            blockB[count] = rhs(k, j2);
            count += 1;
          }
        }
      }
    };
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool LhsSelfAdjoint,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool RhsSelfAdjoint,
              bool ConjugateRhs,
              int ResStorageOrder,
              int ResInnerStride>
    struct product_selfadjoint_matrix;
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool LhsSelfAdjoint,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool RhsSelfAdjoint,
              bool ConjugateRhs,
              int ResInnerStride>
    struct product_selfadjoint_matrix<Scalar,
                                      Index,
                                      LhsStorageOrder,
                                      LhsSelfAdjoint,
                                      ConjugateLhs,
                                      RhsStorageOrder,
                                      RhsSelfAdjoint,
                                      ConjugateRhs,
                                      RowMajor,
                                      ResInnerStride> {
      static inline void run(Index rows,
                             Index cols,
                             const Scalar* lhs,
                             Index lhsStride,
                             const Scalar* rhs,
                             Index rhsStride,
                             Scalar* res,
                             Index resIncr,
                             Index resStride,
                             const Scalar& alpha,
                             level3_blocking<Scalar, Scalar>& blocking) {
        product_selfadjoint_matrix<
            Scalar,
            Index,
            logical_xor(RhsSelfAdjoint, RhsStorageOrder == RowMajor) ? ColMajor : RowMajor,
            RhsSelfAdjoint,
            NumTraits<Scalar>::IsComplex && logical_xor(RhsSelfAdjoint, ConjugateRhs),
            logical_xor(LhsSelfAdjoint, LhsStorageOrder == RowMajor) ? ColMajor : RowMajor,
            LhsSelfAdjoint,
            NumTraits<Scalar>::IsComplex && logical_xor(LhsSelfAdjoint, ConjugateLhs),
            ColMajor,
            ResInnerStride>::run(cols, rows, rhs, rhsStride, lhs, lhsStride, res, resIncr, resStride, alpha, blocking);
      }
    };
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    struct product_selfadjoint_matrix<Scalar,
                                      Index,
                                      LhsStorageOrder,
                                      true,
                                      ConjugateLhs,
                                      RhsStorageOrder,
                                      false,
                                      ConjugateRhs,
                                      ColMajor,
                                      ResInnerStride> {
      static __attribute__((noinline)) void run(Index rows,
                                                Index cols,
                                                const Scalar* _lhs,
                                                Index lhsStride,
                                                const Scalar* _rhs,
                                                Index rhsStride,
                                                Scalar* res,
                                                Index resIncr,
                                                Index resStride,
                                                const Scalar& alpha,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    __attribute__((noinline)) void
    product_selfadjoint_matrix<Scalar,
                               Index,
                               LhsStorageOrder,
                               true,
                               ConjugateLhs,
                               RhsStorageOrder,
                               false,
                               ConjugateRhs,
                               ColMajor,
                               ResInnerStride>::run(Index rows,
                                                    Index cols,
                                                    const Scalar* _lhs,
                                                    Index lhsStride,
                                                    const Scalar* _rhs,
                                                    Index rhsStride,
                                                    Scalar* _res,
                                                    Index resIncr,
                                                    Index resStride,
                                                    const Scalar& alpha,
                                                    level3_blocking<Scalar, Scalar>& blocking) {
      Index size = rows;
      typedef gebp_traits<Scalar, Scalar> Traits;
      typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
      typedef const_blas_data_mapper<Scalar, Index, (LhsStorageOrder == RowMajor) ? ColMajor : RowMajor>
          LhsTransposeMapper;
      typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
      typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
      LhsMapper lhs(_lhs, lhsStride);
      LhsTransposeMapper lhs_transpose(_lhs, lhsStride);
      RhsMapper rhs(_rhs, rhsStride);
      ResMapper res(_res, resStride, resIncr);
      Index kc = blocking.kc();
      Index mc = (std::min)(rows, blocking.mc());
      kc = (std::min)(kc, mc);
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * cols;
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      gebp_kernel<Scalar, Scalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp_kernel;
      symm_pack_lhs<Scalar, Index, Traits::mr, Traits::LhsProgress, LhsStorageOrder> pack_lhs;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
      gemm_pack_lhs<Scalar,
                    Index,
                    LhsTransposeMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    LhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                    true>
          pack_lhs_transposed;
      for (Index k2 = 0; k2 < size; k2 += kc) {
        const Index actual_kc = (std::min)(k2 + kc, size) - k2;
        pack_rhs(blockB, rhs.getSubMapper(k2, 0), actual_kc, cols);
        for (Index i2 = 0; i2 < k2; i2 += mc) {
          const Index actual_mc = (std::min)(i2 + mc, k2) - i2;
          pack_lhs_transposed(blockA, lhs_transpose.getSubMapper(i2, k2), actual_kc, actual_mc);
          gebp_kernel(res.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, alpha);
        }
        {
          const Index actual_mc = (std::min)(k2 + kc, size) - k2;
          pack_lhs(blockA, &lhs(k2, k2), lhsStride, actual_kc, actual_mc);
          gebp_kernel(res.getSubMapper(k2, 0), blockA, blockB, actual_mc, actual_kc, cols, alpha);
        }
        for (Index i2 = k2 + kc; i2 < size; i2 += mc) {
          const Index actual_mc = (std::min)(i2 + mc, size) - i2;
          gemm_pack_lhs<Scalar,
                        Index,
                        LhsMapper,
                        Traits::mr,
                        Traits::LhsProgress,
                        typename Traits::LhsPacket4Packing,
                        LhsStorageOrder,
                        false>()(blockA, lhs.getSubMapper(i2, k2), actual_kc, actual_mc);
          gebp_kernel(res.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, alpha);
        }
      }
    }
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    struct product_selfadjoint_matrix<Scalar,
                                      Index,
                                      LhsStorageOrder,
                                      false,
                                      ConjugateLhs,
                                      RhsStorageOrder,
                                      true,
                                      ConjugateRhs,
                                      ColMajor,
                                      ResInnerStride> {
      static __attribute__((noinline)) void run(Index rows,
                                                Index cols,
                                                const Scalar* _lhs,
                                                Index lhsStride,
                                                const Scalar* _rhs,
                                                Index rhsStride,
                                                Scalar* res,
                                                Index resIncr,
                                                Index resStride,
                                                const Scalar& alpha,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar,
              typename Index,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride>
    __attribute__((noinline)) void
    product_selfadjoint_matrix<Scalar,
                               Index,
                               LhsStorageOrder,
                               false,
                               ConjugateLhs,
                               RhsStorageOrder,
                               true,
                               ConjugateRhs,
                               ColMajor,
                               ResInnerStride>::run(Index rows,
                                                    Index cols,
                                                    const Scalar* _lhs,
                                                    Index lhsStride,
                                                    const Scalar* _rhs,
                                                    Index rhsStride,
                                                    Scalar* _res,
                                                    Index resIncr,
                                                    Index resStride,
                                                    const Scalar& alpha,
                                                    level3_blocking<Scalar, Scalar>& blocking) {
      Index size = cols;
      typedef gebp_traits<Scalar, Scalar> Traits;
      typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
      typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
      LhsMapper lhs(_lhs, lhsStride);
      ResMapper res(_res, resStride, resIncr);
      Index kc = blocking.kc();
      Index mc = (std::min)(rows, blocking.mc());
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * cols;
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      gebp_kernel<Scalar, Scalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp_kernel;
      gemm_pack_lhs<Scalar,
                    Index,
                    LhsMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    LhsStorageOrder>
          pack_lhs;
      symm_pack_rhs<Scalar, Index, Traits::nr, RhsStorageOrder> pack_rhs;
      for (Index k2 = 0; k2 < size; k2 += kc) {
        const Index actual_kc = (std::min)(k2 + kc, size) - k2;
        pack_rhs(blockB, _rhs, rhsStride, actual_kc, cols, k2);
        for (Index i2 = 0; i2 < rows; i2 += mc) {
          const Index actual_mc = (std::min)(i2 + mc, rows) - i2;
          pack_lhs(blockA, lhs.getSubMapper(i2, k2), actual_kc, actual_mc);
          gebp_kernel(res.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, alpha);
        }
      }
    }
  }  // namespace internal
  namespace internal {
    template <typename Lhs, int LhsMode, typename Rhs, int RhsMode>
    struct selfadjoint_product_impl<Lhs, LhsMode, false, Rhs, RhsMode, false> {
      typedef typename Product<Lhs, Rhs>::Scalar Scalar;
      typedef internal::blas_traits<Lhs> LhsBlasTraits;
      typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
      typedef internal::blas_traits<Rhs> RhsBlasTraits;
      typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
      enum {
        LhsIsUpper = (LhsMode & (Upper | Lower)) == Upper,
        LhsIsSelfAdjoint = (LhsMode & SelfAdjoint) == SelfAdjoint,
        RhsIsUpper = (RhsMode & (Upper | Lower)) == Upper,
        RhsIsSelfAdjoint = (RhsMode & SelfAdjoint) == SelfAdjoint
      };
      template <typename Dest>
      static void run(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
        (static_cast<bool>(dst.rows() == a_lhs.rows() && dst.cols() == a_rhs.cols())
             ? void(0)
             : __assert_fail("dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/products/SelfadjointMatrixMatrix.h",
                             516,
                             __extension__ __PRETTY_FUNCTION__));
        add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
        add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
        Scalar actualAlpha =
            alpha * LhsBlasTraits::extractScalarFactor(a_lhs) * RhsBlasTraits::extractScalarFactor(a_rhs);
        typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                              Scalar,
                                              Scalar,
                                              Lhs::MaxRowsAtCompileTime,
                                              Rhs::MaxColsAtCompileTime,
                                              Lhs::MaxColsAtCompileTime,
                                              1>
            BlockingType;
        BlockingType blocking(lhs.rows(), rhs.cols(), lhs.cols(), 1, false);
        internal::product_selfadjoint_matrix<
            Scalar,
            Index,
            internal::logical_xor(LhsIsUpper, internal::traits<Lhs>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            LhsIsSelfAdjoint,
            NumTraits<Scalar>::IsComplex && internal::logical_xor(LhsIsUpper, bool(LhsBlasTraits::NeedToConjugate)),
            internal::logical_xor(RhsIsUpper, internal::traits<Rhs>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            RhsIsSelfAdjoint,
            NumTraits<Scalar>::IsComplex && internal::logical_xor(RhsIsUpper, bool(RhsBlasTraits::NeedToConjugate)),
            internal::traits<Dest>::Flags & RowMajorBit ? RowMajor : ColMajor,
            Dest::InnerStrideAtCompileTime>::run(lhs.rows(),
                                                 rhs.cols(),
                                                 &lhs.coeffRef(0, 0),
                                                 lhs.outerStride(),
                                                 &rhs.coeffRef(0, 0),
                                                 rhs.outerStride(),
                                                 &dst.coeffRef(0, 0),
                                                 dst.innerStride(),
                                                 dst.outerStride(),
                                                 actualAlpha,
                                                 blocking);
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar, typename Index, int UpLo, bool ConjLhs, bool ConjRhs>
  struct selfadjoint_rank1_update<Scalar, Index, ColMajor, UpLo, ConjLhs, ConjRhs> {
    static void run(Index size, Scalar* mat, Index stride, const Scalar* vecX, const Scalar* vecY, const Scalar& alpha) {
      internal::conj_if<ConjRhs> cj;
      typedef Map<const Matrix<Scalar, Dynamic, 1>> OtherMap;
      typedef std::conditional_t<ConjLhs, typename OtherMap::ConjugateReturnType, const OtherMap&> ConjLhsType;
      for (Index i = 0; i < size; ++i) {
        Map<Matrix<Scalar, Dynamic, 1>>(mat + stride * i + (UpLo == Lower ? i : 0),
                                        (UpLo == Lower ? size - i : (i + 1))) +=
            (alpha * cj(vecY[i])) *
            ConjLhsType(OtherMap(vecX + (UpLo == Lower ? i : 0), UpLo == Lower ? size - i : (i + 1)));
      }
    }
  };
  template <typename Scalar, typename Index, int UpLo, bool ConjLhs, bool ConjRhs>
  struct selfadjoint_rank1_update<Scalar, Index, RowMajor, UpLo, ConjLhs, ConjRhs> {
    static void run(Index size, Scalar* mat, Index stride, const Scalar* vecX, const Scalar* vecY, const Scalar& alpha) {
      selfadjoint_rank1_update<Scalar, Index, ColMajor, UpLo == Lower ? Upper : Lower, ConjRhs, ConjLhs>::run(
          size, mat, stride, vecY, vecX, alpha);
    }
  };
  template <typename MatrixType, typename OtherType, int UpLo, bool OtherIsVector = OtherType::IsVectorAtCompileTime>
  struct selfadjoint_product_selector;
  template <typename MatrixType, typename OtherType, int UpLo>
  struct selfadjoint_product_selector<MatrixType, OtherType, UpLo, true> {
    static void run(MatrixType& mat, const OtherType& other, const typename MatrixType::Scalar& alpha) {
      typedef typename MatrixType::Scalar Scalar;
      typedef internal::blas_traits<OtherType> OtherBlasTraits;
      typedef typename OtherBlasTraits::DirectLinearAccessType ActualOtherType;
      typedef internal::remove_all_t<ActualOtherType> ActualOtherType_;
      internal::add_const_on_value_type_t<ActualOtherType> actualOther = OtherBlasTraits::extract(other.derived());
      Scalar actualAlpha = alpha * OtherBlasTraits::extractScalarFactor(other.derived());
      enum {
        StorageOrder = (internal::traits<MatrixType>::Flags & RowMajorBit) ? RowMajor : ColMajor,
        UseOtherDirectly = ActualOtherType_::InnerStrideAtCompileTime == 1
      };
      internal::
          gemv_static_vector_if<Scalar, OtherType::SizeAtCompileTime, OtherType::MaxSizeAtCompileTime, !UseOtherDirectly>
              static_other;
      Eigen::internal::check_size_for_overflow<Scalar>(other.size());
      Scalar* actualOtherPtr =
          ((UseOtherDirectly ? const_cast<Scalar*>(actualOther.data()) : static_other.data())) != 0
              ? ((UseOtherDirectly ? const_cast<Scalar*>(actualOther.data()) : static_other.data()))
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * other.size() <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * other.size() + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * other.size()));
      Eigen::internal::aligned_stack_memory_handler<Scalar> actualOtherPtr_stack_memory_destructor(
          ((UseOtherDirectly ? const_cast<Scalar*>(actualOther.data()) : static_other.data())) == 0 ? actualOtherPtr
                                                                                                    : 0,
          other.size(),
          sizeof(Scalar) * other.size() > 131072);
      if (!UseOtherDirectly)
        Map<typename ActualOtherType_::PlainObject>(actualOtherPtr, actualOther.size()) = actualOther;
      selfadjoint_rank1_update<Scalar,
                               Index,
                               StorageOrder,
                               UpLo,
                               OtherBlasTraits::NeedToConjugate && NumTraits<Scalar>::IsComplex,
                               (!OtherBlasTraits::NeedToConjugate) &&
                                   NumTraits<Scalar>::IsComplex>::run(other.size(),
                                                                      mat.data(),
                                                                      mat.outerStride(),
                                                                      actualOtherPtr,
                                                                      actualOtherPtr,
                                                                      actualAlpha);
    }
  };
  template <typename MatrixType, typename OtherType, int UpLo>
  struct selfadjoint_product_selector<MatrixType, OtherType, UpLo, false> {
    static void run(MatrixType& mat, const OtherType& other, const typename MatrixType::Scalar& alpha) {
      typedef typename MatrixType::Scalar Scalar;
      typedef internal::blas_traits<OtherType> OtherBlasTraits;
      typedef typename OtherBlasTraits::DirectLinearAccessType ActualOtherType;
      typedef internal::remove_all_t<ActualOtherType> ActualOtherType_;
      internal::add_const_on_value_type_t<ActualOtherType> actualOther = OtherBlasTraits::extract(other.derived());
      Scalar actualAlpha = alpha * OtherBlasTraits::extractScalarFactor(other.derived());
      enum {
        IsRowMajor = (internal::traits<MatrixType>::Flags & RowMajorBit) ? 1 : 0,
        OtherIsRowMajor = ActualOtherType_::Flags & RowMajorBit ? 1 : 0
      };
      Index size = mat.cols();
      Index depth = actualOther.cols();
      typedef internal::gemm_blocking_space<IsRowMajor ? RowMajor : ColMajor,
                                            Scalar,
                                            Scalar,
                                            MatrixType::MaxColsAtCompileTime,
                                            MatrixType::MaxColsAtCompileTime,
                                            ActualOtherType_::MaxColsAtCompileTime>
          BlockingType;
      BlockingType blocking(size, size, depth, 1, false);
      internal::general_matrix_matrix_triangular_product<
          Index,
          Scalar,
          OtherIsRowMajor ? RowMajor : ColMajor,
          OtherBlasTraits::NeedToConjugate && NumTraits<Scalar>::IsComplex,
          Scalar,
          OtherIsRowMajor ? ColMajor : RowMajor,
          (!OtherBlasTraits::NeedToConjugate) && NumTraits<Scalar>::IsComplex,
          IsRowMajor ? RowMajor : ColMajor,
          MatrixType::InnerStrideAtCompileTime,
          UpLo>::run(size,
                     depth,
                     actualOther.data(),
                     actualOther.outerStride(),
                     actualOther.data(),
                     actualOther.outerStride(),
                     mat.data(),
                     mat.innerStride(),
                     mat.outerStride(),
                     actualAlpha,
                     blocking);
    }
  };
  template <typename MatrixType, unsigned int UpLo>
  template <typename DerivedU>
  SelfAdjointView<MatrixType, UpLo>& SelfAdjointView<MatrixType, UpLo>::rankUpdate(const MatrixBase<DerivedU>& u,
                                                                                   const Scalar& alpha) {
    selfadjoint_product_selector<MatrixType, DerivedU, UpLo>::run(
        _expression().const_cast_derived(), u.derived(), alpha);
    return *this;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar, typename Index, typename UType, typename VType, int UpLo>
    struct selfadjoint_rank2_update_selector;
    template <typename Scalar, typename Index, typename UType, typename VType>
    struct selfadjoint_rank2_update_selector<Scalar, Index, UType, VType, Lower> {
      static void run(Scalar* mat, Index stride, const UType& u, const VType& v, const Scalar& alpha) {
        const Index size = u.size();
        for (Index i = 0; i < size; ++i) {
          Map<Matrix<Scalar, Dynamic, 1>>(mat + stride * i + i, size - i) +=
              (numext::conj(alpha) * numext::conj(u.coeff(i))) * v.tail(size - i) +
              (alpha * numext::conj(v.coeff(i))) * u.tail(size - i);
        }
      }
    };
    template <typename Scalar, typename Index, typename UType, typename VType>
    struct selfadjoint_rank2_update_selector<Scalar, Index, UType, VType, Upper> {
      static void run(Scalar* mat, Index stride, const UType& u, const VType& v, const Scalar& alpha) {
        const Index size = u.size();
        for (Index i = 0; i < size; ++i)
          Map<Matrix<Scalar, Dynamic, 1>>(mat + stride * i, i + 1) +=
              (numext::conj(alpha) * numext::conj(u.coeff(i))) * v.head(i + 1) +
              (alpha * numext::conj(v.coeff(i))) * u.head(i + 1);
      }
    };
    template <bool Cond, typename T>
    using conj_expr_if =
        std::conditional<!Cond, const T&, CwiseUnaryOp<scalar_conjugate_op<typename traits<T>::Scalar>, T>>;
  }  // namespace internal
  template <typename MatrixType, unsigned int UpLo>
  template <typename DerivedU, typename DerivedV>
  SelfAdjointView<MatrixType, UpLo>& SelfAdjointView<MatrixType, UpLo>::rankUpdate(const MatrixBase<DerivedU>& u,
                                                                                   const MatrixBase<DerivedV>& v,
                                                                                   const Scalar& alpha) {
    typedef internal::blas_traits<DerivedU> UBlasTraits;
    typedef typename UBlasTraits::DirectLinearAccessType ActualUType;
    typedef internal::remove_all_t<ActualUType> ActualUType_;
    internal::add_const_on_value_type_t<ActualUType> actualU = UBlasTraits::extract(u.derived());
    typedef internal::blas_traits<DerivedV> VBlasTraits;
    typedef typename VBlasTraits::DirectLinearAccessType ActualVType;
    typedef internal::remove_all_t<ActualVType> ActualVType_;
    internal::add_const_on_value_type_t<ActualVType> actualV = VBlasTraits::extract(v.derived());
    enum { IsRowMajor = (internal::traits<MatrixType>::Flags & RowMajorBit) ? 1 : 0 };
    Scalar actualAlpha = alpha * UBlasTraits::extractScalarFactor(u.derived()) *
                         numext::conj(VBlasTraits::extractScalarFactor(v.derived()));
    if (IsRowMajor)
      actualAlpha = numext::conj(actualAlpha);
    typedef internal::remove_all_t<
        typename internal::conj_expr_if<int(IsRowMajor) ^ int(UBlasTraits::NeedToConjugate), ActualUType_>::type>
        UType;
    typedef internal::remove_all_t<
        typename internal::conj_expr_if<int(IsRowMajor) ^ int(VBlasTraits::NeedToConjugate), ActualVType_>::type>
        VType;
    internal::selfadjoint_rank2_update_selector<Scalar,
                                                Index,
                                                UType,
                                                VType,
                                                (IsRowMajor ? int(UpLo == Upper ? Lower : Upper)
                                                            : UpLo)>::run(_expression().const_cast_derived().data(),
                                                                          _expression().outerStride(),
                                                                          UType(actualU),
                                                                          VType(actualV),
                                                                          actualAlpha);
    return *this;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Index,
              int Mode,
              typename LhsScalar,
              bool ConjLhs,
              typename RhsScalar,
              bool ConjRhs,
              int StorageOrder,
              int Version = Specialized>
    struct triangular_matrix_vector_product;
    template <typename Index, int Mode, typename LhsScalar, bool ConjLhs, typename RhsScalar, bool ConjRhs, int Version>
    struct triangular_matrix_vector_product<Index, Mode, LhsScalar, ConjLhs, RhsScalar, ConjRhs, ColMajor, Version> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      enum {
        IsLower = ((Mode & Lower) == Lower),
        HasUnitDiag = (Mode & UnitDiag) == UnitDiag,
        HasZeroDiag = (Mode & ZeroDiag) == ZeroDiag
      };
      static __attribute__((noinline)) void run(Index _rows,
                                                Index _cols,
                                                const LhsScalar* _lhs,
                                                Index lhsStride,
                                                const RhsScalar* _rhs,
                                                Index rhsIncr,
                                                ResScalar* _res,
                                                Index resIncr,
                                                const RhsScalar& alpha);
    };
    template <typename Index, int Mode, typename LhsScalar, bool ConjLhs, typename RhsScalar, bool ConjRhs, int Version>
    __attribute__((noinline)) void
    triangular_matrix_vector_product<Index, Mode, LhsScalar, ConjLhs, RhsScalar, ConjRhs, ColMajor, Version>::run(
        Index _rows,
        Index _cols,
        const LhsScalar* _lhs,
        Index lhsStride,
        const RhsScalar* _rhs,
        Index rhsIncr,
        ResScalar* _res,
        Index resIncr,
        const RhsScalar& alpha) {
      static const Index PanelWidth = 8;
      Index size = (std::min)(_rows, _cols);
      Index rows = IsLower ? _rows : (std::min)(_rows, _cols);
      Index cols = IsLower ? (std::min)(_rows, _cols) : _cols;
      typedef Map<const Matrix<LhsScalar, Dynamic, Dynamic, ColMajor>, 0, OuterStride<>> LhsMap;
      const LhsMap lhs(_lhs, rows, cols, OuterStride<>(lhsStride));
      typename conj_expr_if<ConjLhs, LhsMap>::type cjLhs(lhs);
      typedef Map<const Matrix<RhsScalar, Dynamic, 1>, 0, InnerStride<>> RhsMap;
      const RhsMap rhs(_rhs, cols, InnerStride<>(rhsIncr));
      typename conj_expr_if<ConjRhs, RhsMap>::type cjRhs(rhs);
      typedef Map<Matrix<ResScalar, Dynamic, 1>> ResMap;
      ResMap res(_res, rows);
      typedef const_blas_data_mapper<LhsScalar, Index, ColMajor> LhsMapper;
      typedef const_blas_data_mapper<RhsScalar, Index, RowMajor> RhsMapper;
      for (Index pi = 0; pi < size; pi += PanelWidth) {
        Index actualPanelWidth = (std::min)(PanelWidth, size - pi);
        for (Index k = 0; k < actualPanelWidth; ++k) {
          Index i = pi + k;
          Index s = IsLower ? ((HasUnitDiag || HasZeroDiag) ? i + 1 : i) : pi;
          Index r = IsLower ? actualPanelWidth - k : k + 1;
          if ((!(HasUnitDiag || HasZeroDiag)) || (--r) > 0)
            res.segment(s, r) += (alpha * cjRhs.coeff(i)) * cjLhs.col(i).segment(s, r);
          if (HasUnitDiag)
            res.coeffRef(i) += alpha * cjRhs.coeff(i);
        }
        Index r = IsLower ? rows - pi - actualPanelWidth : pi;
        if (r > 0) {
          Index s = IsLower ? pi + actualPanelWidth : 0;
          general_matrix_vector_product<Index,
                                        LhsScalar,
                                        LhsMapper,
                                        ColMajor,
                                        ConjLhs,
                                        RhsScalar,
                                        RhsMapper,
                                        ConjRhs,
                                        BuiltIn>::run(r,
                                                      actualPanelWidth,
                                                      LhsMapper(&lhs.coeffRef(s, pi), lhsStride),
                                                      RhsMapper(&rhs.coeffRef(pi), rhsIncr),
                                                      &res.coeffRef(s),
                                                      resIncr,
                                                      alpha);
        }
      }
      if ((!IsLower) && cols > size) {
        general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, ConjLhs, RhsScalar, RhsMapper, ConjRhs>::run(
            rows,
            cols - size,
            LhsMapper(&lhs.coeffRef(0, size), lhsStride),
            RhsMapper(&rhs.coeffRef(size), rhsIncr),
            _res,
            resIncr,
            alpha);
      }
    }
    template <typename Index, int Mode, typename LhsScalar, bool ConjLhs, typename RhsScalar, bool ConjRhs, int Version>
    struct triangular_matrix_vector_product<Index, Mode, LhsScalar, ConjLhs, RhsScalar, ConjRhs, RowMajor, Version> {
      typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
      enum {
        IsLower = ((Mode & Lower) == Lower),
        HasUnitDiag = (Mode & UnitDiag) == UnitDiag,
        HasZeroDiag = (Mode & ZeroDiag) == ZeroDiag
      };
      static __attribute__((noinline)) void run(Index _rows,
                                                Index _cols,
                                                const LhsScalar* _lhs,
                                                Index lhsStride,
                                                const RhsScalar* _rhs,
                                                Index rhsIncr,
                                                ResScalar* _res,
                                                Index resIncr,
                                                const ResScalar& alpha);
    };
    template <typename Index, int Mode, typename LhsScalar, bool ConjLhs, typename RhsScalar, bool ConjRhs, int Version>
    __attribute__((noinline)) void
    triangular_matrix_vector_product<Index, Mode, LhsScalar, ConjLhs, RhsScalar, ConjRhs, RowMajor, Version>::run(
        Index _rows,
        Index _cols,
        const LhsScalar* _lhs,
        Index lhsStride,
        const RhsScalar* _rhs,
        Index rhsIncr,
        ResScalar* _res,
        Index resIncr,
        const ResScalar& alpha) {
      static const Index PanelWidth = 8;
      Index diagSize = (std::min)(_rows, _cols);
      Index rows = IsLower ? _rows : diagSize;
      Index cols = IsLower ? diagSize : _cols;
      typedef Map<const Matrix<LhsScalar, Dynamic, Dynamic, RowMajor>, 0, OuterStride<>> LhsMap;
      const LhsMap lhs(_lhs, rows, cols, OuterStride<>(lhsStride));
      typename conj_expr_if<ConjLhs, LhsMap>::type cjLhs(lhs);
      typedef Map<const Matrix<RhsScalar, Dynamic, 1>> RhsMap;
      const RhsMap rhs(_rhs, cols);
      typename conj_expr_if<ConjRhs, RhsMap>::type cjRhs(rhs);
      typedef Map<Matrix<ResScalar, Dynamic, 1>, 0, InnerStride<>> ResMap;
      ResMap res(_res, rows, InnerStride<>(resIncr));
      typedef const_blas_data_mapper<LhsScalar, Index, RowMajor> LhsMapper;
      typedef const_blas_data_mapper<RhsScalar, Index, RowMajor> RhsMapper;
      for (Index pi = 0; pi < diagSize; pi += PanelWidth) {
        Index actualPanelWidth = (std::min)(PanelWidth, diagSize - pi);
        for (Index k = 0; k < actualPanelWidth; ++k) {
          Index i = pi + k;
          Index s = IsLower ? pi : ((HasUnitDiag || HasZeroDiag) ? i + 1 : i);
          Index r = IsLower ? k + 1 : actualPanelWidth - k;
          if ((!(HasUnitDiag || HasZeroDiag)) || (--r) > 0)
            res.coeffRef(i) += alpha * (cjLhs.row(i).segment(s, r).cwiseProduct(cjRhs.segment(s, r).transpose())).sum();
          if (HasUnitDiag)
            res.coeffRef(i) += alpha * cjRhs.coeff(i);
        }
        Index r = IsLower ? pi : cols - pi - actualPanelWidth;
        if (r > 0) {
          Index s = IsLower ? 0 : pi + actualPanelWidth;
          general_matrix_vector_product<Index,
                                        LhsScalar,
                                        LhsMapper,
                                        RowMajor,
                                        ConjLhs,
                                        RhsScalar,
                                        RhsMapper,
                                        ConjRhs,
                                        BuiltIn>::run(actualPanelWidth,
                                                      r,
                                                      LhsMapper(&lhs.coeffRef(pi, s), lhsStride),
                                                      RhsMapper(&rhs.coeffRef(s), rhsIncr),
                                                      &res.coeffRef(pi),
                                                      resIncr,
                                                      alpha);
        }
      }
      if (IsLower && rows > diagSize) {
        general_matrix_vector_product<Index, LhsScalar, LhsMapper, RowMajor, ConjLhs, RhsScalar, RhsMapper, ConjRhs>::run(
            rows - diagSize,
            cols,
            LhsMapper(&lhs.coeffRef(diagSize, 0), lhsStride),
            RhsMapper(&rhs.coeffRef(0), rhsIncr),
            &res.coeffRef(diagSize),
            resIncr,
            alpha);
      }
    }
    template <int Mode, int StorageOrder>
    struct trmv_selector;
  }  // namespace internal
  namespace internal {
    template <int Mode, typename Lhs, typename Rhs>
    struct triangular_product_impl<Mode, true, Lhs, false, Rhs, true> {
      template <typename Dest>
      static void run(Dest& dst, const Lhs& lhs, const Rhs& rhs, const typename Dest::Scalar& alpha) {
        (static_cast<bool>(dst.rows() == lhs.rows() && dst.cols() == rhs.cols())
             ? void(0)
             : __assert_fail("dst.rows()==lhs.rows() && dst.cols()==rhs.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/products/TriangularMatrixVector.h",
                             186,
                             __extension__ __PRETTY_FUNCTION__));
        internal::trmv_selector<Mode, (int(internal::traits<Lhs>::Flags) & RowMajorBit) ? RowMajor : ColMajor>::run(
            lhs, rhs, dst, alpha);
      }
    };
    template <int Mode, typename Lhs, typename Rhs>
    struct triangular_product_impl<Mode, false, Lhs, true, Rhs, false> {
      template <typename Dest>
      static void run(Dest& dst, const Lhs& lhs, const Rhs& rhs, const typename Dest::Scalar& alpha) {
        (static_cast<bool>(dst.rows() == lhs.rows() && dst.cols() == rhs.cols())
             ? void(0)
             : __assert_fail("dst.rows()==lhs.rows() && dst.cols()==rhs.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/products/TriangularMatrixVector.h",
                             199,
                             __extension__ __PRETTY_FUNCTION__));
        Transpose<Dest> dstT(dst);
        internal::trmv_selector<(Mode & (UnitDiag | ZeroDiag)) | ((Mode & Lower) ? Upper : Lower),
                                (int(internal::traits<Rhs>::Flags) & RowMajorBit) ? ColMajor
                                                                                  : RowMajor>::run(rhs.transpose(),
                                                                                                   lhs.transpose(),
                                                                                                   dstT,
                                                                                                   alpha);
      }
    };
  }  // namespace internal
  namespace internal {
    template <int Mode>
    struct trmv_selector<Mode, ColMajor> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        typedef typename Lhs::Scalar LhsScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef typename Dest::Scalar ResScalar;
        typedef internal::blas_traits<Lhs> LhsBlasTraits;
        typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
        typedef internal::blas_traits<Rhs> RhsBlasTraits;
        typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
        typedef Map<Matrix<ResScalar, Dynamic, 1>, plain_enum_min(AlignedMax, internal::packet_traits<ResScalar>::size)>
            MappedDest;
        add_const_on_value_type_t<ActualLhsType> actualLhs = LhsBlasTraits::extract(lhs);
        add_const_on_value_type_t<ActualRhsType> actualRhs = RhsBlasTraits::extract(rhs);
        LhsScalar lhs_alpha = LhsBlasTraits::extractScalarFactor(lhs);
        RhsScalar rhs_alpha = RhsBlasTraits::extractScalarFactor(rhs);
        ResScalar actualAlpha = alpha * lhs_alpha * rhs_alpha;
        enum {
          EvalToDestAtCompileTime = Dest::InnerStrideAtCompileTime == 1,
          ComplexByReal = (NumTraits<LhsScalar>::IsComplex) && (!NumTraits<RhsScalar>::IsComplex),
          MightCannotUseDest = (Dest::InnerStrideAtCompileTime != 1) || ComplexByReal
        };
        gemv_static_vector_if<ResScalar, Dest::SizeAtCompileTime, Dest::MaxSizeAtCompileTime, MightCannotUseDest>
            static_dest;
        bool alphaIsCompatible = (!ComplexByReal) || numext::is_exactly_zero(numext::imag(actualAlpha));
        bool evalToDest = EvalToDestAtCompileTime && alphaIsCompatible;
        RhsScalar compatibleAlpha = get_factor<ResScalar, RhsScalar>::run(actualAlpha);
        Eigen::internal::check_size_for_overflow<ResScalar>(dest.size());
        ResScalar* actualDestPtr =
            (evalToDest ? dest.data() : static_dest.data()) != 0
                ? (evalToDest ? dest.data() : static_dest.data())
                : reinterpret_cast<ResScalar*>(
                      (sizeof(ResScalar) * dest.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(ResScalar) * dest.size() + 64 - 1)) + 64 -
                                 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(ResScalar) * dest.size()));
        Eigen::internal::aligned_stack_memory_handler<ResScalar> actualDestPtr_stack_memory_destructor(
            (evalToDest ? dest.data() : static_dest.data()) == 0 ? actualDestPtr : 0,
            dest.size(),
            sizeof(ResScalar) * dest.size() > 131072);
        if (!evalToDest) {
          if (!alphaIsCompatible) {
            MappedDest(actualDestPtr, dest.size()).setZero();
            compatibleAlpha = RhsScalar(1);
          } else
            MappedDest(actualDestPtr, dest.size()) = dest;
        }
        internal::triangular_matrix_vector_product<Index,
                                                   Mode,
                                                   LhsScalar,
                                                   LhsBlasTraits::NeedToConjugate,
                                                   RhsScalar,
                                                   RhsBlasTraits::NeedToConjugate,
                                                   ColMajor>::run(actualLhs.rows(),
                                                                  actualLhs.cols(),
                                                                  actualLhs.data(),
                                                                  actualLhs.outerStride(),
                                                                  actualRhs.data(),
                                                                  actualRhs.innerStride(),
                                                                  actualDestPtr,
                                                                  1,
                                                                  compatibleAlpha);
        if (!evalToDest) {
          if (!alphaIsCompatible)
            dest += actualAlpha * MappedDest(actualDestPtr, dest.size());
          else
            dest = MappedDest(actualDestPtr, dest.size());
        }
        if (((Mode & UnitDiag) == UnitDiag) && !numext::is_exactly_one(lhs_alpha)) {
          Index diagSize = (std::min)(lhs.rows(), lhs.cols());
          dest.head(diagSize) -= (lhs_alpha - LhsScalar(1)) * rhs.head(diagSize);
        }
      }
    };
    template <int Mode>
    struct trmv_selector<Mode, RowMajor> {
      template <typename Lhs, typename Rhs, typename Dest>
      static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
        typedef typename Lhs::Scalar LhsScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef typename Dest::Scalar ResScalar;
        typedef internal::blas_traits<Lhs> LhsBlasTraits;
        typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
        typedef internal::blas_traits<Rhs> RhsBlasTraits;
        typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
        typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
        std::add_const_t<ActualLhsType> actualLhs = LhsBlasTraits::extract(lhs);
        std::add_const_t<ActualRhsType> actualRhs = RhsBlasTraits::extract(rhs);
        LhsScalar lhs_alpha = LhsBlasTraits::extractScalarFactor(lhs);
        RhsScalar rhs_alpha = RhsBlasTraits::extractScalarFactor(rhs);
        ResScalar actualAlpha = alpha * lhs_alpha * rhs_alpha;
        enum { DirectlyUseRhs = ActualRhsTypeCleaned::InnerStrideAtCompileTime == 1 };
        gemv_static_vector_if<RhsScalar,
                              ActualRhsTypeCleaned::SizeAtCompileTime,
                              ActualRhsTypeCleaned::MaxSizeAtCompileTime,
                              !DirectlyUseRhs>
            static_rhs;
        Eigen::internal::check_size_for_overflow<RhsScalar>(actualRhs.size());
        RhsScalar* actualRhsPtr =
            (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data()) != 0
                ? (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data())
                : reinterpret_cast<RhsScalar*>(
                      (sizeof(RhsScalar) * actualRhs.size() <= 131072)
                          ? reinterpret_cast<void*>(
                                (internal::UIntPtr(__builtin_alloca(sizeof(RhsScalar) * actualRhs.size() + 64 - 1)) +
                                 64 - 1) &
                                ~(std::size_t(64 - 1)))
                          : Eigen::internal::aligned_malloc(sizeof(RhsScalar) * actualRhs.size()));
        Eigen::internal::aligned_stack_memory_handler<RhsScalar> actualRhsPtr_stack_memory_destructor(
            (DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data()) == 0 ? actualRhsPtr : 0,
            actualRhs.size(),
            sizeof(RhsScalar) * actualRhs.size() > 131072);
        if (!DirectlyUseRhs) {
          Map<typename ActualRhsTypeCleaned::PlainObject>(actualRhsPtr, actualRhs.size()) = actualRhs;
        }
        internal::triangular_matrix_vector_product<Index,
                                                   Mode,
                                                   LhsScalar,
                                                   LhsBlasTraits::NeedToConjugate,
                                                   RhsScalar,
                                                   RhsBlasTraits::NeedToConjugate,
                                                   RowMajor>::run(actualLhs.rows(),
                                                                  actualLhs.cols(),
                                                                  actualLhs.data(),
                                                                  actualLhs.outerStride(),
                                                                  actualRhsPtr,
                                                                  1,
                                                                  dest.data(),
                                                                  dest.innerStride(),
                                                                  actualAlpha);
        if (((Mode & UnitDiag) == UnitDiag) && !numext::is_exactly_one(lhs_alpha)) {
          Index diagSize = (std::min)(lhs.rows(), lhs.cols());
          dest.head(diagSize) -= (lhs_alpha - LhsScalar(1)) * rhs.head(diagSize);
        }
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar,
              typename Index,
              int Mode,
              bool LhsIsTriangular,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResStorageOrder,
              int ResInnerStride,
              int Version = Specialized>
    struct product_triangular_matrix_matrix;
    template <typename Scalar,
              typename Index,
              int Mode,
              bool LhsIsTriangular,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int Version>
    struct product_triangular_matrix_matrix<Scalar,
                                            Index,
                                            Mode,
                                            LhsIsTriangular,
                                            LhsStorageOrder,
                                            ConjugateLhs,
                                            RhsStorageOrder,
                                            ConjugateRhs,
                                            RowMajor,
                                            ResInnerStride,
                                            Version> {
      static inline void run(Index rows,
                             Index cols,
                             Index depth,
                             const Scalar* lhs,
                             Index lhsStride,
                             const Scalar* rhs,
                             Index rhsStride,
                             Scalar* res,
                             Index resIncr,
                             Index resStride,
                             const Scalar& alpha,
                             level3_blocking<Scalar, Scalar>& blocking) {
        product_triangular_matrix_matrix<Scalar,
                                         Index,
                                         (Mode & (UnitDiag | ZeroDiag)) | ((Mode & Upper) ? Lower : Upper),
                                         (!LhsIsTriangular),
                                         RhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                         ConjugateRhs,
                                         LhsStorageOrder == RowMajor ? ColMajor : RowMajor,
                                         ConjugateLhs,
                                         ColMajor,
                                         ResInnerStride>::run(cols,
                                                              rows,
                                                              depth,
                                                              rhs,
                                                              rhsStride,
                                                              lhs,
                                                              lhsStride,
                                                              res,
                                                              resIncr,
                                                              resStride,
                                                              alpha,
                                                              blocking);
      }
    };
    template <typename Scalar,
              typename Index,
              int Mode,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int Version>
    struct product_triangular_matrix_matrix<Scalar,
                                            Index,
                                            Mode,
                                            true,
                                            LhsStorageOrder,
                                            ConjugateLhs,
                                            RhsStorageOrder,
                                            ConjugateRhs,
                                            ColMajor,
                                            ResInnerStride,
                                            Version> {
      typedef gebp_traits<Scalar, Scalar> Traits;
      enum {
        SmallPanelWidth = 2 * plain_enum_max(Traits::mr, Traits::nr),
        IsLower = (Mode & Lower) == Lower,
        SetDiag = (Mode & (ZeroDiag | UnitDiag)) ? 0 : 1
      };
      static __attribute__((noinline)) void run(Index _rows,
                                                Index _cols,
                                                Index _depth,
                                                const Scalar* lhs_,
                                                Index lhsStride,
                                                const Scalar* rhs_,
                                                Index rhsStride,
                                                Scalar* res,
                                                Index resIncr,
                                                Index resStride,
                                                const Scalar& alpha,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar,
              typename Index,
              int Mode,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int Version>
    __attribute__((noinline)) void
    product_triangular_matrix_matrix<Scalar,
                                     Index,
                                     Mode,
                                     true,
                                     LhsStorageOrder,
                                     ConjugateLhs,
                                     RhsStorageOrder,
                                     ConjugateRhs,
                                     ColMajor,
                                     ResInnerStride,
                                     Version>::run(Index _rows,
                                                   Index _cols,
                                                   Index _depth,
                                                   const Scalar* lhs_,
                                                   Index lhsStride,
                                                   const Scalar* rhs_,
                                                   Index rhsStride,
                                                   Scalar* res_,
                                                   Index resIncr,
                                                   Index resStride,
                                                   const Scalar& alpha,
                                                   level3_blocking<Scalar, Scalar>& blocking) {
      Index diagSize = (std::min)(_rows, _depth);
      Index rows = IsLower ? _rows : diagSize;
      Index depth = IsLower ? diagSize : _depth;
      Index cols = _cols;
      typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
      typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
      typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
      LhsMapper lhs(lhs_, lhsStride);
      RhsMapper rhs(rhs_, rhsStride);
      ResMapper res(res_, resStride, resIncr);
      Index kc = blocking.kc();
      Index mc = (std::min)(rows, blocking.mc());
      Index panelWidth = (std::min)(Index(SmallPanelWidth), (std::min)(kc, mc));
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * cols;
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      internal::constructor_without_unaligned_array_assert a;
      Matrix<Scalar, SmallPanelWidth, SmallPanelWidth, LhsStorageOrder> triangularBuffer(a);
      triangularBuffer.setZero();
      if ((Mode & ZeroDiag) == ZeroDiag)
        triangularBuffer.diagonal().setZero();
      else
        triangularBuffer.diagonal().setOnes();
      gebp_kernel<Scalar, Scalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp_kernel;
      gemm_pack_lhs<Scalar,
                    Index,
                    LhsMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    LhsStorageOrder>
          pack_lhs;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
      for (Index k2 = IsLower ? depth : 0; IsLower ? k2 > 0 : k2 < depth; IsLower ? k2 -= kc : k2 += kc) {
        Index actual_kc = (std::min)(IsLower ? k2 : depth - k2, kc);
        Index actual_k2 = IsLower ? k2 - actual_kc : k2;
        if ((!IsLower) && (k2 < rows) && (k2 + actual_kc > rows)) {
          actual_kc = rows - k2;
          k2 = k2 + actual_kc - kc;
        }
        pack_rhs(blockB, rhs.getSubMapper(actual_k2, 0), actual_kc, cols);
        if (IsLower || actual_k2 < rows) {
          for (Index k1 = 0; k1 < actual_kc; k1 += panelWidth) {
            Index actualPanelWidth = std::min<Index>(actual_kc - k1, panelWidth);
            Index lengthTarget = IsLower ? actual_kc - k1 - actualPanelWidth : k1;
            Index startBlock = actual_k2 + k1;
            Index blockBOffset = k1;
            for (Index k = 0; k < actualPanelWidth; ++k) {
              if (SetDiag)
                triangularBuffer.coeffRef(k, k) = lhs(startBlock + k, startBlock + k);
              for (Index i = IsLower ? k + 1 : 0; IsLower ? i < actualPanelWidth : i < k; ++i)
                triangularBuffer.coeffRef(i, k) = lhs(startBlock + i, startBlock + k);
            }
            pack_lhs(blockA,
                     LhsMapper(triangularBuffer.data(), triangularBuffer.outerStride()),
                     actualPanelWidth,
                     actualPanelWidth);
            gebp_kernel(res.getSubMapper(startBlock, 0),
                        blockA,
                        blockB,
                        actualPanelWidth,
                        actualPanelWidth,
                        cols,
                        alpha,
                        actualPanelWidth,
                        actual_kc,
                        0,
                        blockBOffset);
            if (lengthTarget > 0) {
              Index startTarget = IsLower ? actual_k2 + k1 + actualPanelWidth : actual_k2;
              pack_lhs(blockA, lhs.getSubMapper(startTarget, startBlock), actualPanelWidth, lengthTarget);
              gebp_kernel(res.getSubMapper(startTarget, 0),
                          blockA,
                          blockB,
                          lengthTarget,
                          actualPanelWidth,
                          cols,
                          alpha,
                          actualPanelWidth,
                          actual_kc,
                          0,
                          blockBOffset);
            }
          }
        }
        {
          Index start = IsLower ? k2 : 0;
          Index end = IsLower ? rows : (std::min)(actual_k2, rows);
          for (Index i2 = start; i2 < end; i2 += mc) {
            const Index actual_mc = (std::min)(i2 + mc, end) - i2;
            gemm_pack_lhs<Scalar,
                          Index,
                          LhsMapper,
                          Traits::mr,
                          Traits::LhsProgress,
                          typename Traits::LhsPacket4Packing,
                          LhsStorageOrder,
                          false>()(blockA, lhs.getSubMapper(i2, actual_k2), actual_kc, actual_mc);
            gebp_kernel(res.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, alpha, -1, -1, 0, 0);
          }
        }
      }
    }
    template <typename Scalar,
              typename Index,
              int Mode,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int Version>
    struct product_triangular_matrix_matrix<Scalar,
                                            Index,
                                            Mode,
                                            false,
                                            LhsStorageOrder,
                                            ConjugateLhs,
                                            RhsStorageOrder,
                                            ConjugateRhs,
                                            ColMajor,
                                            ResInnerStride,
                                            Version> {
      typedef gebp_traits<Scalar, Scalar> Traits;
      enum {
        SmallPanelWidth = plain_enum_max(Traits::mr, Traits::nr),
        IsLower = (Mode & Lower) == Lower,
        SetDiag = (Mode & (ZeroDiag | UnitDiag)) ? 0 : 1
      };
      static __attribute__((noinline)) void run(Index _rows,
                                                Index _cols,
                                                Index _depth,
                                                const Scalar* lhs_,
                                                Index lhsStride,
                                                const Scalar* rhs_,
                                                Index rhsStride,
                                                Scalar* res,
                                                Index resIncr,
                                                Index resStride,
                                                const Scalar& alpha,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar,
              typename Index,
              int Mode,
              int LhsStorageOrder,
              bool ConjugateLhs,
              int RhsStorageOrder,
              bool ConjugateRhs,
              int ResInnerStride,
              int Version>
    __attribute__((noinline)) void
    product_triangular_matrix_matrix<Scalar,
                                     Index,
                                     Mode,
                                     false,
                                     LhsStorageOrder,
                                     ConjugateLhs,
                                     RhsStorageOrder,
                                     ConjugateRhs,
                                     ColMajor,
                                     ResInnerStride,
                                     Version>::run(Index _rows,
                                                   Index _cols,
                                                   Index _depth,
                                                   const Scalar* lhs_,
                                                   Index lhsStride,
                                                   const Scalar* rhs_,
                                                   Index rhsStride,
                                                   Scalar* res_,
                                                   Index resIncr,
                                                   Index resStride,
                                                   const Scalar& alpha,
                                                   level3_blocking<Scalar, Scalar>& blocking) {
      const Index PacketBytes = packet_traits<Scalar>::size * sizeof(Scalar);
      Index diagSize = (std::min)(_cols, _depth);
      Index rows = _rows;
      Index depth = IsLower ? _depth : diagSize;
      Index cols = IsLower ? diagSize : _cols;
      typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
      typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
      typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
      LhsMapper lhs(lhs_, lhsStride);
      RhsMapper rhs(rhs_, rhsStride);
      ResMapper res(res_, resStride, resIncr);
      Index kc = blocking.kc();
      Index mc = (std::min)(rows, blocking.mc());
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * cols + 64 / sizeof(Scalar);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      internal::constructor_without_unaligned_array_assert a;
      Matrix<Scalar, SmallPanelWidth, SmallPanelWidth, RhsStorageOrder> triangularBuffer(a);
      triangularBuffer.setZero();
      if ((Mode & ZeroDiag) == ZeroDiag)
        triangularBuffer.diagonal().setZero();
      else
        triangularBuffer.diagonal().setOnes();
      gebp_kernel<Scalar, Scalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp_kernel;
      gemm_pack_lhs<Scalar,
                    Index,
                    LhsMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    LhsStorageOrder>
          pack_lhs;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder, false, true> pack_rhs_panel;
      for (Index k2 = IsLower ? 0 : depth; IsLower ? k2 < depth : k2 > 0; IsLower ? k2 += kc : k2 -= kc) {
        Index actual_kc = (std::min)(IsLower ? depth - k2 : k2, kc);
        Index actual_k2 = IsLower ? k2 : k2 - actual_kc;
        if (IsLower && (k2 < cols) && (actual_k2 + actual_kc > cols)) {
          actual_kc = cols - k2;
          k2 = actual_k2 + actual_kc - kc;
        }
        Index rs = IsLower ? (std::min)(cols, actual_k2) : cols - k2;
        Index ts = (IsLower && actual_k2 >= cols) ? 0 : actual_kc;
        Scalar* geb = blockB + ts * ts;
        geb = geb + internal::first_aligned<PacketBytes>(geb, PacketBytes / sizeof(Scalar));
        pack_rhs(geb, rhs.getSubMapper(actual_k2, IsLower ? 0 : k2), actual_kc, rs);
        if (ts > 0) {
          for (Index j2 = 0; j2 < actual_kc; j2 += SmallPanelWidth) {
            Index actualPanelWidth = std::min<Index>(actual_kc - j2, SmallPanelWidth);
            Index actual_j2 = actual_k2 + j2;
            Index panelOffset = IsLower ? j2 + actualPanelWidth : 0;
            Index panelLength = IsLower ? actual_kc - j2 - actualPanelWidth : j2;
            pack_rhs_panel(blockB + j2 * actual_kc,
                           rhs.getSubMapper(actual_k2 + panelOffset, actual_j2),
                           panelLength,
                           actualPanelWidth,
                           actual_kc,
                           panelOffset);
            for (Index j = 0; j < actualPanelWidth; ++j) {
              if (SetDiag)
                triangularBuffer.coeffRef(j, j) = rhs(actual_j2 + j, actual_j2 + j);
              for (Index k = IsLower ? j + 1 : 0; IsLower ? k < actualPanelWidth : k < j; ++k)
                triangularBuffer.coeffRef(k, j) = rhs(actual_j2 + k, actual_j2 + j);
            }
            pack_rhs_panel(blockB + j2 * actual_kc,
                           RhsMapper(triangularBuffer.data(), triangularBuffer.outerStride()),
                           actualPanelWidth,
                           actualPanelWidth,
                           actual_kc,
                           j2);
          }
        }
        for (Index i2 = 0; i2 < rows; i2 += mc) {
          const Index actual_mc = (std::min)(mc, rows - i2);
          pack_lhs(blockA, lhs.getSubMapper(i2, actual_k2), actual_kc, actual_mc);
          if (ts > 0) {
            for (Index j2 = 0; j2 < actual_kc; j2 += SmallPanelWidth) {
              Index actualPanelWidth = std::min<Index>(actual_kc - j2, SmallPanelWidth);
              Index panelLength = IsLower ? actual_kc - j2 : j2 + actualPanelWidth;
              Index blockOffset = IsLower ? j2 : 0;
              gebp_kernel(res.getSubMapper(i2, actual_k2 + j2),
                          blockA,
                          blockB + j2 * actual_kc,
                          actual_mc,
                          panelLength,
                          actualPanelWidth,
                          alpha,
                          actual_kc,
                          actual_kc,
                          blockOffset,
                          blockOffset);
            }
          }
          gebp_kernel(
              res.getSubMapper(i2, IsLower ? 0 : k2), blockA, geb, actual_mc, actual_kc, rs, alpha, -1, -1, 0, 0);
        }
      }
    }
  }  // namespace internal
  namespace internal {
    template <int Mode, bool LhsIsTriangular, typename Lhs, typename Rhs>
    struct triangular_product_impl<Mode, LhsIsTriangular, Lhs, false, Rhs, false> {
      template <typename Dest>
      static void run(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const typename Dest::Scalar& alpha) {
        typedef typename Lhs::Scalar LhsScalar;
        typedef typename Rhs::Scalar RhsScalar;
        typedef typename Dest::Scalar Scalar;
        typedef internal::blas_traits<Lhs> LhsBlasTraits;
        typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
        typedef internal::remove_all_t<ActualLhsType> ActualLhsTypeCleaned;
        typedef internal::blas_traits<Rhs> RhsBlasTraits;
        typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
        typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
        internal::add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
        internal::add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
        LhsScalar lhs_alpha = LhsBlasTraits::extractScalarFactor(a_lhs);
        RhsScalar rhs_alpha = RhsBlasTraits::extractScalarFactor(a_rhs);
        Scalar actualAlpha = alpha * lhs_alpha * rhs_alpha;
        typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor,
                                              Scalar,
                                              Scalar,
                                              Lhs::MaxRowsAtCompileTime,
                                              Rhs::MaxColsAtCompileTime,
                                              Lhs::MaxColsAtCompileTime,
                                              4>
            BlockingType;
        enum { IsLower = (Mode & Lower) == Lower };
        Index stripedRows = ((!LhsIsTriangular) || (IsLower)) ? lhs.rows() : (std::min)(lhs.rows(), lhs.cols());
        Index stripedCols = ((LhsIsTriangular) || (!IsLower)) ? rhs.cols() : (std::min)(rhs.cols(), rhs.rows());
        Index stripedDepth = LhsIsTriangular ? ((!IsLower) ? lhs.cols() : (std::min)(lhs.cols(), lhs.rows()))
                                             : ((IsLower) ? rhs.rows() : (std::min)(rhs.rows(), rhs.cols()));
        BlockingType blocking(stripedRows, stripedCols, stripedDepth, 1, false);
        internal::product_triangular_matrix_matrix<
            Scalar,
            Index,
            Mode,
            LhsIsTriangular,
            (internal::traits<ActualLhsTypeCleaned>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            LhsBlasTraits::NeedToConjugate,
            (internal::traits<ActualRhsTypeCleaned>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            RhsBlasTraits::NeedToConjugate,
            (internal::traits<Dest>::Flags & RowMajorBit) ? RowMajor : ColMajor,
            Dest::InnerStrideAtCompileTime>::run(stripedRows,
                                                 stripedCols,
                                                 stripedDepth,
                                                 &lhs.coeffRef(0, 0),
                                                 lhs.outerStride(),
                                                 &rhs.coeffRef(0, 0),
                                                 rhs.outerStride(),
                                                 &dst.coeffRef(0, 0),
                                                 dst.innerStride(),
                                                 dst.outerStride(),
                                                 actualAlpha,
                                                 blocking);
        if ((Mode & UnitDiag) == UnitDiag) {
          if (LhsIsTriangular && !numext::is_exactly_one(lhs_alpha)) {
            Index diagSize = (std::min)(lhs.rows(), lhs.cols());
            dst.topRows(diagSize) -= ((lhs_alpha - LhsScalar(1)) * a_rhs).topRows(diagSize);
          } else if ((!LhsIsTriangular) && !numext::is_exactly_one(rhs_alpha)) {
            Index diagSize = (std::min)(rhs.rows(), rhs.cols());
            dst.leftCols(diagSize) -= (rhs_alpha - RhsScalar(1)) * a_lhs.leftCols(diagSize);
          }
        }
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    struct trsmKernelL {
      static void kernel(Index size,
                         Index otherSize,
                         const Scalar* _tri,
                         Index triStride,
                         Scalar* _other,
                         Index otherIncr,
                         Index otherStride);
    };
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    struct trsmKernelR {
      static void kernel(Index size,
                         Index otherSize,
                         const Scalar* _tri,
                         Index triStride,
                         Scalar* _other,
                         Index otherIncr,
                         Index otherStride);
    };
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    inline void trsmKernelL<Scalar, Index, Mode, Conjugate, TriStorageOrder, OtherInnerStride>::kernel(
        Index size,
        Index otherSize,
        const Scalar* _tri,
        Index triStride,
        Scalar* _other,
        Index otherIncr,
        Index otherStride) {
      typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> TriMapper;
      typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> OtherMapper;
      TriMapper tri(_tri, triStride);
      OtherMapper other(_other, otherStride, otherIncr);
      enum { IsLower = (Mode & Lower) == Lower };
      conj_if<Conjugate> conj;
      for (Index k = 0; k < size; ++k) {
        Index i = IsLower ? k : -k - 1;
        Index rs = size - k - 1;
        Index s = TriStorageOrder == RowMajor ? (IsLower ? 0 : i + 1) : IsLower ? i + 1 : i - rs;
        Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1) / conj(tri(i, i));
        for (Index j = 0; j < otherSize; ++j) {
          if (TriStorageOrder == RowMajor) {
            Scalar b(0);
            const Scalar* l = &tri(i, s);
            typename OtherMapper::LinearMapper r = other.getLinearMapper(s, j);
            for (Index i3 = 0; i3 < k; ++i3)
              b += conj(l[i3]) * r(i3);
            other(i, j) = (other(i, j) - b) * a;
          } else {
            Scalar& otherij = other(i, j);
            otherij *= a;
            Scalar b = otherij;
            typename OtherMapper::LinearMapper r = other.getLinearMapper(s, j);
            typename TriMapper::LinearMapper l = tri.getLinearMapper(s, i);
            for (Index i3 = 0; i3 < rs; ++i3)
              r(i3) -= b * conj(l(i3));
          }
        }
      }
    }
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    inline void trsmKernelR<Scalar, Index, Mode, Conjugate, TriStorageOrder, OtherInnerStride>::kernel(
        Index size,
        Index otherSize,
        const Scalar* _tri,
        Index triStride,
        Scalar* _other,
        Index otherIncr,
        Index otherStride) {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> LhsMapper;
      typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> RhsMapper;
      LhsMapper lhs(_other, otherStride, otherIncr);
      RhsMapper rhs(_tri, triStride);
      enum { RhsStorageOrder = TriStorageOrder, IsLower = (Mode & Lower) == Lower };
      conj_if<Conjugate> conj;
      for (Index k = 0; k < size; ++k) {
        Index j = IsLower ? size - k - 1 : k;
        typename LhsMapper::LinearMapper r = lhs.getLinearMapper(0, j);
        for (Index k3 = 0; k3 < k; ++k3) {
          Scalar b = conj(rhs(IsLower ? j + 1 + k3 : k3, j));
          typename LhsMapper::LinearMapper a = lhs.getLinearMapper(0, IsLower ? j + 1 + k3 : k3);
          for (Index i = 0; i < otherSize; ++i)
            r(i) -= a(i) * b;
        }
        if ((Mode & UnitDiag) == 0) {
          Scalar inv_rjj = RealScalar(1) / conj(rhs(j, j));
          for (Index i = 0; i < otherSize; ++i)
            r(i) *= inv_rjj;
        }
      }
    }
    template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    struct triangular_solve_matrix<Scalar, Index, Side, Mode, Conjugate, TriStorageOrder, RowMajor, OtherInnerStride> {
      static void run(Index size,
                      Index cols,
                      const Scalar* tri,
                      Index triStride,
                      Scalar* _other,
                      Index otherIncr,
                      Index otherStride,
                      level3_blocking<Scalar, Scalar>& blocking) {
        triangular_solve_matrix<Scalar,
                                Index,
                                Side == OnTheLeft ? OnTheRight : OnTheLeft,
                                (Mode & UnitDiag) | ((Mode & Upper) ? Lower : Upper),
                                NumTraits<Scalar>::IsComplex && Conjugate,
                                TriStorageOrder == RowMajor ? ColMajor : RowMajor,
                                ColMajor,
                                OtherInnerStride>::run(size,
                                                       cols,
                                                       tri,
                                                       triStride,
                                                       _other,
                                                       otherIncr,
                                                       otherStride,
                                                       blocking);
      }
    };
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    struct triangular_solve_matrix<Scalar, Index, OnTheLeft, Mode, Conjugate, TriStorageOrder, ColMajor, OtherInnerStride> {
      static __attribute__((noinline)) void run(Index size,
                                                Index otherSize,
                                                const Scalar* _tri,
                                                Index triStride,
                                                Scalar* _other,
                                                Index otherIncr,
                                                Index otherStride,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    __attribute__((noinline)) void
    triangular_solve_matrix<Scalar, Index, OnTheLeft, Mode, Conjugate, TriStorageOrder, ColMajor, OtherInnerStride>::run(
        Index size,
        Index otherSize,
        const Scalar* _tri,
        Index triStride,
        Scalar* _other,
        Index otherIncr,
        Index otherStride,
        level3_blocking<Scalar, Scalar>& blocking) {
      Index cols = otherSize;
      std::ptrdiff_t l1, l2, l3;
      manage_caching_sizes(GetAction, &l1, &l2, &l3);
      typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> TriMapper;
      typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> OtherMapper;
      TriMapper tri(_tri, triStride);
      OtherMapper other(_other, otherStride, otherIncr);
      typedef gebp_traits<Scalar, Scalar> Traits;
      enum { SmallPanelWidth = plain_enum_max(Traits::mr, Traits::nr), IsLower = (Mode & Lower) == Lower };
      Index kc = blocking.kc();
      Index mc = (std::min)(size, blocking.mc());
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * cols;
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      gebp_kernel<Scalar, Scalar, Index, OtherMapper, Traits::mr, Traits::nr, Conjugate, false> gebp_kernel;
      gemm_pack_lhs<Scalar,
                    Index,
                    TriMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    TriStorageOrder>
          pack_lhs;
      gemm_pack_rhs<Scalar, Index, OtherMapper, Traits::nr, ColMajor, false, true> pack_rhs;
      Index subcols = cols > 0 ? l2 / (4 * sizeof(Scalar) * std::max<Index>(otherStride, size)) : 0;
      subcols = std::max<Index>((subcols / Traits::nr) * Traits::nr, Traits::nr);
      for (Index k2 = IsLower ? 0 : size; IsLower ? k2 < size : k2 > 0; IsLower ? k2 += kc : k2 -= kc) {
        const Index actual_kc = (std::min)(IsLower ? size - k2 : k2, kc);
        for (Index j2 = 0; j2 < cols; j2 += subcols) {
          Index actual_cols = (std::min)(cols - j2, subcols);
          for (Index k1 = 0; k1 < actual_kc; k1 += SmallPanelWidth) {
            Index actualPanelWidth = std::min<Index>(actual_kc - k1, SmallPanelWidth);
            {
              Index i = IsLower ? k2 + k1 : k2 - k1;
              trsmKernelL<Scalar, Index, Mode, Conjugate, TriStorageOrder, OtherInnerStride>::kernel(
                  actualPanelWidth,
                  actual_cols,
                  _tri + i + (i)*triStride,
                  triStride,
                  _other + i * OtherInnerStride + j2 * otherStride,
                  otherIncr,
                  otherStride);
            }
            Index lengthTarget = actual_kc - k1 - actualPanelWidth;
            Index startBlock = IsLower ? k2 + k1 : k2 - k1 - actualPanelWidth;
            Index blockBOffset = IsLower ? k1 : lengthTarget;
            pack_rhs(blockB + actual_kc * j2,
                     other.getSubMapper(startBlock, j2),
                     actualPanelWidth,
                     actual_cols,
                     actual_kc,
                     blockBOffset);
            if (lengthTarget > 0) {
              Index startTarget = IsLower ? k2 + k1 + actualPanelWidth : k2 - actual_kc;
              pack_lhs(blockA, tri.getSubMapper(startTarget, startBlock), actualPanelWidth, lengthTarget);
              gebp_kernel(other.getSubMapper(startTarget, j2),
                          blockA,
                          blockB + actual_kc * j2,
                          lengthTarget,
                          actualPanelWidth,
                          actual_cols,
                          Scalar(-1),
                          actualPanelWidth,
                          actual_kc,
                          0,
                          blockBOffset);
            }
          }
        }
        {
          Index start = IsLower ? k2 + kc : 0;
          Index end = IsLower ? size : k2 - kc;
          for (Index i2 = start; i2 < end; i2 += mc) {
            const Index actual_mc = (std::min)(mc, end - i2);
            if (actual_mc > 0) {
              pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2 - kc), actual_kc, actual_mc);
              gebp_kernel(
                  other.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0);
            }
          }
        }
      }
    }
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    struct triangular_solve_matrix<Scalar, Index, OnTheRight, Mode, Conjugate, TriStorageOrder, ColMajor, OtherInnerStride> {
      static __attribute__((noinline)) void run(Index size,
                                                Index otherSize,
                                                const Scalar* _tri,
                                                Index triStride,
                                                Scalar* _other,
                                                Index otherIncr,
                                                Index otherStride,
                                                level3_blocking<Scalar, Scalar>& blocking);
    };
    template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
    __attribute__((noinline)) void
    triangular_solve_matrix<Scalar, Index, OnTheRight, Mode, Conjugate, TriStorageOrder, ColMajor, OtherInnerStride>::run(
        Index size,
        Index otherSize,
        const Scalar* _tri,
        Index triStride,
        Scalar* _other,
        Index otherIncr,
        Index otherStride,
        level3_blocking<Scalar, Scalar>& blocking) {
      Index rows = otherSize;
      typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> LhsMapper;
      typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> RhsMapper;
      LhsMapper lhs(_other, otherStride, otherIncr);
      RhsMapper rhs(_tri, triStride);
      typedef gebp_traits<Scalar, Scalar> Traits;
      enum {
        RhsStorageOrder = TriStorageOrder,
        SmallPanelWidth = plain_enum_max(Traits::mr, Traits::nr),
        IsLower = (Mode & Lower) == Lower
      };
      Index kc = blocking.kc();
      Index mc = (std::min)(rows, blocking.mc());
      std::size_t sizeA = kc * mc;
      std::size_t sizeB = kc * size;
      Eigen::internal::check_size_for_overflow<Scalar>(sizeA);
      Scalar* blockA =
          (blocking.blockA()) != 0
              ? (blocking.blockA())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeA <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeA + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeA));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockA_stack_memory_destructor(
          (blocking.blockA()) == 0 ? blockA : 0, sizeA, sizeof(Scalar) * sizeA > 131072);
      Eigen::internal::check_size_for_overflow<Scalar>(sizeB);
      Scalar* blockB =
          (blocking.blockB()) != 0
              ? (blocking.blockB())
              : reinterpret_cast<Scalar*>(
                    (sizeof(Scalar) * sizeB <= 131072)
                        ? reinterpret_cast<void*>(
                              (internal::UIntPtr(__builtin_alloca(sizeof(Scalar) * sizeB + 64 - 1)) + 64 - 1) &
                              ~(std::size_t(64 - 1)))
                        : Eigen::internal::aligned_malloc(sizeof(Scalar) * sizeB));
      Eigen::internal::aligned_stack_memory_handler<Scalar> blockB_stack_memory_destructor(
          (blocking.blockB()) == 0 ? blockB : 0, sizeB, sizeof(Scalar) * sizeB > 131072);
      gebp_kernel<Scalar, Scalar, Index, LhsMapper, Traits::mr, Traits::nr, false, Conjugate> gebp_kernel;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
      gemm_pack_rhs<Scalar, Index, RhsMapper, Traits::nr, RhsStorageOrder, false, true> pack_rhs_panel;
      gemm_pack_lhs<Scalar,
                    Index,
                    LhsMapper,
                    Traits::mr,
                    Traits::LhsProgress,
                    typename Traits::LhsPacket4Packing,
                    ColMajor,
                    false,
                    true>
          pack_lhs_panel;
      for (Index k2 = IsLower ? size : 0; IsLower ? k2 > 0 : k2 < size; IsLower ? k2 -= kc : k2 += kc) {
        const Index actual_kc = (std::min)(IsLower ? k2 : size - k2, kc);
        Index actual_k2 = IsLower ? k2 - actual_kc : k2;
        Index startPanel = IsLower ? 0 : k2 + actual_kc;
        Index rs = IsLower ? actual_k2 : size - actual_k2 - actual_kc;
        Scalar* geb = blockB + actual_kc * actual_kc;
        if (rs > 0)
          pack_rhs(geb, rhs.getSubMapper(actual_k2, startPanel), actual_kc, rs);
        {
          for (Index j2 = 0; j2 < actual_kc; j2 += SmallPanelWidth) {
            Index actualPanelWidth = std::min<Index>(actual_kc - j2, SmallPanelWidth);
            Index actual_j2 = actual_k2 + j2;
            Index panelOffset = IsLower ? j2 + actualPanelWidth : 0;
            Index panelLength = IsLower ? actual_kc - j2 - actualPanelWidth : j2;
            if (panelLength > 0)
              pack_rhs_panel(blockB + j2 * actual_kc,
                             rhs.getSubMapper(actual_k2 + panelOffset, actual_j2),
                             panelLength,
                             actualPanelWidth,
                             actual_kc,
                             panelOffset);
          }
        }
        for (Index i2 = 0; i2 < rows; i2 += mc) {
          const Index actual_mc = (std::min)(mc, rows - i2);
          {
            for (Index j2 = IsLower ? (actual_kc - ((actual_kc % SmallPanelWidth) ? Index(actual_kc % SmallPanelWidth)
                                                                                  : Index(SmallPanelWidth)))
                                    : 0;
                 IsLower ? j2 >= 0 : j2 < actual_kc;
                 IsLower ? j2 -= SmallPanelWidth : j2 += SmallPanelWidth) {
              Index actualPanelWidth = std::min<Index>(actual_kc - j2, SmallPanelWidth);
              Index absolute_j2 = actual_k2 + j2;
              Index panelOffset = IsLower ? j2 + actualPanelWidth : 0;
              Index panelLength = IsLower ? actual_kc - j2 - actualPanelWidth : j2;
              if (panelLength > 0) {
                gebp_kernel(lhs.getSubMapper(i2, absolute_j2),
                            blockA,
                            blockB + j2 * actual_kc,
                            actual_mc,
                            panelLength,
                            actualPanelWidth,
                            Scalar(-1),
                            actual_kc,
                            actual_kc,
                            panelOffset,
                            panelOffset);
              }
              {
                trsmKernelR<Scalar, Index, Mode, Conjugate, TriStorageOrder, OtherInnerStride>::kernel(
                    actualPanelWidth,
                    actual_mc,
                    _tri + absolute_j2 + absolute_j2 * triStride,
                    triStride,
                    _other + i2 * OtherInnerStride + absolute_j2 * otherStride,
                    otherIncr,
                    otherStride);
              }
              pack_lhs_panel(blockA, lhs.getSubMapper(i2, absolute_j2), actualPanelWidth, actual_mc, actual_kc, j2);
            }
          }
          if (rs > 0)
            gebp_kernel(
                lhs.getSubMapper(i2, startPanel), blockA, geb, actual_mc, actual_kc, rs, Scalar(-1), -1, -1, 0, 0);
        }
      }
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename LhsScalar, typename RhsScalar, typename Index, int Mode, bool Conjugate, int StorageOrder>
    struct triangular_solve_vector<LhsScalar, RhsScalar, Index, OnTheRight, Mode, Conjugate, StorageOrder> {
      static void run(Index size, const LhsScalar* _lhs, Index lhsStride, RhsScalar* rhs) {
        triangular_solve_vector<LhsScalar,
                                RhsScalar,
                                Index,
                                OnTheLeft,
                                ((Mode & Upper) == Upper ? Lower : Upper) | (Mode & UnitDiag),
                                Conjugate,
                                StorageOrder == RowMajor ? ColMajor : RowMajor>::run(size, _lhs, lhsStride, rhs);
      }
    };
    template <typename LhsScalar, typename RhsScalar, typename Index, int Mode, bool Conjugate>
    struct triangular_solve_vector<LhsScalar, RhsScalar, Index, OnTheLeft, Mode, Conjugate, RowMajor> {
      enum { IsLower = ((Mode & Lower) == Lower) };
      static void run(Index size, const LhsScalar* _lhs, Index lhsStride, RhsScalar* rhs) {
        typedef Map<const Matrix<LhsScalar, Dynamic, Dynamic, RowMajor>, 0, OuterStride<>> LhsMap;
        const LhsMap lhs(_lhs, size, size, OuterStride<>(lhsStride));
        typedef const_blas_data_mapper<LhsScalar, Index, RowMajor> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, ColMajor> RhsMapper;
        std::conditional_t<Conjugate,
                           const CwiseUnaryOp<typename internal::scalar_conjugate_op<LhsScalar>, LhsMap>,
                           const LhsMap&>
            cjLhs(lhs);
        static const Index PanelWidth = 8;
        for (Index pi = IsLower ? 0 : size; IsLower ? pi < size : pi > 0;
             IsLower ? pi += PanelWidth : pi -= PanelWidth) {
          Index actualPanelWidth = (std::min)(IsLower ? size - pi : pi, PanelWidth);
          Index r = IsLower ? pi : size - pi;
          if (r > 0) {
            Index startRow = IsLower ? pi : pi - actualPanelWidth;
            Index startCol = IsLower ? 0 : pi;
            general_matrix_vector_product<Index, LhsScalar, LhsMapper, RowMajor, Conjugate, RhsScalar, RhsMapper, false>::
                run(actualPanelWidth,
                    r,
                    LhsMapper(&lhs.coeffRef(startRow, startCol), lhsStride),
                    RhsMapper(rhs + startCol, 1),
                    rhs + startRow,
                    1,
                    RhsScalar(-1));
          }
          for (Index k = 0; k < actualPanelWidth; ++k) {
            Index i = IsLower ? pi + k : pi - k - 1;
            Index s = IsLower ? pi : i + 1;
            if (k > 0)
              rhs[i] -= (cjLhs.row(i).segment(s, k).transpose().cwiseProduct(
                             Map<const Matrix<RhsScalar, Dynamic, 1>>(rhs + s, k)))
                            .sum();
            if ((!(Mode & UnitDiag)) && !is_identically_zero(rhs[i]))
              rhs[i] /= cjLhs(i, i);
          }
        }
      }
    };
    template <typename LhsScalar, typename RhsScalar, typename Index, int Mode, bool Conjugate>
    struct triangular_solve_vector<LhsScalar, RhsScalar, Index, OnTheLeft, Mode, Conjugate, ColMajor> {
      enum { IsLower = ((Mode & Lower) == Lower) };
      static void run(Index size, const LhsScalar* _lhs, Index lhsStride, RhsScalar* rhs) {
        typedef Map<const Matrix<LhsScalar, Dynamic, Dynamic, ColMajor>, 0, OuterStride<>> LhsMap;
        const LhsMap lhs(_lhs, size, size, OuterStride<>(lhsStride));
        typedef const_blas_data_mapper<LhsScalar, Index, ColMajor> LhsMapper;
        typedef const_blas_data_mapper<RhsScalar, Index, ColMajor> RhsMapper;
        std::conditional_t<Conjugate,
                           const CwiseUnaryOp<typename internal::scalar_conjugate_op<LhsScalar>, LhsMap>,
                           const LhsMap&>
            cjLhs(lhs);
        static const Index PanelWidth = 8;
        for (Index pi = IsLower ? 0 : size; IsLower ? pi < size : pi > 0;
             IsLower ? pi += PanelWidth : pi -= PanelWidth) {
          Index actualPanelWidth = (std::min)(IsLower ? size - pi : pi, PanelWidth);
          Index startBlock = IsLower ? pi : pi - actualPanelWidth;
          Index endBlock = IsLower ? pi + actualPanelWidth : 0;
          for (Index k = 0; k < actualPanelWidth; ++k) {
            Index i = IsLower ? pi + k : pi - k - 1;
            if (!is_identically_zero(rhs[i])) {
              if (!(Mode & UnitDiag))
                rhs[i] /= cjLhs.coeff(i, i);
              Index r = actualPanelWidth - k - 1;
              Index s = IsLower ? i + 1 : i - r;
              if (r > 0)
                Map<Matrix<RhsScalar, Dynamic, 1>>(rhs + s, r) -= rhs[i] * cjLhs.col(i).segment(s, r);
            }
          }
          Index r = IsLower ? size - endBlock : startBlock;
          if (r > 0) {
            general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, Conjugate, RhsScalar, RhsMapper, false>::
                run(r,
                    actualPanelWidth,
                    LhsMapper(&lhs.coeffRef(endBlock, startBlock), lhsStride),
                    RhsMapper(rhs + startBlock, 1),
                    rhs + endBlock,
                    1,
                    RhsScalar(-1));
          }
        }
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived>
    class BandMatrixBase : public EigenBase<Derived> {
    public:
      enum {
        Flags = internal::traits<Derived>::Flags,
        CoeffReadCost = internal::traits<Derived>::CoeffReadCost,
        RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
        ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
        MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
        Supers = internal::traits<Derived>::Supers,
        Subs = internal::traits<Derived>::Subs,
        Options = internal::traits<Derived>::Options
      };
      typedef typename internal::traits<Derived>::Scalar Scalar;
      typedef Matrix<Scalar, RowsAtCompileTime, ColsAtCompileTime> DenseMatrixType;
      typedef typename DenseMatrixType::StorageIndex StorageIndex;
      typedef typename internal::traits<Derived>::CoefficientsType CoefficientsType;
      typedef EigenBase<Derived> Base;

    protected:
      enum {
        DataRowsAtCompileTime = ((Supers != Dynamic) && (Subs != Dynamic)) ? 1 + Supers + Subs : Dynamic,
        SizeAtCompileTime = min_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime)
      };

    public:
      using Base::cols;
      using Base::derived;
      using Base::rows;
      inline Index supers() const { return derived().supers(); }
      inline Index subs() const { return derived().subs(); }
      inline const CoefficientsType& coeffs() const { return derived().coeffs(); }
      inline CoefficientsType& coeffs() { return derived().coeffs(); }
      inline Block<CoefficientsType, Dynamic, 1> col(Index i) {
        static_assert((int(Options) & int(RowMajor)) == 0, "THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES");
        ;
        Index start = 0;
        Index len = coeffs().rows();
        if (i <= supers()) {
          start = supers() - i;
          len = (std::min)(rows(), std::max<Index>(0, coeffs().rows() - (supers() - i)));
        } else if (i >= rows() - subs())
          len = std::max<Index>(0, coeffs().rows() - (i + 1 - rows() + subs()));
        return Block<CoefficientsType, Dynamic, 1>(coeffs(), start, i, len, 1);
      }
      inline Block<CoefficientsType, 1, SizeAtCompileTime> diagonal() {
        return Block<CoefficientsType, 1, SizeAtCompileTime>(coeffs(), supers(), 0, 1, (std::min)(rows(), cols()));
      }
      inline const Block<const CoefficientsType, 1, SizeAtCompileTime> diagonal() const {
        return Block<const CoefficientsType, 1, SizeAtCompileTime>(
            coeffs(), supers(), 0, 1, (std::min)(rows(), cols()));
      }
      template <int Index>
      struct DiagonalIntReturnType {
        enum {
          ReturnOpposite =
              (int(Options) & int(SelfAdjoint)) && (((Index) > 0 && Supers == 0) || ((Index) < 0 && Subs == 0)),
          Conjugate = ReturnOpposite && NumTraits<Scalar>::IsComplex,
          ActualIndex = ReturnOpposite ? -Index : Index,
          DiagonalSize =
              (RowsAtCompileTime == Dynamic || ColsAtCompileTime == Dynamic)
                  ? Dynamic
                  : (ActualIndex < 0 ? min_size_prefer_dynamic(ColsAtCompileTime, RowsAtCompileTime + ActualIndex)
                                     : min_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime - ActualIndex))
        };
        typedef Block<CoefficientsType, 1, DiagonalSize> BuildType;
        typedef std::conditional_t<Conjugate, CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, BuildType>, BuildType>
            Type;
      };
      template <int N>
      inline typename DiagonalIntReturnType<N>::Type diagonal() {
        return typename DiagonalIntReturnType<N>::BuildType(
            coeffs(), supers() - N, (std::max)(0, N), 1, diagonalLength(N));
      }
      template <int N>
      inline const typename DiagonalIntReturnType<N>::Type diagonal() const {
        return typename DiagonalIntReturnType<N>::BuildType(
            coeffs(), supers() - N, (std::max)(0, N), 1, diagonalLength(N));
      }
      inline Block<CoefficientsType, 1, Dynamic> diagonal(Index i) {
        (static_cast<bool>((i < 0 && -i <= subs()) || (i >= 0 && i <= supers()))
             ? void(0)
             : __assert_fail("(i<0 && -i<=subs()) || (i>=0 && i<=supers())",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/BandMatrix.h",
                             125,
                             __extension__ __PRETTY_FUNCTION__));
        return Block<CoefficientsType, 1, Dynamic>(coeffs(), supers() - i, std::max<Index>(0, i), 1, diagonalLength(i));
      }
      inline const Block<const CoefficientsType, 1, Dynamic> diagonal(Index i) const {
        (static_cast<bool>((i < 0 && -i <= subs()) || (i >= 0 && i <= supers()))
             ? void(0)
             : __assert_fail("(i<0 && -i<=subs()) || (i>=0 && i<=supers())",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/BandMatrix.h",
                             132,
                             __extension__ __PRETTY_FUNCTION__));
        return Block<const CoefficientsType, 1, Dynamic>(
            coeffs(), supers() - i, std::max<Index>(0, i), 1, diagonalLength(i));
      }
      template <typename Dest>
      inline void evalTo(Dest& dst) const {
        dst.resize(rows(), cols());
        dst.setZero();
        dst.diagonal() = diagonal();
        for (Index i = 1; i <= supers(); ++i)
          dst.diagonal(i) = diagonal(i);
        for (Index i = 1; i <= subs(); ++i)
          dst.diagonal(-i) = diagonal(-i);
      }
      DenseMatrixType toDenseMatrix() const {
        DenseMatrixType res(rows(), cols());
        evalTo(res);
        return res;
      }

    protected:
      inline Index diagonalLength(Index i) const {
        return i < 0 ? (std::min)(cols(), rows() + i) : (std::min)(rows(), cols() - i);
      }
    };
    template <typename Scalar_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    struct traits<BandMatrix<Scalar_, Rows_, Cols_, Supers_, Subs_, Options_>> {
      typedef Scalar_ Scalar;
      typedef Dense StorageKind;
      typedef Eigen::Index StorageIndex;
      enum {
        CoeffReadCost = NumTraits<Scalar>::ReadCost,
        RowsAtCompileTime = Rows_,
        ColsAtCompileTime = Cols_,
        MaxRowsAtCompileTime = Rows_,
        MaxColsAtCompileTime = Cols_,
        Flags = LvalueBit,
        Supers = Supers_,
        Subs = Subs_,
        Options = Options_,
        DataRowsAtCompileTime = ((Supers != Dynamic) && (Subs != Dynamic)) ? 1 + Supers + Subs : Dynamic
      };
      typedef Matrix<Scalar, DataRowsAtCompileTime, ColsAtCompileTime, int(Options) & int(RowMajor) ? RowMajor : ColMajor>
          CoefficientsType;
    };
    template <typename Scalar_, int Rows, int Cols, int Supers, int Subs, int Options>
    class BandMatrix : public BandMatrixBase<BandMatrix<Scalar_, Rows, Cols, Supers, Subs, Options>> {
    public:
      typedef typename internal::traits<BandMatrix>::Scalar Scalar;
      typedef typename internal::traits<BandMatrix>::StorageIndex StorageIndex;
      typedef typename internal::traits<BandMatrix>::CoefficientsType CoefficientsType;
      explicit inline BandMatrix(Index rows = Rows, Index cols = Cols, Index supers = Supers, Index subs = Subs)
          : m_coeffs(1 + supers + subs, cols), m_rows(rows), m_supers(supers), m_subs(subs) {}
      inline constexpr Index rows() const { return m_rows.value(); }
      inline constexpr Index cols() const { return m_coeffs.cols(); }
      inline constexpr Index supers() const { return m_supers.value(); }
      inline constexpr Index subs() const { return m_subs.value(); }
      inline const CoefficientsType& coeffs() const { return m_coeffs; }
      inline CoefficientsType& coeffs() { return m_coeffs; }

    protected:
      CoefficientsType m_coeffs;
      internal::variable_if_dynamic<Index, Rows> m_rows;
      internal::variable_if_dynamic<Index, Supers> m_supers;
      internal::variable_if_dynamic<Index, Subs> m_subs;
    };
    template <typename CoefficientsType_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    class BandMatrixWrapper;
    template <typename CoefficientsType_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    struct traits<BandMatrixWrapper<CoefficientsType_, Rows_, Cols_, Supers_, Subs_, Options_>> {
      typedef typename CoefficientsType_::Scalar Scalar;
      typedef typename CoefficientsType_::StorageKind StorageKind;
      typedef typename CoefficientsType_::StorageIndex StorageIndex;
      enum {
        CoeffReadCost = internal::traits<CoefficientsType_>::CoeffReadCost,
        RowsAtCompileTime = Rows_,
        ColsAtCompileTime = Cols_,
        MaxRowsAtCompileTime = Rows_,
        MaxColsAtCompileTime = Cols_,
        Flags = LvalueBit,
        Supers = Supers_,
        Subs = Subs_,
        Options = Options_,
        DataRowsAtCompileTime = ((Supers != Dynamic) && (Subs != Dynamic)) ? 1 + Supers + Subs : Dynamic
      };
      typedef CoefficientsType_ CoefficientsType;
    };
    template <typename CoefficientsType_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    class BandMatrixWrapper
        : public BandMatrixBase<BandMatrixWrapper<CoefficientsType_, Rows_, Cols_, Supers_, Subs_, Options_>> {
    public:
      typedef typename internal::traits<BandMatrixWrapper>::Scalar Scalar;
      typedef typename internal::traits<BandMatrixWrapper>::CoefficientsType CoefficientsType;
      typedef typename internal::traits<BandMatrixWrapper>::StorageIndex StorageIndex;
      explicit inline BandMatrixWrapper(const CoefficientsType& coeffs,
                                        Index rows = Rows_,
                                        Index cols = Cols_,
                                        Index supers = Supers_,
                                        Index subs = Subs_)
          : m_coeffs(coeffs), m_rows(rows), m_supers(supers), m_subs(subs) {
        Eigen::internal::ignore_unused_variable(cols);
        ;
      }
      inline constexpr Index rows() const { return m_rows.value(); }
      inline constexpr Index cols() const { return m_coeffs.cols(); }
      inline constexpr Index supers() const { return m_supers.value(); }
      inline constexpr Index subs() const { return m_subs.value(); }
      inline const CoefficientsType& coeffs() const { return m_coeffs; }

    protected:
      const CoefficientsType& m_coeffs;
      internal::variable_if_dynamic<Index, Rows_> m_rows;
      internal::variable_if_dynamic<Index, Supers_> m_supers;
      internal::variable_if_dynamic<Index, Subs_> m_subs;
    };
    template <typename Scalar, int Size, int Options>
    class TridiagonalMatrix
        : public BandMatrix<Scalar, Size, Size, Options & SelfAdjoint ? 0 : 1, 1, Options | RowMajor> {
      typedef BandMatrix<Scalar, Size, Size, Options & SelfAdjoint ? 0 : 1, 1, Options | RowMajor> Base;
      typedef typename Base::StorageIndex StorageIndex;

    public:
      explicit TridiagonalMatrix(Index size = Size) : Base(size, size, Options & SelfAdjoint ? 0 : 1, 1) {}
      inline typename Base::template DiagonalIntReturnType<1>::Type super() { return Base::template diagonal<1>(); }
      inline const typename Base::template DiagonalIntReturnType<1>::Type super() const {
        return Base::template diagonal<1>();
      }
      inline typename Base::template DiagonalIntReturnType<-1>::Type sub() { return Base::template diagonal<-1>(); }
      inline const typename Base::template DiagonalIntReturnType<-1>::Type sub() const {
        return Base::template diagonal<-1>();
      }

    protected:
    };
    struct BandShape {};
    template <typename Scalar_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    struct evaluator_traits<BandMatrix<Scalar_, Rows_, Cols_, Supers_, Subs_, Options_>>
        : public evaluator_traits_base<BandMatrix<Scalar_, Rows_, Cols_, Supers_, Subs_, Options_>> {
      typedef BandShape Shape;
    };
    template <typename CoefficientsType_, int Rows_, int Cols_, int Supers_, int Subs_, int Options_>
    struct evaluator_traits<BandMatrixWrapper<CoefficientsType_, Rows_, Cols_, Supers_, Subs_, Options_>>
        : public evaluator_traits_base<BandMatrixWrapper<CoefficientsType_, Rows_, Cols_, Supers_, Subs_, Options_>> {
      typedef BandShape Shape;
    };
    template <>
    struct AssignmentKind<DenseShape, BandShape> {
      typedef EigenBase2EigenBase Kind;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename XprType, typename EvaluatorKind>
    class inner_iterator_selector;
  }
  template <typename XprType>
  class InnerIterator {
  protected:
    typedef internal::inner_iterator_selector<XprType, typename internal::evaluator_traits<XprType>::Kind> IteratorType;
    typedef internal::evaluator<XprType> EvaluatorType;
    typedef typename internal::traits<XprType>::Scalar Scalar;

  public:
    InnerIterator(const XprType& xpr, const Index& outerId) : m_eval(xpr), m_iter(m_eval, outerId, xpr.innerSize()) {}
    inline Scalar value() const { return m_iter.value(); }
    inline InnerIterator& operator++() {
      m_iter.operator++();
      return *this;
    }
    inline InnerIterator& operator+=(Index i) {
      m_iter.operator+=(i);
      return *this;
    }
    inline InnerIterator operator+(Index i) {
      InnerIterator result(*this);
      result += i;
      return result;
    }
    inline Index index() const { return m_iter.index(); }
    inline Index row() const { return m_iter.row(); }
    inline Index col() const { return m_iter.col(); }
    inline operator bool() const { return m_iter; }

  protected:
    EvaluatorType m_eval;
    IteratorType m_iter;

  private:
    template <typename T>
    InnerIterator(const EigenBase<T>&, Index outer);
  };
  namespace internal {
    template <typename XprType>
    class inner_iterator_selector<XprType, IndexBased> {
    protected:
      typedef evaluator<XprType> EvaluatorType;
      typedef typename traits<XprType>::Scalar Scalar;
      enum { IsRowMajor = (XprType::Flags & RowMajorBit) == RowMajorBit };

    public:
      inline inner_iterator_selector(const EvaluatorType& eval, const Index& outerId, const Index& innerSize)
          : m_eval(eval), m_inner(0), m_outer(outerId), m_end(innerSize) {}
      inline Scalar value() const {
        return (IsRowMajor) ? m_eval.coeff(m_outer, m_inner) : m_eval.coeff(m_inner, m_outer);
      }
      inline inner_iterator_selector& operator++() {
        m_inner++;
        return *this;
      }
      inline Index index() const { return m_inner; }
      inline Index row() const { return IsRowMajor ? m_outer : index(); }
      inline Index col() const { return IsRowMajor ? index() : m_outer; }
      inline operator bool() const { return m_inner < m_end && m_inner >= 0; }

    protected:
      const EvaluatorType& m_eval;
      Index m_inner;
      const Index m_outer;
      const Index m_end;
    };
    template <typename XprType>
    class inner_iterator_selector<XprType, IteratorBased> : public evaluator<XprType>::InnerIterator {
    protected:
      typedef typename evaluator<XprType>::InnerIterator Base;
      typedef evaluator<XprType> EvaluatorType;

    public:
      inline inner_iterator_selector(const EvaluatorType& eval, const Index& outerId, const Index&)
          : Base(eval, outerId) {}
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Vector, typename RealVector, bool IsComplex>
    struct rcond_compute_sign {
      static inline Vector run(const Vector& v) {
        const RealVector v_abs = v.cwiseAbs();
        return (v_abs.array() == static_cast<typename Vector::RealScalar>(0))
            .select(Vector::Ones(v.size()), v.cwiseQuotient(v_abs));
      }
    };
    template <typename Vector>
    struct rcond_compute_sign<Vector, Vector, false> {
      static inline Vector run(const Vector& v) {
        return (v.array() < static_cast<typename Vector::RealScalar>(0))
            .select(-Vector::Ones(v.size()), Vector::Ones(v.size()));
      }
    };
    template <typename Decomposition>
    typename Decomposition::RealScalar rcond_invmatrix_L1_norm_estimate(const Decomposition& dec) {
      typedef typename Decomposition::MatrixType MatrixType;
      typedef typename Decomposition::Scalar Scalar;
      typedef typename Decomposition::RealScalar RealScalar;
      typedef typename internal::plain_col_type<MatrixType>::type Vector;
      typedef typename internal::plain_col_type<MatrixType, RealScalar>::type RealVector;
      const bool is_complex = (NumTraits<Scalar>::IsComplex != 0);
      (static_cast<bool>(dec.rows() == dec.cols())
           ? void(0)
           : __assert_fail("dec.rows() == dec.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/ConditionEstimator.h",
                           67,
                           __extension__ __PRETTY_FUNCTION__));
      const Index n = dec.rows();
      if (n == 0)
        return 0;
      Vector v = dec.solve(Vector::Ones(n) / Scalar(n));
      RealScalar lower_bound = v.template lpNorm<1>();
      if (n == 1)
        return lower_bound;
      RealScalar old_lower_bound = lower_bound;
      Vector sign_vector(n);
      Vector old_sign_vector;
      Index v_max_abs_index = -1;
      Index old_v_max_abs_index = v_max_abs_index;
      for (int k = 0; k < 4; ++k) {
        sign_vector = internal::rcond_compute_sign<Vector, RealVector, is_complex>::run(v);
        if (k > 0 && !is_complex && sign_vector == old_sign_vector) {
          break;
        }
        v = dec.adjoint().solve(sign_vector);
        v.real().cwiseAbs().maxCoeff(&v_max_abs_index);
        if (v_max_abs_index == old_v_max_abs_index) {
          break;
        }
        v = dec.solve(Vector::Unit(n, v_max_abs_index));
        lower_bound = v.template lpNorm<1>();
        if (lower_bound <= old_lower_bound) {
          break;
        }
        if (!is_complex) {
          old_sign_vector = sign_vector;
        }
        old_v_max_abs_index = v_max_abs_index;
        old_lower_bound = lower_bound;
      }
      Scalar alternating_sign(RealScalar(1));
      for (Index i = 0; i < n; ++i) {
        v[i] = alternating_sign * static_cast<RealScalar>(RealScalar(1) + (RealScalar(i) / (RealScalar(n - 1))));
        alternating_sign = -alternating_sign;
      }
      v = dec.solve(v);
      const RealScalar alternate_lower_bound = (2 * v.template lpNorm<1>()) / (3 * RealScalar(n));
      return numext::maxi(lower_bound, alternate_lower_bound);
    }
    template <typename Decomposition>
    typename Decomposition::RealScalar rcond_estimate_helper(typename Decomposition::RealScalar matrix_norm,
                                                             const Decomposition& dec) {
      typedef typename Decomposition::RealScalar RealScalar;
      (static_cast<bool>(dec.rows() == dec.cols())
           ? void(0)
           : __assert_fail("dec.rows() == dec.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/ConditionEstimator.h",
                           164,
                           __extension__ __PRETTY_FUNCTION__));
      if (dec.rows() == 0)
        return NumTraits<RealScalar>::infinity();
      if (numext::is_exactly_zero(matrix_norm))
        return RealScalar(0);
      if (dec.rows() == 1)
        return RealScalar(1);
      const RealScalar inverse_matrix_norm = rcond_invmatrix_L1_norm_estimate(dec);
      return (numext::is_exactly_zero(inverse_matrix_norm) ? RealScalar(0)
                                                           : (RealScalar(1) / inverse_matrix_norm) / matrix_norm);
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived, int UnrollCount, int InnerSize>
    struct all_unroller {
      enum {
        IsRowMajor = (int(Derived::Flags) & int(RowMajor)),
        i = (UnrollCount - 1) / InnerSize,
        j = (UnrollCount - 1) % InnerSize
      };
      static inline bool run(const Derived& mat) {
        return all_unroller<Derived, UnrollCount - 1, InnerSize>::run(mat) &&
               mat.coeff(IsRowMajor ? i : j, IsRowMajor ? j : i);
      }
    };
    template <typename Derived, int InnerSize>
    struct all_unroller<Derived, 0, InnerSize> {
      static inline bool run(const Derived&) { return true; }
    };
    template <typename Derived, int InnerSize>
    struct all_unroller<Derived, Dynamic, InnerSize> {
      static inline bool run(const Derived&) { return false; }
    };
    template <typename Derived, int UnrollCount, int InnerSize>
    struct any_unroller {
      enum {
        IsRowMajor = (int(Derived::Flags) & int(RowMajor)),
        i = (UnrollCount - 1) / InnerSize,
        j = (UnrollCount - 1) % InnerSize
      };
      static inline bool run(const Derived& mat) {
        return any_unroller<Derived, UnrollCount - 1, InnerSize>::run(mat) ||
               mat.coeff(IsRowMajor ? i : j, IsRowMajor ? j : i);
      }
    };
    template <typename Derived, int InnerSize>
    struct any_unroller<Derived, 0, InnerSize> {
      static inline bool run(const Derived&) { return false; }
    };
    template <typename Derived, int InnerSize>
    struct any_unroller<Derived, Dynamic, InnerSize> {
      static inline bool run(const Derived&) { return false; }
    };
  }  // namespace internal
  template <typename Derived>
  inline bool DenseBase<Derived>::all() const {
    typedef internal::evaluator<Derived> Evaluator;
    enum {
      unroll = SizeAtCompileTime != Dynamic &&
               SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= 110,
    };
    Evaluator evaluator(derived());
    if (unroll)
      return internal::all_unroller < Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic,
             InnerSizeAtCompileTime > ::run(evaluator);
    else {
      for (Index i = 0; i < derived().outerSize(); ++i)
        for (Index j = 0; j < derived().innerSize(); ++j)
          if (!evaluator.coeff(IsRowMajor ? i : j, IsRowMajor ? j : i))
            return false;
      return true;
    }
  }
  template <typename Derived>
  inline bool DenseBase<Derived>::any() const {
    typedef internal::evaluator<Derived> Evaluator;
    enum {
      unroll = SizeAtCompileTime != Dynamic &&
               SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= 110,
    };
    Evaluator evaluator(derived());
    if (unroll)
      return internal::any_unroller < Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic,
             InnerSizeAtCompileTime > ::run(evaluator);
    else {
      for (Index i = 0; i < derived().outerSize(); ++i)
        for (Index j = 0; j < derived().innerSize(); ++j)
          if (evaluator.coeff(IsRowMajor ? i : j, IsRowMajor ? j : i))
            return true;
      return false;
    }
  }
  template <typename Derived>
  inline Eigen::Index DenseBase<Derived>::count() const {
    return derived().template cast<bool>().template cast<Index>().sum();
  }
  template <typename Derived>
  inline bool DenseBase<Derived>::hasNaN() const {
    return !((derived().array() == derived().array()).all());
  }
  template <typename Derived>
  inline bool DenseBase<Derived>::allFinite() const {
    return !((derived() - derived()).hasNaN());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename ConditionMatrixType, typename ThenMatrixType, typename ElseMatrixType>
    struct traits<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>> : traits<ThenMatrixType> {
      typedef typename traits<ThenMatrixType>::Scalar Scalar;
      typedef Dense StorageKind;
      typedef typename traits<ThenMatrixType>::XprKind XprKind;
      typedef typename ConditionMatrixType::Nested ConditionMatrixNested;
      typedef typename ThenMatrixType::Nested ThenMatrixNested;
      typedef typename ElseMatrixType::Nested ElseMatrixNested;
      enum {
        RowsAtCompileTime = ConditionMatrixType::RowsAtCompileTime,
        ColsAtCompileTime = ConditionMatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = ConditionMatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = ConditionMatrixType::MaxColsAtCompileTime,
        Flags = (unsigned int)ThenMatrixType::Flags & ElseMatrixType::Flags & RowMajorBit
      };
    };
  }  // namespace internal
  template <typename ConditionMatrixType, typename ThenMatrixType, typename ElseMatrixType>
  class Select : public internal::dense_xpr_base<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>>::type,
                 internal::no_assignment_operator {
  public:
    typedef typename internal::dense_xpr_base<Select>::type Base;
    typedef typename Eigen::internal::traits<Select>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Select>::type Nested;
    typedef typename Eigen::internal::traits<Select>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Select>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Select>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Select>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Select>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    inline Select(const ConditionMatrixType& a_conditionMatrix,
                  const ThenMatrixType& a_thenMatrix,
                  const ElseMatrixType& a_elseMatrix)
        : m_condition(a_conditionMatrix), m_then(a_thenMatrix), m_else(a_elseMatrix) {
      (static_cast<bool>(m_condition.rows() == m_then.rows() && m_condition.rows() == m_else.rows())
           ? void(0)
           : __assert_fail("m_condition.rows() == m_then.rows() && m_condition.rows() == m_else.rows()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Select.h",
                           68,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_condition.cols() == m_then.cols() && m_condition.cols() == m_else.cols())
           ? void(0)
           : __assert_fail("m_condition.cols() == m_then.cols() && m_condition.cols() == m_else.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Select.h",
                           69,
                           __extension__ __PRETTY_FUNCTION__));
    }
    inline constexpr Index rows() const noexcept { return m_condition.rows(); }
    inline constexpr Index cols() const noexcept { return m_condition.cols(); }
    inline const Scalar coeff(Index i, Index j) const {
      if (m_condition.coeff(i, j))
        return m_then.coeff(i, j);
      else
        return m_else.coeff(i, j);
    }
    inline const Scalar coeff(Index i) const {
      if (m_condition.coeff(i))
        return m_then.coeff(i);
      else
        return m_else.coeff(i);
    }
    inline const ConditionMatrixType& conditionMatrix() const { return m_condition; }
    inline const ThenMatrixType& thenMatrix() const { return m_then; }
    inline const ElseMatrixType& elseMatrix() const { return m_else; }

  protected:
    typename ConditionMatrixType::Nested m_condition;
    typename ThenMatrixType::Nested m_then;
    typename ElseMatrixType::Nested m_else;
  };
  template <typename Derived>
  template <typename ThenDerived, typename ElseDerived>
  inline const Select<Derived, ThenDerived, ElseDerived> DenseBase<Derived>::select(
      const DenseBase<ThenDerived>& thenMatrix, const DenseBase<ElseDerived>& elseMatrix) const {
    return Select<Derived, ThenDerived, ElseDerived>(derived(), thenMatrix.derived(), elseMatrix.derived());
  }
  template <typename Derived>
  template <typename ThenDerived>
  inline const Select<Derived, ThenDerived, typename ThenDerived::ConstantReturnType> DenseBase<Derived>::select(
      const DenseBase<ThenDerived>& thenMatrix, const typename ThenDerived::Scalar& elseScalar) const {
    return Select<Derived, ThenDerived, typename ThenDerived::ConstantReturnType>(
        derived(), thenMatrix.derived(), ThenDerived::Constant(rows(), cols(), elseScalar));
  }
  template <typename Derived>
  template <typename ElseDerived>
  inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived> DenseBase<Derived>::select(
      const typename ElseDerived::Scalar& thenScalar, const DenseBase<ElseDerived>& elseMatrix) const {
    return Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived>(
        derived(), ElseDerived::Constant(rows(), cols(), thenScalar), elseMatrix.derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType, typename MemberOp, int Direction>
  class PartialReduxExpr;
  namespace internal {
    template <typename MatrixType, typename MemberOp, int Direction>
    struct traits<PartialReduxExpr<MatrixType, MemberOp, Direction>> : traits<MatrixType> {
      typedef typename MemberOp::result_type Scalar;
      typedef typename traits<MatrixType>::StorageKind StorageKind;
      typedef typename traits<MatrixType>::XprKind XprKind;
      typedef typename MatrixType::Scalar InputScalar;
      enum {
        RowsAtCompileTime = Direction == Vertical ? 1 : MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = Direction == Horizontal ? 1 : MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = Direction == Vertical ? 1 : MatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = Direction == Horizontal ? 1 : MatrixType::MaxColsAtCompileTime,
        Flags = RowsAtCompileTime == 1 ? RowMajorBit : 0,
        TraversalSize = Direction == Vertical ? MatrixType::RowsAtCompileTime : MatrixType::ColsAtCompileTime
      };
    };
  }  // namespace internal
  template <typename MatrixType, typename MemberOp, int Direction>
  class PartialReduxExpr : public internal::dense_xpr_base<PartialReduxExpr<MatrixType, MemberOp, Direction>>::type,
                           internal::no_assignment_operator {
  public:
    typedef typename internal::dense_xpr_base<PartialReduxExpr>::type Base;
    typedef typename Eigen::internal::traits<PartialReduxExpr>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<PartialReduxExpr>::type Nested;
    typedef typename Eigen::internal::traits<PartialReduxExpr>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<PartialReduxExpr>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<PartialReduxExpr>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<PartialReduxExpr>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<PartialReduxExpr>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    explicit PartialReduxExpr(const MatrixType& mat, const MemberOp& func = MemberOp())
        : m_matrix(mat), m_functor(func) {}
    constexpr Index rows() const noexcept { return (Direction == Vertical ? 1 : m_matrix.rows()); }
    constexpr Index cols() const noexcept { return (Direction == Horizontal ? 1 : m_matrix.cols()); }
    typename MatrixType::Nested nestedExpression() const { return m_matrix; }
    const MemberOp& functor() const { return m_functor; }

  protected:
    typename MatrixType::Nested m_matrix;
    const MemberOp m_functor;
  };
  template <typename A, typename B>
  struct partial_redux_dummy_func;
  namespace internal {
    template <typename ResultType, typename Scalar>
    struct member_norm {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size + 5) * NumTraits<Scalar>::MulCost + (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.norm();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_stableNorm {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size + 5) * NumTraits<Scalar>::MulCost + (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.stableNorm();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_blueNorm {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size + 5) * NumTraits<Scalar>::MulCost + (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.blueNorm();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_hypotNorm {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * functor_traits<scalar_hypot_op<Scalar>>::Cost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.hypotNorm();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_all {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.all();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_any {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.any();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_count {
      typedef ResultType result_type;
      typedef partial_redux_dummy_func<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 0 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.count();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_sum {
      typedef ResultType result_type;
      typedef internal::scalar_sum_op<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 1 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.sum();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_minCoeff {
      typedef ResultType result_type;
      typedef internal::scalar_min_op<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 1 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.minCoeff();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_maxCoeff {
      typedef ResultType result_type;
      typedef internal::scalar_max_op<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      enum { Vectorizable = 1 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.maxCoeff();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <typename ResultType, typename Scalar>
    struct member_prod {
      typedef ResultType result_type;
      typedef internal::scalar_product_op<Scalar, Scalar> BinaryOp;
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * NumTraits<Scalar>::MulCost };
      };
      enum { Vectorizable = 1 };
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.prod();
      }
      BinaryOp binaryFunc() const { return BinaryOp(); }
    };
    template <int p, typename ResultType, typename Scalar>
    struct member_lpnorm {
      typedef ResultType result_type;
      enum { Vectorizable = 0 };
      template <int Size>
      struct Cost {
        enum { value = (Size + 5) * NumTraits<Scalar>::MulCost + (Size - 1) * NumTraits<Scalar>::AddCost };
      };
      member_lpnorm() {}
      template <typename XprType>
      inline ResultType operator()(const XprType& mat) const {
        return mat.template lpNorm<p>();
      }
    };
    template <typename BinaryOpT, typename Scalar>
    struct member_redux {
      typedef BinaryOpT BinaryOp;
      typedef typename result_of<BinaryOp(const Scalar&, const Scalar&)>::type result_type;
      enum { Vectorizable = functor_traits<BinaryOp>::PacketAccess };
      template <int Size>
      struct Cost {
        enum { value = (Size - 1) * functor_traits<BinaryOp>::Cost };
      };
      explicit member_redux(const BinaryOp func) : m_functor(func) {}
      template <typename Derived>
      inline result_type operator()(const DenseBase<Derived>& mat) const {
        return mat.redux(m_functor);
      }
      const BinaryOp& binaryFunc() const { return m_functor; }
      const BinaryOp m_functor;
    };
  }  // namespace internal
  template <typename ExpressionType, int Direction>
  class VectorwiseOp {
  public:
    typedef typename ExpressionType::Scalar Scalar;
    typedef typename ExpressionType::RealScalar RealScalar;
    typedef Eigen::Index Index;
    typedef typename internal::ref_selector<ExpressionType>::non_const_type ExpressionTypeNested;
    typedef internal::remove_all_t<ExpressionTypeNested> ExpressionTypeNestedCleaned;
    template <template <typename OutScalar, typename InputScalar> class Functor, typename ReturnScalar = Scalar>
    struct ReturnType {
      typedef PartialReduxExpr<ExpressionType, Functor<ReturnScalar, Scalar>, Direction> Type;
    };
    template <typename BinaryOp>
    struct ReduxReturnType {
      typedef PartialReduxExpr<ExpressionType, internal::member_redux<BinaryOp, Scalar>, Direction> Type;
    };
    enum { isVertical = (Direction == Vertical) ? 1 : 0, isHorizontal = (Direction == Horizontal) ? 1 : 0 };

  protected:
    template <typename OtherDerived>
    struct ExtendedType {
      typedef Replicate<OtherDerived,
                        isVertical ? 1 : ExpressionType::RowsAtCompileTime,
                        isHorizontal ? 1 : ExpressionType::ColsAtCompileTime>
          Type;
    };
    template <typename OtherDerived>
    typename ExtendedType<OtherDerived>::Type extendedTo(const DenseBase<OtherDerived>& other) const {
      static_assert(internal::check_implication(isVertical, OtherDerived::MaxColsAtCompileTime == 1),
                    "YOU_PASSED_A_ROW_VECTOR_BUT_A_COLUMN_VECTOR_WAS_EXPECTED");
      static_assert(internal::check_implication(isHorizontal, OtherDerived::MaxRowsAtCompileTime == 1),
                    "YOU_PASSED_A_COLUMN_VECTOR_BUT_A_ROW_VECTOR_WAS_EXPECTED");
      return typename ExtendedType<OtherDerived>::Type(
          other.derived(), isVertical ? 1 : m_matrix.rows(), isHorizontal ? 1 : m_matrix.cols());
    }
    template <typename OtherDerived>
    struct OppositeExtendedType {
      typedef Replicate<OtherDerived,
                        isHorizontal ? 1 : ExpressionType::RowsAtCompileTime,
                        isVertical ? 1 : ExpressionType::ColsAtCompileTime>
          Type;
    };
    template <typename OtherDerived>
    typename OppositeExtendedType<OtherDerived>::Type extendedToOpposite(const DenseBase<OtherDerived>& other) const {
      static_assert(internal::check_implication(isHorizontal, OtherDerived::MaxColsAtCompileTime == 1),
                    "YOU_PASSED_A_ROW_VECTOR_BUT_A_COLUMN_VECTOR_WAS_EXPECTED");
      static_assert(internal::check_implication(isVertical, OtherDerived::MaxRowsAtCompileTime == 1),
                    "YOU_PASSED_A_COLUMN_VECTOR_BUT_A_ROW_VECTOR_WAS_EXPECTED");
      return typename OppositeExtendedType<OtherDerived>::Type(
          other.derived(), isHorizontal ? 1 : m_matrix.rows(), isVertical ? 1 : m_matrix.cols());
    }

  public:
    explicit inline VectorwiseOp(ExpressionType& matrix) : m_matrix(matrix) {}
    inline const ExpressionType& _expression() const { return m_matrix; }
    typedef internal::subvector_stl_iterator<ExpressionType, DirectionType(Direction)> iterator;
    typedef internal::subvector_stl_iterator<const ExpressionType, DirectionType(Direction)> const_iterator;
    typedef internal::subvector_stl_reverse_iterator<ExpressionType, DirectionType(Direction)> reverse_iterator;
    typedef internal::subvector_stl_reverse_iterator<const ExpressionType, DirectionType(Direction)>
        const_reverse_iterator;
    iterator begin() { return iterator(m_matrix, 0); }
    const_iterator begin() const { return const_iterator(m_matrix, 0); }
    const_iterator cbegin() const { return const_iterator(m_matrix, 0); }
    reverse_iterator rbegin() {
      return reverse_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>() - 1);
    }
    const_reverse_iterator rbegin() const {
      return const_reverse_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>() - 1);
    }
    const_reverse_iterator crbegin() const {
      return const_reverse_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>() - 1);
    }
    iterator end() { return iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
    const_iterator end() const {
      return const_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>());
    }
    const_iterator cend() const {
      return const_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>());
    }
    reverse_iterator rend() { return reverse_iterator(m_matrix, -1); }
    const_reverse_iterator rend() const { return const_reverse_iterator(m_matrix, -1); }
    const_reverse_iterator crend() const { return const_reverse_iterator(m_matrix, -1); }
    template <typename BinaryOp>
    const typename ReduxReturnType<BinaryOp>::Type redux(const BinaryOp& func = BinaryOp()) const {
      (static_cast<bool>(redux_length() > 0 && "you are using an empty matrix")
           ? void(0)
           : __assert_fail("redux_length()>0 && \"you are using an empty matrix\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/VectorwiseOp.h",
                           340,
                           __extension__ __PRETTY_FUNCTION__));
      return typename ReduxReturnType<BinaryOp>::Type(_expression(), internal::member_redux<BinaryOp, Scalar>(func));
    }
    typedef typename ReturnType<internal::member_minCoeff>::Type MinCoeffReturnType;
    typedef typename ReturnType<internal::member_maxCoeff>::Type MaxCoeffReturnType;
    typedef PartialReduxExpr<const CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const ExpressionTypeNestedCleaned>,
                             internal::member_sum<RealScalar, RealScalar>,
                             Direction>
        SquaredNormReturnType;
    typedef CwiseUnaryOp<internal::scalar_sqrt_op<RealScalar>, const SquaredNormReturnType> NormReturnType;
    typedef typename ReturnType<internal::member_blueNorm, RealScalar>::Type BlueNormReturnType;
    typedef typename ReturnType<internal::member_stableNorm, RealScalar>::Type StableNormReturnType;
    typedef typename ReturnType<internal::member_hypotNorm, RealScalar>::Type HypotNormReturnType;
    typedef typename ReturnType<internal::member_sum>::Type SumReturnType;
    typedef CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<SumReturnType>::Scalar, Scalar>,
                          const SumReturnType,
                          const typename internal::plain_constant_type<SumReturnType, Scalar>::type>
        MeanReturnType;
    typedef typename ReturnType<internal::member_all>::Type AllReturnType;
    typedef typename ReturnType<internal::member_any>::Type AnyReturnType;
    typedef PartialReduxExpr<ExpressionType, internal::member_count<Index, Scalar>, Direction> CountReturnType;
    typedef typename ReturnType<internal::member_prod>::Type ProdReturnType;
    typedef Reverse<const ExpressionType, Direction> ConstReverseReturnType;
    typedef Reverse<ExpressionType, Direction> ReverseReturnType;
    template <int p>
    struct LpNormReturnType {
      typedef PartialReduxExpr<ExpressionType, internal::member_lpnorm<p, RealScalar, Scalar>, Direction> Type;
    };
    const MinCoeffReturnType minCoeff() const {
      (static_cast<bool>(redux_length() > 0 && "you are using an empty matrix")
           ? void(0)
           : __assert_fail("redux_length()>0 && \"you are using an empty matrix\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/VectorwiseOp.h",
                           379,
                           __extension__ __PRETTY_FUNCTION__));
      return MinCoeffReturnType(_expression());
    }
    const MaxCoeffReturnType maxCoeff() const {
      (static_cast<bool>(redux_length() > 0 && "you are using an empty matrix")
           ? void(0)
           : __assert_fail("redux_length()>0 && \"you are using an empty matrix\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/VectorwiseOp.h",
                           398,
                           __extension__ __PRETTY_FUNCTION__));
      return MaxCoeffReturnType(_expression());
    }
    const SquaredNormReturnType squaredNorm() const { return SquaredNormReturnType(m_matrix.cwiseAbs2()); }
    const NormReturnType norm() const { return NormReturnType(squaredNorm()); }
    template <int p>
    const typename LpNormReturnType<p>::Type lpNorm() const {
      return typename LpNormReturnType<p>::Type(_expression());
    }
    const BlueNormReturnType blueNorm() const { return BlueNormReturnType(_expression()); }
    const StableNormReturnType stableNorm() const { return StableNormReturnType(_expression()); }
    const HypotNormReturnType hypotNorm() const { return HypotNormReturnType(_expression()); }
    const SumReturnType sum() const { return SumReturnType(_expression()); }
    const MeanReturnType mean() const {
      return sum() / Scalar(Direction == Vertical ? m_matrix.rows() : m_matrix.cols());
    }
    const AllReturnType all() const { return AllReturnType(_expression()); }
    const AnyReturnType any() const { return AnyReturnType(_expression()); }
    const CountReturnType count() const { return CountReturnType(_expression()); }
    const ProdReturnType prod() const { return ProdReturnType(_expression()); }
    const ConstReverseReturnType reverse() const { return ConstReverseReturnType(_expression()); }
    ReverseReturnType reverse() { return ReverseReturnType(_expression()); }
    typedef Replicate<ExpressionType, (isVertical ? Dynamic : 1), (isHorizontal ? Dynamic : 1)> ReplicateReturnType;
    const ReplicateReturnType replicate(Index factor) const;
    template <int Factor>
    const Replicate<ExpressionType, isVertical * Factor + isHorizontal, isHorizontal * Factor + isVertical> replicate(
        Index factor = Factor) const {
      return Replicate<ExpressionType, (isVertical ? Factor : 1), (isHorizontal ? Factor : 1)>(
          _expression(), isVertical ? factor : 1, isHorizontal ? factor : 1);
    }
    template <typename OtherDerived>
    ExpressionType& operator=(const DenseBase<OtherDerived>& other) {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix = extendedTo(other.derived());
    }
    template <typename OtherDerived>
    ExpressionType& operator+=(const DenseBase<OtherDerived>& other) {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix += extendedTo(other.derived());
    }
    template <typename OtherDerived>
    ExpressionType& operator-=(const DenseBase<OtherDerived>& other) {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix -= extendedTo(other.derived());
    }
    template <typename OtherDerived>
    ExpressionType& operator*=(const DenseBase<OtherDerived>& other) {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert(
          (Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind, ArrayXpr>::value),
          "THIS_METHOD_IS_ONLY_FOR_ARRAYS_NOT_MATRICES");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      m_matrix *= extendedTo(other.derived());
      return m_matrix;
    }
    template <typename OtherDerived>
    ExpressionType& operator/=(const DenseBase<OtherDerived>& other) {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert(
          (Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind, ArrayXpr>::value),
          "THIS_METHOD_IS_ONLY_FOR_ARRAYS_NOT_MATRICES");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      m_matrix /= extendedTo(other.derived());
      return m_matrix;
    }
    template <typename OtherDerived>
    inline CwiseBinaryOp<internal::scalar_sum_op<Scalar, typename OtherDerived::Scalar>,
                         const ExpressionTypeNestedCleaned,
                         const typename ExtendedType<OtherDerived>::Type>
    operator+(const DenseBase<OtherDerived>& other) const {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix + extendedTo(other.derived());
    }
    template <typename OtherDerived>
    CwiseBinaryOp<internal::scalar_difference_op<Scalar, typename OtherDerived::Scalar>,
                  const ExpressionTypeNestedCleaned,
                  const typename ExtendedType<OtherDerived>::Type>
    operator-(const DenseBase<OtherDerived>& other) const {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix - extendedTo(other.derived());
    }
    template <typename OtherDerived>
    inline CwiseBinaryOp<internal::scalar_product_op<Scalar>,
                         const ExpressionTypeNestedCleaned,
                         const typename ExtendedType<OtherDerived>::Type>
    operator*(const DenseBase<OtherDerived>& other) const {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert(
          (Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind, ArrayXpr>::value),
          "THIS_METHOD_IS_ONLY_FOR_ARRAYS_NOT_MATRICES");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix * extendedTo(other.derived());
    }
    template <typename OtherDerived>
    CwiseBinaryOp<internal::scalar_quotient_op<Scalar>,
                  const ExpressionTypeNestedCleaned,
                  const typename ExtendedType<OtherDerived>::Type>
    operator/(const DenseBase<OtherDerived>& other) const {
      static_assert(OtherDerived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
      static_assert(
          (Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind, ArrayXpr>::value),
          "THIS_METHOD_IS_ONLY_FOR_ARRAYS_NOT_MATRICES");
      static_assert((Eigen::internal::is_same<typename Eigen::internal::traits<ExpressionType>::XprKind,
                                              typename Eigen::internal::traits<OtherDerived>::XprKind>::value),
                    "YOU_CANNOT_MIX_ARRAYS_AND_MATRICES");
      return m_matrix / extendedTo(other.derived());
    }
    CwiseBinaryOp<internal::scalar_quotient_op<Scalar>,
                  const ExpressionTypeNestedCleaned,
                  const typename OppositeExtendedType<NormReturnType>::Type>
    normalized() const {
      return m_matrix.cwiseQuotient(extendedToOpposite(this->norm()));
    }
    void normalize() { m_matrix = this->normalized(); }
    inline void reverseInPlace();
    typedef Homogeneous<ExpressionType, Direction> HomogeneousReturnType;
    HomogeneousReturnType homogeneous() const;
    typedef typename ExpressionType::PlainObject CrossReturnType;
    template <typename OtherDerived>
    const CrossReturnType cross(const MatrixBase<OtherDerived>& other) const;
    enum {
      HNormalized_Size = Direction == Vertical ? internal::traits<ExpressionType>::RowsAtCompileTime
                                               : internal::traits<ExpressionType>::ColsAtCompileTime,
      HNormalized_SizeMinusOne = HNormalized_Size == Dynamic ? Dynamic : HNormalized_Size - 1
    };
    typedef Block<const ExpressionType,
                  Direction == Vertical ? int(HNormalized_SizeMinusOne)
                                        : int(internal::traits<ExpressionType>::RowsAtCompileTime),
                  Direction == Horizontal ? int(HNormalized_SizeMinusOne)
                                          : int(internal::traits<ExpressionType>::ColsAtCompileTime)>
        HNormalized_Block;
    typedef Block<const ExpressionType,
                  Direction == Vertical ? 1 : int(internal::traits<ExpressionType>::RowsAtCompileTime),
                  Direction == Horizontal ? 1 : int(internal::traits<ExpressionType>::ColsAtCompileTime)>
        HNormalized_Factors;
    typedef CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<ExpressionType>::Scalar>,
                          const HNormalized_Block,
                          const Replicate<HNormalized_Factors,
                                          Direction == Vertical ? HNormalized_SizeMinusOne : 1,
                                          Direction == Horizontal ? HNormalized_SizeMinusOne : 1>>
        HNormalizedReturnType;
    const HNormalizedReturnType hnormalized() const;

  protected:
    Index redux_length() const { return Direction == Vertical ? m_matrix.rows() : m_matrix.cols(); }
    ExpressionTypeNested m_matrix;
  };
  template <typename Derived>
  inline typename DenseBase<Derived>::ColwiseReturnType DenseBase<Derived>::colwise() {
    return ColwiseReturnType(derived());
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::RowwiseReturnType DenseBase<Derived>::rowwise() {
    return RowwiseReturnType(derived());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Func, typename Evaluator>
    struct packetwise_redux_traits {
      enum {
        OuterSize = int(Evaluator::IsRowMajor) ? Evaluator::RowsAtCompileTime : Evaluator::ColsAtCompileTime,
        Cost = OuterSize == Dynamic
                   ? HugeCost
                   : OuterSize * Evaluator::CoeffReadCost + (OuterSize - 1) * functor_traits<Func>::Cost,
        Unrolling = Cost <= 110 ? CompleteUnrolling : NoUnrolling
      };
    };
    template <typename PacketType, typename Func>
    PacketType packetwise_redux_empty_value(const Func&) {
      const typename unpacket_traits<PacketType>::type zero(0);
      return pset1<PacketType>(zero);
    }
    template <typename PacketType, typename Scalar>
    PacketType packetwise_redux_empty_value(const scalar_product_op<Scalar, Scalar>&) {
      return pset1<PacketType>(Scalar(1));
    }
    template <typename Func, typename Evaluator, int Unrolling = packetwise_redux_traits<Func, Evaluator>::Unrolling>
    struct packetwise_redux_impl;
    template <typename Func, typename Evaluator>
    struct packetwise_redux_impl<Func, Evaluator, CompleteUnrolling> {
      typedef redux_novec_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> Base;
      typedef typename Evaluator::Scalar Scalar;
      template <typename PacketType>
      static inline PacketType run(const Evaluator& eval, const Func& func, Index) {
        return redux_vec_unroller<Func, Evaluator, 0, packetwise_redux_traits<Func, Evaluator>::OuterSize>::template run<
            PacketType>(eval, func);
      }
    };
    template <typename Func, typename Evaluator, int Start>
    struct redux_vec_unroller<Func, Evaluator, Start, 0> {
      template <typename PacketType>
      static inline PacketType run(const Evaluator&, const Func& f) {
        return packetwise_redux_empty_value<PacketType>(f);
      }
    };
    template <typename Func, typename Evaluator>
    struct packetwise_redux_impl<Func, Evaluator, NoUnrolling> {
      typedef typename Evaluator::Scalar Scalar;
      typedef typename redux_traits<Func, Evaluator>::PacketType PacketScalar;
      template <typename PacketType>
      static PacketType run(const Evaluator& eval, const Func& func, Index size) {
        if (size == 0)
          return packetwise_redux_empty_value<PacketType>(func);
        const Index size4 = (size - 1) & (~3);
        PacketType p = eval.template packetByOuterInner<Unaligned, PacketType>(0, 0);
        Index i = 1;
        for (; i < size4; i += 4)
          p = func.packetOp(
              p,
              func.packetOp(func.packetOp(eval.template packetByOuterInner<Unaligned, PacketType>(i + 0, 0),
                                          eval.template packetByOuterInner<Unaligned, PacketType>(i + 1, 0)),
                            func.packetOp(eval.template packetByOuterInner<Unaligned, PacketType>(i + 2, 0),
                                          eval.template packetByOuterInner<Unaligned, PacketType>(i + 3, 0))));
        for (; i < size; ++i)
          p = func.packetOp(p, eval.template packetByOuterInner<Unaligned, PacketType>(i, 0));
        return p;
      }
    };
    template <typename ArgType, typename MemberOp, int Direction>
    struct evaluator<PartialReduxExpr<ArgType, MemberOp, Direction>>
        : evaluator_base<PartialReduxExpr<ArgType, MemberOp, Direction>> {
      typedef PartialReduxExpr<ArgType, MemberOp, Direction> XprType;
      typedef typename internal::nested_eval<ArgType, 1>::type ArgTypeNested;
      typedef add_const_on_value_type_t<ArgTypeNested> ConstArgTypeNested;
      typedef internal::remove_all_t<ArgTypeNested> ArgTypeNestedCleaned;
      typedef typename ArgType::Scalar InputScalar;
      typedef typename XprType::Scalar Scalar;
      enum {
        TraversalSize = Direction == int(Vertical) ? int(ArgType::RowsAtCompileTime) : int(ArgType::ColsAtCompileTime)
      };
      typedef typename MemberOp::template Cost<int(TraversalSize)> CostOpType;
      enum {
        CoeffReadCost = TraversalSize == Dynamic ? HugeCost
                        : TraversalSize == 0
                            ? 1
                            : int(TraversalSize) * int(evaluator<ArgType>::CoeffReadCost) + int(CostOpType::value),
        ArgFlags_ = evaluator<ArgType>::Flags,
        Vectorizable_ = bool(int(ArgFlags_) & PacketAccessBit) && bool(MemberOp::Vectorizable) &&
                        (Direction == int(Vertical) ? bool(ArgFlags_ & RowMajorBit) : (ArgFlags_ & RowMajorBit) == 0) &&
                        (TraversalSize != 0),
        Flags = (traits<XprType>::Flags & RowMajorBit) |
                (evaluator<ArgType>::Flags & (HereditaryBits & (~RowMajorBit))) |
                (Vectorizable_ ? PacketAccessBit : 0) | LinearAccessBit,
        Alignment = 0
      };
      explicit evaluator(const XprType xpr) : m_arg(xpr.nestedExpression()), m_functor(xpr.functor()) {
        static_assert((TraversalSize == Dynamic ? HugeCost : (TraversalSize == 0 ? 1 : int(CostOpType::value))) >= 0 &&
                          (TraversalSize == Dynamic ? HugeCost : (TraversalSize == 0 ? 1 : int(CostOpType::value))) <=
                              HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
        static_assert((CoeffReadCost) >= 0 && (CoeffReadCost) <= HugeCost * HugeCost,
                      "EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE");
        ;
        ;
      }
      typedef typename XprType::CoeffReturnType CoeffReturnType;
      inline const Scalar coeff(Index i, Index j) const { return coeff(Direction == Vertical ? j : i); }
      inline const Scalar coeff(Index index) const {
        return m_functor(m_arg.template subVector<DirectionType(Direction)>(index));
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index i, Index j) const {
        return packet<LoadMode, PacketType>(Direction == Vertical ? j : i);
      }
      template <int LoadMode, typename PacketType>
      inline PacketType packet(Index idx) const {
        enum { PacketSize = internal::unpacket_traits<PacketType>::size };
        typedef Block<const ArgTypeNestedCleaned,
                      Direction == Vertical ? int(ArgType::RowsAtCompileTime) : int(PacketSize),
                      Direction == Vertical ? int(PacketSize) : int(ArgType::ColsAtCompileTime),
                      true>
            PanelType;
        PanelType panel(m_arg,
                        Direction == Vertical ? 0 : idx,
                        Direction == Vertical ? idx : 0,
                        Direction == Vertical ? m_arg.rows() : Index(PacketSize),
                        Direction == Vertical ? Index(PacketSize) : m_arg.cols());
        if (PacketSize == 1)
          return internal::pset1<PacketType>(coeff(idx));
        typedef typename internal::redux_evaluator<PanelType> PanelEvaluator;
        PanelEvaluator panel_eval(panel);
        typedef typename MemberOp::BinaryOp BinaryOp;
        PacketType p = internal::packetwise_redux_impl<BinaryOp, PanelEvaluator>::template run<PacketType>(
            panel_eval, m_functor.binaryFunc(), m_arg.outerSize());
        return p;
      }

    protected:
      ConstArgTypeNested m_arg;
      const MemberOp m_functor;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar>
    struct scalar_random_op {
      inline const Scalar operator()() const { return random<Scalar>(); }
    };
    template <typename Scalar>
    struct functor_traits<scalar_random_op<Scalar>> {
      enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false, IsRepeatable = false };
    };
  }  // namespace internal
  template <typename Derived>
  inline const typename DenseBase<Derived>::RandomReturnType DenseBase<Derived>::Random(Index rows, Index cols) {
    return NullaryExpr(rows, cols, internal::scalar_random_op<Scalar>());
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::RandomReturnType DenseBase<Derived>::Random(Index size) {
    return NullaryExpr(size, internal::scalar_random_op<Scalar>());
  }
  template <typename Derived>
  inline const typename DenseBase<Derived>::RandomReturnType DenseBase<Derived>::Random() {
    return NullaryExpr(RowsAtCompileTime, ColsAtCompileTime, internal::scalar_random_op<Scalar>());
  }
  template <typename Derived>
  inline Derived& DenseBase<Derived>::setRandom() {
    return *this = Random(rows(), cols());
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setRandom(Index newSize) {
    resize(newSize);
    return setRandom();
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setRandom(Index rows, Index cols) {
    resize(rows, cols);
    return setRandom();
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setRandom(NoChange_t, Index cols) {
    return setRandom(rows(), cols);
  }
  template <typename Derived>
  inline Derived& PlainObjectBase<Derived>::setRandom(Index rows, NoChange_t) {
    return setRandom(rows, cols());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, int RowFactor, int ColFactor>
    struct traits<Replicate<MatrixType, RowFactor, ColFactor>> : traits<MatrixType> {
      typedef typename MatrixType::Scalar Scalar;
      typedef typename traits<MatrixType>::StorageKind StorageKind;
      typedef typename traits<MatrixType>::XprKind XprKind;
      typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNested_;
      enum {
        RowsAtCompileTime = RowFactor == Dynamic || int(MatrixType::RowsAtCompileTime) == Dynamic
                                ? Dynamic
                                : RowFactor * MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = ColFactor == Dynamic || int(MatrixType::ColsAtCompileTime) == Dynamic
                                ? Dynamic
                                : ColFactor * MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = RowsAtCompileTime,
        MaxColsAtCompileTime = ColsAtCompileTime,
        IsRowMajor = MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1   ? 1
                     : MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1 ? 0
                     : (MatrixType::Flags & RowMajorBit)                      ? 1
                                                                              : 0,
        Flags = IsRowMajor ? RowMajorBit : 0
      };
    };
  }  // namespace internal
  template <typename MatrixType, int RowFactor, int ColFactor>
  class Replicate : public internal::dense_xpr_base<Replicate<MatrixType, RowFactor, ColFactor>>::type {
    typedef typename internal::traits<Replicate>::MatrixTypeNested MatrixTypeNested;
    typedef typename internal::traits<Replicate>::MatrixTypeNested_ MatrixTypeNested_;

  public:
    typedef typename internal::dense_xpr_base<Replicate>::type Base;
    typedef typename Eigen::internal::traits<Replicate>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Replicate>::type Nested;
    typedef typename Eigen::internal::traits<Replicate>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Replicate>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Replicate>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Replicate>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Replicate>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    typedef internal::remove_all_t<MatrixType> NestedExpression;
    template <typename OriginalMatrixType>
    inline explicit Replicate(const OriginalMatrixType& matrix)
        : m_matrix(matrix), m_rowFactor(RowFactor), m_colFactor(ColFactor) {
      static_assert((internal::is_same<std::remove_const_t<MatrixType>, OriginalMatrixType>::value),
                    "THE_MATRIX_OR_EXPRESSION_THAT_YOU_PASSED_DOES_NOT_HAVE_THE_EXPECTED_TYPE");
      (static_cast<bool>(RowFactor != Dynamic && ColFactor != Dynamic)
           ? void(0)
           : __assert_fail("RowFactor!=Dynamic && ColFactor!=Dynamic",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Core/Replicate.h",
                           81,
                           __extension__ __PRETTY_FUNCTION__));
    }
    template <typename OriginalMatrixType>
    inline Replicate(const OriginalMatrixType& matrix, Index rowFactor, Index colFactor)
        : m_matrix(matrix), m_rowFactor(rowFactor), m_colFactor(colFactor) {
      static_assert((internal::is_same<std::remove_const_t<MatrixType>, OriginalMatrixType>::value),
                    "THE_MATRIX_OR_EXPRESSION_THAT_YOU_PASSED_DOES_NOT_HAVE_THE_EXPECTED_TYPE");
    }
    constexpr inline Index rows() const { return m_matrix.rows() * m_rowFactor.value(); }
    constexpr inline Index cols() const { return m_matrix.cols() * m_colFactor.value(); }
    const MatrixTypeNested_& nestedExpression() const { return m_matrix; }

  protected:
    MatrixTypeNested m_matrix;
    const internal::variable_if_dynamic<Index, RowFactor> m_rowFactor;
    const internal::variable_if_dynamic<Index, ColFactor> m_colFactor;
  };
  template <typename Derived>
  template <int RowFactor, int ColFactor>
  const Replicate<Derived, RowFactor, ColFactor> DenseBase<Derived>::replicate() const {
    return Replicate<Derived, RowFactor, ColFactor>(derived());
  }
  template <typename ExpressionType, int Direction>
  const typename VectorwiseOp<ExpressionType, Direction>::ReplicateReturnType
  VectorwiseOp<ExpressionType, Direction>::replicate(Index factor) const {
    return typename VectorwiseOp<ExpressionType, Direction>::ReplicateReturnType(
        _expression(), Direction == Vertical ? factor : 1, Direction == Horizontal ? factor : 1);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, int Direction>
    struct traits<Reverse<MatrixType, Direction>> : traits<MatrixType> {
      typedef typename MatrixType::Scalar Scalar;
      typedef typename traits<MatrixType>::StorageKind StorageKind;
      typedef typename traits<MatrixType>::XprKind XprKind;
      typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNested_;
      enum {
        RowsAtCompileTime = MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
        Flags = MatrixTypeNested_::Flags & (RowMajorBit | LvalueBit)
      };
    };
    template <typename PacketType, bool ReversePacket>
    struct reverse_packet_cond {
      static inline PacketType run(const PacketType& x) { return preverse(x); }
    };
    template <typename PacketType>
    struct reverse_packet_cond<PacketType, false> {
      static inline PacketType run(const PacketType& x) { return x; }
    };
  }  // namespace internal
  template <typename MatrixType, int Direction>
  class Reverse : public internal::dense_xpr_base<Reverse<MatrixType, Direction>>::type {
  public:
    typedef typename internal::dense_xpr_base<Reverse>::type Base;
    typedef typename Eigen::internal::traits<Reverse>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Reverse>::type Nested;
    typedef typename Eigen::internal::traits<Reverse>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Reverse>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Reverse>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Reverse>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Reverse>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    typedef internal::remove_all_t<MatrixType> NestedExpression;
    using Base::IsRowMajor;

  protected:
    enum {
      PacketSize = internal::packet_traits<Scalar>::size,
      IsColMajor = !IsRowMajor,
      ReverseRow = (Direction == Vertical) || (Direction == BothDirections),
      ReverseCol = (Direction == Horizontal) || (Direction == BothDirections),
      OffsetRow = ReverseRow && IsColMajor ? PacketSize : 1,
      OffsetCol = ReverseCol && IsRowMajor ? PacketSize : 1,
      ReversePacket = (Direction == BothDirections) || ((Direction == Vertical) && IsColMajor) ||
                      ((Direction == Horizontal) && IsRowMajor)
    };
    typedef internal::reverse_packet_cond<PacketScalar, ReversePacket> reverse_packet;

  public:
    explicit inline Reverse(const MatrixType& matrix) : m_matrix(matrix) {}
    using Base::operator=;
    inline Reverse& operator=(const Reverse& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Reverse& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Reverse(const Reverse&) = default;
    constexpr inline Index rows() const noexcept { return m_matrix.rows(); }
    constexpr inline Index cols() const noexcept { return m_matrix.cols(); }
    inline Index innerStride() const { return -m_matrix.innerStride(); }
    const internal::remove_all_t<typename MatrixType::Nested>& nestedExpression() const { return m_matrix; }

  protected:
    typename MatrixType::Nested m_matrix;
  };
  template <typename Derived>
  inline typename DenseBase<Derived>::ReverseReturnType DenseBase<Derived>::reverse() {
    return ReverseReturnType(derived());
  }
  template <typename Derived>
  inline void DenseBase<Derived>::reverseInPlace() {
    if (cols() > rows()) {
      Index half = cols() / 2;
      leftCols(half).swap(rightCols(half).reverse());
      if ((cols() % 2) == 1) {
        Index half2 = rows() / 2;
        col(half).head(half2).swap(col(half).tail(half2).reverse());
      }
    } else {
      Index half = rows() / 2;
      topRows(half).swap(bottomRows(half).reverse());
      if ((rows() % 2) == 1) {
        Index half2 = cols() / 2;
        row(half).head(half2).swap(row(half).tail(half2).reverse());
      }
    }
  }
  namespace internal {
    template <int Direction>
    struct vectorwise_reverse_inplace_impl;
    template <>
    struct vectorwise_reverse_inplace_impl<Vertical> {
      template <typename ExpressionType>
      static void run(ExpressionType& xpr) {
        constexpr Index HalfAtCompileTime =
            ExpressionType::RowsAtCompileTime == Dynamic ? Dynamic : ExpressionType::RowsAtCompileTime / 2;
        Index half = xpr.rows() / 2;
        xpr.template topRows<HalfAtCompileTime>(half).swap(
            xpr.template bottomRows<HalfAtCompileTime>(half).colwise().reverse());
      }
    };
    template <>
    struct vectorwise_reverse_inplace_impl<Horizontal> {
      template <typename ExpressionType>
      static void run(ExpressionType& xpr) {
        constexpr Index HalfAtCompileTime =
            ExpressionType::ColsAtCompileTime == Dynamic ? Dynamic : ExpressionType::ColsAtCompileTime / 2;
        Index half = xpr.cols() / 2;
        xpr.template leftCols<HalfAtCompileTime>(half).swap(
            xpr.template rightCols<HalfAtCompileTime>(half).rowwise().reverse());
      }
    };
  }  // namespace internal
  template <typename ExpressionType, int Direction>
  void VectorwiseOp<ExpressionType, Direction>::reverseInPlace() {
    internal::vectorwise_reverse_inplace_impl<Direction>::run(m_matrix);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename ExpressionType>
    struct traits<ArrayWrapper<ExpressionType>> : public traits<remove_all_t<typename ExpressionType::Nested>> {
      typedef ArrayXpr XprKind;
      enum {
        Flags0 = traits<remove_all_t<typename ExpressionType::Nested>>::Flags,
        LvalueBitFlag = is_lvalue<ExpressionType>::value ? LvalueBit : 0,
        Flags = (Flags0 & ~(NestByRefBit | LvalueBit)) | LvalueBitFlag
      };
    };
  }  // namespace internal
  template <typename ExpressionType>
  class ArrayWrapper : public ArrayBase<ArrayWrapper<ExpressionType>> {
  public:
    typedef ArrayBase<ArrayWrapper> Base;
    typedef typename Eigen::internal::traits<ArrayWrapper>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<ArrayWrapper>::type Nested;
    typedef typename Eigen::internal::traits<ArrayWrapper>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<ArrayWrapper>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<ArrayWrapper>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<ArrayWrapper>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<ArrayWrapper>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    using Base::operator=;
    inline ArrayWrapper& operator=(const ArrayWrapper& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline ArrayWrapper& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    ArrayWrapper(const ArrayWrapper&) = default;
    typedef internal::remove_all_t<ExpressionType> NestedExpression;
    typedef std::conditional_t<internal::is_lvalue<ExpressionType>::value, Scalar, const Scalar>
        ScalarWithConstIfNotLvalue;
    typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
    using Base::coeffRef;
    explicit inline ArrayWrapper(ExpressionType& matrix) : m_expression(matrix) {}
    constexpr inline Index rows() const noexcept { return m_expression.rows(); }
    constexpr inline Index cols() const noexcept { return m_expression.cols(); }
    constexpr inline Index outerStride() const noexcept { return m_expression.outerStride(); }
    constexpr inline Index innerStride() const noexcept { return m_expression.innerStride(); }
    inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
    inline const Scalar* data() const { return m_expression.data(); }
    inline const Scalar& coeffRef(Index rowId, Index colId) const { return m_expression.coeffRef(rowId, colId); }
    inline const Scalar& coeffRef(Index index) const { return m_expression.coeffRef(index); }
    template <typename Dest>
    inline void evalTo(Dest& dst) const {
      dst = m_expression;
    }
    const internal::remove_all_t<NestedExpressionType>& nestedExpression() const { return m_expression; }
    void resize(Index newSize) { m_expression.resize(newSize); }
    void resize(Index rows, Index cols) { m_expression.resize(rows, cols); }

  protected:
    NestedExpressionType m_expression;
  };
  namespace internal {
    template <typename ExpressionType>
    struct traits<MatrixWrapper<ExpressionType>> : public traits<remove_all_t<typename ExpressionType::Nested>> {
      typedef MatrixXpr XprKind;
      enum {
        Flags0 = traits<remove_all_t<typename ExpressionType::Nested>>::Flags,
        LvalueBitFlag = is_lvalue<ExpressionType>::value ? LvalueBit : 0,
        Flags = (Flags0 & ~(NestByRefBit | LvalueBit)) | LvalueBitFlag
      };
    };
  }  // namespace internal
  template <typename ExpressionType>
  class MatrixWrapper : public MatrixBase<MatrixWrapper<ExpressionType>> {
  public:
    typedef MatrixBase<MatrixWrapper<ExpressionType>> Base;
    typedef typename Eigen::internal::traits<MatrixWrapper>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<MatrixWrapper>::type Nested;
    typedef typename Eigen::internal::traits<MatrixWrapper>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<MatrixWrapper>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<MatrixWrapper>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<MatrixWrapper>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<MatrixWrapper>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    using Base::operator=;
    inline MatrixWrapper& operator=(const MatrixWrapper& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline MatrixWrapper& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    MatrixWrapper(const MatrixWrapper&) = default;
    typedef internal::remove_all_t<ExpressionType> NestedExpression;
    typedef std::conditional_t<internal::is_lvalue<ExpressionType>::value, Scalar, const Scalar>
        ScalarWithConstIfNotLvalue;
    typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
    using Base::coeffRef;
    explicit inline MatrixWrapper(ExpressionType& matrix) : m_expression(matrix) {}
    constexpr inline Index rows() const noexcept { return m_expression.rows(); }
    constexpr inline Index cols() const noexcept { return m_expression.cols(); }
    constexpr inline Index outerStride() const noexcept { return m_expression.outerStride(); }
    constexpr inline Index innerStride() const noexcept { return m_expression.innerStride(); }
    inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
    inline const Scalar* data() const { return m_expression.data(); }
    inline const Scalar& coeffRef(Index rowId, Index colId) const {
      return m_expression.derived().coeffRef(rowId, colId);
    }
    inline const Scalar& coeffRef(Index index) const { return m_expression.coeffRef(index); }
    const internal::remove_all_t<NestedExpressionType>& nestedExpression() const { return m_expression; }
    void resize(Index newSize) { m_expression.resize(newSize); }
    void resize(Index rows, Index cols) { m_expression.resize(rows, cols); }

  protected:
    NestedExpressionType m_expression;
  };
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename IteratorType>
    struct indexed_based_stl_iterator_traits;
    template <typename Derived>
    class indexed_based_stl_iterator_base {
    protected:
      typedef indexed_based_stl_iterator_traits<Derived> traits;
      typedef typename traits::XprType XprType;
      typedef indexed_based_stl_iterator_base<typename traits::non_const_iterator> non_const_iterator;
      typedef indexed_based_stl_iterator_base<typename traits::const_iterator> const_iterator;
      typedef std::conditional_t<internal::is_const<XprType>::value, non_const_iterator, const_iterator> other_iterator;
      friend class indexed_based_stl_iterator_base<typename traits::const_iterator>;
      friend class indexed_based_stl_iterator_base<typename traits::non_const_iterator>;

    public:
      typedef Index difference_type;
      typedef std::random_access_iterator_tag iterator_category;
      indexed_based_stl_iterator_base() noexcept(true) : mp_xpr(0), m_index(0) {}
      indexed_based_stl_iterator_base(XprType& xpr, Index index) noexcept(true) : mp_xpr(&xpr), m_index(index) {}
      indexed_based_stl_iterator_base(const non_const_iterator& other) noexcept(true)
          : mp_xpr(other.mp_xpr), m_index(other.m_index) {}
      indexed_based_stl_iterator_base& operator=(const non_const_iterator& other) {
        mp_xpr = other.mp_xpr;
        m_index = other.m_index;
        return *this;
      }
      Derived& operator++() {
        ++m_index;
        return derived();
      }
      Derived& operator--() {
        --m_index;
        return derived();
      }
      Derived operator++(int) {
        Derived prev(derived());
        operator++();
        return prev;
      }
      Derived operator--(int) {
        Derived prev(derived());
        operator--();
        return prev;
      }
      friend Derived operator+(const indexed_based_stl_iterator_base& a, Index b) {
        Derived ret(a.derived());
        ret += b;
        return ret;
      }
      friend Derived operator-(const indexed_based_stl_iterator_base& a, Index b) {
        Derived ret(a.derived());
        ret -= b;
        return ret;
      }
      friend Derived operator+(Index a, const indexed_based_stl_iterator_base& b) {
        Derived ret(b.derived());
        ret += a;
        return ret;
      }
      friend Derived operator-(Index a, const indexed_based_stl_iterator_base& b) {
        Derived ret(b.derived());
        ret -= a;
        return ret;
      }
      Derived& operator+=(Index b) {
        m_index += b;
        return derived();
      }
      Derived& operator-=(Index b) {
        m_index -= b;
        return derived();
      }
      difference_type operator-(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             68,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index - other.m_index;
      }
      difference_type operator-(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             74,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index - other.m_index;
      }
      bool operator==(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             78,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index == other.m_index;
      }
      bool operator!=(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             79,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index != other.m_index;
      }
      bool operator<(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             80,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index < other.m_index;
      }
      bool operator<=(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             81,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index <= other.m_index;
      }
      bool operator>(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             82,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index > other.m_index;
      }
      bool operator>=(const indexed_based_stl_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             83,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index >= other.m_index;
      }
      bool operator==(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             85,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index == other.m_index;
      }
      bool operator!=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             86,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index != other.m_index;
      }
      bool operator<(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             87,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index < other.m_index;
      }
      bool operator<=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             88,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index <= other.m_index;
      }
      bool operator>(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             89,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index > other.m_index;
      }
      bool operator>=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             90,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index >= other.m_index;
      }

    protected:
      Derived& derived() { return static_cast<Derived&>(*this); }
      const Derived& derived() const { return static_cast<const Derived&>(*this); }
      XprType* mp_xpr;
      Index m_index;
    };
    template <typename Derived>
    class indexed_based_stl_reverse_iterator_base {
    protected:
      typedef indexed_based_stl_iterator_traits<Derived> traits;
      typedef typename traits::XprType XprType;
      typedef indexed_based_stl_reverse_iterator_base<typename traits::non_const_iterator> non_const_iterator;
      typedef indexed_based_stl_reverse_iterator_base<typename traits::const_iterator> const_iterator;
      typedef std::conditional_t<internal::is_const<XprType>::value, non_const_iterator, const_iterator> other_iterator;
      friend class indexed_based_stl_reverse_iterator_base<typename traits::const_iterator>;
      friend class indexed_based_stl_reverse_iterator_base<typename traits::non_const_iterator>;

    public:
      typedef Index difference_type;
      typedef std::random_access_iterator_tag iterator_category;
      indexed_based_stl_reverse_iterator_base() : mp_xpr(0), m_index(0) {}
      indexed_based_stl_reverse_iterator_base(XprType& xpr, Index index) : mp_xpr(&xpr), m_index(index) {}
      indexed_based_stl_reverse_iterator_base(const non_const_iterator& other)
          : mp_xpr(other.mp_xpr), m_index(other.m_index) {}
      indexed_based_stl_reverse_iterator_base& operator=(const non_const_iterator& other) {
        mp_xpr = other.mp_xpr;
        m_index = other.m_index;
        return *this;
      }
      Derived& operator++() {
        --m_index;
        return derived();
      }
      Derived& operator--() {
        ++m_index;
        return derived();
      }
      Derived operator++(int) {
        Derived prev(derived());
        operator++();
        return prev;
      }
      Derived operator--(int) {
        Derived prev(derived());
        operator--();
        return prev;
      }
      friend Derived operator+(const indexed_based_stl_reverse_iterator_base& a, Index b) {
        Derived ret(a.derived());
        ret += b;
        return ret;
      }
      friend Derived operator-(const indexed_based_stl_reverse_iterator_base& a, Index b) {
        Derived ret(a.derived());
        ret -= b;
        return ret;
      }
      friend Derived operator+(Index a, const indexed_based_stl_reverse_iterator_base& b) {
        Derived ret(b.derived());
        ret += a;
        return ret;
      }
      friend Derived operator-(Index a, const indexed_based_stl_reverse_iterator_base& b) {
        Derived ret(b.derived());
        ret -= a;
        return ret;
      }
      Derived& operator+=(Index b) {
        m_index -= b;
        return derived();
      }
      Derived& operator-=(Index b) {
        m_index += b;
        return derived();
      }
      difference_type operator-(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             147,
                             __extension__ __PRETTY_FUNCTION__));
        return other.m_index - m_index;
      }
      difference_type operator-(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             153,
                             __extension__ __PRETTY_FUNCTION__));
        return other.m_index - m_index;
      }
      bool operator==(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             157,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index == other.m_index;
      }
      bool operator!=(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             158,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index != other.m_index;
      }
      bool operator<(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             159,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index > other.m_index;
      }
      bool operator<=(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             160,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index >= other.m_index;
      }
      bool operator>(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             161,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index < other.m_index;
      }
      bool operator>=(const indexed_based_stl_reverse_iterator_base& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             162,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index <= other.m_index;
      }
      bool operator==(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             164,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index == other.m_index;
      }
      bool operator!=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             165,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index != other.m_index;
      }
      bool operator<(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             166,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index > other.m_index;
      }
      bool operator<=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             167,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index >= other.m_index;
      }
      bool operator>(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             168,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index < other.m_index;
      }
      bool operator>=(const other_iterator& other) const {
        (static_cast<bool>(mp_xpr == other.mp_xpr)
             ? void(0)
             : __assert_fail("mp_xpr == other.mp_xpr",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Core/StlIterators.h",
                             169,
                             __extension__ __PRETTY_FUNCTION__));
        return m_index <= other.m_index;
      }

    protected:
      Derived& derived() { return static_cast<Derived&>(*this); }
      const Derived& derived() const { return static_cast<const Derived&>(*this); }
      XprType* mp_xpr;
      Index m_index;
    };
    template <typename XprType>
    class pointer_based_stl_iterator {
      enum { is_lvalue = internal::is_lvalue<XprType>::value };
      typedef pointer_based_stl_iterator<std::remove_const_t<XprType>> non_const_iterator;
      typedef pointer_based_stl_iterator<std::add_const_t<XprType>> const_iterator;
      typedef std::conditional_t<internal::is_const<XprType>::value, non_const_iterator, const_iterator> other_iterator;
      friend class pointer_based_stl_iterator<std::add_const_t<XprType>>;
      friend class pointer_based_stl_iterator<std::remove_const_t<XprType>>;

    public:
      typedef Index difference_type;
      typedef typename XprType::Scalar value_type;
      typedef std::random_access_iterator_tag iterator_category;
      typedef std::conditional_t<bool(is_lvalue), value_type*, const value_type*> pointer;
      typedef std::conditional_t<bool(is_lvalue), value_type&, const value_type&> reference;
      pointer_based_stl_iterator() noexcept(true) : m_ptr(0) {}
      pointer_based_stl_iterator(XprType& xpr, Index index) noexcept(true) : m_incr(xpr.innerStride()) {
        m_ptr = xpr.data() + index * m_incr.value();
      }
      pointer_based_stl_iterator(const non_const_iterator& other) noexcept(true)
          : m_ptr(other.m_ptr), m_incr(other.m_incr) {}
      pointer_based_stl_iterator& operator=(const non_const_iterator& other) noexcept(true) {
        m_ptr = other.m_ptr;
        m_incr.setValue(other.m_incr);
        return *this;
      }
      reference operator*() const { return *m_ptr; }
      reference operator[](Index i) const { return *(m_ptr + i * m_incr.value()); }
      pointer operator->() const { return m_ptr; }
      pointer_based_stl_iterator& operator++() {
        m_ptr += m_incr.value();
        return *this;
      }
      pointer_based_stl_iterator& operator--() {
        m_ptr -= m_incr.value();
        return *this;
      }
      pointer_based_stl_iterator operator++(int) {
        pointer_based_stl_iterator prev(*this);
        operator++();
        return prev;
      }
      pointer_based_stl_iterator operator--(int) {
        pointer_based_stl_iterator prev(*this);
        operator--();
        return prev;
      }
      friend pointer_based_stl_iterator operator+(const pointer_based_stl_iterator& a, Index b) {
        pointer_based_stl_iterator ret(a);
        ret += b;
        return ret;
      }
      friend pointer_based_stl_iterator operator-(const pointer_based_stl_iterator& a, Index b) {
        pointer_based_stl_iterator ret(a);
        ret -= b;
        return ret;
      }
      friend pointer_based_stl_iterator operator+(Index a, const pointer_based_stl_iterator& b) {
        pointer_based_stl_iterator ret(b);
        ret += a;
        return ret;
      }
      friend pointer_based_stl_iterator operator-(Index a, const pointer_based_stl_iterator& b) {
        pointer_based_stl_iterator ret(b);
        ret -= a;
        return ret;
      }
      pointer_based_stl_iterator& operator+=(Index b) {
        m_ptr += b * m_incr.value();
        return *this;
      }
      pointer_based_stl_iterator& operator-=(Index b) {
        m_ptr -= b * m_incr.value();
        return *this;
      }
      difference_type operator-(const pointer_based_stl_iterator& other) const {
        return (m_ptr - other.m_ptr) / m_incr.value();
      }
      difference_type operator-(const other_iterator& other) const { return (m_ptr - other.m_ptr) / m_incr.value(); }
      bool operator==(const pointer_based_stl_iterator& other) const { return m_ptr == other.m_ptr; }
      bool operator!=(const pointer_based_stl_iterator& other) const { return m_ptr != other.m_ptr; }
      bool operator<(const pointer_based_stl_iterator& other) const { return m_ptr < other.m_ptr; }
      bool operator<=(const pointer_based_stl_iterator& other) const { return m_ptr <= other.m_ptr; }
      bool operator>(const pointer_based_stl_iterator& other) const { return m_ptr > other.m_ptr; }
      bool operator>=(const pointer_based_stl_iterator& other) const { return m_ptr >= other.m_ptr; }
      bool operator==(const other_iterator& other) const { return m_ptr == other.m_ptr; }
      bool operator!=(const other_iterator& other) const { return m_ptr != other.m_ptr; }
      bool operator<(const other_iterator& other) const { return m_ptr < other.m_ptr; }
      bool operator<=(const other_iterator& other) const { return m_ptr <= other.m_ptr; }
      bool operator>(const other_iterator& other) const { return m_ptr > other.m_ptr; }
      bool operator>=(const other_iterator& other) const { return m_ptr >= other.m_ptr; }

    protected:
      pointer m_ptr;
      internal::variable_if_dynamic<Index, XprType::InnerStrideAtCompileTime> m_incr;
    };
    template <typename XprType_>
    struct indexed_based_stl_iterator_traits<generic_randaccess_stl_iterator<XprType_>> {
      typedef XprType_ XprType;
      typedef generic_randaccess_stl_iterator<std::remove_const_t<XprType>> non_const_iterator;
      typedef generic_randaccess_stl_iterator<std::add_const_t<XprType>> const_iterator;
    };
    template <typename XprType>
    class generic_randaccess_stl_iterator
        : public indexed_based_stl_iterator_base<generic_randaccess_stl_iterator<XprType>> {
    public:
      typedef typename XprType::Scalar value_type;

    protected:
      enum {
        has_direct_access = (internal::traits<XprType>::Flags & DirectAccessBit) ? 1 : 0,
        is_lvalue = internal::is_lvalue<XprType>::value
      };
      typedef indexed_based_stl_iterator_base<generic_randaccess_stl_iterator> Base;
      using Base::m_index;
      using Base::mp_xpr;
      typedef const value_type read_only_ref_t;

    public:
      typedef std::conditional_t<bool(is_lvalue), value_type*, const value_type*> pointer;
      typedef std::conditional_t<bool(is_lvalue), value_type&, read_only_ref_t> reference;
      generic_randaccess_stl_iterator() : Base() {}
      generic_randaccess_stl_iterator(XprType& xpr, Index index) : Base(xpr, index) {}
      generic_randaccess_stl_iterator(const typename Base::non_const_iterator& other) : Base(other) {}
      using Base::operator=;
      reference operator*() const { return (*mp_xpr)(m_index); }
      reference operator[](Index i) const { return (*mp_xpr)(m_index + i); }
      pointer operator->() const { return &((*mp_xpr)(m_index)); }
    };
    template <typename XprType_, DirectionType Direction>
    struct indexed_based_stl_iterator_traits<subvector_stl_iterator<XprType_, Direction>> {
      typedef XprType_ XprType;
      typedef subvector_stl_iterator<std::remove_const_t<XprType>, Direction> non_const_iterator;
      typedef subvector_stl_iterator<std::add_const_t<XprType>, Direction> const_iterator;
    };
    template <typename XprType, DirectionType Direction>
    class subvector_stl_iterator : public indexed_based_stl_iterator_base<subvector_stl_iterator<XprType, Direction>> {
    protected:
      enum { is_lvalue = internal::is_lvalue<XprType>::value };
      typedef indexed_based_stl_iterator_base<subvector_stl_iterator> Base;
      using Base::m_index;
      using Base::mp_xpr;
      typedef std::conditional_t<Direction == Vertical, typename XprType::ColXpr, typename XprType::RowXpr>
          SubVectorType;
      typedef std::conditional_t<Direction == Vertical, typename XprType::ConstColXpr, typename XprType::ConstRowXpr>
          ConstSubVectorType;

    public:
      typedef std::conditional_t<bool(is_lvalue), SubVectorType, ConstSubVectorType> reference;
      typedef typename reference::PlainObject value_type;

    private:
      class subvector_stl_iterator_ptr {
      public:
        subvector_stl_iterator_ptr(const reference& subvector) : m_subvector(subvector) {}
        reference* operator->() { return &m_subvector; }

      private:
        reference m_subvector;
      };

    public:
      typedef subvector_stl_iterator_ptr pointer;
      subvector_stl_iterator() : Base() {}
      subvector_stl_iterator(XprType& xpr, Index index) : Base(xpr, index) {}
      reference operator*() const { return (*mp_xpr).template subVector<Direction>(m_index); }
      reference operator[](Index i) const { return (*mp_xpr).template subVector<Direction>(m_index + i); }
      pointer operator->() const { return (*mp_xpr).template subVector<Direction>(m_index); }
    };
    template <typename XprType_, DirectionType Direction>
    struct indexed_based_stl_iterator_traits<subvector_stl_reverse_iterator<XprType_, Direction>> {
      typedef XprType_ XprType;
      typedef subvector_stl_reverse_iterator<std::remove_const_t<XprType>, Direction> non_const_iterator;
      typedef subvector_stl_reverse_iterator<std::add_const_t<XprType>, Direction> const_iterator;
    };
    template <typename XprType, DirectionType Direction>
    class subvector_stl_reverse_iterator
        : public indexed_based_stl_reverse_iterator_base<subvector_stl_reverse_iterator<XprType, Direction>> {
    protected:
      enum { is_lvalue = internal::is_lvalue<XprType>::value };
      typedef indexed_based_stl_reverse_iterator_base<subvector_stl_reverse_iterator> Base;
      using Base::m_index;
      using Base::mp_xpr;
      typedef std::conditional_t<Direction == Vertical, typename XprType::ColXpr, typename XprType::RowXpr>
          SubVectorType;
      typedef std::conditional_t<Direction == Vertical, typename XprType::ConstColXpr, typename XprType::ConstRowXpr>
          ConstSubVectorType;

    public:
      typedef std::conditional_t<bool(is_lvalue), SubVectorType, ConstSubVectorType> reference;
      typedef typename reference::PlainObject value_type;

    private:
      class subvector_stl_reverse_iterator_ptr {
      public:
        subvector_stl_reverse_iterator_ptr(const reference& subvector) : m_subvector(subvector) {}
        reference* operator->() { return &m_subvector; }

      private:
        reference m_subvector;
      };

    public:
      typedef subvector_stl_reverse_iterator_ptr pointer;
      subvector_stl_reverse_iterator() : Base() {}
      subvector_stl_reverse_iterator(XprType& xpr, Index index) : Base(xpr, index) {}
      reference operator*() const { return (*mp_xpr).template subVector<Direction>(m_index); }
      reference operator[](Index i) const { return (*mp_xpr).template subVector<Direction>(m_index + i); }
      pointer operator->() const { return (*mp_xpr).template subVector<Direction>(m_index); }
    };
  }  // namespace internal
  template <typename Derived>
  inline typename DenseBase<Derived>::iterator DenseBase<Derived>::begin() {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return iterator(derived(), 0);
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::begin() const {
    return cbegin();
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::cbegin() const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return const_iterator(derived(), 0);
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::iterator DenseBase<Derived>::end() {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return iterator(derived(), size());
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::end() const {
    return cend();
  }
  template <typename Derived>
  inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::cend() const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return const_iterator(derived(), size());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_real_op<typename Derived::Scalar>, const Derived>(real)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_real_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_imag_op<typename Derived::Scalar>, const Derived>(imag)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_imag_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_conjugate_op<typename Derived::Scalar>, const Derived>(conj)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_conjugate_op<typename Derived::Scalar>, const Derived>(
        x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_inverse_op<typename Derived::Scalar>, const Derived>(
      inverse)(const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_inverse_op<typename Derived::Scalar>, const Derived>(
        x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_sin_op<typename Derived::Scalar>, const Derived>(sin)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_sin_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_cos_op<typename Derived::Scalar>, const Derived>(cos)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_cos_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tan_op<typename Derived::Scalar>, const Derived>(tan)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_tan_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_atan_op<typename Derived::Scalar>, const Derived>(atan)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_atan_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_asin_op<typename Derived::Scalar>, const Derived>(asin)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_asin_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_acos_op<typename Derived::Scalar>, const Derived>(acos)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_acos_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_sinh_op<typename Derived::Scalar>, const Derived>(sinh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_sinh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_cosh_op<typename Derived::Scalar>, const Derived>(cosh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_cosh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<typename Derived::Scalar>, const Derived>(tanh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_asinh_op<typename Derived::Scalar>, const Derived>(asinh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_asinh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_acosh_op<typename Derived::Scalar>, const Derived>(acosh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_acosh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_atanh_op<typename Derived::Scalar>, const Derived>(atanh)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_atanh_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<typename Derived::Scalar>, const Derived>(
      logistic)(const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_logistic_op<typename Derived::Scalar>, const Derived>(
        x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_lgamma_op<typename Derived::Scalar>, const Derived>(lgamma)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_lgamma_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_digamma_op<typename Derived::Scalar>, const Derived>(
      digamma)(const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_digamma_op<typename Derived::Scalar>, const Derived>(
        x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_erf_op<typename Derived::Scalar>, const Derived>(erf)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_erf_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_erfc_op<typename Derived::Scalar>, const Derived>(erfc)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_erfc_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_ndtri_op<typename Derived::Scalar>, const Derived>(ndtri)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_ndtri_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_exp_op<typename Derived::Scalar>, const Derived>(exp)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_exp_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_expm1_op<typename Derived::Scalar>, const Derived>(expm1)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_expm1_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_log_op<typename Derived::Scalar>, const Derived>(log)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_log_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_log1p_op<typename Derived::Scalar>, const Derived>(log1p)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_log1p_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_log10_op<typename Derived::Scalar>, const Derived>(log10)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_log10_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_log2_op<typename Derived::Scalar>, const Derived>(log2)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_log2_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_abs_op<typename Derived::Scalar>, const Derived>(abs)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_abs_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_abs2_op<typename Derived::Scalar>, const Derived>(abs2)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_abs2_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_arg_op<typename Derived::Scalar>, const Derived>(arg)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_arg_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_sqrt_op<typename Derived::Scalar>, const Derived>(sqrt)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_sqrt_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<typename Derived::Scalar>, const Derived>(rsqrt)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_square_op<typename Derived::Scalar>, const Derived>(square)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_square_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_cube_op<typename Derived::Scalar>, const Derived>(cube)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_cube_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_rint_op<typename Derived::Scalar>, const Derived>(rint)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_rint_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_round_op<typename Derived::Scalar>, const Derived>(round)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_round_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_floor_op<typename Derived::Scalar>, const Derived>(floor)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_floor_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_ceil_op<typename Derived::Scalar>, const Derived>(ceil)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_ceil_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_isnan_op<typename Derived::Scalar>, const Derived>(isnan)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_isnan_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_isinf_op<typename Derived::Scalar>, const Derived>(isinf)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_isinf_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_isfinite_op<typename Derived::Scalar>, const Derived>(
      isfinite)(const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_isfinite_op<typename Derived::Scalar>, const Derived>(
        x.derived());
  }
  template <typename Derived>
  inline const Eigen::CwiseUnaryOp<Eigen::internal::scalar_sign_op<typename Derived::Scalar>, const Derived>(sign)(
      const Eigen::ArrayBase<Derived>& x) {
    return Eigen::CwiseUnaryOp<Eigen::internal::scalar_sign_op<typename Derived::Scalar>, const Derived>(x.derived());
  }
  template <typename Derived, typename ScalarExponent>
  using GlobalUnaryPowReturnType = std::enable_if_t<
      !internal::is_arithmetic<typename NumTraits<Derived>::Real>::value &&
          internal::is_arithmetic<typename NumTraits<ScalarExponent>::Real>::value,
      CwiseUnaryOp<internal::scalar_unary_pow_op<typename Derived::Scalar, ScalarExponent>, const Derived>>;
  template <typename Derived, typename ScalarExponent>
  inline const GlobalUnaryPowReturnType<Derived, ScalarExponent> pow(const Eigen::ArrayBase<Derived>& x,
                                                                     const ScalarExponent& exponent) {
    return GlobalUnaryPowReturnType<Derived, ScalarExponent>(
        x.derived(), internal::scalar_unary_pow_op<typename Derived::Scalar, ScalarExponent>(exponent));
  }
  template <typename Derived, typename ExponentDerived>
  inline const Eigen::CwiseBinaryOp<
      Eigen::internal::scalar_pow_op<typename Derived::Scalar, typename ExponentDerived::Scalar>,
      const Derived,
      const ExponentDerived>
  pow(const Eigen::ArrayBase<Derived>& x, const Eigen::ArrayBase<ExponentDerived>& exponents) {
    return Eigen::CwiseBinaryOp<
        Eigen::internal::scalar_pow_op<typename Derived::Scalar, typename ExponentDerived::Scalar>,
        const Derived,
        const ExponentDerived>(x.derived(), exponents.derived());
  }
  template <typename Scalar, typename Derived>
  inline const CwiseBinaryOp<
      internal::scalar_pow_op<typename internal::promote_scalar_arg<
                                  typename Derived::Scalar,
                                  Scalar,
                                  (Eigen::internal::has_ReturnType<Eigen::ScalarBinaryOpTraits<
                                       Scalar,
                                       typename Derived::Scalar,
                                       Eigen::internal::scalar_pow_op<Scalar, typename Derived::Scalar>>>::value)>::type,
                              typename internal::traits<Derived>::Scalar>,
      const typename internal::plain_constant_type<
          Derived,
          typename internal::promote_scalar_arg<
              typename Derived::Scalar,
              Scalar,
              (Eigen::internal::has_ReturnType<Eigen::ScalarBinaryOpTraits<
                   Scalar,
                   typename Derived::Scalar,
                   Eigen::internal::scalar_pow_op<Scalar, typename Derived::Scalar>>>::value)>::type>::type,
      const Derived>
  pow(const Scalar& x, const Eigen::ArrayBase<Derived>& exponents) {
    typedef typename internal::promote_scalar_arg<
        typename Derived::Scalar,
        Scalar,
        (Eigen::internal::has_ReturnType<Eigen::ScalarBinaryOpTraits<
             Scalar,
             typename Derived::Scalar,
             Eigen::internal::scalar_pow_op<Scalar, typename Derived::Scalar>>>::value)>::type PromotedScalar;
    return CwiseBinaryOp<internal::scalar_pow_op<PromotedScalar, typename internal::traits<Derived>::Scalar>,
                         const typename internal::plain_constant_type<Derived, PromotedScalar>::type,
                         const Derived>(
        typename internal::plain_constant_type<Derived, PromotedScalar>::type(
            exponents.derived().rows(), exponents.derived().cols(), internal::scalar_constant_op<PromotedScalar>(x)),
        exponents.derived());
  }
  template <typename LhsDerived, typename RhsDerived>
  inline const std::enable_if_t<
      std::is_same<typename LhsDerived::Scalar, typename RhsDerived::Scalar>::value,
      Eigen::CwiseBinaryOp<Eigen::internal::scalar_atan2_op<typename LhsDerived::Scalar, typename RhsDerived::Scalar>,
                           const LhsDerived,
                           const RhsDerived>>
  atan2(const Eigen::ArrayBase<LhsDerived>& x, const Eigen::ArrayBase<RhsDerived>& exponents) {
    return Eigen::CwiseBinaryOp<
        Eigen::internal::scalar_atan2_op<typename LhsDerived::Scalar, typename RhsDerived::Scalar>,
        const LhsDerived,
        const RhsDerived>(x.derived(), exponents.derived());
  }
  namespace internal {
    template <typename Derived>
    struct real_retval<ArrayBase<Derived>> {
      typedef const Eigen::CwiseUnaryOp<Eigen::internal::scalar_real_op<typename Derived::Scalar>, const Derived> type;
    };
    template <typename Derived>
    struct real_impl<ArrayBase<Derived>> {
      static inline typename real_retval<ArrayBase<Derived>>::type run(const Eigen::ArrayBase<Derived>& x) {
        return typename real_retval<ArrayBase<Derived>>::type(x.derived());
      }
    };
    template <typename Derived>
    struct imag_retval<ArrayBase<Derived>> {
      typedef const Eigen::CwiseUnaryOp<Eigen::internal::scalar_imag_op<typename Derived::Scalar>, const Derived> type;
    };
    template <typename Derived>
    struct imag_impl<ArrayBase<Derived>> {
      static inline typename imag_retval<ArrayBase<Derived>>::type run(const Eigen::ArrayBase<Derived>& x) {
        return typename imag_retval<ArrayBase<Derived>>::type(x.derived());
      }
    };
    template <typename Derived>
    struct abs2_retval<ArrayBase<Derived>> {
      typedef const Eigen::CwiseUnaryOp<Eigen::internal::scalar_abs2_op<typename Derived::Scalar>, const Derived> type;
    };
    template <typename Derived>
    struct abs2_impl<ArrayBase<Derived>> {
      static inline typename abs2_retval<ArrayBase<Derived>>::type run(const Eigen::ArrayBase<Derived>& x) {
        return typename abs2_retval<ArrayBase<Derived>>::type(x.derived());
      }
    };
  }  // namespace internal
}  // namespace Eigen

#pragma clang diagnostic pop

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <typename DecompositionType>
    struct traits<kernel_retval_base<DecompositionType>> {
      typedef typename DecompositionType::MatrixType MatrixType;
      typedef Matrix<typename MatrixType::Scalar,
                     MatrixType::ColsAtCompileTime,
                     Dynamic,
                     MatrixType::Options,
                     MatrixType::MaxColsAtCompileTime,
                     MatrixType::MaxColsAtCompileTime>
          ReturnType;
    };
    template <typename DecompositionType_>
    struct kernel_retval_base : public ReturnByValue<kernel_retval_base<DecompositionType_>> {
      typedef DecompositionType_ DecompositionType;
      typedef ReturnByValue<kernel_retval_base> Base;
      explicit kernel_retval_base(const DecompositionType& dec)
          : m_dec(dec), m_rank(dec.rank()), m_cols(m_rank == dec.cols() ? 1 : dec.cols() - m_rank) {}
      inline Index rows() const { return m_dec.cols(); }
      inline Index cols() const { return m_cols; }
      inline Index rank() const { return m_rank; }
      inline const DecompositionType& dec() const { return m_dec; }
      template <typename Dest>
      inline void evalTo(Dest& dst) const {
        static_cast<const kernel_retval<DecompositionType>*>(this)->evalTo(dst);
      }

    protected:
      const DecompositionType& m_dec;
      Index m_rank, m_cols;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename DecompositionType>
    struct traits<image_retval_base<DecompositionType>> {
      typedef typename DecompositionType::MatrixType MatrixType;
      typedef Matrix<typename MatrixType::Scalar,
                     MatrixType::RowsAtCompileTime,
                     Dynamic,
                     MatrixType::Options,
                     MatrixType::MaxRowsAtCompileTime,
                     MatrixType::MaxColsAtCompileTime>
          ReturnType;
    };
    template <typename DecompositionType_>
    struct image_retval_base : public ReturnByValue<image_retval_base<DecompositionType_>> {
      typedef DecompositionType_ DecompositionType;
      typedef typename DecompositionType::MatrixType MatrixType;
      typedef ReturnByValue<image_retval_base> Base;
      image_retval_base(const DecompositionType& dec, const MatrixType& originalMatrix)
          : m_dec(dec), m_rank(dec.rank()), m_cols(m_rank == 0 ? 1 : m_rank), m_originalMatrix(originalMatrix) {}
      inline Index rows() const { return m_dec.rows(); }
      inline Index cols() const { return m_cols; }
      inline Index rank() const { return m_rank; }
      inline const DecompositionType& dec() const { return m_dec; }
      inline const MatrixType& originalMatrix() const { return m_originalMatrix; }
      template <typename Dest>
      inline void evalTo(Dest& dst) const {
        static_cast<const image_retval<DecompositionType>*>(this)->evalTo(dst);
      }

    protected:
      const DecompositionType& m_dec;
      Index m_rank, m_cols;
      const MatrixType& m_originalMatrix;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<FullPivLU<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
  }  // namespace internal
  template <typename MatrixType_>
  class FullPivLU : public SolverBase<FullPivLU<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<FullPivLU> Base;
    friend class SolverBase<FullPivLU>;
    typedef typename Eigen::internal::traits<FullPivLU>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<FullPivLU>::type Nested;
    typedef typename Eigen::internal::traits<FullPivLU>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<FullPivLU>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<FullPivLU>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<FullPivLU>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<FullPivLU>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename internal::plain_row_type<MatrixType, StorageIndex>::type IntRowVectorType;
    typedef typename internal::plain_col_type<MatrixType, StorageIndex>::type IntColVectorType;
    typedef PermutationMatrix<ColsAtCompileTime, MaxColsAtCompileTime> PermutationQType;
    typedef PermutationMatrix<RowsAtCompileTime, MaxRowsAtCompileTime> PermutationPType;
    typedef typename MatrixType::PlainObject PlainObject;
    FullPivLU();
    FullPivLU(Index rows, Index cols);
    template <typename InputType>
    explicit FullPivLU(const EigenBase<InputType>& matrix);
    template <typename InputType>
    explicit FullPivLU(EigenBase<InputType>& matrix);
    template <typename InputType>
    FullPivLU& compute(const EigenBase<InputType>& matrix) {
      m_lu = matrix.derived();
      computeInPlace();
      return *this;
    }
    inline const MatrixType& matrixLU() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           136,
                           __extension__ __PRETTY_FUNCTION__));
      return m_lu;
    }
    inline Index nonzeroPivots() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           149,
                           __extension__ __PRETTY_FUNCTION__));
      return m_nonzero_pivots;
    }
    RealScalar maxPivot() const { return m_maxpivot; }
    inline const PermutationPType& permutationP() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           164,
                           __extension__ __PRETTY_FUNCTION__));
      return m_p;
    }
    inline const PermutationQType& permutationQ() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           174,
                           __extension__ __PRETTY_FUNCTION__));
      return m_q;
    }
    inline const internal::kernel_retval<FullPivLU> kernel() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           194,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::kernel_retval<FullPivLU>(*this);
    }
    inline const internal::image_retval<FullPivLU> image(const MatrixType& originalMatrix) const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           220,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::image_retval<FullPivLU>(*this, originalMatrix);
    }
    inline RealScalar rcond() const {
      (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           254,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::rcond_estimate_helper(m_l1_norm, *this);
    }
    typename internal::traits<MatrixType>::Scalar determinant() const;
    FullPivLU& setThreshold(const RealScalar& threshold) {
      m_usePrescribedThreshold = true;
      m_prescribedThreshold = threshold;
      return *this;
    }
    FullPivLU& setThreshold(Default_t) {
      m_usePrescribedThreshold = false;
      return *this;
    }
    RealScalar threshold() const {
      (static_cast<bool>(m_isInitialized || m_usePrescribedThreshold)
           ? void(0)
           : __assert_fail("m_isInitialized || m_usePrescribedThreshold",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           319,
                           __extension__ __PRETTY_FUNCTION__));
      return m_usePrescribedThreshold ? m_prescribedThreshold
                                      : NumTraits<Scalar>::epsilon() * RealScalar(m_lu.diagonalSize());
    }
    inline Index rank() const {
      using std::abs;
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           335,
                           __extension__ __PRETTY_FUNCTION__));
      RealScalar premultiplied_threshold = abs(m_maxpivot) * threshold();
      Index result = 0;
      for (Index i = 0; i < m_nonzero_pivots; ++i)
        result += (abs(m_lu.coeff(i, i)) > premultiplied_threshold);
      return result;
    }
    inline Index dimensionOfKernel() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           351,
                           __extension__ __PRETTY_FUNCTION__));
      return cols() - rank();
    }
    inline bool isInjective() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           364,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == cols();
    }
    inline bool isSurjective() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           377,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == rows();
    }
    inline bool isInvertible() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           389,
                           __extension__ __PRETTY_FUNCTION__));
      return isInjective() && (m_lu.rows() == m_lu.cols());
    }
    inline const Inverse<FullPivLU> inverse() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           402,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_lu.rows() == m_lu.cols() && "You can't take the inverse of a non-square matrix!")
           ? void(0)
           : __assert_fail("m_lu.rows() == m_lu.cols() && \"You can't take the inverse of a non-square matrix!\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/FullPivLU.h",
                           403,
                           __extension__ __PRETTY_FUNCTION__));
      return Inverse<FullPivLU>(*this);
    }
    MatrixType reconstructedMatrix() const;
    constexpr inline Index rows() const noexcept { return m_lu.rows(); }
    constexpr inline Index cols() const noexcept { return m_lu.cols(); }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void computeInPlace();
    MatrixType m_lu;
    PermutationPType m_p;
    PermutationQType m_q;
    IntColVectorType m_rowsTranspositions;
    IntRowVectorType m_colsTranspositions;
    Index m_nonzero_pivots;
    RealScalar m_l1_norm;
    RealScalar m_maxpivot, m_prescribedThreshold;
    signed char m_det_pq;
    bool m_isInitialized, m_usePrescribedThreshold;
  };
  template <typename MatrixType>
  FullPivLU<MatrixType>::FullPivLU() : m_isInitialized(false), m_usePrescribedThreshold(false) {}
  template <typename MatrixType>
  FullPivLU<MatrixType>::FullPivLU(Index rows, Index cols)
      : m_lu(rows, cols),
        m_p(rows),
        m_q(cols),
        m_rowsTranspositions(rows),
        m_colsTranspositions(cols),
        m_isInitialized(false),
        m_usePrescribedThreshold(false) {}
  template <typename MatrixType>
  template <typename InputType>
  FullPivLU<MatrixType>::FullPivLU(const EigenBase<InputType>& matrix)
      : m_lu(matrix.rows(), matrix.cols()),
        m_p(matrix.rows()),
        m_q(matrix.cols()),
        m_rowsTranspositions(matrix.rows()),
        m_colsTranspositions(matrix.cols()),
        m_isInitialized(false),
        m_usePrescribedThreshold(false) {
    compute(matrix.derived());
  }
  template <typename MatrixType>
  template <typename InputType>
  FullPivLU<MatrixType>::FullPivLU(EigenBase<InputType>& matrix)
      : m_lu(matrix.derived()),
        m_p(matrix.rows()),
        m_q(matrix.cols()),
        m_rowsTranspositions(matrix.rows()),
        m_colsTranspositions(matrix.cols()),
        m_isInitialized(false),
        m_usePrescribedThreshold(false) {
    computeInPlace();
  }
  template <typename MatrixType>
  void FullPivLU<MatrixType>::computeInPlace() {
    (static_cast<bool>(m_lu.rows() <= NumTraits<int>::highest() && m_lu.cols() <= NumTraits<int>::highest())
         ? void(0)
         : __assert_fail("m_lu.rows()<=NumTraits<int>::highest() && m_lu.cols()<=NumTraits<int>::highest()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/FullPivLU.h",
                         490,
                         __extension__ __PRETTY_FUNCTION__));
    m_l1_norm = m_lu.cwiseAbs().colwise().sum().maxCoeff();
    const Index size = m_lu.diagonalSize();
    const Index rows = m_lu.rows();
    const Index cols = m_lu.cols();
    m_rowsTranspositions.resize(m_lu.rows());
    m_colsTranspositions.resize(m_lu.cols());
    Index number_of_transpositions = 0;
    m_nonzero_pivots = size;
    m_maxpivot = RealScalar(0);
    for (Index k = 0; k < size; ++k) {
      Index row_of_biggest_in_corner, col_of_biggest_in_corner;
      typedef internal::scalar_score_coeff_op<Scalar> Scoring;
      typedef typename Scoring::result_type Score;
      Score biggest_in_corner;
      biggest_in_corner = m_lu.bottomRightCorner(rows - k, cols - k)
                              .unaryExpr(Scoring())
                              .maxCoeff(&row_of_biggest_in_corner, &col_of_biggest_in_corner);
      row_of_biggest_in_corner += k;
      col_of_biggest_in_corner += k;
      if (numext::is_exactly_zero(biggest_in_corner)) {
        m_nonzero_pivots = k;
        for (Index i = k; i < size; ++i) {
          m_rowsTranspositions.coeffRef(i) = internal::convert_index<StorageIndex>(i);
          m_colsTranspositions.coeffRef(i) = internal::convert_index<StorageIndex>(i);
        }
        break;
      }
      RealScalar abs_pivot = internal::abs_knowing_score<Scalar>()(
          m_lu(row_of_biggest_in_corner, col_of_biggest_in_corner), biggest_in_corner);
      if (abs_pivot > m_maxpivot)
        m_maxpivot = abs_pivot;
      m_rowsTranspositions.coeffRef(k) = internal::convert_index<StorageIndex>(row_of_biggest_in_corner);
      m_colsTranspositions.coeffRef(k) = internal::convert_index<StorageIndex>(col_of_biggest_in_corner);
      if (k != row_of_biggest_in_corner) {
        m_lu.row(k).swap(m_lu.row(row_of_biggest_in_corner));
        ++number_of_transpositions;
      }
      if (k != col_of_biggest_in_corner) {
        m_lu.col(k).swap(m_lu.col(col_of_biggest_in_corner));
        ++number_of_transpositions;
      }
      if (k < rows - 1)
        m_lu.col(k).tail(rows - k - 1) /= m_lu.coeff(k, k);
      if (k < size - 1)
        m_lu.block(k + 1, k + 1, rows - k - 1, cols - k - 1).noalias() -=
            m_lu.col(k).tail(rows - k - 1) * m_lu.row(k).tail(cols - k - 1);
    }
    m_p.setIdentity(rows);
    for (Index k = size - 1; k >= 0; --k)
      m_p.applyTranspositionOnTheRight(k, m_rowsTranspositions.coeff(k));
    m_q.setIdentity(cols);
    for (Index k = 0; k < size; ++k)
      m_q.applyTranspositionOnTheRight(k, m_colsTranspositions.coeff(k));
    m_det_pq = (number_of_transpositions % 2) ? -1 : 1;
    m_isInitialized = true;
  }
  template <typename MatrixType>
  typename internal::traits<MatrixType>::Scalar FullPivLU<MatrixType>::determinant() const {
    (static_cast<bool>(m_isInitialized && "LU is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/FullPivLU.h",
                         580,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_lu.rows() == m_lu.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_lu.rows() == m_lu.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/FullPivLU.h",
                         581,
                         __extension__ __PRETTY_FUNCTION__));
    return Scalar(m_det_pq) * Scalar(m_lu.diagonal().prod());
  }
  template <typename MatrixType>
  MatrixType FullPivLU<MatrixType>::reconstructedMatrix() const {
    (static_cast<bool>(m_isInitialized && "LU is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/FullPivLU.h",
                         591,
                         __extension__ __PRETTY_FUNCTION__));
    const Index smalldim = (std::min)(m_lu.rows(), m_lu.cols());
    MatrixType res(m_lu.rows(), m_lu.cols());
    res = m_lu.leftCols(smalldim).template triangularView<UnitLower>().toDenseMatrix() *
          m_lu.topRows(smalldim).template triangularView<Upper>().toDenseMatrix();
    res = m_p.inverse() * res;
    res = res * m_q.inverse();
    return res;
  }
  namespace internal {
    template <typename MatrixType_>
    struct kernel_retval<FullPivLU<MatrixType_>> : kernel_retval_base<FullPivLU<MatrixType_>> {
      typedef typename FullPivLU<MatrixType_>::MatrixType MatrixType;
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      typedef Eigen::internal::kernel_retval_base<FullPivLU<MatrixType_>> Base;
      using Base::cols;
      using Base::dec;
      using Base::rank;
      using Base::rows;
      kernel_retval(const FullPivLU<MatrixType_>& dec) : Base(dec) {}
      enum {
        MaxSmallDimAtCompileTime =
            min_size_prefer_fixed(MatrixType::MaxColsAtCompileTime, MatrixType::MaxRowsAtCompileTime)
      };
      template <typename Dest>
      void evalTo(Dest& dst) const {
        using std::abs;
        const Index cols = dec().matrixLU().cols(), dimker = cols - rank();
        if (dimker == 0) {
          dst.setZero();
          return;
        }
        Matrix<Index, Dynamic, 1, 0, MaxSmallDimAtCompileTime, 1> pivots(rank());
        RealScalar premultiplied_threshold = dec().maxPivot() * dec().threshold();
        Index p = 0;
        for (Index i = 0; i < dec().nonzeroPivots(); ++i)
          if (abs(dec().matrixLU().coeff(i, i)) > premultiplied_threshold)
            pivots.coeffRef(p++) = i;
        ;
        Matrix<typename MatrixType::Scalar,
               Dynamic,
               Dynamic,
               MatrixType::Options,
               MaxSmallDimAtCompileTime,
               MatrixType::MaxColsAtCompileTime>
            m(dec().matrixLU().block(0, 0, rank(), cols));
        for (Index i = 0; i < rank(); ++i) {
          if (i)
            m.row(i).head(i).setZero();
          m.row(i).tail(cols - i) = dec().matrixLU().row(pivots.coeff(i)).tail(cols - i);
        }
        m.block(0, 0, rank(), rank());
        m.block(0, 0, rank(), rank()).template triangularView<StrictlyLower>().setZero();
        for (Index i = 0; i < rank(); ++i)
          m.col(i).swap(m.col(pivots.coeff(i)));
        m.topLeftCorner(rank(), rank()).template triangularView<Upper>().solveInPlace(m.topRightCorner(rank(), dimker));
        for (Index i = rank() - 1; i >= 0; --i)
          m.col(i).swap(m.col(pivots.coeff(i)));
        for (Index i = 0; i < rank(); ++i)
          dst.row(dec().permutationQ().indices().coeff(i)) = -m.row(i).tail(dimker);
        for (Index i = rank(); i < cols; ++i)
          dst.row(dec().permutationQ().indices().coeff(i)).setZero();
        for (Index k = 0; k < dimker; ++k)
          dst.coeffRef(dec().permutationQ().indices().coeff(rank() + k), k) = Scalar(1);
      }
    };
    template <typename MatrixType_>
    struct image_retval<FullPivLU<MatrixType_>> : image_retval_base<FullPivLU<MatrixType_>> {
      typedef typename FullPivLU<MatrixType_>::MatrixType MatrixType;
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      typedef Eigen::internal::image_retval_base<FullPivLU<MatrixType_>> Base;
      using Base::cols;
      using Base::dec;
      using Base::originalMatrix;
      using Base::rank;
      using Base::rows;
      image_retval(const FullPivLU<MatrixType_>& dec, const MatrixType& originalMatrix) : Base(dec, originalMatrix) {}
      enum {
        MaxSmallDimAtCompileTime =
            min_size_prefer_fixed(MatrixType::MaxColsAtCompileTime, MatrixType::MaxRowsAtCompileTime)
      };
      template <typename Dest>
      void evalTo(Dest& dst) const {
        using std::abs;
        if (rank() == 0) {
          dst.setZero();
          return;
        }
        Matrix<Index, Dynamic, 1, 0, MaxSmallDimAtCompileTime, 1> pivots(rank());
        RealScalar premultiplied_threshold = dec().maxPivot() * dec().threshold();
        Index p = 0;
        for (Index i = 0; i < dec().nonzeroPivots(); ++i)
          if (abs(dec().matrixLU().coeff(i, i)) > premultiplied_threshold)
            pivots.coeffRef(p++) = i;
        ;
        for (Index i = 0; i < rank(); ++i)
          dst.col(i) = originalMatrix().col(dec().permutationQ().indices().coeff(pivots.coeff(i)));
      }
    };
  }  // namespace internal
  template <typename MatrixType_>
  template <typename RhsType, typename DstType>
  void FullPivLU<MatrixType_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    const Index rows = this->rows(), cols = this->cols(), nonzero_pivots = this->rank();
    const Index smalldim = (std::min)(rows, cols);
    if (nonzero_pivots == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(rhs.rows(), rhs.cols());
    c = permutationP() * rhs;
    m_lu.topLeftCorner(smalldim, smalldim).template triangularView<UnitLower>().solveInPlace(c.topRows(smalldim));
    if (rows > cols)
      c.bottomRows(rows - cols) -= m_lu.bottomRows(rows - cols) * c.topRows(cols);
    m_lu.topLeftCorner(nonzero_pivots, nonzero_pivots)
        .template triangularView<Upper>()
        .solveInPlace(c.topRows(nonzero_pivots));
    for (Index i = 0; i < nonzero_pivots; ++i)
      dst.row(permutationQ().indices().coeff(i)) = c.row(i);
    for (Index i = nonzero_pivots; i < m_lu.cols(); ++i)
      dst.row(permutationQ().indices().coeff(i)).setZero();
  }
  template <typename MatrixType_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void FullPivLU<MatrixType_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    const Index rows = this->rows(), cols = this->cols(), nonzero_pivots = this->rank();
    const Index smalldim = (std::min)(rows, cols);
    if (nonzero_pivots == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(rhs.rows(), rhs.cols());
    c = permutationQ().inverse() * rhs;
    m_lu.topLeftCorner(nonzero_pivots, nonzero_pivots)
        .template triangularView<Upper>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(nonzero_pivots));
    m_lu.topLeftCorner(smalldim, smalldim)
        .template triangularView<UnitLower>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(smalldim));
    PermutationPType invp = permutationP().inverse().eval();
    for (Index i = 0; i < smalldim; ++i)
      dst.row(invp.indices().coeff(i)) = c.row(i);
    for (Index i = smalldim; i < rows; ++i)
      dst.row(invp.indices().coeff(i)).setZero();
  }
  namespace internal {
    template <typename DstXprType, typename MatrixType>
    struct Assignment<DstXprType,
                      Inverse<FullPivLU<MatrixType>>,
                      internal::assign_op<typename DstXprType::Scalar, typename FullPivLU<MatrixType>::Scalar>,
                      Dense2Dense> {
      typedef FullPivLU<MatrixType> LuType;
      typedef Inverse<LuType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename MatrixType::Scalar>&) {
        dst = src.nestedExpression().solve(MatrixType::Identity(src.rows(), src.cols()));
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline const FullPivLU<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::fullPivLu() const {
    return FullPivLU<PlainObject>(eval());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<PartialPivLU<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      typedef traits<MatrixType_> BaseTraits;
      enum { Flags = BaseTraits::Flags & RowMajorBit, CoeffReadCost = Dynamic };
    };
    template <typename T, typename Derived>
    struct enable_if_ref;
    template <typename T, typename Derived>
    struct enable_if_ref<Ref<T>, Derived> {
      typedef Derived type;
    };
  }  // namespace internal
  template <typename MatrixType_>
  class PartialPivLU : public SolverBase<PartialPivLU<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<PartialPivLU> Base;
    friend class SolverBase<PartialPivLU>;
    typedef typename Eigen::internal::traits<PartialPivLU>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<PartialPivLU>::type Nested;
    typedef typename Eigen::internal::traits<PartialPivLU>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<PartialPivLU>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<PartialPivLU>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<PartialPivLU>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<PartialPivLU>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef PermutationMatrix<RowsAtCompileTime, MaxRowsAtCompileTime> PermutationType;
    typedef Transpositions<RowsAtCompileTime, MaxRowsAtCompileTime> TranspositionType;
    typedef typename MatrixType::PlainObject PlainObject;
    PartialPivLU();
    explicit PartialPivLU(Index size);
    template <typename InputType>
    explicit PartialPivLU(const EigenBase<InputType>& matrix);
    template <typename InputType>
    explicit PartialPivLU(EigenBase<InputType>& matrix);
    ~PartialPivLU() {}
    template <typename InputType>
    PartialPivLU& compute(const EigenBase<InputType>& matrix) {
      m_lu = matrix.derived();
      compute();
      return *this;
    }
    inline const MatrixType& matrixLU() const {
      (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           159,
                           __extension__ __PRETTY_FUNCTION__));
      return m_lu;
    }
    inline const PermutationType& permutationP() const {
      (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           168,
                           __extension__ __PRETTY_FUNCTION__));
      return m_p;
    }
    inline RealScalar rcond() const {
      (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           201,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::rcond_estimate_helper(m_l1_norm, *this);
    }
    inline const Inverse<PartialPivLU> inverse() const {
      (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           215,
                           __extension__ __PRETTY_FUNCTION__));
      return Inverse<PartialPivLU>(*this);
    }
    Scalar determinant() const;
    MatrixType reconstructedMatrix() const;
    constexpr inline Index rows() const noexcept { return m_lu.rows(); }
    constexpr inline Index cols() const noexcept { return m_lu.cols(); }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const {
      dst = permutationP() * rhs;
      m_lu.template triangularView<UnitLower>().solveInPlace(dst);
      m_lu.template triangularView<Upper>().solveInPlace(dst);
    }
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
      (static_cast<bool>(rhs.rows() == m_lu.cols())
           ? void(0)
           : __assert_fail("rhs.rows() == m_lu.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           270,
                           __extension__ __PRETTY_FUNCTION__));
      dst = m_lu.template triangularView<Upper>().transpose().template conjugateIf<Conjugate>().solve(rhs);
      m_lu.template triangularView<UnitLower>().transpose().template conjugateIf<Conjugate>().solveInPlace(dst);
      dst = permutationP().transpose() * dst;
    }

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void compute();
    MatrixType m_lu;
    PermutationType m_p;
    TranspositionType m_rowsTranspositions;
    RealScalar m_l1_norm;
    signed char m_det_p;
    bool m_isInitialized;
  };
  template <typename MatrixType>
  PartialPivLU<MatrixType>::PartialPivLU()
      : m_lu(), m_p(), m_rowsTranspositions(), m_l1_norm(0), m_det_p(0), m_isInitialized(false) {}
  template <typename MatrixType>
  PartialPivLU<MatrixType>::PartialPivLU(Index size)
      : m_lu(size, size), m_p(size), m_rowsTranspositions(size), m_l1_norm(0), m_det_p(0), m_isInitialized(false) {}
  template <typename MatrixType>
  template <typename InputType>
  PartialPivLU<MatrixType>::PartialPivLU(const EigenBase<InputType>& matrix)
      : m_lu(matrix.rows(), matrix.cols()),
        m_p(matrix.rows()),
        m_rowsTranspositions(matrix.rows()),
        m_l1_norm(0),
        m_det_p(0),
        m_isInitialized(false) {
    compute(matrix.derived());
  }
  template <typename MatrixType>
  template <typename InputType>
  PartialPivLU<MatrixType>::PartialPivLU(EigenBase<InputType>& matrix)
      : m_lu(matrix.derived()),
        m_p(matrix.rows()),
        m_rowsTranspositions(matrix.rows()),
        m_l1_norm(0),
        m_det_p(0),
        m_isInitialized(false) {
    compute();
  }
  namespace internal {
    template <typename Scalar, int StorageOrder, typename PivIndex, int SizeAtCompileTime = Dynamic>
    struct partial_lu_impl {
      static constexpr int UnBlockedBound = 16;
      static constexpr bool UnBlockedAtCompileTime =
          SizeAtCompileTime != Dynamic && SizeAtCompileTime <= UnBlockedBound;
      static constexpr int ActualSizeAtCompileTime = UnBlockedAtCompileTime ? SizeAtCompileTime : Dynamic;
      static constexpr int RRows = SizeAtCompileTime == 2 ? 1 : Dynamic;
      static constexpr int RCols = SizeAtCompileTime == 2 ? 1 : Dynamic;
      typedef Matrix<Scalar, ActualSizeAtCompileTime, ActualSizeAtCompileTime, StorageOrder> MatrixType;
      typedef Ref<MatrixType> MatrixTypeRef;
      typedef Ref<Matrix<Scalar, Dynamic, Dynamic, StorageOrder>> BlockType;
      typedef typename MatrixType::RealScalar RealScalar;
      static Index unblocked_lu(MatrixTypeRef& lu, PivIndex* row_transpositions, PivIndex& nb_transpositions) {
        typedef scalar_score_coeff_op<Scalar> Scoring;
        typedef typename Scoring::result_type Score;
        const Index rows = lu.rows();
        const Index cols = lu.cols();
        const Index size = (std::min)(rows, cols);
        const Index endk = UnBlockedAtCompileTime ? size - 1 : size;
        nb_transpositions = 0;
        Index first_zero_pivot = -1;
        for (Index k = 0; k < endk; ++k) {
          int rrows = internal::convert_index<int>(rows - k - 1);
          int rcols = internal::convert_index<int>(cols - k - 1);
          Index row_of_biggest_in_col;
          Score biggest_in_corner = lu.col(k).tail(rows - k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
          row_of_biggest_in_col += k;
          row_transpositions[k] = PivIndex(row_of_biggest_in_col);
          if (!numext::is_exactly_zero(biggest_in_corner)) {
            if (k != row_of_biggest_in_col) {
              lu.row(k).swap(lu.row(row_of_biggest_in_col));
              ++nb_transpositions;
            }
            lu.col(k).tail(fix<RRows>(rrows)) /= lu.coeff(k, k);
          } else if (first_zero_pivot == -1) {
            first_zero_pivot = k;
          }
          if (k < rows - 1)
            lu.bottomRightCorner(fix<RRows>(rrows), fix<RCols>(rcols)).noalias() -=
                lu.col(k).tail(fix<RRows>(rrows)) * lu.row(k).tail(fix<RCols>(rcols));
        }
        if (UnBlockedAtCompileTime) {
          Index k = endk;
          row_transpositions[k] = PivIndex(k);
          if (numext::is_exactly_zero(Scoring()(lu(k, k))) && first_zero_pivot == -1)
            first_zero_pivot = k;
        }
        return first_zero_pivot;
      }
      static Index blocked_lu(Index rows,
                              Index cols,
                              Scalar* lu_data,
                              Index luStride,
                              PivIndex* row_transpositions,
                              PivIndex& nb_transpositions,
                              Index maxBlockSize = 256) {
        MatrixTypeRef lu = MatrixType::Map(lu_data, rows, cols, OuterStride<>(luStride));
        const Index size = (std::min)(rows, cols);
        if (UnBlockedAtCompileTime || size <= UnBlockedBound) {
          return unblocked_lu(lu, row_transpositions, nb_transpositions);
        }
        Index blockSize;
        {
          blockSize = size / 8;
          blockSize = (blockSize / 16) * 16;
          blockSize = (std::min)((std::max)(blockSize, Index(8)), maxBlockSize);
        }
        nb_transpositions = 0;
        Index first_zero_pivot = -1;
        for (Index k = 0; k < size; k += blockSize) {
          Index bs = (std::min)(size - k, blockSize);
          Index trows = rows - k - bs;
          Index tsize = size - k - bs;
          BlockType A_0 = lu.block(0, 0, rows, k);
          BlockType A_2 = lu.block(0, k + bs, rows, tsize);
          BlockType A11 = lu.block(k, k, bs, bs);
          BlockType A12 = lu.block(k, k + bs, bs, tsize);
          BlockType A21 = lu.block(k + bs, k, trows, bs);
          BlockType A22 = lu.block(k + bs, k + bs, trows, tsize);
          PivIndex nb_transpositions_in_panel;
          Index ret = blocked_lu(
              trows + bs, bs, &lu.coeffRef(k, k), luStride, row_transpositions + k, nb_transpositions_in_panel, 16);
          if (ret >= 0 && first_zero_pivot == -1)
            first_zero_pivot = k + ret;
          nb_transpositions += nb_transpositions_in_panel;
          for (Index i = k; i < k + bs; ++i) {
            Index piv = (row_transpositions[i] += internal::convert_index<PivIndex>(k));
            A_0.row(i).swap(A_0.row(piv));
          }
          if (trows) {
            for (Index i = k; i < k + bs; ++i)
              A_2.row(i).swap(A_2.row(row_transpositions[i]));
            A11.template triangularView<UnitLower>().solveInPlace(A12);
            A22.noalias() -= A21 * A12;
          }
        }
        return first_zero_pivot;
      }
    };
    template <typename MatrixType, typename TranspositionType>
    void partial_lu_inplace(MatrixType& lu,
                            TranspositionType& row_transpositions,
                            typename TranspositionType::StorageIndex& nb_transpositions) {
      if (lu.rows() == 0 || lu.cols() == 0) {
        nb_transpositions = 0;
        return;
      }
      (static_cast<bool>(lu.cols() == row_transpositions.size())
           ? void(0)
           : __assert_fail("lu.cols() == row_transpositions.size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           534,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(row_transpositions.size() < 2 ||
                         (&row_transpositions.coeffRef(1) - &row_transpositions.coeffRef(0)) == 1)
           ? void(0)
           : __assert_fail("row_transpositions.size() < 2 || "
                           "(&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/LU/PartialPivLU.h",
                           535,
                           __extension__ __PRETTY_FUNCTION__));
      partial_lu_impl<typename MatrixType::Scalar,
                      MatrixType::Flags & RowMajorBit ? RowMajor : ColMajor,
                      typename TranspositionType::StorageIndex,
                      internal::min_size_prefer_fixed(MatrixType::RowsAtCompileTime,
                                                      MatrixType::ColsAtCompileTime)>::blocked_lu(lu.rows(),
                                                                                                  lu.cols(),
                                                                                                  &lu.coeffRef(0, 0),
                                                                                                  lu.outerStride(),
                                                                                                  &row_transpositions
                                                                                                       .coeffRef(0),
                                                                                                  nb_transpositions);
    }
  }  // namespace internal
  template <typename MatrixType>
  void PartialPivLU<MatrixType>::compute() {
    (static_cast<bool>(m_lu.rows() < NumTraits<int>::highest())
         ? void(0)
         : __assert_fail("m_lu.rows()<NumTraits<int>::highest()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/PartialPivLU.h",
                         551,
                         __extension__ __PRETTY_FUNCTION__));
    if (m_lu.cols() > 0)
      m_l1_norm = m_lu.cwiseAbs().colwise().sum().maxCoeff();
    else
      m_l1_norm = RealScalar(0);
    (static_cast<bool>(m_lu.rows() == m_lu.cols() &&
                       "PartialPivLU is only for square (and moreover invertible) matrices")
         ? void(0)
         : __assert_fail(
               "m_lu.rows() == m_lu.cols() && \"PartialPivLU is only for square (and moreover invertible) matrices\"",
               "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
               "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/LU/"
               "PartialPivLU.h",
               558,
               __extension__ __PRETTY_FUNCTION__));
    const Index size = m_lu.rows();
    m_rowsTranspositions.resize(size);
    typename TranspositionType::StorageIndex nb_transpositions;
    internal::partial_lu_inplace(m_lu, m_rowsTranspositions, nb_transpositions);
    m_det_p = (nb_transpositions % 2) ? -1 : 1;
    m_p = m_rowsTranspositions;
    m_isInitialized = true;
  }
  template <typename MatrixType>
  typename PartialPivLU<MatrixType>::Scalar PartialPivLU<MatrixType>::determinant() const {
    (static_cast<bool>(m_isInitialized && "PartialPivLU is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"PartialPivLU is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/PartialPivLU.h",
                         575,
                         __extension__ __PRETTY_FUNCTION__));
    return Scalar(m_det_p) * m_lu.diagonal().prod();
  }
  template <typename MatrixType>
  MatrixType PartialPivLU<MatrixType>::reconstructedMatrix() const {
    (static_cast<bool>(m_isInitialized && "LU is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/PartialPivLU.h",
                         585,
                         __extension__ __PRETTY_FUNCTION__));
    MatrixType res = m_lu.template triangularView<UnitLower>().toDenseMatrix() * m_lu.template triangularView<Upper>();
    res = m_p.inverse() * res;
    return res;
  }
  namespace internal {
    template <typename DstXprType, typename MatrixType>
    struct Assignment<DstXprType,
                      Inverse<PartialPivLU<MatrixType>>,
                      internal::assign_op<typename DstXprType::Scalar, typename PartialPivLU<MatrixType>::Scalar>,
                      Dense2Dense> {
      typedef PartialPivLU<MatrixType> LuType;
      typedef Inverse<LuType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename LuType::Scalar>&) {
        dst = src.nestedExpression().solve(MatrixType::Identity(src.rows(), src.cols()));
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline const PartialPivLU<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::partialPivLu() const {
    return PartialPivLU<PlainObject>(eval());
  }
  template <typename Derived>
  inline const PartialPivLU<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::lu() const {
    return PartialPivLU<PlainObject>(eval());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived>
    inline const typename Derived::Scalar bruteforce_det3_helper(const MatrixBase<Derived>& matrix,
                                                                 int a,
                                                                 int b,
                                                                 int c) {
      return matrix.coeff(0, a) * (matrix.coeff(1, b) * matrix.coeff(2, c) - matrix.coeff(1, c) * matrix.coeff(2, b));
    }
    template <typename Derived, int DeterminantType = Derived::RowsAtCompileTime>
    struct determinant_impl {
      static inline typename traits<Derived>::Scalar run(const Derived& m) {
        if (Derived::ColsAtCompileTime == Dynamic && m.rows() == 0)
          return typename traits<Derived>::Scalar(1);
        return m.partialPivLu().determinant();
      }
    };
    template <typename Derived>
    struct determinant_impl<Derived, 1> {
      static inline typename traits<Derived>::Scalar run(const Derived& m) { return m.coeff(0, 0); }
    };
    template <typename Derived>
    struct determinant_impl<Derived, 2> {
      static inline typename traits<Derived>::Scalar run(const Derived& m) {
        return m.coeff(0, 0) * m.coeff(1, 1) - m.coeff(1, 0) * m.coeff(0, 1);
      }
    };
    template <typename Derived>
    struct determinant_impl<Derived, 3> {
      static inline typename traits<Derived>::Scalar run(const Derived& m) {
        return bruteforce_det3_helper(m, 0, 1, 2) - bruteforce_det3_helper(m, 1, 0, 2) +
               bruteforce_det3_helper(m, 2, 0, 1);
      }
    };
    template <typename Derived>
    struct determinant_impl<Derived, 4> {
      typedef typename traits<Derived>::Scalar Scalar;
      static Scalar run(const Derived& m) {
        Scalar d2_01 = det2(m, 0, 1);
        Scalar d2_02 = det2(m, 0, 2);
        Scalar d2_03 = det2(m, 0, 3);
        Scalar d2_12 = det2(m, 1, 2);
        Scalar d2_13 = det2(m, 1, 3);
        Scalar d2_23 = det2(m, 2, 3);
        Scalar d3_0 = det3(m, 1, d2_23, 2, d2_13, 3, d2_12);
        Scalar d3_1 = det3(m, 0, d2_23, 2, d2_03, 3, d2_02);
        Scalar d3_2 = det3(m, 0, d2_13, 1, d2_03, 3, d2_01);
        Scalar d3_3 = det3(m, 0, d2_12, 1, d2_02, 2, d2_01);
        return internal::pmadd(static_cast<Scalar>(-m(0, 3)), d3_0, static_cast<Scalar>(m(1, 3) * d3_1)) +
               internal::pmadd(static_cast<Scalar>(-m(2, 3)), d3_2, static_cast<Scalar>(m(3, 3) * d3_3));
      }

    protected:
      static Scalar det2(const Derived& m, Index i0, Index i1) { return m(i0, 0) * m(i1, 1) - m(i1, 0) * m(i0, 1); }
      static Scalar det3(
          const Derived& m, Index i0, const Scalar& d0, Index i1, const Scalar& d1, Index i2, const Scalar& d2) {
        return internal::pmadd(
            m(i0, 2), d0, internal::pmadd(static_cast<Scalar>(-m(i1, 2)), d1, static_cast<Scalar>(m(i2, 2) * d2)));
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline typename internal::traits<Derived>::Scalar MatrixBase<Derived>::determinant() const {
    (static_cast<bool>(rows() == cols())
         ? void(0)
         : __assert_fail("rows() == cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/Determinant.h",
                         112,
                         __extension__ __PRETTY_FUNCTION__));
    typedef typename internal::nested_eval<Derived, Base::RowsAtCompileTime>::type Nested;
    return internal::determinant_impl<internal::remove_all_t<Nested>>::run(derived());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, typename ResultType, int Size = MatrixType::RowsAtCompileTime>
    struct compute_inverse {
      static inline void run(const MatrixType& matrix, ResultType& result) { result = matrix.partialPivLu().inverse(); }
    };
    template <typename MatrixType, typename ResultType, int Size = MatrixType::RowsAtCompileTime>
    struct compute_inverse_and_det_with_check {};
    template <typename MatrixType, typename ResultType>
    struct compute_inverse<MatrixType, ResultType, 1> {
      static inline void run(const MatrixType& matrix, ResultType& result) {
        typedef typename MatrixType::Scalar Scalar;
        internal::evaluator<MatrixType> matrixEval(matrix);
        result.coeffRef(0, 0) = Scalar(1) / matrixEval.coeff(0, 0);
      }
    };
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_and_det_with_check<MatrixType, ResultType, 1> {
      static inline void run(const MatrixType& matrix,
                             const typename MatrixType::RealScalar& absDeterminantThreshold,
                             ResultType& result,
                             typename ResultType::Scalar& determinant,
                             bool& invertible) {
        using std::abs;
        determinant = matrix.coeff(0, 0);
        invertible = abs(determinant) > absDeterminantThreshold;
        if (invertible)
          result.coeffRef(0, 0) = typename ResultType::Scalar(1) / determinant;
      }
    };
    template <typename MatrixType, typename ResultType>
    inline void compute_inverse_size2_helper(const MatrixType& matrix,
                                             const typename ResultType::Scalar& invdet,
                                             ResultType& result) {
      typename ResultType::Scalar temp = matrix.coeff(0, 0);
      result.coeffRef(0, 0) = matrix.coeff(1, 1) * invdet;
      result.coeffRef(1, 0) = -matrix.coeff(1, 0) * invdet;
      result.coeffRef(0, 1) = -matrix.coeff(0, 1) * invdet;
      result.coeffRef(1, 1) = temp * invdet;
    }
    template <typename MatrixType, typename ResultType>
    struct compute_inverse<MatrixType, ResultType, 2> {
      static inline void run(const MatrixType& matrix, ResultType& result) {
        typedef typename ResultType::Scalar Scalar;
        const Scalar invdet = typename MatrixType::Scalar(1) / matrix.determinant();
        compute_inverse_size2_helper(matrix, invdet, result);
      }
    };
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_and_det_with_check<MatrixType, ResultType, 2> {
      static inline void run(const MatrixType& matrix,
                             const typename MatrixType::RealScalar& absDeterminantThreshold,
                             ResultType& inverse,
                             typename ResultType::Scalar& determinant,
                             bool& invertible) {
        using std::abs;
        typedef typename ResultType::Scalar Scalar;
        determinant = matrix.determinant();
        invertible = abs(determinant) > absDeterminantThreshold;
        if (!invertible)
          return;
        const Scalar invdet = Scalar(1) / determinant;
        compute_inverse_size2_helper(matrix, invdet, inverse);
      }
    };
    template <typename MatrixType, int i, int j>
    inline typename MatrixType::Scalar cofactor_3x3(const MatrixType& m) {
      enum { i1 = (i + 1) % 3, i2 = (i + 2) % 3, j1 = (j + 1) % 3, j2 = (j + 2) % 3 };
      return m.coeff(i1, j1) * m.coeff(i2, j2) - m.coeff(i1, j2) * m.coeff(i2, j1);
    }
    template <typename MatrixType, typename ResultType>
    inline void compute_inverse_size3_helper(const MatrixType& matrix,
                                             const typename ResultType::Scalar& invdet,
                                             const Matrix<typename ResultType::Scalar, 3, 1>& cofactors_col0,
                                             ResultType& result) {
      typedef typename ResultType::Scalar Scalar;
      const Scalar c01 = cofactor_3x3<MatrixType, 0, 1>(matrix) * invdet;
      const Scalar c11 = cofactor_3x3<MatrixType, 1, 1>(matrix) * invdet;
      const Scalar c02 = cofactor_3x3<MatrixType, 0, 2>(matrix) * invdet;
      result.coeffRef(1, 2) = cofactor_3x3<MatrixType, 2, 1>(matrix) * invdet;
      result.coeffRef(2, 1) = cofactor_3x3<MatrixType, 1, 2>(matrix) * invdet;
      result.coeffRef(2, 2) = cofactor_3x3<MatrixType, 2, 2>(matrix) * invdet;
      result.coeffRef(1, 0) = c01;
      result.coeffRef(1, 1) = c11;
      result.coeffRef(2, 0) = c02;
      result.row(0) = cofactors_col0 * invdet;
    }
    template <typename MatrixType, typename ResultType>
    struct compute_inverse<MatrixType, ResultType, 3> {
      static inline void run(const MatrixType& matrix, ResultType& result) {
        typedef typename ResultType::Scalar Scalar;
        Matrix<typename MatrixType::Scalar, 3, 1> cofactors_col0;
        cofactors_col0.coeffRef(0) = cofactor_3x3<MatrixType, 0, 0>(matrix);
        cofactors_col0.coeffRef(1) = cofactor_3x3<MatrixType, 1, 0>(matrix);
        cofactors_col0.coeffRef(2) = cofactor_3x3<MatrixType, 2, 0>(matrix);
        const Scalar det = (cofactors_col0.cwiseProduct(matrix.col(0))).sum();
        const Scalar invdet = Scalar(1) / det;
        compute_inverse_size3_helper(matrix, invdet, cofactors_col0, result);
      }
    };
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_and_det_with_check<MatrixType, ResultType, 3> {
      static inline void run(const MatrixType& matrix,
                             const typename MatrixType::RealScalar& absDeterminantThreshold,
                             ResultType& inverse,
                             typename ResultType::Scalar& determinant,
                             bool& invertible) {
        typedef typename ResultType::Scalar Scalar;
        Matrix<Scalar, 3, 1> cofactors_col0;
        cofactors_col0.coeffRef(0) = cofactor_3x3<MatrixType, 0, 0>(matrix);
        cofactors_col0.coeffRef(1) = cofactor_3x3<MatrixType, 1, 0>(matrix);
        cofactors_col0.coeffRef(2) = cofactor_3x3<MatrixType, 2, 0>(matrix);
        determinant = (cofactors_col0.cwiseProduct(matrix.col(0))).sum();
        invertible = Eigen::numext::abs(determinant) > absDeterminantThreshold;
        if (!invertible)
          return;
        const Scalar invdet = Scalar(1) / determinant;
        compute_inverse_size3_helper(matrix, invdet, cofactors_col0, inverse);
      }
    };
    template <typename Derived>
    inline const typename Derived::Scalar general_det3_helper(
        const MatrixBase<Derived>& matrix, int i1, int i2, int i3, int j1, int j2, int j3) {
      return matrix.coeff(i1, j1) *
             (matrix.coeff(i2, j2) * matrix.coeff(i3, j3) - matrix.coeff(i2, j3) * matrix.coeff(i3, j2));
    }
    template <typename MatrixType, int i, int j>
    inline typename MatrixType::Scalar cofactor_4x4(const MatrixType& matrix) {
      enum {
        i1 = (i + 1) % 4,
        i2 = (i + 2) % 4,
        i3 = (i + 3) % 4,
        j1 = (j + 1) % 4,
        j2 = (j + 2) % 4,
        j3 = (j + 3) % 4
      };
      return general_det3_helper(matrix, i1, i2, i3, j1, j2, j3) + general_det3_helper(matrix, i2, i3, i1, j1, j2, j3) +
             general_det3_helper(matrix, i3, i1, i2, j1, j2, j3);
    }
    template <int Arch, typename Scalar, typename MatrixType, typename ResultType>
    struct compute_inverse_size4 {
      static void run(const MatrixType& matrix, ResultType& result) {
        result.coeffRef(0, 0) = cofactor_4x4<MatrixType, 0, 0>(matrix);
        result.coeffRef(1, 0) = -cofactor_4x4<MatrixType, 0, 1>(matrix);
        result.coeffRef(2, 0) = cofactor_4x4<MatrixType, 0, 2>(matrix);
        result.coeffRef(3, 0) = -cofactor_4x4<MatrixType, 0, 3>(matrix);
        result.coeffRef(0, 2) = cofactor_4x4<MatrixType, 2, 0>(matrix);
        result.coeffRef(1, 2) = -cofactor_4x4<MatrixType, 2, 1>(matrix);
        result.coeffRef(2, 2) = cofactor_4x4<MatrixType, 2, 2>(matrix);
        result.coeffRef(3, 2) = -cofactor_4x4<MatrixType, 2, 3>(matrix);
        result.coeffRef(0, 1) = -cofactor_4x4<MatrixType, 1, 0>(matrix);
        result.coeffRef(1, 1) = cofactor_4x4<MatrixType, 1, 1>(matrix);
        result.coeffRef(2, 1) = -cofactor_4x4<MatrixType, 1, 2>(matrix);
        result.coeffRef(3, 1) = cofactor_4x4<MatrixType, 1, 3>(matrix);
        result.coeffRef(0, 3) = -cofactor_4x4<MatrixType, 3, 0>(matrix);
        result.coeffRef(1, 3) = cofactor_4x4<MatrixType, 3, 1>(matrix);
        result.coeffRef(2, 3) = -cofactor_4x4<MatrixType, 3, 2>(matrix);
        result.coeffRef(3, 3) = cofactor_4x4<MatrixType, 3, 3>(matrix);
        result /= (matrix.col(0).cwiseProduct(result.row(0).transpose())).sum();
      }
    };
    template <typename MatrixType, typename ResultType>
    struct compute_inverse<MatrixType, ResultType, 4>
        : compute_inverse_size4<Architecture::Target, typename MatrixType::Scalar, MatrixType, ResultType> {};
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_and_det_with_check<MatrixType, ResultType, 4> {
      static inline void run(const MatrixType& matrix,
                             const typename MatrixType::RealScalar& absDeterminantThreshold,
                             ResultType& inverse,
                             typename ResultType::Scalar& determinant,
                             bool& invertible) {
        using std::abs;
        determinant = matrix.determinant();
        invertible = abs(determinant) > absDeterminantThreshold;
        if (invertible && extract_data(matrix) != extract_data(inverse)) {
          compute_inverse<MatrixType, ResultType>::run(matrix, inverse);
        } else if (invertible) {
          MatrixType matrix_t = matrix;
          compute_inverse<MatrixType, ResultType>::run(matrix_t, inverse);
        }
      }
    };
  }  // namespace internal
  namespace internal {
    template <typename DstXprType, typename XprType>
    struct Assignment<DstXprType,
                      Inverse<XprType>,
                      internal::assign_op<typename DstXprType::Scalar, typename XprType::Scalar>,
                      Dense2Dense> {
      typedef Inverse<XprType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename XprType::Scalar>&) {
        if constexpr (Eigen::internal::traits<XprType>::MaxRowsAtCompileTime == Eigen::Dynamic ||
                      Eigen::internal::traits<XprType>::MaxColsAtCompileTime == Eigen::Dynamic ||
                      Eigen::internal::traits<DstXprType>::MaxRowsAtCompileTime == Eigen::Dynamic ||
                      Eigen::internal::traits<DstXprType>::MaxColsAtCompileTime == Eigen::Dynamic) {
          Index dstRows = src.rows();
          Index dstCols = src.cols();
          if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
            dst.resize(dstRows, dstCols);
        } else {
          constexpr Index srcRows = Eigen::internal::traits<XprType>::RowsAtCompileTime;
          constexpr Index srcCols = Eigen::internal::traits<XprType>::ColsAtCompileTime;
          constexpr Index dstRows = Eigen::internal::traits<DstXprType>::RowsAtCompileTime;
          constexpr Index dstCols = Eigen::internal::traits<DstXprType>::ColsAtCompileTime;
          static_assert(((dstRows == srcRows) && (dstCols == srcCols)), "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
          ;
        }
        const int Size = plain_enum_min(XprType::ColsAtCompileTime, DstXprType::ColsAtCompileTime);
        ;
        (static_cast<bool>(((Size <= 1) || (Size > 4) || (extract_data(src.nestedExpression()) != extract_data(dst))) &&
                           "Aliasing problem detected in inverse(), you need to do inverse().eval() here.")
             ? void(0)
             : __assert_fail("( (Size<=1) || (Size>4) || (extract_data(src.nestedExpression())!=extract_data(dst))) && "
                             "\"Aliasing problem detected in inverse(), you need to do inverse().eval() here.\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/LU/InverseImpl.h",
                             335,
                             __extension__ __PRETTY_FUNCTION__));
        typedef typename internal::nested_eval<XprType, XprType::ColsAtCompileTime>::type ActualXprType;
        typedef internal::remove_all_t<ActualXprType> ActualXprTypeCleanded;
        ActualXprType actual_xpr(src.nestedExpression());
        compute_inverse<ActualXprTypeCleanded, DstXprType>::run(actual_xpr, dst);
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline const Inverse<Derived> MatrixBase<Derived>::inverse() const {
    static_assert(!NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    (static_cast<bool>(rows() == cols())
         ? void(0)
         : __assert_fail("rows() == cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/InverseImpl.h",
                         371,
                         __extension__ __PRETTY_FUNCTION__));
    return Inverse<Derived>(derived());
  }
  template <typename Derived>
  template <typename ResultType>
  inline void MatrixBase<Derived>::computeInverseAndDetWithCheck(ResultType& inverse,
                                                                 typename ResultType::Scalar& determinant,
                                                                 bool& invertible,
                                                                 const RealScalar& absDeterminantThreshold) const {
    (static_cast<bool>(rows() == cols())
         ? void(0)
         : __assert_fail("rows() == cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/InverseImpl.h",
                         405,
                         __extension__ __PRETTY_FUNCTION__));
    typedef std::conditional_t<RowsAtCompileTime == 2,
                               internal::remove_all_t<typename internal::nested_eval<Derived, 2>::type>,
                               PlainObject>
        MatrixType;
    internal::compute_inverse_and_det_with_check<MatrixType, ResultType>::run(
        derived(), absDeterminantThreshold, inverse, determinant, invertible);
  }
  template <typename Derived>
  template <typename ResultType>
  inline void MatrixBase<Derived>::computeInverseWithCheck(ResultType& inverse,
                                                           bool& invertible,
                                                           const RealScalar& absDeterminantThreshold) const {
    Scalar determinant;
    (static_cast<bool>(rows() == cols())
         ? void(0)
         : __assert_fail("rows() == cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/LU/InverseImpl.h",
                         446,
                         __extension__ __PRETTY_FUNCTION__));
    computeInverseAndDetWithCheck(inverse, determinant, invertible, absDeterminantThreshold);
  }
}  // namespace Eigen
namespace Eigen {
  namespace internal {
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_size4<Architecture::Target, float, MatrixType, ResultType> {
      enum {
        MatrixAlignment = traits<MatrixType>::Alignment,
        ResultAlignment = traits<ResultType>::Alignment,
        StorageOrdersMatch = (MatrixType::Flags & RowMajorBit) == (ResultType::Flags & RowMajorBit)
      };
      typedef std::
          conditional_t<(MatrixType::Flags & LinearAccessBit), MatrixType const&, typename MatrixType::PlainObject>
              ActualMatrixType;
      static void run(const MatrixType& mat, ResultType& result) {
        ActualMatrixType matrix(mat);
        const float* data = matrix.data();
        const Index stride = matrix.innerStride();
        Packet4f L1 = ploadt<Packet4f, MatrixAlignment>(data);
        Packet4f L2 = ploadt<Packet4f, MatrixAlignment>(data + stride * 4);
        Packet4f L3 = ploadt<Packet4f, MatrixAlignment>(data + stride * 8);
        Packet4f L4 = ploadt<Packet4f, MatrixAlignment>(data + stride * 12);
        Packet4f A, B, C, D;
        if (!StorageOrdersMatch) {
          A = vec4f_unpacklo(L1, L2);
          B = vec4f_unpacklo(L3, L4);
          C = vec4f_unpackhi(L1, L2);
          D = vec4f_unpackhi(L3, L4);
        } else {
          A = vec4f_movelh(L1, L2);
          B = vec4f_movehl(L2, L1);
          C = vec4f_movelh(L3, L4);
          D = vec4f_movehl(L4, L3);
        }
        Packet4f AB, DC;
        AB = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((A)), (__v4sf)(__m128)((A)), (int)((shuffle_mask<3, 3, 0, 0>::mask))))),
                  B);
        AB = psub(AB,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((A)), (__v4sf)(__m128)((A)), (int)((shuffle_mask<1, 1, 2, 2>::mask))))),
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((B)), (__v4sf)(__m128)((B)), (int)((shuffle_mask<2, 3, 0, 1>::mask)))))));
        DC = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((D)), (__v4sf)(__m128)((D)), (int)((shuffle_mask<3, 3, 0, 0>::mask))))),
                  C);
        DC = psub(DC,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((D)), (__v4sf)(__m128)((D)), (int)((shuffle_mask<1, 1, 2, 2>::mask))))),
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((C)), (__v4sf)(__m128)((C)), (int)((shuffle_mask<2, 3, 0, 1>::mask)))))));
        Packet4f dA, dB, dC, dD;
        dA = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((A)), (__v4sf)(__m128)((A)), (int)((shuffle_mask<3, 3, 1, 1>::mask))))),
                  A);
        dA = psub(dA, vec4f_movehl(dA, dA));
        dB = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((B)), (__v4sf)(__m128)((B)), (int)((shuffle_mask<3, 3, 1, 1>::mask))))),
                  B);
        dB = psub(dB, vec4f_movehl(dB, dB));
        dC = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((C)), (__v4sf)(__m128)((C)), (int)((shuffle_mask<3, 3, 1, 1>::mask))))),
                  C);
        dC = psub(dC, vec4f_movehl(dC, dC));
        dD = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((D)), (__v4sf)(__m128)((D)), (int)((shuffle_mask<3, 3, 1, 1>::mask))))),
                  D);
        dD = psub(dD, vec4f_movehl(dD, dD));
        Packet4f d, d1, d2;
        d = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                     (__v4sf)(__m128)((DC)), (__v4sf)(__m128)((DC)), (int)((shuffle_mask<0, 2, 1, 3>::mask))))),
                 AB);
        d = padd(d, vec4f_movehl(d, d));
        d = padd(d,
                 Packet4f(((__m128)__builtin_ia32_shufps(
                     (__v4sf)(__m128)((d)), (__v4sf)(__m128)((d)), (int)((shuffle_mask<1, 0, 0, 0>::mask))))));
        d1 = pmul(dA, dD);
        d2 = pmul(dB, dC);
        Packet4f det = Packet4f(((__m128)__builtin_ia32_shufps((__v4sf)(__m128)((psub(padd(d1, d2), d))),
                                                               (__v4sf)(__m128)((psub(padd(d1, d2), d))),
                                                               (int)((shuffle_mask<0, 0, 0, 0>::mask)))));
        Packet4f rd = preciprocal(det);
        Packet4f iA, iB, iC, iD;
        iD = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((C)), (__v4sf)(__m128)((C)), (int)((shuffle_mask<0, 0, 2, 2>::mask))))),
                  vec4f_movelh(AB, AB));
        iD = padd(iD,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((C)), (__v4sf)(__m128)((C)), (int)((shuffle_mask<1, 1, 3, 3>::mask))))),
                       vec4f_movehl(AB, AB)));
        iD = psub(pmul(D,
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((dA)), (__v4sf)(__m128)((dA)), (int)((shuffle_mask<0, 0, 0, 0>::mask)))))),
                  iD);
        iA = pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((B)), (__v4sf)(__m128)((B)), (int)((shuffle_mask<0, 0, 2, 2>::mask))))),
                  vec4f_movelh(DC, DC));
        iA = padd(iA,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((B)), (__v4sf)(__m128)((B)), (int)((shuffle_mask<1, 1, 3, 3>::mask))))),
                       vec4f_movehl(DC, DC)));
        iA = psub(pmul(A,
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((dD)), (__v4sf)(__m128)((dD)), (int)((shuffle_mask<0, 0, 0, 0>::mask)))))),
                  iA);
        iB = pmul(D,
                  Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((AB)), (__v4sf)(__m128)((AB)), (int)((shuffle_mask<3, 0, 3, 0>::mask))))));
        iB = psub(iB,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((D)), (__v4sf)(__m128)((D)), (int)((shuffle_mask<1, 0, 3, 2>::mask))))),
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((AB)), (__v4sf)(__m128)((AB)), (int)((shuffle_mask<2, 1, 2, 1>::mask)))))));
        iB = psub(pmul(C,
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((dB)), (__v4sf)(__m128)((dB)), (int)((shuffle_mask<0, 0, 0, 0>::mask)))))),
                  iB);
        iC = pmul(A,
                  Packet4f(((__m128)__builtin_ia32_shufps(
                      (__v4sf)(__m128)((DC)), (__v4sf)(__m128)((DC)), (int)((shuffle_mask<3, 0, 3, 0>::mask))))));
        iC = psub(iC,
                  pmul(Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((A)), (__v4sf)(__m128)((A)), (int)((shuffle_mask<1, 0, 3, 2>::mask))))),
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((DC)), (__v4sf)(__m128)((DC)), (int)((shuffle_mask<2, 1, 2, 1>::mask)))))));
        iC = psub(pmul(B,
                       Packet4f(((__m128)__builtin_ia32_shufps(
                           (__v4sf)(__m128)((dC)), (__v4sf)(__m128)((dC)), (int)((shuffle_mask<0, 0, 0, 0>::mask)))))),
                  iC);
        alignas(16) const float sign_mask[4] = {0.0f, -0.0f, -0.0f, 0.0f};
        const Packet4f p4f_sign_PNNP = pload<Packet4f>(sign_mask);
        rd = pxor(rd, p4f_sign_PNNP);
        iA = pmul(iA, rd);
        iB = pmul(iB, rd);
        iC = pmul(iC, rd);
        iD = pmul(iD, rd);
        Index res_stride = result.outerStride();
        float* res = result.data();
        pstoret<float, Packet4f, ResultAlignment>(
            res + 0,
            Packet4f(((__m128)__builtin_ia32_shufps(
                (__v4sf)(__m128)((iA)), (__v4sf)(__m128)((iB)), (int)((shuffle_mask<3, 1, 3, 1>::mask))))));
        pstoret<float, Packet4f, ResultAlignment>(
            res + res_stride,
            Packet4f(((__m128)__builtin_ia32_shufps(
                (__v4sf)(__m128)((iA)), (__v4sf)(__m128)((iB)), (int)((shuffle_mask<2, 0, 2, 0>::mask))))));
        pstoret<float, Packet4f, ResultAlignment>(
            res + 2 * res_stride,
            Packet4f(((__m128)__builtin_ia32_shufps(
                (__v4sf)(__m128)((iC)), (__v4sf)(__m128)((iD)), (int)((shuffle_mask<3, 1, 3, 1>::mask))))));
        pstoret<float, Packet4f, ResultAlignment>(
            res + 3 * res_stride,
            Packet4f(((__m128)__builtin_ia32_shufps(
                (__v4sf)(__m128)((iC)), (__v4sf)(__m128)((iD)), (int)((shuffle_mask<2, 0, 2, 0>::mask))))));
      }
    };
    template <typename MatrixType, typename ResultType>
    struct compute_inverse_size4<Architecture::Target, double, MatrixType, ResultType> {
      enum {
        MatrixAlignment = traits<MatrixType>::Alignment,
        ResultAlignment = traits<ResultType>::Alignment,
        StorageOrdersMatch = (MatrixType::Flags & RowMajorBit) == (ResultType::Flags & RowMajorBit)
      };
      typedef std::
          conditional_t<(MatrixType::Flags & LinearAccessBit), MatrixType const&, typename MatrixType::PlainObject>
              ActualMatrixType;
      static void run(const MatrixType& mat, ResultType& result) {
        ActualMatrixType matrix(mat);
        Packet2d A1, A2, B1, B2, C1, C2, D1, D2;
        const double* data = matrix.data();
        const Index stride = matrix.innerStride();
        if (StorageOrdersMatch) {
          A1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 0);
          B1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 2);
          A2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 4);
          B2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 6);
          C1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 8);
          D1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 10);
          C2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 12);
          D2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 14);
        } else {
          Packet2d temp;
          A1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 0);
          C1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 2);
          A2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 4);
          C2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 6);
          temp = A1;
          A1 = vec2d_unpacklo(A1, A2);
          A2 = vec2d_unpackhi(temp, A2);
          temp = C1;
          C1 = vec2d_unpacklo(C1, C2);
          C2 = vec2d_unpackhi(temp, C2);
          B1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 8);
          D1 = ploadt<Packet2d, MatrixAlignment>(data + stride * 10);
          B2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 12);
          D2 = ploadt<Packet2d, MatrixAlignment>(data + stride * 14);
          temp = B1;
          B1 = vec2d_unpacklo(B1, B2);
          B2 = vec2d_unpackhi(temp, B2);
          temp = D1;
          D1 = vec2d_unpacklo(D1, D2);
          D2 = vec2d_unpackhi(temp, D2);
        }
        Packet2d dA, dB, dC, dD;
        dA = Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(A2), (__v2df)(__m128d)(A2), (int)(1))));
        dA = pmul(A1, dA);
        dA = psub(dA,
                  Packet2d(((__m128d)__builtin_ia32_shufpd(
                      (__v2df)(__m128d)(dA), (__v2df)(__m128d)(dA), (int)((1 << 1) | 1)))));
        dB = Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(B2), (__v2df)(__m128d)(B2), (int)(1))));
        dB = pmul(B1, dB);
        dB = psub(dB,
                  Packet2d(((__m128d)__builtin_ia32_shufpd(
                      (__v2df)(__m128d)(dB), (__v2df)(__m128d)(dB), (int)((1 << 1) | 1)))));
        dC = Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(C2), (__v2df)(__m128d)(C2), (int)(1))));
        dC = pmul(C1, dC);
        dC = psub(dC,
                  Packet2d(((__m128d)__builtin_ia32_shufpd(
                      (__v2df)(__m128d)(dC), (__v2df)(__m128d)(dC), (int)((1 << 1) | 1)))));
        dD = Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(D2), (__v2df)(__m128d)(D2), (int)(1))));
        dD = pmul(D1, dD);
        dD = psub(dD,
                  Packet2d(((__m128d)__builtin_ia32_shufpd(
                      (__v2df)(__m128d)(dD), (__v2df)(__m128d)(dD), (int)((1 << 1) | 1)))));
        Packet2d DC1, DC2, AB1, AB2;
        AB1 = pmul(B1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(A2), (__v2df)(__m128d)(A2), (int)((1 << 1) | 1)))));
        AB2 = pmul(B2,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(A1), (__v2df)(__m128d)(A1), (int)((0 << 1) | 0)))));
        AB1 = psub(AB1,
                   pmul(B2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(A1), (__v2df)(__m128d)(A1), (int)((1 << 1) | 1))))));
        AB2 = psub(AB2,
                   pmul(B1,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(A2), (__v2df)(__m128d)(A2), (int)((0 << 1) | 0))))));
        DC1 = pmul(C1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(D2), (__v2df)(__m128d)(D2), (int)((1 << 1) | 1)))));
        DC2 = pmul(C2,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(D1), (__v2df)(__m128d)(D1), (int)((0 << 1) | 0)))));
        DC1 = psub(DC1,
                   pmul(C2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(D1), (__v2df)(__m128d)(D1), (int)((1 << 1) | 1))))));
        DC2 = psub(DC2,
                   pmul(C1,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(D2), (__v2df)(__m128d)(D2), (int)((0 << 1) | 0))))));
        Packet2d d1, d2;
        Packet2d det;
        Packet2d rd;
        d1 = pmul(AB1,
                  Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC1), (__v2df)(__m128d)(DC2), (int)(0)))));
        d2 = pmul(AB2,
                  Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC1), (__v2df)(__m128d)(DC2), (int)(3)))));
        rd = padd(d1, d2);
        rd = padd(rd,
                  Packet2d(((__m128d)__builtin_ia32_shufpd(
                      (__v2df)(__m128d)(rd), (__v2df)(__m128d)(rd), (int)((1 << 1) | 1)))));
        d1 = pmul(dA, dD);
        d2 = pmul(dB, dC);
        det = padd(d1, d2);
        det = psub(det, rd);
        det = Packet2d(
            ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(det), (__v2df)(__m128d)(det), (int)((0 << 1) | 0))));
        rd = pdiv(pset1<Packet2d>(1.0), det);
        Packet2d iA1, iA2, iB1, iB2, iC1, iC2, iD1, iD2;
        iD1 = pmul(AB1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(C1), (__v2df)(__m128d)(C1), (int)((0 << 1) | 0)))));
        iD2 = pmul(AB1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(C2), (__v2df)(__m128d)(C2), (int)((0 << 1) | 0)))));
        iD1 = padd(iD1,
                   pmul(AB2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(C1), (__v2df)(__m128d)(C1), (int)((1 << 1) | 1))))));
        iD2 = padd(iD2,
                   pmul(AB2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(C2), (__v2df)(__m128d)(C2), (int)((1 << 1) | 1))))));
        dA = Packet2d(
            ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(dA), (__v2df)(__m128d)(dA), (int)((0 << 1) | 0))));
        iD1 = psub(pmul(D1, dA), iD1);
        iD2 = psub(pmul(D2, dA), iD2);
        iA1 = pmul(DC1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(B1), (__v2df)(__m128d)(B1), (int)((0 << 1) | 0)))));
        iA2 = pmul(DC1,
                   Packet2d(((__m128d)__builtin_ia32_shufpd(
                       (__v2df)(__m128d)(B2), (__v2df)(__m128d)(B2), (int)((0 << 1) | 0)))));
        iA1 = padd(iA1,
                   pmul(DC2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(B1), (__v2df)(__m128d)(B1), (int)((1 << 1) | 1))))));
        iA2 = padd(iA2,
                   pmul(DC2,
                        Packet2d(((__m128d)__builtin_ia32_shufpd(
                            (__v2df)(__m128d)(B2), (__v2df)(__m128d)(B2), (int)((1 << 1) | 1))))));
        dD = Packet2d(
            ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(dD), (__v2df)(__m128d)(dD), (int)((0 << 1) | 0))));
        iA1 = psub(pmul(A1, dD), iA1);
        iA2 = psub(pmul(A2, dD), iA2);
        iB1 = pmul(
            D1, Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(AB2), (__v2df)(__m128d)(AB1), (int)(1)))));
        iB2 = pmul(
            D2, Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(AB2), (__v2df)(__m128d)(AB1), (int)(1)))));
        iB1 = psub(
            iB1,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(D1), (__v2df)(__m128d)(D1), (int)(1)))),
                 Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(AB2), (__v2df)(__m128d)(AB1), (int)(2))))));
        iB2 = psub(
            iB2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(D2), (__v2df)(__m128d)(D2), (int)(1)))),
                 Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(AB2), (__v2df)(__m128d)(AB1), (int)(2))))));
        dB = Packet2d(
            ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(dB), (__v2df)(__m128d)(dB), (int)((0 << 1) | 0))));
        iB1 = psub(pmul(C1, dB), iB1);
        iB2 = psub(pmul(C2, dB), iB2);
        iC1 = pmul(
            A1, Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC2), (__v2df)(__m128d)(DC1), (int)(1)))));
        iC2 = pmul(
            A2, Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC2), (__v2df)(__m128d)(DC1), (int)(1)))));
        iC1 = psub(
            iC1,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(A1), (__v2df)(__m128d)(A1), (int)(1)))),
                 Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC2), (__v2df)(__m128d)(DC1), (int)(2))))));
        iC2 = psub(
            iC2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(A2), (__v2df)(__m128d)(A2), (int)(1)))),
                 Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(DC2), (__v2df)(__m128d)(DC1), (int)(2))))));
        dC = Packet2d(
            ((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(dC), (__v2df)(__m128d)(dC), (int)((0 << 1) | 0))));
        iC1 = psub(pmul(B1, dC), iC1);
        iC2 = psub(pmul(B2, dC), iC2);
        alignas(16) const double sign_mask1[2] = {0.0, -0.0};
        alignas(16) const double sign_mask2[2] = {-0.0, 0.0};
        const Packet2d sign_PN = pload<Packet2d>(sign_mask1);
        const Packet2d sign_NP = pload<Packet2d>(sign_mask2);
        d1 = pxor(rd, sign_PN);
        d2 = pxor(rd, sign_NP);
        Index res_stride = result.outerStride();
        double* res = result.data();
        pstoret<double, Packet2d, ResultAlignment>(
            res + 0,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iA2), (__v2df)(__m128d)(iA1), (int)(3)))),
                 d1));
        pstoret<double, Packet2d, ResultAlignment>(
            res + res_stride,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iA2), (__v2df)(__m128d)(iA1), (int)(0)))),
                 d2));
        pstoret<double, Packet2d, ResultAlignment>(
            res + 2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iB2), (__v2df)(__m128d)(iB1), (int)(3)))),
                 d1));
        pstoret<double, Packet2d, ResultAlignment>(
            res + res_stride + 2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iB2), (__v2df)(__m128d)(iB1), (int)(0)))),
                 d2));
        pstoret<double, Packet2d, ResultAlignment>(
            res + 2 * res_stride,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iC2), (__v2df)(__m128d)(iC1), (int)(3)))),
                 d1));
        pstoret<double, Packet2d, ResultAlignment>(
            res + 3 * res_stride,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iC2), (__v2df)(__m128d)(iC1), (int)(0)))),
                 d2));
        pstoret<double, Packet2d, ResultAlignment>(
            res + 2 * res_stride + 2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iD2), (__v2df)(__m128d)(iD1), (int)(3)))),
                 d1));
        pstoret<double, Packet2d, ResultAlignment>(
            res + 3 * res_stride + 2,
            pmul(Packet2d(((__m128d)__builtin_ia32_shufpd((__v2df)(__m128d)(iD2), (__v2df)(__m128d)(iD1), (int)(0)))),
                 d2));
      }
    };
  }  // namespace internal
}  // namespace Eigen
#pragma clang diagnostic pop
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  template <typename Scalar>
  class JacobiRotation {
  public:
    typedef typename NumTraits<Scalar>::Real RealScalar;
    JacobiRotation() {}
    JacobiRotation(const Scalar& c, const Scalar& s) : m_c(c), m_s(s) {}
    Scalar& c() { return m_c; }
    Scalar c() const { return m_c; }
    Scalar& s() { return m_s; }
    Scalar s() const { return m_s; }
    JacobiRotation operator*(const JacobiRotation& other) {
      using numext::conj;
      return JacobiRotation(m_c * other.m_c - conj(m_s) * other.m_s,
                            conj(m_c * conj(other.m_s) + conj(m_s) * conj(other.m_c)));
    }
    JacobiRotation transpose() const {
      using numext::conj;
      return JacobiRotation(m_c, -conj(m_s));
    }
    JacobiRotation adjoint() const {
      using numext::conj;
      return JacobiRotation(conj(m_c), -m_s);
    }
    template <typename Derived>
    bool makeJacobi(const MatrixBase<Derived>&, Index p, Index q);
    bool makeJacobi(const RealScalar& x, const Scalar& y, const RealScalar& z);
    void makeGivens(const Scalar& p, const Scalar& q, Scalar* r = 0);

  protected:
    void makeGivens(const Scalar& p, const Scalar& q, Scalar* r, internal::true_type);
    void makeGivens(const Scalar& p, const Scalar& q, Scalar* r, internal::false_type);
    Scalar m_c, m_s;
  };
  template <typename Scalar>
  bool JacobiRotation<Scalar>::makeJacobi(const RealScalar& x, const Scalar& y, const RealScalar& z) {
    using std::abs;
    using std::sqrt;
    RealScalar deno = RealScalar(2) * abs(y);
    if (deno < (std::numeric_limits<RealScalar>::min)()) {
      m_c = Scalar(1);
      m_s = Scalar(0);
      return false;
    } else {
      RealScalar tau = (x - z) / deno;
      RealScalar w = sqrt(numext::abs2(tau) + RealScalar(1));
      RealScalar t;
      if (tau > RealScalar(0)) {
        t = RealScalar(1) / (tau + w);
      } else {
        t = RealScalar(1) / (tau - w);
      }
      RealScalar sign_t = t > RealScalar(0) ? RealScalar(1) : RealScalar(-1);
      RealScalar n = RealScalar(1) / sqrt(numext::abs2(t) + RealScalar(1));
      m_s = -sign_t * (numext::conj(y) / abs(y)) * abs(t) * n;
      m_c = n;
      return true;
    }
  }
  template <typename Scalar>
  template <typename Derived>
  inline bool JacobiRotation<Scalar>::makeJacobi(const MatrixBase<Derived>& m, Index p, Index q) {
    return makeJacobi(numext::real(m.coeff(p, p)), m.coeff(p, q), numext::real(m.coeff(q, q)));
  }
  template <typename Scalar>
  void JacobiRotation<Scalar>::makeGivens(const Scalar& p, const Scalar& q, Scalar* r) {
    makeGivens(p, q, r, std::conditional_t<NumTraits<Scalar>::IsComplex, internal::true_type, internal::false_type>());
  }
  template <typename Scalar>
  void JacobiRotation<Scalar>::makeGivens(const Scalar& p, const Scalar& q, Scalar* r, internal::true_type) {
    using numext::conj;
    using std::abs;
    using std::sqrt;
    if (q == Scalar(0)) {
      m_c = numext::real(p) < 0 ? Scalar(-1) : Scalar(1);
      m_s = 0;
      if (r)
        *r = m_c * p;
    } else if (p == Scalar(0)) {
      m_c = 0;
      m_s = -q / abs(q);
      if (r)
        *r = abs(q);
    } else {
      RealScalar p1 = numext::norm1(p);
      RealScalar q1 = numext::norm1(q);
      if (p1 >= q1) {
        Scalar ps = p / p1;
        RealScalar p2 = numext::abs2(ps);
        Scalar qs = q / p1;
        RealScalar q2 = numext::abs2(qs);
        RealScalar u = sqrt(RealScalar(1) + q2 / p2);
        if (numext::real(p) < RealScalar(0))
          u = -u;
        m_c = Scalar(1) / u;
        m_s = -qs * conj(ps) * (m_c / p2);
        if (r)
          *r = p * u;
      } else {
        Scalar ps = p / q1;
        RealScalar p2 = numext::abs2(ps);
        Scalar qs = q / q1;
        RealScalar q2 = numext::abs2(qs);
        RealScalar u = q1 * sqrt(p2 + q2);
        if (numext::real(p) < RealScalar(0))
          u = -u;
        p1 = abs(p);
        ps = p / p1;
        m_c = p1 / u;
        m_s = -conj(ps) * (q / u);
        if (r)
          *r = ps * u;
      }
    }
  }
  template <typename Scalar>
  void JacobiRotation<Scalar>::makeGivens(const Scalar& p, const Scalar& q, Scalar* r, internal::false_type) {
    using std::abs;
    using std::sqrt;
    if (numext::is_exactly_zero(q)) {
      m_c = p < Scalar(0) ? Scalar(-1) : Scalar(1);
      m_s = Scalar(0);
      if (r)
        *r = abs(p);
    } else if (numext::is_exactly_zero(p)) {
      m_c = Scalar(0);
      m_s = q < Scalar(0) ? Scalar(1) : Scalar(-1);
      if (r)
        *r = abs(q);
    } else if (abs(p) > abs(q)) {
      Scalar t = q / p;
      Scalar u = sqrt(Scalar(1) + numext::abs2(t));
      if (p < Scalar(0))
        u = -u;
      m_c = Scalar(1) / u;
      m_s = -t * m_c;
      if (r)
        *r = p * u;
    } else {
      Scalar t = p / q;
      Scalar u = sqrt(Scalar(1) + numext::abs2(t));
      if (q < Scalar(0))
        u = -u;
      m_s = -Scalar(1) / u;
      m_c = -t * m_s;
      if (r)
        *r = q * u;
    }
  }
  namespace internal {
    template <typename VectorX, typename VectorY, typename OtherScalar>
    void apply_rotation_in_the_plane(DenseBase<VectorX>& xpr_x,
                                     DenseBase<VectorY>& xpr_y,
                                     const JacobiRotation<OtherScalar>& j);
  }
  template <typename Derived>
  template <typename OtherScalar>
  inline void MatrixBase<Derived>::applyOnTheLeft(Index p, Index q, const JacobiRotation<OtherScalar>& j) {
    RowXpr x(this->row(p));
    RowXpr y(this->row(q));
    internal::apply_rotation_in_the_plane(x, y, j);
  }
  template <typename Derived>
  template <typename OtherScalar>
  inline void MatrixBase<Derived>::applyOnTheRight(Index p, Index q, const JacobiRotation<OtherScalar>& j) {
    ColXpr x(this->col(p));
    ColXpr y(this->col(q));
    internal::apply_rotation_in_the_plane(x, y, j.transpose());
  }
  namespace internal {
    template <typename Scalar, typename OtherScalar, int SizeAtCompileTime, int MinAlignment, bool Vectorizable>
    struct apply_rotation_in_the_plane_selector {
      static inline void run(Scalar* x, Index incrx, Scalar* y, Index incry, Index size, OtherScalar c, OtherScalar s) {
        for (Index i = 0; i < size; ++i) {
          Scalar xi = *x;
          Scalar yi = *y;
          *x = c * xi + numext::conj(s) * yi;
          *y = -s * xi + numext::conj(c) * yi;
          x += incrx;
          y += incry;
        }
      }
    };
    template <typename Scalar, typename OtherScalar, int SizeAtCompileTime, int MinAlignment>
    struct apply_rotation_in_the_plane_selector<Scalar, OtherScalar, SizeAtCompileTime, MinAlignment, true> {
      static inline void run(Scalar* x, Index incrx, Scalar* y, Index incry, Index size, OtherScalar c, OtherScalar s) {
        typedef typename packet_traits<Scalar>::type Packet;
        typedef typename packet_traits<OtherScalar>::type OtherPacket;
        enum {
          RequiredAlignment =
              plain_enum_max(unpacket_traits<Packet>::alignment, unpacket_traits<OtherPacket>::alignment),
          PacketSize = packet_traits<Scalar>::size,
          OtherPacketSize = packet_traits<OtherScalar>::size
        };
        if (size >= 2 * PacketSize && SizeAtCompileTime == Dynamic && ((incrx == 1 && incry == 1) || PacketSize == 1)) {
          enum { Peeling = 2 };
          Index alignedStart = internal::first_default_aligned(y, size);
          Index alignedEnd = alignedStart + ((size - alignedStart) / PacketSize) * PacketSize;
          const OtherPacket pc = pset1<OtherPacket>(c);
          const OtherPacket ps = pset1<OtherPacket>(s);
          conj_helper<OtherPacket, Packet, NumTraits<OtherScalar>::IsComplex, false> pcj;
          conj_helper<OtherPacket, Packet, false, false> pm;
          for (Index i = 0; i < alignedStart; ++i) {
            Scalar xi = x[i];
            Scalar yi = y[i];
            x[i] = c * xi + numext::conj(s) * yi;
            y[i] = -s * xi + numext::conj(c) * yi;
          }
          Scalar* __restrict px = x + alignedStart;
          Scalar* __restrict py = y + alignedStart;
          if (internal::first_default_aligned(x, size) == alignedStart) {
            for (Index i = alignedStart; i < alignedEnd; i += PacketSize) {
              Packet xi = pload<Packet>(px);
              Packet yi = pload<Packet>(py);
              pstore(px, padd(pm.pmul(pc, xi), pcj.pmul(ps, yi)));
              pstore(py, psub(pcj.pmul(pc, yi), pm.pmul(ps, xi)));
              px += PacketSize;
              py += PacketSize;
            }
          } else {
            Index peelingEnd = alignedStart + ((size - alignedStart) / (Peeling * PacketSize)) * (Peeling * PacketSize);
            for (Index i = alignedStart; i < peelingEnd; i += Peeling * PacketSize) {
              Packet xi = ploadu<Packet>(px);
              Packet xi1 = ploadu<Packet>(px + PacketSize);
              Packet yi = pload<Packet>(py);
              Packet yi1 = pload<Packet>(py + PacketSize);
              pstoreu(px, padd(pm.pmul(pc, xi), pcj.pmul(ps, yi)));
              pstoreu(px + PacketSize, padd(pm.pmul(pc, xi1), pcj.pmul(ps, yi1)));
              pstore(py, psub(pcj.pmul(pc, yi), pm.pmul(ps, xi)));
              pstore(py + PacketSize, psub(pcj.pmul(pc, yi1), pm.pmul(ps, xi1)));
              px += Peeling * PacketSize;
              py += Peeling * PacketSize;
            }
            if (alignedEnd != peelingEnd) {
              Packet xi = ploadu<Packet>(x + peelingEnd);
              Packet yi = pload<Packet>(y + peelingEnd);
              pstoreu(x + peelingEnd, padd(pm.pmul(pc, xi), pcj.pmul(ps, yi)));
              pstore(y + peelingEnd, psub(pcj.pmul(pc, yi), pm.pmul(ps, xi)));
            }
          }
          for (Index i = alignedEnd; i < size; ++i) {
            Scalar xi = x[i];
            Scalar yi = y[i];
            x[i] = c * xi + numext::conj(s) * yi;
            y[i] = -s * xi + numext::conj(c) * yi;
          }
        } else if (SizeAtCompileTime != Dynamic && MinAlignment >= RequiredAlignment) {
          const OtherPacket pc = pset1<OtherPacket>(c);
          const OtherPacket ps = pset1<OtherPacket>(s);
          conj_helper<OtherPacket, Packet, NumTraits<OtherScalar>::IsComplex, false> pcj;
          conj_helper<OtherPacket, Packet, false, false> pm;
          Scalar* __restrict px = x;
          Scalar* __restrict py = y;
          for (Index i = 0; i < size; i += PacketSize) {
            Packet xi = pload<Packet>(px);
            Packet yi = pload<Packet>(py);
            pstore(px, padd(pm.pmul(pc, xi), pcj.pmul(ps, yi)));
            pstore(py, psub(pcj.pmul(pc, yi), pm.pmul(ps, xi)));
            px += PacketSize;
            py += PacketSize;
          }
        } else {
          apply_rotation_in_the_plane_selector<Scalar, OtherScalar, SizeAtCompileTime, MinAlignment, false>::run(
              x, incrx, y, incry, size, c, s);
        }
      }
    };
    template <typename VectorX, typename VectorY, typename OtherScalar>
    void inline apply_rotation_in_the_plane(DenseBase<VectorX>& xpr_x,
                                            DenseBase<VectorY>& xpr_y,
                                            const JacobiRotation<OtherScalar>& j) {
      typedef typename VectorX::Scalar Scalar;
      constexpr bool Vectorizable =
          (int(evaluator<VectorX>::Flags) & int(evaluator<VectorY>::Flags) & PacketAccessBit) &&
          (int(packet_traits<Scalar>::size) == int(packet_traits<OtherScalar>::size));
      (static_cast<bool>(xpr_x.size() == xpr_y.size())
           ? void(0)
           : __assert_fail("xpr_x.size() == xpr_y.size()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Jacobi/Jacobi.h",
                           465,
                           __extension__ __PRETTY_FUNCTION__));
      Index size = xpr_x.size();
      Index incrx = xpr_x.derived().innerStride();
      Index incry = xpr_y.derived().innerStride();
      Scalar* __restrict x = &xpr_x.derived().coeffRef(0);
      Scalar* __restrict y = &xpr_y.derived().coeffRef(0);
      OtherScalar c = j.c();
      OtherScalar s = j.s();
      if (numext::is_exactly_one(c) && numext::is_exactly_zero(s))
        return;
      apply_rotation_in_the_plane_selector<Scalar,
                                           OtherScalar,
                                           VectorX::SizeAtCompileTime,
                                           plain_enum_min(evaluator<VectorX>::Alignment, evaluator<VectorY>::Alignment),
                                           Vectorizable>::run(x, incrx, y, incry, size, c, s);
    }
  }  // namespace internal
}  // namespace Eigen

#pragma clang diagnostic pop

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <typename MatrixType_, int UpLo_>
    struct traits<LLT<MatrixType_, UpLo_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
    template <typename MatrixType, int UpLo>
    struct LLT_Traits;
  }  // namespace internal
  template <typename MatrixType_, int UpLo_>
  class LLT : public SolverBase<LLT<MatrixType_, UpLo_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<LLT> Base;
    friend class SolverBase<LLT>;
    typedef typename Eigen::internal::traits<LLT>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<LLT>::type Nested;
    typedef typename Eigen::internal::traits<LLT>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<LLT>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<LLT>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<LLT>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<LLT>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum { MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime };
    enum { PacketSize = internal::packet_traits<Scalar>::size, AlignmentMask = int(PacketSize) - 1, UpLo = UpLo_ };
    typedef internal::LLT_Traits<MatrixType, UpLo> Traits;
    LLT() : m_matrix(), m_isInitialized(false) {}
    explicit LLT(Index size) : m_matrix(size, size), m_isInitialized(false) {}
    template <typename InputType>
    explicit LLT(const EigenBase<InputType>& matrix) : m_matrix(matrix.rows(), matrix.cols()), m_isInitialized(false) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit LLT(EigenBase<InputType>& matrix) : m_matrix(matrix.derived()), m_isInitialized(false) {
      compute(matrix.derived());
    }
    inline typename Traits::MatrixU matrixU() const {
      (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           137,
                           __extension__ __PRETTY_FUNCTION__));
      return Traits::getU(m_matrix);
    }
    inline typename Traits::MatrixL matrixL() const {
      (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           145,
                           __extension__ __PRETTY_FUNCTION__));
      return Traits::getL(m_matrix);
    }
    template <typename Derived>
    void solveInPlace(const MatrixBase<Derived>& bAndX) const;
    template <typename InputType>
    LLT& compute(const EigenBase<InputType>& matrix);
    RealScalar rcond() const {
      (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           180,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_info == Success && "LLT failed because matrix appears to be negative")
           ? void(0)
           : __assert_fail("m_info == Success && \"LLT failed because matrix appears to be negative\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           181,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::rcond_estimate_helper(m_l1_norm, *this);
    }
    inline const MatrixType& matrixLLT() const {
      (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           192,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrix;
    }
    MatrixType reconstructedMatrix() const;
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           208,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    const LLT& adjoint() const noexcept { return *this; }
    inline constexpr Index rows() const noexcept { return m_matrix.rows(); }
    inline constexpr Index cols() const noexcept { return m_matrix.cols(); }
    template <typename VectorType>
    LLT& rankUpdate(const VectorType& vec, const RealScalar& sigma = 1);
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    MatrixType m_matrix;
    RealScalar m_l1_norm;
    bool m_isInitialized;
    ComputationInfo m_info;
  };
  namespace internal {
    template <typename Scalar, int UpLo>
    struct llt_inplace;
    template <typename MatrixType, typename VectorType>
    static Index llt_rank_update_lower(MatrixType& mat,
                                       const VectorType& vec,
                                       const typename MatrixType::RealScalar& sigma) {
      using std::sqrt;
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      typedef typename MatrixType::ColXpr ColXpr;
      typedef internal::remove_all_t<ColXpr> ColXprCleaned;
      typedef typename ColXprCleaned::SegmentReturnType ColXprSegment;
      typedef Matrix<Scalar, Dynamic, 1> TempVectorType;
      typedef typename TempVectorType::SegmentReturnType TempVecSegment;
      Index n = mat.cols();
      (static_cast<bool>(mat.rows() == n && vec.size() == n)
           ? void(0)
           : __assert_fail("mat.rows()==n && vec.size()==n",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LLT.h",
                           271,
                           __extension__ __PRETTY_FUNCTION__));
      TempVectorType temp;
      if (sigma > 0) {
        temp = sqrt(sigma) * vec;
        for (Index i = 0; i < n; ++i) {
          JacobiRotation<Scalar> g;
          g.makeGivens(mat(i, i), -temp(i), &mat(i, i));
          Index rs = n - i - 1;
          if (rs > 0) {
            ColXprSegment x(mat.col(i).tail(rs));
            TempVecSegment y(temp.tail(rs));
            apply_rotation_in_the_plane(x, y, g);
          }
        }
      } else {
        temp = vec;
        RealScalar beta = 1;
        for (Index j = 0; j < n; ++j) {
          RealScalar Ljj = numext::real(mat.coeff(j, j));
          RealScalar dj = numext::abs2(Ljj);
          Scalar wj = temp.coeff(j);
          RealScalar swj2 = sigma * numext::abs2(wj);
          RealScalar gamma = dj * beta + swj2;
          RealScalar x = dj + swj2 / beta;
          if (x <= RealScalar(0))
            return j;
          RealScalar nLjj = sqrt(x);
          mat.coeffRef(j, j) = nLjj;
          beta += swj2 / dj;
          Index rs = n - j - 1;
          if (rs) {
            temp.tail(rs) -= (wj / Ljj) * mat.col(j).tail(rs);
            if (!numext::is_exactly_zero(gamma))
              mat.col(j).tail(rs) =
                  (nLjj / Ljj) * mat.col(j).tail(rs) + (nLjj * sigma * numext::conj(wj) / gamma) * temp.tail(rs);
          }
        }
      }
      return -1;
    }
    template <typename Scalar>
    struct llt_inplace<Scalar, Lower> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      template <typename MatrixType>
      static Index unblocked(MatrixType& mat) {
        using std::sqrt;
        (static_cast<bool>(mat.rows() == mat.cols())
             ? void(0)
             : __assert_fail("mat.rows()==mat.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Cholesky/LLT.h",
                             337,
                             __extension__ __PRETTY_FUNCTION__));
        const Index size = mat.rows();
        for (Index k = 0; k < size; ++k) {
          Index rs = size - k - 1;
          Block<MatrixType, Dynamic, 1> A21(mat, k + 1, k, rs, 1);
          Block<MatrixType, 1, Dynamic> A10(mat, k, 0, 1, k);
          Block<MatrixType, Dynamic, Dynamic> A20(mat, k + 1, 0, rs, k);
          RealScalar x = numext::real(mat.coeff(k, k));
          if (k > 0)
            x -= A10.squaredNorm();
          if (x <= RealScalar(0))
            return k;
          mat.coeffRef(k, k) = x = sqrt(x);
          if (k > 0 && rs > 0)
            A21.noalias() -= A20 * A10.adjoint();
          if (rs > 0)
            A21 /= x;
        }
        return -1;
      }
      template <typename MatrixType>
      static Index blocked(MatrixType& m) {
        (static_cast<bool>(m.rows() == m.cols())
             ? void(0)
             : __assert_fail("m.rows()==m.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Cholesky/LLT.h",
                             362,
                             __extension__ __PRETTY_FUNCTION__));
        Index size = m.rows();
        if (size < 32)
          return unblocked(m);
        Index blockSize = size / 8;
        blockSize = (blockSize / 16) * 16;
        blockSize = (std::min)((std::max)(blockSize, Index(8)), Index(128));
        for (Index k = 0; k < size; k += blockSize) {
          Index bs = (std::min)(blockSize, size - k);
          Index rs = size - k - bs;
          Block<MatrixType, Dynamic, Dynamic> A11(m, k, k, bs, bs);
          Block<MatrixType, Dynamic, Dynamic> A21(m, k + bs, k, rs, bs);
          Block<MatrixType, Dynamic, Dynamic> A22(m, k + bs, k + bs, rs, rs);
          Index ret;
          if ((ret = unblocked(A11)) >= 0)
            return k + ret;
          if (rs > 0)
            A11.adjoint().template triangularView<Upper>().template solveInPlace<OnTheRight>(A21);
          if (rs > 0)
            A22.template selfadjointView<Lower>().rankUpdate(A21, typename NumTraits<RealScalar>::Literal(-1));
        }
        return -1;
      }
      template <typename MatrixType, typename VectorType>
      static Index rankUpdate(MatrixType& mat, const VectorType& vec, const RealScalar& sigma) {
        return Eigen::internal::llt_rank_update_lower(mat, vec, sigma);
      }
    };
    template <typename Scalar>
    struct llt_inplace<Scalar, Upper> {
      typedef typename NumTraits<Scalar>::Real RealScalar;
      template <typename MatrixType>
      static inline Index unblocked(MatrixType& mat) {
        Transpose<MatrixType> matt(mat);
        return llt_inplace<Scalar, Lower>::unblocked(matt);
      }
      template <typename MatrixType>
      static inline Index blocked(MatrixType& mat) {
        Transpose<MatrixType> matt(mat);
        return llt_inplace<Scalar, Lower>::blocked(matt);
      }
      template <typename MatrixType, typename VectorType>
      static Index rankUpdate(MatrixType& mat, const VectorType& vec, const RealScalar& sigma) {
        Transpose<MatrixType> matt(mat);
        return llt_inplace<Scalar, Lower>::rankUpdate(matt, vec.conjugate(), sigma);
      }
    };
    template <typename MatrixType>
    struct LLT_Traits<MatrixType, Lower> {
      typedef const TriangularView<const MatrixType, Lower> MatrixL;
      typedef const TriangularView<const typename MatrixType::AdjointReturnType, Upper> MatrixU;
      static inline MatrixL getL(const MatrixType& m) { return MatrixL(m); }
      static inline MatrixU getU(const MatrixType& m) { return MatrixU(m.adjoint()); }
      static bool inplace_decomposition(MatrixType& m) {
        return llt_inplace<typename MatrixType::Scalar, Lower>::blocked(m) == -1;
      }
    };
    template <typename MatrixType>
    struct LLT_Traits<MatrixType, Upper> {
      typedef const TriangularView<const typename MatrixType::AdjointReturnType, Lower> MatrixL;
      typedef const TriangularView<const MatrixType, Upper> MatrixU;
      static inline MatrixL getL(const MatrixType& m) { return MatrixL(m.adjoint()); }
      static inline MatrixU getU(const MatrixType& m) { return MatrixU(m); }
      static bool inplace_decomposition(MatrixType& m) {
        return llt_inplace<typename MatrixType::Scalar, Upper>::blocked(m) == -1;
      }
    };
  }  // namespace internal
  template <typename MatrixType, int UpLo_>
  template <typename InputType>
  LLT<MatrixType, UpLo_>& LLT<MatrixType, UpLo_>::compute(const EigenBase<InputType>& a) {
    (static_cast<bool>(a.rows() == a.cols())
         ? void(0)
         : __assert_fail("a.rows()==a.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         460,
                         __extension__ __PRETTY_FUNCTION__));
    const Index size = a.rows();
    m_matrix.resize(size, size);
    if (!internal::is_same_dense(m_matrix, a.derived()))
      m_matrix = a.derived();
    m_l1_norm = RealScalar(0);
    for (Index col = 0; col < size; ++col) {
      RealScalar abs_col_sum;
      if (UpLo_ == Lower)
        abs_col_sum =
            m_matrix.col(col).tail(size - col).template lpNorm<1>() + m_matrix.row(col).head(col).template lpNorm<1>();
      else
        abs_col_sum =
            m_matrix.col(col).head(col).template lpNorm<1>() + m_matrix.row(col).tail(size - col).template lpNorm<1>();
      if (abs_col_sum > m_l1_norm)
        m_l1_norm = abs_col_sum;
    }
    m_isInitialized = true;
    bool ok = Traits::inplace_decomposition(m_matrix);
    m_info = ok ? Success : NumericalIssue;
    return *this;
  }
  template <typename MatrixType_, int UpLo_>
  template <typename VectorType>
  LLT<MatrixType_, UpLo_>& LLT<MatrixType_, UpLo_>::rankUpdate(const VectorType& v, const RealScalar& sigma) {
    static_assert(VectorType::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    (static_cast<bool>(v.size() == m_matrix.cols())
         ? void(0)
         : __assert_fail("v.size()==m_matrix.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         497,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_isInitialized)
         ? void(0)
         : __assert_fail("m_isInitialized",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         498,
                         __extension__ __PRETTY_FUNCTION__));
    if (internal::llt_inplace<typename MatrixType::Scalar, UpLo>::rankUpdate(m_matrix, v, sigma) >= 0)
      m_info = NumericalIssue;
    else
      m_info = Success;
    return *this;
  }
  template <typename MatrixType_, int UpLo_>
  template <typename RhsType, typename DstType>
  void LLT<MatrixType_, UpLo_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    _solve_impl_transposed<true>(rhs, dst);
  }
  template <typename MatrixType_, int UpLo_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void LLT<MatrixType_, UpLo_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    dst = rhs;
    matrixL().template conjugateIf<!Conjugate>().solveInPlace(dst);
    matrixU().template conjugateIf<!Conjugate>().solveInPlace(dst);
  }
  template <typename MatrixType, int UpLo_>
  template <typename Derived>
  void LLT<MatrixType, UpLo_>::solveInPlace(const MatrixBase<Derived>& bAndX) const {
    (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         545,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_matrix.rows() == bAndX.rows())
         ? void(0)
         : __assert_fail("m_matrix.rows()==bAndX.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         546,
                         __extension__ __PRETTY_FUNCTION__));
    matrixL().solveInPlace(bAndX);
    matrixU().solveInPlace(bAndX);
  }
  template <typename MatrixType, int UpLo_>
  MatrixType LLT<MatrixType, UpLo_>::reconstructedMatrix() const {
    (static_cast<bool>(m_isInitialized && "LLT is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LLT is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LLT.h",
                         558,
                         __extension__ __PRETTY_FUNCTION__));
    return matrixL() * matrixL().adjoint().toDenseMatrix();
  }
  template <typename Derived>
  inline const LLT<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::llt() const {
    return LLT<PlainObject>(derived());
  }
  template <typename MatrixType, unsigned int UpLo>
  inline const LLT<typename SelfAdjointView<MatrixType, UpLo>::PlainObject, UpLo>
  SelfAdjointView<MatrixType, UpLo>::llt() const {
    return LLT<PlainObject, UpLo>(m_matrix);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_, int UpLo_>
    struct traits<LDLT<MatrixType_, UpLo_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
    template <typename MatrixType, int UpLo>
    struct LDLT_Traits;
    enum SignMatrix { PositiveSemiDef, NegativeSemiDef, ZeroSign, Indefinite };
  }  // namespace internal
  template <typename MatrixType_, int UpLo_>
  class LDLT : public SolverBase<LDLT<MatrixType_, UpLo_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<LDLT> Base;
    friend class SolverBase<LDLT>;
    typedef typename Eigen::internal::traits<LDLT>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<LDLT>::type Nested;
    typedef typename Eigen::internal::traits<LDLT>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<LDLT>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<LDLT>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<LDLT>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<LDLT>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
      UpLo = UpLo_
    };
    typedef Matrix<Scalar, RowsAtCompileTime, 1, 0, MaxRowsAtCompileTime, 1> TmpMatrixType;
    typedef Transpositions<RowsAtCompileTime, MaxRowsAtCompileTime> TranspositionType;
    typedef PermutationMatrix<RowsAtCompileTime, MaxRowsAtCompileTime> PermutationType;
    typedef internal::LDLT_Traits<MatrixType, UpLo> Traits;
    LDLT() : m_matrix(), m_transpositions(), m_sign(internal::ZeroSign), m_isInitialized(false) {}
    explicit LDLT(Index size)
        : m_matrix(size, size),
          m_transpositions(size),
          m_temporary(size),
          m_sign(internal::ZeroSign),
          m_isInitialized(false) {}
    template <typename InputType>
    explicit LDLT(const EigenBase<InputType>& matrix)
        : m_matrix(matrix.rows(), matrix.cols()),
          m_transpositions(matrix.rows()),
          m_temporary(matrix.rows()),
          m_sign(internal::ZeroSign),
          m_isInitialized(false) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit LDLT(EigenBase<InputType>& matrix)
        : m_matrix(matrix.derived()),
          m_transpositions(matrix.rows()),
          m_temporary(matrix.rows()),
          m_sign(internal::ZeroSign),
          m_isInitialized(false) {
      compute(matrix.derived());
    }
    void setZero() { m_isInitialized = false; }
    inline typename Traits::MatrixU matrixU() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           159,
                           __extension__ __PRETTY_FUNCTION__));
      return Traits::getU(m_matrix);
    }
    inline typename Traits::MatrixL matrixL() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           167,
                           __extension__ __PRETTY_FUNCTION__));
      return Traits::getL(m_matrix);
    }
    inline const TranspositionType& transpositionsP() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           176,
                           __extension__ __PRETTY_FUNCTION__));
      return m_transpositions;
    }
    inline Diagonal<const MatrixType> vectorD() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           184,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrix.diagonal();
    }
    inline bool isPositive() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           192,
                           __extension__ __PRETTY_FUNCTION__));
      return m_sign == internal::PositiveSemiDef || m_sign == internal::ZeroSign;
    }
    inline bool isNegative(void) const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           200,
                           __extension__ __PRETTY_FUNCTION__));
      return m_sign == internal::NegativeSemiDef || m_sign == internal::ZeroSign;
    }
    template <typename Derived>
    bool solveInPlace(MatrixBase<Derived>& bAndX) const;
    template <typename InputType>
    LDLT& compute(const EigenBase<InputType>& matrix);
    RealScalar rcond() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           240,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::rcond_estimate_helper(m_l1_norm, *this);
    }
    template <typename Derived>
    LDLT& rankUpdate(const MatrixBase<Derived>& w, const RealScalar& alpha = 1);
    inline const MatrixType& matrixLDLT() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           255,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrix;
    }
    MatrixType reconstructedMatrix() const;
    const LDLT& adjoint() const { return *this; }
    inline constexpr Index rows() const noexcept { return m_matrix.rows(); }
    inline constexpr Index cols() const noexcept { return m_matrix.cols(); }
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           281,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    MatrixType m_matrix;
    RealScalar m_l1_norm;
    TranspositionType m_transpositions;
    TmpMatrixType m_temporary;
    internal::SignMatrix m_sign;
    bool m_isInitialized;
    ComputationInfo m_info;
  };
  namespace internal {
    template <int UpLo>
    struct ldlt_inplace;
    template <>
    struct ldlt_inplace<Lower> {
      template <typename MatrixType, typename TranspositionType, typename Workspace>
      static bool unblocked(MatrixType& mat, TranspositionType& transpositions, Workspace& temp, SignMatrix& sign) {
        using std::abs;
        typedef typename MatrixType::Scalar Scalar;
        typedef typename MatrixType::RealScalar RealScalar;
        typedef typename TranspositionType::StorageIndex IndexType;
        (static_cast<bool>(mat.rows() == mat.cols())
             ? void(0)
             : __assert_fail("mat.rows()==mat.cols()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Cholesky/LDLT.h",
                             327,
                             __extension__ __PRETTY_FUNCTION__));
        const Index size = mat.rows();
        bool found_zero_pivot = false;
        bool ret = true;
        if (size <= 1) {
          transpositions.setIdentity();
          if (size == 0)
            sign = ZeroSign;
          else if (numext::real(mat.coeff(0, 0)) > static_cast<RealScalar>(0))
            sign = PositiveSemiDef;
          else if (numext::real(mat.coeff(0, 0)) < static_cast<RealScalar>(0))
            sign = NegativeSemiDef;
          else
            sign = ZeroSign;
          return true;
        }
        for (Index k = 0; k < size; ++k) {
          Index index_of_biggest_in_corner;
          mat.diagonal().tail(size - k).cwiseAbs().maxCoeff(&index_of_biggest_in_corner);
          index_of_biggest_in_corner += k;
          transpositions.coeffRef(k) = IndexType(index_of_biggest_in_corner);
          if (k != index_of_biggest_in_corner) {
            Index s = size - index_of_biggest_in_corner - 1;
            mat.row(k).head(k).swap(mat.row(index_of_biggest_in_corner).head(k));
            mat.col(k).tail(s).swap(mat.col(index_of_biggest_in_corner).tail(s));
            numext::swap(mat.coeffRef(k, k), mat.coeffRef(index_of_biggest_in_corner, index_of_biggest_in_corner));
            for (Index i = k + 1; i < index_of_biggest_in_corner; ++i) {
              Scalar tmp = mat.coeffRef(i, k);
              mat.coeffRef(i, k) = numext::conj(mat.coeffRef(index_of_biggest_in_corner, i));
              mat.coeffRef(index_of_biggest_in_corner, i) = numext::conj(tmp);
            }
            if (NumTraits<Scalar>::IsComplex)
              mat.coeffRef(index_of_biggest_in_corner, k) = numext::conj(mat.coeff(index_of_biggest_in_corner, k));
          }
          Index rs = size - k - 1;
          Block<MatrixType, Dynamic, 1> A21(mat, k + 1, k, rs, 1);
          Block<MatrixType, 1, Dynamic> A10(mat, k, 0, 1, k);
          Block<MatrixType, Dynamic, Dynamic> A20(mat, k + 1, 0, rs, k);
          if (k > 0) {
            temp.head(k) = mat.diagonal().real().head(k).asDiagonal() * A10.adjoint();
            mat.coeffRef(k, k) -= (A10 * temp.head(k)).value();
            if (rs > 0)
              A21.noalias() -= A20 * temp.head(k);
          }
          RealScalar realAkk = numext::real(mat.coeffRef(k, k));
          bool pivot_is_valid = (abs(realAkk) > RealScalar(0));
          if (k == 0 && !pivot_is_valid) {
            sign = ZeroSign;
            for (Index j = 0; j < size; ++j) {
              transpositions.coeffRef(j) = IndexType(j);
              ret = ret && (mat.col(j).tail(size - j - 1).array() == Scalar(0)).all();
            }
            return ret;
          }
          if ((rs > 0) && pivot_is_valid)
            A21 /= realAkk;
          else if (rs > 0)
            ret = ret && (A21.array() == Scalar(0)).all();
          if (found_zero_pivot && pivot_is_valid)
            ret = false;
          else if (!pivot_is_valid)
            found_zero_pivot = true;
          if (sign == PositiveSemiDef) {
            if (realAkk < static_cast<RealScalar>(0))
              sign = Indefinite;
          } else if (sign == NegativeSemiDef) {
            if (realAkk > static_cast<RealScalar>(0))
              sign = Indefinite;
          } else if (sign == ZeroSign) {
            if (realAkk > static_cast<RealScalar>(0))
              sign = PositiveSemiDef;
            else if (realAkk < static_cast<RealScalar>(0))
              sign = NegativeSemiDef;
          }
        }
        return ret;
      }
      template <typename MatrixType, typename WDerived>
      static bool updateInPlace(MatrixType& mat,
                                MatrixBase<WDerived>& w,
                                const typename MatrixType::RealScalar& sigma = 1) {
        using numext::isfinite;
        typedef typename MatrixType::Scalar Scalar;
        typedef typename MatrixType::RealScalar RealScalar;
        const Index size = mat.rows();
        (static_cast<bool>(mat.cols() == size && w.size() == size)
             ? void(0)
             : __assert_fail("mat.cols() == size && w.size()==size",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Cholesky/LDLT.h",
                             442,
                             __extension__ __PRETTY_FUNCTION__));
        RealScalar alpha = 1;
        for (Index j = 0; j < size; j++) {
          if (!(isfinite)(alpha))
            break;
          RealScalar dj = numext::real(mat.coeff(j, j));
          Scalar wj = w.coeff(j);
          RealScalar swj2 = sigma * numext::abs2(wj);
          RealScalar gamma = dj * alpha + swj2;
          mat.coeffRef(j, j) += swj2 / alpha;
          alpha += swj2 / dj;
          Index rs = size - j - 1;
          w.tail(rs) -= wj * mat.col(j).tail(rs);
          if (!numext::is_exactly_zero(gamma))
            mat.col(j).tail(rs) += (sigma * numext::conj(wj) / gamma) * w.tail(rs);
        }
        return true;
      }
      template <typename MatrixType, typename TranspositionType, typename Workspace, typename WType>
      static bool update(MatrixType& mat,
                         const TranspositionType& transpositions,
                         Workspace& tmp,
                         const WType& w,
                         const typename MatrixType::RealScalar& sigma = 1) {
        tmp = transpositions * w;
        return ldlt_inplace<Lower>::updateInPlace(mat, tmp, sigma);
      }
    };
    template <>
    struct ldlt_inplace<Upper> {
      template <typename MatrixType, typename TranspositionType, typename Workspace>
      static inline bool unblocked(MatrixType& mat,
                                   TranspositionType& transpositions,
                                   Workspace& temp,
                                   SignMatrix& sign) {
        Transpose<MatrixType> matt(mat);
        return ldlt_inplace<Lower>::unblocked(matt, transpositions, temp, sign);
      }
      template <typename MatrixType, typename TranspositionType, typename Workspace, typename WType>
      static inline bool update(MatrixType& mat,
                                TranspositionType& transpositions,
                                Workspace& tmp,
                                WType& w,
                                const typename MatrixType::RealScalar& sigma = 1) {
        Transpose<MatrixType> matt(mat);
        return ldlt_inplace<Lower>::update(matt, transpositions, tmp, w.conjugate(), sigma);
      }
    };
    template <typename MatrixType>
    struct LDLT_Traits<MatrixType, Lower> {
      typedef const TriangularView<const MatrixType, UnitLower> MatrixL;
      typedef const TriangularView<const typename MatrixType::AdjointReturnType, UnitUpper> MatrixU;
      static inline MatrixL getL(const MatrixType& m) { return MatrixL(m); }
      static inline MatrixU getU(const MatrixType& m) { return MatrixU(m.adjoint()); }
    };
    template <typename MatrixType>
    struct LDLT_Traits<MatrixType, Upper> {
      typedef const TriangularView<const typename MatrixType::AdjointReturnType, UnitLower> MatrixL;
      typedef const TriangularView<const MatrixType, UnitUpper> MatrixU;
      static inline MatrixL getL(const MatrixType& m) { return MatrixL(m.adjoint()); }
      static inline MatrixU getU(const MatrixType& m) { return MatrixU(m); }
    };
  }  // namespace internal
  template <typename MatrixType, int UpLo_>
  template <typename InputType>
  LDLT<MatrixType, UpLo_>& LDLT<MatrixType, UpLo_>::compute(const EigenBase<InputType>& a) {
    (static_cast<bool>(a.rows() == a.cols())
         ? void(0)
         : __assert_fail("a.rows()==a.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LDLT.h",
                         531,
                         __extension__ __PRETTY_FUNCTION__));
    const Index size = a.rows();
    m_matrix = a.derived();
    m_l1_norm = RealScalar(0);
    for (Index col = 0; col < size; ++col) {
      RealScalar abs_col_sum;
      if (UpLo_ == Lower)
        abs_col_sum =
            m_matrix.col(col).tail(size - col).template lpNorm<1>() + m_matrix.row(col).head(col).template lpNorm<1>();
      else
        abs_col_sum =
            m_matrix.col(col).head(col).template lpNorm<1>() + m_matrix.row(col).tail(size - col).template lpNorm<1>();
      if (abs_col_sum > m_l1_norm)
        m_l1_norm = abs_col_sum;
    }
    m_transpositions.resize(size);
    m_isInitialized = false;
    m_temporary.resize(size);
    m_sign = internal::ZeroSign;
    m_info = internal::ldlt_inplace<UpLo>::unblocked(m_matrix, m_transpositions, m_temporary, m_sign) ? Success
                                                                                                      : NumericalIssue;
    m_isInitialized = true;
    return *this;
  }
  template <typename MatrixType, int UpLo_>
  template <typename Derived>
  LDLT<MatrixType, UpLo_>& LDLT<MatrixType, UpLo_>::rankUpdate(
      const MatrixBase<Derived>& w, const typename LDLT<MatrixType, UpLo_>::RealScalar& sigma) {
    typedef typename TranspositionType::StorageIndex IndexType;
    const Index size = w.rows();
    if (m_isInitialized) {
      (static_cast<bool>(m_matrix.rows() == size)
           ? void(0)
           : __assert_fail("m_matrix.rows()==size",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Cholesky/LDLT.h",
                           574,
                           __extension__ __PRETTY_FUNCTION__));
    } else {
      m_matrix.resize(size, size);
      m_matrix.setZero();
      m_transpositions.resize(size);
      for (Index i = 0; i < size; i++)
        m_transpositions.coeffRef(i) = IndexType(i);
      m_temporary.resize(size);
      m_sign = sigma >= 0 ? internal::PositiveSemiDef : internal::NegativeSemiDef;
      m_isInitialized = true;
    }
    internal::ldlt_inplace<UpLo>::update(m_matrix, m_transpositions, m_temporary, w, sigma);
    return *this;
  }
  template <typename MatrixType_, int UpLo_>
  template <typename RhsType, typename DstType>
  void LDLT<MatrixType_, UpLo_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    _solve_impl_transposed<true>(rhs, dst);
  }
  template <typename MatrixType_, int UpLo_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void LDLT<MatrixType_, UpLo_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    dst = m_transpositions * rhs;
    matrixL().template conjugateIf<!Conjugate>().solveInPlace(dst);
    using std::abs;
    const typename Diagonal<const MatrixType>::RealReturnType vecD(vectorD());
    RealScalar tolerance = (std::numeric_limits<RealScalar>::min)();
    for (Index i = 0; i < vecD.size(); ++i) {
      if (abs(vecD(i)) > tolerance)
        dst.row(i) /= vecD(i);
      else
        dst.row(i).setZero();
    }
    matrixL().transpose().template conjugateIf<Conjugate>().solveInPlace(dst);
    dst = m_transpositions.transpose() * dst;
  }
  template <typename MatrixType, int UpLo_>
  template <typename Derived>
  bool LDLT<MatrixType, UpLo_>::solveInPlace(MatrixBase<Derived>& bAndX) const {
    (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LDLT.h",
                         662,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_matrix.rows() == bAndX.rows())
         ? void(0)
         : __assert_fail("m_matrix.rows() == bAndX.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LDLT.h",
                         663,
                         __extension__ __PRETTY_FUNCTION__));
    bAndX = this->solve(bAndX);
    return true;
  }
  template <typename MatrixType, int UpLo_>
  MatrixType LDLT<MatrixType, UpLo_>::reconstructedMatrix() const {
    (static_cast<bool>(m_isInitialized && "LDLT is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"LDLT is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Cholesky/LDLT.h",
                         677,
                         __extension__ __PRETTY_FUNCTION__));
    const Index size = m_matrix.rows();
    MatrixType res(size, size);
    res.setIdentity();
    res = transpositionsP() * res;
    res = matrixU() * res;
    res = vectorD().real().asDiagonal() * res;
    res = matrixL() * res;
    res = transpositionsP().transpose() * res;
    return res;
  }
  template <typename MatrixType, unsigned int UpLo>
  inline const LDLT<typename SelfAdjointView<MatrixType, UpLo>::PlainObject, UpLo>
  SelfAdjointView<MatrixType, UpLo>::ldlt() const {
    return LDLT<PlainObject, UpLo>(m_matrix);
  }
  template <typename Derived>
  inline const LDLT<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::ldlt() const {
    return LDLT<PlainObject>(derived());
  }
}  // namespace Eigen
#pragma clang diagnostic pop
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <int n>
    struct decrement_size {
      enum { ret = n == Dynamic ? n : n - 1 };
    };
  }  // namespace internal
  template <typename Derived>
  void MatrixBase<Derived>::makeHouseholderInPlace(Scalar& tau, RealScalar& beta) {
    VectorBlock<Derived, internal::decrement_size<Base::SizeAtCompileTime>::ret> essentialPart(
        derived(), 1, size() - 1);
    makeHouseholder(essentialPart, tau, beta);
  }
  template <typename Derived>
  template <typename EssentialPart>
  void MatrixBase<Derived>::makeHouseholder(EssentialPart& essential, Scalar& tau, RealScalar& beta) const {
    using numext::conj;
    using numext::sqrt;
    static_assert(EssentialPart::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    VectorBlock<const Derived, EssentialPart::SizeAtCompileTime> tail(derived(), 1, size() - 1);
    RealScalar tailSqNorm = size() == 1 ? RealScalar(0) : tail.squaredNorm();
    Scalar c0 = coeff(0);
    const RealScalar tol = (std::numeric_limits<RealScalar>::min)();
    if (tailSqNorm <= tol && numext::abs2(numext::imag(c0)) <= tol) {
      tau = RealScalar(0);
      beta = numext::real(c0);
      essential.setZero();
    } else {
      beta = sqrt(numext::abs2(c0) + tailSqNorm);
      if (numext::real(c0) >= RealScalar(0))
        beta = -beta;
      essential = tail / (c0 - beta);
      tau = conj((beta - c0) / beta);
    }
  }
  template <typename Derived>
  template <typename EssentialPart>
  void MatrixBase<Derived>::applyHouseholderOnTheLeft(const EssentialPart& essential,
                                                      const Scalar& tau,
                                                      Scalar* workspace) {
    if (rows() == 1) {
      *this *= Scalar(1) - tau;
    } else if (!numext::is_exactly_zero(tau)) {
      Map<typename internal::plain_row_type<PlainObject>::type> tmp(workspace, cols());
      Block<Derived, EssentialPart::SizeAtCompileTime, Derived::ColsAtCompileTime> bottom(
          derived(), 1, 0, rows() - 1, cols());
      tmp.noalias() = essential.adjoint() * bottom;
      tmp += this->row(0);
      this->row(0) -= tau * tmp;
      bottom.noalias() -= tau * essential * tmp;
    }
  }
  template <typename Derived>
  template <typename EssentialPart>
  void MatrixBase<Derived>::applyHouseholderOnTheRight(const EssentialPart& essential,
                                                       const Scalar& tau,
                                                       Scalar* workspace) {
    if (cols() == 1) {
      *this *= Scalar(1) - tau;
    } else if (!numext::is_exactly_zero(tau)) {
      Map<typename internal::plain_col_type<PlainObject>::type> tmp(workspace, rows());
      Block<Derived, Derived::RowsAtCompileTime, EssentialPart::SizeAtCompileTime> right(
          derived(), 0, 1, rows(), cols() - 1);
      tmp.noalias() = right * essential;
      tmp += this->col(0);
      this->col(0) -= tau * tmp;
      right.noalias() -= tau * tmp * essential.adjoint();
    }
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename VectorsType, typename CoeffsType, int Side>
    struct traits<HouseholderSequence<VectorsType, CoeffsType, Side>> {
      typedef typename VectorsType::Scalar Scalar;
      typedef typename VectorsType::StorageIndex StorageIndex;
      typedef typename VectorsType::StorageKind StorageKind;
      enum {
        RowsAtCompileTime =
            Side == OnTheLeft ? traits<VectorsType>::RowsAtCompileTime : traits<VectorsType>::ColsAtCompileTime,
        ColsAtCompileTime = RowsAtCompileTime,
        MaxRowsAtCompileTime =
            Side == OnTheLeft ? traits<VectorsType>::MaxRowsAtCompileTime : traits<VectorsType>::MaxColsAtCompileTime,
        MaxColsAtCompileTime = MaxRowsAtCompileTime,
        Flags = 0
      };
    };
    struct HouseholderSequenceShape {};
    template <typename VectorsType, typename CoeffsType, int Side>
    struct evaluator_traits<HouseholderSequence<VectorsType, CoeffsType, Side>>
        : public evaluator_traits_base<HouseholderSequence<VectorsType, CoeffsType, Side>> {
      typedef HouseholderSequenceShape Shape;
    };
    template <typename VectorsType, typename CoeffsType, int Side>
    struct hseq_side_dependent_impl {
      typedef Block<const VectorsType, Dynamic, 1> EssentialVectorType;
      typedef HouseholderSequence<VectorsType, CoeffsType, OnTheLeft> HouseholderSequenceType;
      static inline const EssentialVectorType essentialVector(const HouseholderSequenceType& h, Index k) {
        Index start = k + 1 + h.m_shift;
        return Block<const VectorsType, Dynamic, 1>(h.m_vectors, start, k, h.rows() - start, 1);
      }
    };
    template <typename VectorsType, typename CoeffsType>
    struct hseq_side_dependent_impl<VectorsType, CoeffsType, OnTheRight> {
      typedef Transpose<Block<const VectorsType, 1, Dynamic>> EssentialVectorType;
      typedef HouseholderSequence<VectorsType, CoeffsType, OnTheRight> HouseholderSequenceType;
      static inline const EssentialVectorType essentialVector(const HouseholderSequenceType& h, Index k) {
        Index start = k + 1 + h.m_shift;
        return Block<const VectorsType, 1, Dynamic>(h.m_vectors, k, start, 1, h.rows() - start).transpose();
      }
    };
    template <typename OtherScalarType, typename MatrixType>
    struct matrix_type_times_scalar_type {
      typedef typename ScalarBinaryOpTraits<OtherScalarType, typename MatrixType::Scalar>::ReturnType ResultScalar;
      typedef Matrix<ResultScalar,
                     MatrixType::RowsAtCompileTime,
                     MatrixType::ColsAtCompileTime,
                     0,
                     MatrixType::MaxRowsAtCompileTime,
                     MatrixType::MaxColsAtCompileTime>
          Type;
    };
  }  // namespace internal
  template <typename VectorsType, typename CoeffsType, int Side>
  class HouseholderSequence : public EigenBase<HouseholderSequence<VectorsType, CoeffsType, Side>> {
    typedef typename internal::hseq_side_dependent_impl<VectorsType, CoeffsType, Side>::EssentialVectorType
        EssentialVectorType;

  public:
    enum {
      RowsAtCompileTime = internal::traits<HouseholderSequence>::RowsAtCompileTime,
      ColsAtCompileTime = internal::traits<HouseholderSequence>::ColsAtCompileTime,
      MaxRowsAtCompileTime = internal::traits<HouseholderSequence>::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = internal::traits<HouseholderSequence>::MaxColsAtCompileTime
    };
    typedef typename internal::traits<HouseholderSequence>::Scalar Scalar;
    typedef HouseholderSequence<std::conditional_t<NumTraits<Scalar>::IsComplex,
                                                   internal::remove_all_t<typename VectorsType::ConjugateReturnType>,
                                                   VectorsType>,
                                std::conditional_t<NumTraits<Scalar>::IsComplex,
                                                   internal::remove_all_t<typename CoeffsType::ConjugateReturnType>,
                                                   CoeffsType>,
                                Side>
        ConjugateReturnType;
    typedef HouseholderSequence<VectorsType,
                                std::conditional_t<NumTraits<Scalar>::IsComplex,
                                                   internal::remove_all_t<typename CoeffsType::ConjugateReturnType>,
                                                   CoeffsType>,
                                Side>
        AdjointReturnType;
    typedef HouseholderSequence<std::conditional_t<NumTraits<Scalar>::IsComplex,
                                                   internal::remove_all_t<typename VectorsType::ConjugateReturnType>,
                                                   VectorsType>,
                                CoeffsType,
                                Side>
        TransposeReturnType;
    typedef HouseholderSequence<std::add_const_t<VectorsType>, std::add_const_t<CoeffsType>, Side>
        ConstHouseholderSequence;
    HouseholderSequence(const VectorsType& v, const CoeffsType& h)
        : m_vectors(v), m_coeffs(h), m_reverse(false), m_length(v.diagonalSize()), m_shift(0) {}
    HouseholderSequence(const HouseholderSequence& other)
        : m_vectors(other.m_vectors),
          m_coeffs(other.m_coeffs),
          m_reverse(other.m_reverse),
          m_length(other.m_length),
          m_shift(other.m_shift) {}
    constexpr Index rows() const noexcept { return Side == OnTheLeft ? m_vectors.rows() : m_vectors.cols(); }
    constexpr Index cols() const noexcept { return rows(); }
    const EssentialVectorType essentialVector(Index k) const {
      (static_cast<bool>(k >= 0 && k < m_length)
           ? void(0)
           : __assert_fail("k >= 0 && k < m_length",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Householder/HouseholderSequence.h",
                           234,
                           __extension__ __PRETTY_FUNCTION__));
      return internal::hseq_side_dependent_impl<VectorsType, CoeffsType, Side>::essentialVector(*this, k);
    }
    TransposeReturnType transpose() const {
      return TransposeReturnType(m_vectors.conjugate(), m_coeffs)
          .setReverseFlag(!m_reverse)
          .setLength(m_length)
          .setShift(m_shift);
    }
    ConjugateReturnType conjugate() const {
      return ConjugateReturnType(m_vectors.conjugate(), m_coeffs.conjugate())
          .setReverseFlag(m_reverse)
          .setLength(m_length)
          .setShift(m_shift);
    }
    template <bool Cond>
    inline std::conditional_t<Cond, ConjugateReturnType, ConstHouseholderSequence> conjugateIf() const {
      typedef std::conditional_t<Cond, ConjugateReturnType, ConstHouseholderSequence> ReturnType;
      return ReturnType(m_vectors.template conjugateIf<Cond>(), m_coeffs.template conjugateIf<Cond>());
    }
    AdjointReturnType adjoint() const {
      return AdjointReturnType(m_vectors, m_coeffs.conjugate())
          .setReverseFlag(!m_reverse)
          .setLength(m_length)
          .setShift(m_shift);
    }
    AdjointReturnType inverse() const { return adjoint(); }
    template <typename DestType>
    inline void evalTo(DestType& dst) const {
      Matrix<Scalar, DestType::RowsAtCompileTime, 1, AutoAlign | ColMajor, DestType::MaxRowsAtCompileTime, 1> workspace(
          rows());
      evalTo(dst, workspace);
    }
    template <typename Dest, typename Workspace>
    void evalTo(Dest& dst, Workspace& workspace) const {
      workspace.resize(rows());
      Index vecs = m_length;
      if (internal::is_same_dense(dst, m_vectors)) {
        dst.diagonal().setOnes();
        dst.template triangularView<StrictlyUpper>().setZero();
        for (Index k = vecs - 1; k >= 0; --k) {
          Index cornerSize = rows() - k - m_shift;
          if (m_reverse)
            dst.bottomRightCorner(cornerSize, cornerSize)
                .applyHouseholderOnTheRight(essentialVector(k), m_coeffs.coeff(k), workspace.data());
          else
            dst.bottomRightCorner(cornerSize, cornerSize)
                .applyHouseholderOnTheLeft(essentialVector(k), m_coeffs.coeff(k), workspace.data());
          dst.col(k).tail(rows() - k - 1).setZero();
        }
        for (Index k = 0; k < cols() - vecs; ++k)
          dst.col(k).tail(rows() - k - 1).setZero();
      } else if (m_length > BlockSize) {
        dst.setIdentity(rows(), rows());
        if (m_reverse)
          applyThisOnTheLeft(dst, workspace, true);
        else
          applyThisOnTheLeft(dst, workspace, true);
      } else {
        dst.setIdentity(rows(), rows());
        for (Index k = vecs - 1; k >= 0; --k) {
          Index cornerSize = rows() - k - m_shift;
          if (m_reverse)
            dst.bottomRightCorner(cornerSize, cornerSize)
                .applyHouseholderOnTheRight(essentialVector(k), m_coeffs.coeff(k), workspace.data());
          else
            dst.bottomRightCorner(cornerSize, cornerSize)
                .applyHouseholderOnTheLeft(essentialVector(k), m_coeffs.coeff(k), workspace.data());
        }
      }
    }
    template <typename Dest>
    inline void applyThisOnTheRight(Dest& dst) const {
      Matrix<Scalar, 1, Dest::RowsAtCompileTime, RowMajor, 1, Dest::MaxRowsAtCompileTime> workspace(dst.rows());
      applyThisOnTheRight(dst, workspace);
    }
    template <typename Dest, typename Workspace>
    inline void applyThisOnTheRight(Dest& dst, Workspace& workspace) const {
      workspace.resize(dst.rows());
      for (Index k = 0; k < m_length; ++k) {
        Index actual_k = m_reverse ? m_length - k - 1 : k;
        dst.rightCols(rows() - m_shift - actual_k)
            .applyHouseholderOnTheRight(essentialVector(actual_k), m_coeffs.coeff(actual_k), workspace.data());
      }
    }
    template <typename Dest>
    inline void applyThisOnTheLeft(Dest& dst, bool inputIsIdentity = false) const {
      Matrix<Scalar, 1, Dest::ColsAtCompileTime, RowMajor, 1, Dest::MaxColsAtCompileTime> workspace;
      applyThisOnTheLeft(dst, workspace, inputIsIdentity);
    }
    template <typename Dest, typename Workspace>
    inline void applyThisOnTheLeft(Dest& dst, Workspace& workspace, bool inputIsIdentity = false) const {
      if (inputIsIdentity && m_reverse)
        inputIsIdentity = false;
      if (m_length >= BlockSize && dst.cols() > 1) {
        Index blockSize = m_length < Index(2 * BlockSize) ? (m_length + 1) / 2 : Index(BlockSize);
        for (Index i = 0; i < m_length; i += blockSize) {
          Index end = m_reverse ? (std::min)(m_length, i + blockSize) : m_length - i;
          Index k = m_reverse ? i : (std::max)(Index(0), end - blockSize);
          Index bs = end - k;
          Index start = k + m_shift;
          typedef Block<internal::remove_all_t<VectorsType>, Dynamic, Dynamic> SubVectorsType;
          SubVectorsType sub_vecs1(m_vectors.const_cast_derived(),
                                   Side == OnTheRight ? k : start,
                                   Side == OnTheRight ? start : k,
                                   Side == OnTheRight ? bs : m_vectors.rows() - start,
                                   Side == OnTheRight ? m_vectors.cols() - start : bs);
          std::conditional_t<Side == OnTheRight, Transpose<SubVectorsType>, SubVectorsType&> sub_vecs(sub_vecs1);
          Index dstRows = rows() - m_shift - k;
          if (inputIsIdentity) {
            Block<Dest, Dynamic, Dynamic> sub_dst = dst.bottomRightCorner(dstRows, dstRows);
            apply_block_householder_on_the_left(sub_dst, sub_vecs, m_coeffs.segment(k, bs), !m_reverse);
          } else {
            auto sub_dst = dst.bottomRows(dstRows);
            apply_block_householder_on_the_left(sub_dst, sub_vecs, m_coeffs.segment(k, bs), !m_reverse);
          }
        }
      } else {
        workspace.resize(dst.cols());
        for (Index k = 0; k < m_length; ++k) {
          Index actual_k = m_reverse ? k : m_length - k - 1;
          Index dstRows = rows() - m_shift - actual_k;
          if (inputIsIdentity) {
            Block<Dest, Dynamic, Dynamic> sub_dst = dst.bottomRightCorner(dstRows, dstRows);
            sub_dst.applyHouseholderOnTheLeft(essentialVector(actual_k), m_coeffs.coeff(actual_k), workspace.data());
          } else {
            auto sub_dst = dst.bottomRows(dstRows);
            sub_dst.applyHouseholderOnTheLeft(essentialVector(actual_k), m_coeffs.coeff(actual_k), workspace.data());
          }
        }
      }
    }
    template <typename OtherDerived>
    typename internal::matrix_type_times_scalar_type<Scalar, OtherDerived>::Type operator*(
        const MatrixBase<OtherDerived>& other) const {
      typename internal::matrix_type_times_scalar_type<Scalar, OtherDerived>::Type res(
          other.template cast<typename internal::matrix_type_times_scalar_type<Scalar, OtherDerived>::ResultScalar>());
      applyThisOnTheLeft(res, internal::is_identity<OtherDerived>::value && res.rows() == res.cols());
      return res;
    }
    template <typename VectorsType_, typename CoeffsType_, int Side_>
    friend struct internal::hseq_side_dependent_impl;
    HouseholderSequence& setLength(Index length) {
      m_length = length;
      return *this;
    }
    HouseholderSequence& setShift(Index shift) {
      m_shift = shift;
      return *this;
    }
    Index length() const { return m_length; }
    Index shift() const { return m_shift; }
    template <typename VectorsType2, typename CoeffsType2, int Side2>
    friend class HouseholderSequence;

  protected:
    HouseholderSequence& setReverseFlag(bool reverse) {
      m_reverse = reverse;
      return *this;
    }
    bool reverseFlag() const { return m_reverse; }
    typename VectorsType::Nested m_vectors;
    typename CoeffsType::Nested m_coeffs;
    bool m_reverse;
    Index m_length;
    Index m_shift;
    enum { BlockSize = 48 };
  };
  template <typename OtherDerived, typename VectorsType, typename CoeffsType, int Side>
  typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar, OtherDerived>::Type operator*(
      const MatrixBase<OtherDerived>& other, const HouseholderSequence<VectorsType, CoeffsType, Side>& h) {
    typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar, OtherDerived>::Type res(
        other.template cast<typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar,
                                                                             OtherDerived>::ResultScalar>());
    h.applyThisOnTheRight(res);
    return res;
  }
  template <typename VectorsType, typename CoeffsType>
  HouseholderSequence<VectorsType, CoeffsType> householderSequence(const VectorsType& v, const CoeffsType& h) {
    return HouseholderSequence<VectorsType, CoeffsType, OnTheLeft>(v, h);
  }
  template <typename VectorsType, typename CoeffsType>
  HouseholderSequence<VectorsType, CoeffsType, OnTheRight> rightHouseholderSequence(const VectorsType& v,
                                                                                    const CoeffsType& h) {
    return HouseholderSequence<VectorsType, CoeffsType, OnTheRight>(v, h);
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename TriangularFactorType, typename VectorsType, typename CoeffsType>
    void make_block_householder_triangular_factor(TriangularFactorType& triFactor,
                                                  const VectorsType& vectors,
                                                  const CoeffsType& hCoeffs) {
      const Index nbVecs = vectors.cols();
      (static_cast<bool>(triFactor.rows() == nbVecs && triFactor.cols() == nbVecs && vectors.rows() >= nbVecs)
           ? void(0)
           : __assert_fail("triFactor.rows() == nbVecs && triFactor.cols() == nbVecs && vectors.rows()>=nbVecs",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Householder/BlockHouseholder.h",
                           57,
                           __extension__ __PRETTY_FUNCTION__));
      for (Index i = nbVecs - 1; i >= 0; --i) {
        Index rs = vectors.rows() - i - 1;
        Index rt = nbVecs - i - 1;
        if (rt > 0) {
          triFactor.row(i).tail(rt).noalias() = -hCoeffs(i) * vectors.col(i).tail(rs).adjoint() *
                                                vectors.bottomRightCorner(rs, rt).template triangularView<UnitLower>();
          for (Index j = nbVecs - 1; j > i; --j) {
            typename TriangularFactorType::Scalar z = triFactor(i, j);
            triFactor(i, j) = z * triFactor(j, j);
            if (nbVecs - j - 1 > 0)
              triFactor.row(i).tail(nbVecs - j - 1) += z * triFactor.row(j).tail(nbVecs - j - 1);
          }
        }
        triFactor(i, i) = hCoeffs(i);
      }
    }
    template <typename MatrixType, typename VectorsType, typename CoeffsType>
    void apply_block_householder_on_the_left(MatrixType& mat,
                                             const VectorsType& vectors,
                                             const CoeffsType& hCoeffs,
                                             bool forward) {
      enum { TFactorSize = VectorsType::ColsAtCompileTime };
      Index nbVecs = vectors.cols();
      Matrix<typename MatrixType::Scalar, TFactorSize, TFactorSize, RowMajor> T(nbVecs, nbVecs);
      if (forward)
        make_block_householder_triangular_factor(T, vectors, hCoeffs);
      else
        make_block_householder_triangular_factor(T, vectors, hCoeffs.conjugate());
      const TriangularView<const VectorsType, UnitLower> V(vectors);
      Matrix<typename MatrixType::Scalar,
             VectorsType::ColsAtCompileTime,
             MatrixType::ColsAtCompileTime,
             (VectorsType::MaxColsAtCompileTime == 1 && MatrixType::MaxColsAtCompileTime != 1) ? RowMajor : ColMajor,
             VectorsType::MaxColsAtCompileTime,
             MatrixType::MaxColsAtCompileTime>
          tmp = V.adjoint() * mat;
      if (forward)
        tmp = T.template triangularView<Upper>() * tmp;
      else
        tmp = T.template triangularView<Upper>().adjoint() * tmp;
      mat.noalias() -= V * tmp;
    }
  }  // namespace internal
}  // namespace Eigen

#pragma clang diagnostic pop

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<HouseholderQR<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
  }  // namespace internal
  template <typename MatrixType_>
  class HouseholderQR : public SolverBase<HouseholderQR<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<HouseholderQR> Base;
    friend class SolverBase<HouseholderQR>;
    typedef typename Eigen::internal::traits<HouseholderQR>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<HouseholderQR>::type Nested;
    typedef typename Eigen::internal::traits<HouseholderQR>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<HouseholderQR>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<HouseholderQR>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<HouseholderQR>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<HouseholderQR>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef Matrix<Scalar,
                   RowsAtCompileTime,
                   RowsAtCompileTime,
                   (MatrixType::Flags & RowMajorBit) ? RowMajor : ColMajor,
                   MaxRowsAtCompileTime,
                   MaxRowsAtCompileTime>
        MatrixQType;
    typedef typename internal::plain_diag_type<MatrixType>::type HCoeffsType;
    typedef typename internal::plain_row_type<MatrixType>::type RowVectorType;
    typedef HouseholderSequence<MatrixType, internal::remove_all_t<typename HCoeffsType::ConjugateReturnType>>
        HouseholderSequenceType;
    HouseholderQR() : m_qr(), m_hCoeffs(), m_temp(), m_isInitialized(false) {}
    HouseholderQR(Index rows, Index cols)
        : m_qr(rows, cols), m_hCoeffs((std::min)(rows, cols)), m_temp(cols), m_isInitialized(false) {}
    template <typename InputType>
    explicit HouseholderQR(const EigenBase<InputType>& matrix)
        : m_qr(matrix.rows(), matrix.cols()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_temp(matrix.cols()),
          m_isInitialized(false) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit HouseholderQR(EigenBase<InputType>& matrix)
        : m_qr(matrix.derived()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_temp(matrix.cols()),
          m_isInitialized(false) {
      computeInPlace();
    }
    HouseholderSequenceType householderQ() const {
      (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           167,
                           __extension__ __PRETTY_FUNCTION__));
      return HouseholderSequenceType(m_qr, m_hCoeffs.conjugate());
    }
    const MatrixType& matrixQR() const {
      (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           176,
                           __extension__ __PRETTY_FUNCTION__));
      return m_qr;
    }
    template <typename InputType>
    HouseholderQR& compute(const EigenBase<InputType>& matrix) {
      m_qr = matrix.derived();
      computeInPlace();
      return *this;
    }
    typename MatrixType::Scalar determinant() const;
    typename MatrixType::RealScalar absDeterminant() const;
    typename MatrixType::RealScalar logAbsDeterminant() const;
    inline Index rows() const { return m_qr.rows(); }
    inline Index cols() const { return m_qr.cols(); }
    const HCoeffsType& hCoeffs() const { return m_hCoeffs; }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void computeInPlace();
    MatrixType m_qr;
    HCoeffsType m_hCoeffs;
    RowVectorType m_temp;
    bool m_isInitialized;
  };
  namespace internal {
    template <typename HCoeffs, typename Scalar, bool IsComplex>
    struct householder_determinant {
      static void run(const HCoeffs& hCoeffs, Scalar& out_det) {
        out_det = Scalar(1);
        Index size = hCoeffs.rows();
        for (Index i = 0; i < size; i++) {
          if (hCoeffs(i) != Scalar(0))
            out_det *= -numext::conj(hCoeffs(i)) / hCoeffs(i);
        }
      }
    };
    template <typename HCoeffs, typename Scalar>
    struct householder_determinant<HCoeffs, Scalar, false> {
      static void run(const HCoeffs& hCoeffs, Scalar& out_det) {
        bool negated = false;
        Index size = hCoeffs.rows();
        for (Index i = 0; i < size; i++) {
          if (hCoeffs(i) != Scalar(0))
            negated ^= true;
        }
        out_det = negated ? Scalar(-1) : Scalar(1);
      }
    };
  }  // namespace internal
  template <typename MatrixType>
  typename MatrixType::Scalar HouseholderQR<MatrixType>::determinant() const {
    (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         304,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         305,
                         __extension__ __PRETTY_FUNCTION__));
    Scalar detQ;
    internal::householder_determinant<HCoeffsType, Scalar, NumTraits<Scalar>::IsComplex>::run(m_hCoeffs, detQ);
    return m_qr.diagonal().prod() * detQ;
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar HouseholderQR<MatrixType>::absDeterminant() const {
    using std::abs;
    (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         315,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         316,
                         __extension__ __PRETTY_FUNCTION__));
    return abs(m_qr.diagonal().prod());
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar HouseholderQR<MatrixType>::logAbsDeterminant() const {
    (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         323,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/HouseholderQR.h",
                         324,
                         __extension__ __PRETTY_FUNCTION__));
    return m_qr.diagonal().cwiseAbs().array().log().sum();
  }
  namespace internal {
    template <typename MatrixQR, typename HCoeffs>
    void householder_qr_inplace_unblocked(MatrixQR& mat, HCoeffs& hCoeffs, typename MatrixQR::Scalar* tempData = 0) {
      typedef typename MatrixQR::Scalar Scalar;
      typedef typename MatrixQR::RealScalar RealScalar;
      Index rows = mat.rows();
      Index cols = mat.cols();
      Index size = (std::min)(rows, cols);
      (static_cast<bool>(hCoeffs.size() == size)
           ? void(0)
           : __assert_fail("hCoeffs.size() == size",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           340,
                           __extension__ __PRETTY_FUNCTION__));
      typedef Matrix<Scalar, MatrixQR::ColsAtCompileTime, 1> TempType;
      TempType tempVector;
      if (tempData == 0) {
        tempVector.resize(cols);
        tempData = tempVector.data();
      }
      for (Index k = 0; k < size; ++k) {
        Index remainingRows = rows - k;
        Index remainingCols = cols - k - 1;
        RealScalar beta;
        mat.col(k).tail(remainingRows).makeHouseholderInPlace(hCoeffs.coeffRef(k), beta);
        mat.coeffRef(k, k) = beta;
        mat.bottomRightCorner(remainingRows, remainingCols)
            .applyHouseholderOnTheLeft(mat.col(k).tail(remainingRows - 1), hCoeffs.coeffRef(k), tempData + k + 1);
      }
    }
    template <typename MatrixQR, typename HCoeffs, typename VectorQR>
    void householder_qr_inplace_update(MatrixQR& mat,
                                       HCoeffs& hCoeffs,
                                       const VectorQR& newColumn,
                                       typename MatrixQR::Index k,
                                       typename MatrixQR::Scalar* tempData) {
      typedef typename MatrixQR::Index Index;
      typedef typename MatrixQR::RealScalar RealScalar;
      Index rows = mat.rows();
      (static_cast<bool>(k < mat.cols())
           ? void(0)
           : __assert_fail("k < mat.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           381,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(k < rows)
           ? void(0)
           : __assert_fail("k < rows",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           382,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(hCoeffs.size() == mat.cols())
           ? void(0)
           : __assert_fail("hCoeffs.size() == mat.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           383,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(newColumn.size() == rows)
           ? void(0)
           : __assert_fail("newColumn.size() == rows",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           384,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(tempData)
           ? void(0)
           : __assert_fail("tempData",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/HouseholderQR.h",
                           385,
                           __extension__ __PRETTY_FUNCTION__));
      mat.col(k) = newColumn;
      for (Index i = 0; i < k; ++i) {
        Index remainingRows = rows - i;
        mat.col(k)
            .tail(remainingRows)
            .applyHouseholderOnTheLeft(mat.col(i).tail(remainingRows - 1), hCoeffs.coeffRef(i), tempData + i + 1);
      }
      RealScalar beta;
      mat.col(k).tail(rows - k).makeHouseholderInPlace(hCoeffs.coeffRef(k), beta);
      mat.coeffRef(k, k) = beta;
    }
    template <typename MatrixQR,
              typename HCoeffs,
              typename MatrixQRScalar = typename MatrixQR::Scalar,
              bool InnerStrideIsOne =
                  (MatrixQR::InnerStrideAtCompileTime == 1 && HCoeffs::InnerStrideAtCompileTime == 1)>
    struct householder_qr_inplace_blocked {
      static void run(MatrixQR& mat,
                      HCoeffs& hCoeffs,
                      Index maxBlockSize = 32,
                      typename MatrixQR::Scalar* tempData = 0) {
        typedef typename MatrixQR::Scalar Scalar;
        typedef Block<MatrixQR, Dynamic, Dynamic> BlockType;
        Index rows = mat.rows();
        Index cols = mat.cols();
        Index size = (std::min)(rows, cols);
        typedef Matrix<Scalar, Dynamic, 1, ColMajor, MatrixQR::MaxColsAtCompileTime, 1> TempType;
        TempType tempVector;
        if (tempData == 0) {
          tempVector.resize(cols);
          tempData = tempVector.data();
        }
        Index blockSize = (std::min)(maxBlockSize, size);
        Index k = 0;
        for (k = 0; k < size; k += blockSize) {
          Index bs = (std::min)(size - k, blockSize);
          Index tcols = cols - k - bs;
          Index brows = rows - k;
          BlockType A11_21 = mat.block(k, k, brows, bs);
          Block<HCoeffs, Dynamic, 1> hCoeffsSegment = hCoeffs.segment(k, bs);
          householder_qr_inplace_unblocked(A11_21, hCoeffsSegment, tempData);
          if (tcols) {
            BlockType A21_22 = mat.block(k, k + bs, brows, tcols);
            apply_block_householder_on_the_left(A21_22, A11_21, hCoeffsSegment, false);
          }
        }
      }
    };
  }  // namespace internal
  template <typename MatrixType_>
  template <typename RhsType, typename DstType>
  void HouseholderQR<MatrixType_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    const Index rank = (std::min)(rows(), cols());
    typename RhsType::PlainObject c(rhs);
    c.applyOnTheLeft(householderQ().setLength(rank).adjoint());
    m_qr.topLeftCorner(rank, rank).template triangularView<Upper>().solveInPlace(c.topRows(rank));
    dst.topRows(rank) = c.topRows(rank);
    dst.bottomRows(cols() - rank).setZero();
  }
  template <typename MatrixType_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void HouseholderQR<MatrixType_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    const Index rank = (std::min)(rows(), cols());
    typename RhsType::PlainObject c(rhs);
    m_qr.topLeftCorner(rank, rank)
        .template triangularView<Upper>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(rank));
    dst.topRows(rank) = c.topRows(rank);
    dst.bottomRows(rows() - rank).setZero();
    dst.applyOnTheLeft(householderQ().setLength(rank).template conjugateIf<!Conjugate>());
  }
  template <typename MatrixType>
  void HouseholderQR<MatrixType>::computeInPlace() {
    Index rows = m_qr.rows();
    Index cols = m_qr.cols();
    Index size = (std::min)(rows, cols);
    m_hCoeffs.resize(size);
    m_temp.resize(cols);
    internal::householder_qr_inplace_blocked<MatrixType, HCoeffsType>::run(m_qr, m_hCoeffs, 48, m_temp.data());
    m_isInitialized = true;
  }
  template <typename Derived>
  const HouseholderQR<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::householderQr() const {
    return HouseholderQR<PlainObject>(eval());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<FullPivHouseholderQR<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
    template <typename MatrixType>
    struct FullPivHouseholderQRMatrixQReturnType;
    template <typename MatrixType>
    struct traits<FullPivHouseholderQRMatrixQReturnType<MatrixType>> {
      typedef typename MatrixType::PlainObject ReturnType;
    };
  }  // namespace internal
  template <typename MatrixType_>
  class FullPivHouseholderQR : public SolverBase<FullPivHouseholderQR<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<FullPivHouseholderQR> Base;
    friend class SolverBase<FullPivHouseholderQR>;
    typedef typename Eigen::internal::traits<FullPivHouseholderQR>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<FullPivHouseholderQR>::type Nested;
    typedef typename Eigen::internal::traits<FullPivHouseholderQR>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<FullPivHouseholderQR>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<FullPivHouseholderQR>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<FullPivHouseholderQR>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<FullPivHouseholderQR>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef internal::FullPivHouseholderQRMatrixQReturnType<MatrixType> MatrixQReturnType;
    typedef typename internal::plain_diag_type<MatrixType>::type HCoeffsType;
    typedef Matrix<StorageIndex,
                   1,
                   internal::min_size_prefer_dynamic(ColsAtCompileTime, RowsAtCompileTime),
                   RowMajor,
                   1,
                   internal::min_size_prefer_fixed(MaxColsAtCompileTime, MaxRowsAtCompileTime)>
        IntDiagSizeVectorType;
    typedef PermutationMatrix<ColsAtCompileTime, MaxColsAtCompileTime> PermutationType;
    typedef typename internal::plain_row_type<MatrixType>::type RowVectorType;
    typedef typename internal::plain_col_type<MatrixType>::type ColVectorType;
    typedef typename MatrixType::PlainObject PlainObject;
    FullPivHouseholderQR()
        : m_qr(),
          m_hCoeffs(),
          m_rows_transpositions(),
          m_cols_transpositions(),
          m_cols_permutation(),
          m_temp(),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {}
    FullPivHouseholderQR(Index rows, Index cols)
        : m_qr(rows, cols),
          m_hCoeffs((std::min)(rows, cols)),
          m_rows_transpositions((std::min)(rows, cols)),
          m_cols_transpositions((std::min)(rows, cols)),
          m_cols_permutation(cols),
          m_temp(cols),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {}
    template <typename InputType>
    explicit FullPivHouseholderQR(const EigenBase<InputType>& matrix)
        : m_qr(matrix.rows(), matrix.cols()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_rows_transpositions((std::min)(matrix.rows(), matrix.cols())),
          m_cols_transpositions((std::min)(matrix.rows(), matrix.cols())),
          m_cols_permutation(matrix.cols()),
          m_temp(matrix.cols()),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit FullPivHouseholderQR(EigenBase<InputType>& matrix)
        : m_qr(matrix.derived()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_rows_transpositions((std::min)(matrix.rows(), matrix.cols())),
          m_cols_transpositions((std::min)(matrix.rows(), matrix.cols())),
          m_cols_permutation(matrix.cols()),
          m_temp(matrix.cols()),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {
      computeInPlace();
    }
    MatrixQReturnType matrixQ(void) const;
    const MatrixType& matrixQR() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           192,
                           __extension__ __PRETTY_FUNCTION__));
      return m_qr;
    }
    template <typename InputType>
    FullPivHouseholderQR& compute(const EigenBase<InputType>& matrix);
    const PermutationType& colsPermutation() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           202,
                           __extension__ __PRETTY_FUNCTION__));
      return m_cols_permutation;
    }
    const IntDiagSizeVectorType& rowsTranspositions() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           209,
                           __extension__ __PRETTY_FUNCTION__));
      return m_rows_transpositions;
    }
    typename MatrixType::Scalar determinant() const;
    typename MatrixType::RealScalar absDeterminant() const;
    typename MatrixType::RealScalar logAbsDeterminant() const;
    inline Index rank() const {
      using std::abs;
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           266,
                           __extension__ __PRETTY_FUNCTION__));
      RealScalar premultiplied_threshold = abs(m_maxpivot) * threshold();
      Index result = 0;
      for (Index i = 0; i < m_nonzero_pivots; ++i)
        result += (abs(m_qr.coeff(i, i)) > premultiplied_threshold);
      return result;
    }
    inline Index dimensionOfKernel() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           282,
                           __extension__ __PRETTY_FUNCTION__));
      return cols() - rank();
    }
    inline bool isInjective() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           295,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == cols();
    }
    inline bool isSurjective() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           308,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == rows();
    }
    inline bool isInvertible() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           320,
                           __extension__ __PRETTY_FUNCTION__));
      return isInjective() && isSurjective();
    }
    inline const Inverse<FullPivHouseholderQR> inverse() const {
      (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           331,
                           __extension__ __PRETTY_FUNCTION__));
      return Inverse<FullPivHouseholderQR>(*this);
    }
    inline Index rows() const { return m_qr.rows(); }
    inline Index cols() const { return m_qr.cols(); }
    const HCoeffsType& hCoeffs() const { return m_hCoeffs; }
    FullPivHouseholderQR& setThreshold(const RealScalar& threshold) {
      m_usePrescribedThreshold = true;
      m_prescribedThreshold = threshold;
      return *this;
    }
    FullPivHouseholderQR& setThreshold(Default_t) {
      m_usePrescribedThreshold = false;
      return *this;
    }
    RealScalar threshold() const {
      (static_cast<bool>(m_isInitialized || m_usePrescribedThreshold)
           ? void(0)
           : __assert_fail("m_isInitialized || m_usePrescribedThreshold",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           388,
                           __extension__ __PRETTY_FUNCTION__));
      return m_usePrescribedThreshold ? m_prescribedThreshold
                                      : NumTraits<Scalar>::epsilon() * RealScalar(m_qr.diagonalSize());
    }
    inline Index nonzeroPivots() const {
      (static_cast<bool>(m_isInitialized && "LU is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"LU is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/FullPivHouseholderQR.h",
                           404,
                           __extension__ __PRETTY_FUNCTION__));
      return m_nonzero_pivots;
    }
    RealScalar maxPivot() const { return m_maxpivot; }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void computeInPlace();
    MatrixType m_qr;
    HCoeffsType m_hCoeffs;
    IntDiagSizeVectorType m_rows_transpositions;
    IntDiagSizeVectorType m_cols_transpositions;
    PermutationType m_cols_permutation;
    RowVectorType m_temp;
    bool m_isInitialized, m_usePrescribedThreshold;
    RealScalar m_prescribedThreshold, m_maxpivot;
    Index m_nonzero_pivots;
    RealScalar m_precision;
    Index m_det_p;
  };
  template <typename MatrixType>
  typename MatrixType::Scalar FullPivHouseholderQR<MatrixType>::determinant() const {
    (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         443,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         444,
                         __extension__ __PRETTY_FUNCTION__));
    Scalar detQ;
    internal::householder_determinant<HCoeffsType, Scalar, NumTraits<Scalar>::IsComplex>::run(m_hCoeffs, detQ);
    return m_qr.diagonal().prod() * detQ * Scalar(m_det_p);
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar FullPivHouseholderQR<MatrixType>::absDeterminant() const {
    using std::abs;
    (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         454,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         455,
                         __extension__ __PRETTY_FUNCTION__));
    return abs(m_qr.diagonal().prod());
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar FullPivHouseholderQR<MatrixType>::logAbsDeterminant() const {
    (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         462,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         463,
                         __extension__ __PRETTY_FUNCTION__));
    return m_qr.diagonal().cwiseAbs().array().log().sum();
  }
  template <typename MatrixType>
  template <typename InputType>
  FullPivHouseholderQR<MatrixType>& FullPivHouseholderQR<MatrixType>::compute(const EigenBase<InputType>& matrix) {
    m_qr = matrix.derived();
    computeInPlace();
    return *this;
  }
  template <typename MatrixType>
  void FullPivHouseholderQR<MatrixType>::computeInPlace() {
    using std::abs;
    Index rows = m_qr.rows();
    Index cols = m_qr.cols();
    Index size = (std::min)(rows, cols);
    m_hCoeffs.resize(size);
    m_temp.resize(cols);
    m_precision = NumTraits<Scalar>::epsilon() * RealScalar(size);
    m_rows_transpositions.resize(size);
    m_cols_transpositions.resize(size);
    Index number_of_transpositions = 0;
    RealScalar biggest(0);
    m_nonzero_pivots = size;
    m_maxpivot = RealScalar(0);
    for (Index k = 0; k < size; ++k) {
      Index row_of_biggest_in_corner, col_of_biggest_in_corner;
      typedef internal::scalar_score_coeff_op<Scalar> Scoring;
      typedef typename Scoring::result_type Score;
      Score score = m_qr.bottomRightCorner(rows - k, cols - k)
                        .unaryExpr(Scoring())
                        .maxCoeff(&row_of_biggest_in_corner, &col_of_biggest_in_corner);
      row_of_biggest_in_corner += k;
      col_of_biggest_in_corner += k;
      RealScalar biggest_in_corner =
          internal::abs_knowing_score<Scalar>()(m_qr(row_of_biggest_in_corner, col_of_biggest_in_corner), score);
      if (k == 0)
        biggest = biggest_in_corner;
      if (internal::isMuchSmallerThan(biggest_in_corner, biggest, m_precision)) {
        m_nonzero_pivots = k;
        for (Index i = k; i < size; i++) {
          m_rows_transpositions.coeffRef(i) = internal::convert_index<StorageIndex>(i);
          m_cols_transpositions.coeffRef(i) = internal::convert_index<StorageIndex>(i);
          m_hCoeffs.coeffRef(i) = Scalar(0);
        }
        break;
      }
      m_rows_transpositions.coeffRef(k) = internal::convert_index<StorageIndex>(row_of_biggest_in_corner);
      m_cols_transpositions.coeffRef(k) = internal::convert_index<StorageIndex>(col_of_biggest_in_corner);
      if (k != row_of_biggest_in_corner) {
        m_qr.row(k).tail(cols - k).swap(m_qr.row(row_of_biggest_in_corner).tail(cols - k));
        ++number_of_transpositions;
      }
      if (k != col_of_biggest_in_corner) {
        m_qr.col(k).swap(m_qr.col(col_of_biggest_in_corner));
        ++number_of_transpositions;
      }
      RealScalar beta;
      m_qr.col(k).tail(rows - k).makeHouseholderInPlace(m_hCoeffs.coeffRef(k), beta);
      m_qr.coeffRef(k, k) = beta;
      if (abs(beta) > m_maxpivot)
        m_maxpivot = abs(beta);
      m_qr.bottomRightCorner(rows - k, cols - k - 1)
          .applyHouseholderOnTheLeft(m_qr.col(k).tail(rows - k - 1), m_hCoeffs.coeffRef(k), &m_temp.coeffRef(k + 1));
    }
    m_cols_permutation.setIdentity(cols);
    for (Index k = 0; k < size; ++k)
      m_cols_permutation.applyTranspositionOnTheRight(k, m_cols_transpositions.coeff(k));
    m_det_p = (number_of_transpositions % 2) ? -1 : 1;
    m_isInitialized = true;
  }
  template <typename MatrixType_>
  template <typename RhsType, typename DstType>
  void FullPivHouseholderQR<MatrixType_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    const Index l_rank = rank();
    if (l_rank == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(rhs);
    Matrix<typename RhsType::Scalar, 1, RhsType::ColsAtCompileTime> temp(rhs.cols());
    for (Index k = 0; k < l_rank; ++k) {
      Index remainingSize = rows() - k;
      c.row(k).swap(c.row(m_rows_transpositions.coeff(k)));
      c.bottomRightCorner(remainingSize, rhs.cols())
          .applyHouseholderOnTheLeft(m_qr.col(k).tail(remainingSize - 1), m_hCoeffs.coeff(k), &temp.coeffRef(0));
    }
    m_qr.topLeftCorner(l_rank, l_rank).template triangularView<Upper>().solveInPlace(c.topRows(l_rank));
    for (Index i = 0; i < l_rank; ++i)
      dst.row(m_cols_permutation.indices().coeff(i)) = c.row(i);
    for (Index i = l_rank; i < cols(); ++i)
      dst.row(m_cols_permutation.indices().coeff(i)).setZero();
  }
  template <typename MatrixType_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void FullPivHouseholderQR<MatrixType_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    const Index l_rank = rank();
    if (l_rank == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(m_cols_permutation.transpose() * rhs);
    m_qr.topLeftCorner(l_rank, l_rank)
        .template triangularView<Upper>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(l_rank));
    dst.topRows(l_rank) = c.topRows(l_rank);
    dst.bottomRows(rows() - l_rank).setZero();
    Matrix<Scalar, 1, DstType::ColsAtCompileTime> temp(dst.cols());
    const Index size = (std::min)(rows(), cols());
    for (Index k = size - 1; k >= 0; --k) {
      Index remainingSize = rows() - k;
      dst.bottomRightCorner(remainingSize, dst.cols())
          .applyHouseholderOnTheLeft(m_qr.col(k).tail(remainingSize - 1).template conjugateIf<!Conjugate>(),
                                     m_hCoeffs.template conjugateIf<Conjugate>().coeff(k),
                                     &temp.coeffRef(0));
      dst.row(k).swap(dst.row(m_rows_transpositions.coeff(k)));
    }
  }
  namespace internal {
    template <typename DstXprType, typename MatrixType>
    struct Assignment<DstXprType,
                      Inverse<FullPivHouseholderQR<MatrixType>>,
                      internal::assign_op<typename DstXprType::Scalar, typename FullPivHouseholderQR<MatrixType>::Scalar>,
                      Dense2Dense> {
      typedef FullPivHouseholderQR<MatrixType> QrType;
      typedef Inverse<QrType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename QrType::Scalar>&) {
        dst = src.nestedExpression().solve(MatrixType::Identity(src.rows(), src.cols()));
      }
    };
    template <typename MatrixType>
    struct FullPivHouseholderQRMatrixQReturnType
        : public ReturnByValue<FullPivHouseholderQRMatrixQReturnType<MatrixType>> {
    public:
      typedef typename FullPivHouseholderQR<MatrixType>::IntDiagSizeVectorType IntDiagSizeVectorType;
      typedef typename internal::plain_diag_type<MatrixType>::type HCoeffsType;
      typedef Matrix<typename MatrixType::Scalar,
                     1,
                     MatrixType::RowsAtCompileTime,
                     RowMajor,
                     1,
                     MatrixType::MaxRowsAtCompileTime>
          WorkVectorType;
      FullPivHouseholderQRMatrixQReturnType(const MatrixType& qr,
                                            const HCoeffsType& hCoeffs,
                                            const IntDiagSizeVectorType& rowsTranspositions)
          : m_qr(qr), m_hCoeffs(hCoeffs), m_rowsTranspositions(rowsTranspositions) {}
      template <typename ResultType>
      void evalTo(ResultType& result) const {
        const Index rows = m_qr.rows();
        WorkVectorType workspace(rows);
        evalTo(result, workspace);
      }
      template <typename ResultType>
      void evalTo(ResultType& result, WorkVectorType& workspace) const {
        using numext::conj;
        const Index rows = m_qr.rows();
        const Index cols = m_qr.cols();
        const Index size = (std::min)(rows, cols);
        workspace.resize(rows);
        result.setIdentity(rows, rows);
        for (Index k = size - 1; k >= 0; k--) {
          result.block(k, k, rows - k, rows - k)
              .applyHouseholderOnTheLeft(
                  m_qr.col(k).tail(rows - k - 1), conj(m_hCoeffs.coeff(k)), &workspace.coeffRef(k));
          result.row(k).swap(result.row(m_rowsTranspositions.coeff(k)));
        }
      }
      Index rows() const { return m_qr.rows(); }
      Index cols() const { return m_qr.rows(); }

    protected:
      typename MatrixType::Nested m_qr;
      typename HCoeffsType::Nested m_hCoeffs;
      typename IntDiagSizeVectorType::Nested m_rowsTranspositions;
    };
  }  // namespace internal
  template <typename MatrixType>
  inline typename FullPivHouseholderQR<MatrixType>::MatrixQReturnType FullPivHouseholderQR<MatrixType>::matrixQ() const {
    (static_cast<bool>(m_isInitialized && "FullPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"FullPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/FullPivHouseholderQR.h",
                         718,
                         __extension__ __PRETTY_FUNCTION__));
    return MatrixQReturnType(m_qr, m_hCoeffs, m_rows_transpositions);
  }
  template <typename Derived>
  const FullPivHouseholderQR<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::fullPivHouseholderQr()
      const {
    return FullPivHouseholderQR<PlainObject>(eval());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<ColPivHouseholderQR<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
  }  // namespace internal
  template <typename MatrixType_>
  class ColPivHouseholderQR : public SolverBase<ColPivHouseholderQR<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<ColPivHouseholderQR> Base;
    friend class SolverBase<ColPivHouseholderQR>;
    typedef typename Eigen::internal::traits<ColPivHouseholderQR>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<ColPivHouseholderQR>::type Nested;
    typedef typename Eigen::internal::traits<ColPivHouseholderQR>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<ColPivHouseholderQR>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<ColPivHouseholderQR>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<ColPivHouseholderQR>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<ColPivHouseholderQR>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename internal::plain_diag_type<MatrixType>::type HCoeffsType;
    typedef PermutationMatrix<ColsAtCompileTime, MaxColsAtCompileTime> PermutationType;
    typedef typename internal::plain_row_type<MatrixType, Index>::type IntRowVectorType;
    typedef typename internal::plain_row_type<MatrixType>::type RowVectorType;
    typedef typename internal::plain_row_type<MatrixType, RealScalar>::type RealRowVectorType;
    typedef HouseholderSequence<MatrixType, internal::remove_all_t<typename HCoeffsType::ConjugateReturnType>>
        HouseholderSequenceType;
    typedef typename MatrixType::PlainObject PlainObject;

  private:
    typedef typename PermutationType::StorageIndex PermIndexType;

  public:
    ColPivHouseholderQR()
        : m_qr(),
          m_hCoeffs(),
          m_colsPermutation(),
          m_colsTranspositions(),
          m_temp(),
          m_colNormsUpdated(),
          m_colNormsDirect(),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {}
    ColPivHouseholderQR(Index rows, Index cols)
        : m_qr(rows, cols),
          m_hCoeffs((std::min)(rows, cols)),
          m_colsPermutation(PermIndexType(cols)),
          m_colsTranspositions(cols),
          m_temp(cols),
          m_colNormsUpdated(cols),
          m_colNormsDirect(cols),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {}
    template <typename InputType>
    explicit ColPivHouseholderQR(const EigenBase<InputType>& matrix)
        : m_qr(matrix.rows(), matrix.cols()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_colsPermutation(PermIndexType(matrix.cols())),
          m_colsTranspositions(matrix.cols()),
          m_temp(matrix.cols()),
          m_colNormsUpdated(matrix.cols()),
          m_colNormsDirect(matrix.cols()),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit ColPivHouseholderQR(EigenBase<InputType>& matrix)
        : m_qr(matrix.derived()),
          m_hCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_colsPermutation(PermIndexType(matrix.cols())),
          m_colsTranspositions(matrix.cols()),
          m_temp(matrix.cols()),
          m_colNormsUpdated(matrix.cols()),
          m_colNormsDirect(matrix.cols()),
          m_isInitialized(false),
          m_usePrescribedThreshold(false) {
      computeInPlace();
    }
    HouseholderSequenceType householderQ() const;
    HouseholderSequenceType matrixQ() const { return householderQ(); }
    const MatrixType& matrixQR() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           201,
                           __extension__ __PRETTY_FUNCTION__));
      return m_qr;
    }
    const MatrixType& matrixR() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           217,
                           __extension__ __PRETTY_FUNCTION__));
      return m_qr;
    }
    template <typename InputType>
    ColPivHouseholderQR& compute(const EigenBase<InputType>& matrix);
    const PermutationType& colsPermutation() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           229,
                           __extension__ __PRETTY_FUNCTION__));
      return m_colsPermutation;
    }
    typename MatrixType::Scalar determinant() const;
    typename MatrixType::RealScalar absDeterminant() const;
    typename MatrixType::RealScalar logAbsDeterminant() const;
    inline Index rank() const {
      using std::abs;
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           290,
                           __extension__ __PRETTY_FUNCTION__));
      RealScalar premultiplied_threshold = abs(m_maxpivot) * threshold();
      Index result = 0;
      for (Index i = 0; i < m_nonzero_pivots; ++i)
        result += (abs(m_qr.coeff(i, i)) > premultiplied_threshold);
      return result;
    }
    inline Index dimensionOfKernel() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           307,
                           __extension__ __PRETTY_FUNCTION__));
      return cols() - rank();
    }
    inline bool isInjective() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           321,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == cols();
    }
    inline bool isSurjective() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           335,
                           __extension__ __PRETTY_FUNCTION__));
      return rank() == rows();
    }
    inline bool isInvertible() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           348,
                           __extension__ __PRETTY_FUNCTION__));
      return isInjective() && isSurjective();
    }
    inline const Inverse<ColPivHouseholderQR> inverse() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           360,
                           __extension__ __PRETTY_FUNCTION__));
      return Inverse<ColPivHouseholderQR>(*this);
    }
    inline Index rows() const { return m_qr.rows(); }
    inline Index cols() const { return m_qr.cols(); }
    const HCoeffsType& hCoeffs() const { return m_hCoeffs; }
    ColPivHouseholderQR& setThreshold(const RealScalar& threshold) {
      m_usePrescribedThreshold = true;
      m_prescribedThreshold = threshold;
      return *this;
    }
    ColPivHouseholderQR& setThreshold(Default_t) {
      m_usePrescribedThreshold = false;
      return *this;
    }
    RealScalar threshold() const {
      (static_cast<bool>(m_isInitialized || m_usePrescribedThreshold)
           ? void(0)
           : __assert_fail("m_isInitialized || m_usePrescribedThreshold",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           423,
                           __extension__ __PRETTY_FUNCTION__));
      return m_usePrescribedThreshold ? m_prescribedThreshold
                                      : NumTraits<Scalar>::epsilon() * RealScalar(m_qr.diagonalSize());
    }
    inline Index nonzeroPivots() const {
      (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           440,
                           __extension__ __PRETTY_FUNCTION__));
      return m_nonzero_pivots;
    }
    RealScalar maxPivot() const { return m_maxpivot; }
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "Decomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"Decomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/ColPivHouseholderQR.h",
                           459,
                           __extension__ __PRETTY_FUNCTION__));
      return Success;
    }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    friend class CompleteOrthogonalDecomposition<MatrixType>;
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void computeInPlace();
    MatrixType m_qr;
    HCoeffsType m_hCoeffs;
    PermutationType m_colsPermutation;
    IntRowVectorType m_colsTranspositions;
    RowVectorType m_temp;
    RealRowVectorType m_colNormsUpdated;
    RealRowVectorType m_colNormsDirect;
    bool m_isInitialized, m_usePrescribedThreshold;
    RealScalar m_prescribedThreshold, m_maxpivot;
    Index m_nonzero_pivots;
    Index m_det_p;
  };
  template <typename MatrixType>
  typename MatrixType::Scalar ColPivHouseholderQR<MatrixType>::determinant() const {
    (static_cast<bool>(m_isInitialized && "HouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"HouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         498,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         499,
                         __extension__ __PRETTY_FUNCTION__));
    Scalar detQ;
    internal::householder_determinant<HCoeffsType, Scalar, NumTraits<Scalar>::IsComplex>::run(m_hCoeffs, detQ);
    return m_qr.diagonal().prod() * detQ * Scalar(m_det_p);
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar ColPivHouseholderQR<MatrixType>::absDeterminant() const {
    using std::abs;
    (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         510,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         511,
                         __extension__ __PRETTY_FUNCTION__));
    return abs(m_qr.diagonal().prod());
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar ColPivHouseholderQR<MatrixType>::logAbsDeterminant() const {
    (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         519,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_qr.rows() == m_qr.cols() && "You can't take the determinant of a non-square matrix!")
         ? void(0)
         : __assert_fail("m_qr.rows() == m_qr.cols() && \"You can't take the determinant of a non-square matrix!\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         520,
                         __extension__ __PRETTY_FUNCTION__));
    return m_qr.diagonal().cwiseAbs().array().log().sum();
  }
  template <typename MatrixType>
  template <typename InputType>
  ColPivHouseholderQR<MatrixType>& ColPivHouseholderQR<MatrixType>::compute(const EigenBase<InputType>& matrix) {
    m_qr = matrix.derived();
    computeInPlace();
    return *this;
  }
  template <typename MatrixType>
  void ColPivHouseholderQR<MatrixType>::computeInPlace() {
    (static_cast<bool>(m_qr.cols() <= NumTraits<int>::highest())
         ? void(0)
         : __assert_fail("m_qr.cols()<=NumTraits<int>::highest()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         545,
                         __extension__ __PRETTY_FUNCTION__));
    using std::abs;
    Index rows = m_qr.rows();
    Index cols = m_qr.cols();
    Index size = m_qr.diagonalSize();
    m_hCoeffs.resize(size);
    m_temp.resize(cols);
    m_colsTranspositions.resize(m_qr.cols());
    Index number_of_transpositions = 0;
    m_colNormsUpdated.resize(cols);
    m_colNormsDirect.resize(cols);
    for (Index k = 0; k < cols; ++k) {
      m_colNormsDirect.coeffRef(k) = m_qr.col(k).norm();
      m_colNormsUpdated.coeffRef(k) = m_colNormsDirect.coeffRef(k);
    }
    RealScalar threshold_helper =
        numext::abs2<RealScalar>(m_colNormsUpdated.maxCoeff() * NumTraits<RealScalar>::epsilon()) / RealScalar(rows);
    RealScalar norm_downdate_threshold = numext::sqrt(NumTraits<RealScalar>::epsilon());
    m_nonzero_pivots = size;
    m_maxpivot = RealScalar(0);
    for (Index k = 0; k < size; ++k) {
      Index biggest_col_index;
      RealScalar biggest_col_sq_norm = numext::abs2(m_colNormsUpdated.tail(cols - k).maxCoeff(&biggest_col_index));
      biggest_col_index += k;
      if (m_nonzero_pivots == size && biggest_col_sq_norm < threshold_helper * RealScalar(rows - k))
        m_nonzero_pivots = k;
      m_colsTranspositions.coeffRef(k) = biggest_col_index;
      if (k != biggest_col_index) {
        m_qr.col(k).swap(m_qr.col(biggest_col_index));
        numext::swap(m_colNormsUpdated.coeffRef(k), m_colNormsUpdated.coeffRef(biggest_col_index));
        numext::swap(m_colNormsDirect.coeffRef(k), m_colNormsDirect.coeffRef(biggest_col_index));
        ++number_of_transpositions;
      }
      RealScalar beta;
      m_qr.col(k).tail(rows - k).makeHouseholderInPlace(m_hCoeffs.coeffRef(k), beta);
      m_qr.coeffRef(k, k) = beta;
      if (abs(beta) > m_maxpivot)
        m_maxpivot = abs(beta);
      m_qr.bottomRightCorner(rows - k, cols - k - 1)
          .applyHouseholderOnTheLeft(m_qr.col(k).tail(rows - k - 1), m_hCoeffs.coeffRef(k), &m_temp.coeffRef(k + 1));
      for (Index j = k + 1; j < cols; ++j) {
        if (!numext::is_exactly_zero(m_colNormsUpdated.coeffRef(j))) {
          RealScalar temp = abs(m_qr.coeffRef(k, j)) / m_colNormsUpdated.coeffRef(j);
          temp = (RealScalar(1) + temp) * (RealScalar(1) - temp);
          temp = temp < RealScalar(0) ? RealScalar(0) : temp;
          RealScalar temp2 =
              temp * numext::abs2<RealScalar>(m_colNormsUpdated.coeffRef(j) / m_colNormsDirect.coeffRef(j));
          if (temp2 <= norm_downdate_threshold) {
            m_colNormsDirect.coeffRef(j) = m_qr.col(j).tail(rows - k - 1).norm();
            m_colNormsUpdated.coeffRef(j) = m_colNormsDirect.coeffRef(j);
          } else {
            m_colNormsUpdated.coeffRef(j) *= numext::sqrt(temp);
          }
        }
      }
    }
    m_colsPermutation.setIdentity(PermIndexType(cols));
    for (PermIndexType k = 0; k < size; ++k)
      m_colsPermutation.applyTranspositionOnTheRight(k, PermIndexType(m_colsTranspositions.coeff(k)));
    m_det_p = (number_of_transpositions % 2) ? -1 : 1;
    m_isInitialized = true;
  }
  template <typename MatrixType_>
  template <typename RhsType, typename DstType>
  void ColPivHouseholderQR<MatrixType_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    const Index nonzero_pivots = nonzeroPivots();
    if (nonzero_pivots == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(rhs);
    c.applyOnTheLeft(householderQ().setLength(nonzero_pivots).adjoint());
    m_qr.topLeftCorner(nonzero_pivots, nonzero_pivots)
        .template triangularView<Upper>()
        .solveInPlace(c.topRows(nonzero_pivots));
    for (Index i = 0; i < nonzero_pivots; ++i)
      dst.row(m_colsPermutation.indices().coeff(i)) = c.row(i);
    for (Index i = nonzero_pivots; i < cols(); ++i)
      dst.row(m_colsPermutation.indices().coeff(i)).setZero();
  }
  template <typename MatrixType_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void ColPivHouseholderQR<MatrixType_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    const Index nonzero_pivots = nonzeroPivots();
    if (nonzero_pivots == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(m_colsPermutation.transpose() * rhs);
    m_qr.topLeftCorner(nonzero_pivots, nonzero_pivots)
        .template triangularView<Upper>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(nonzero_pivots));
    dst.topRows(nonzero_pivots) = c.topRows(nonzero_pivots);
    dst.bottomRows(rows() - nonzero_pivots).setZero();
    dst.applyOnTheLeft(householderQ().setLength(nonzero_pivots).template conjugateIf<!Conjugate>());
  }
  namespace internal {
    template <typename DstXprType, typename MatrixType>
    struct Assignment<DstXprType,
                      Inverse<ColPivHouseholderQR<MatrixType>>,
                      internal::assign_op<typename DstXprType::Scalar, typename ColPivHouseholderQR<MatrixType>::Scalar>,
                      Dense2Dense> {
      typedef ColPivHouseholderQR<MatrixType> QrType;
      typedef Inverse<QrType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename QrType::Scalar>&) {
        dst = src.nestedExpression().solve(MatrixType::Identity(src.rows(), src.cols()));
      }
    };
  }  // namespace internal
  template <typename MatrixType>
  typename ColPivHouseholderQR<MatrixType>::HouseholderSequenceType ColPivHouseholderQR<MatrixType>::householderQ()
      const {
    (static_cast<bool>(m_isInitialized && "ColPivHouseholderQR is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"ColPivHouseholderQR is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/ColPivHouseholderQR.h",
                         718,
                         __extension__ __PRETTY_FUNCTION__));
    return HouseholderSequenceType(m_qr, m_hCoeffs.conjugate());
  }
  template <typename Derived>
  const ColPivHouseholderQR<typename MatrixBase<Derived>::PlainObject> MatrixBase<Derived>::colPivHouseholderQr() const {
    return ColPivHouseholderQR<PlainObject>(eval());
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    struct traits<CompleteOrthogonalDecomposition<MatrixType_>> : traits<MatrixType_> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
  }  // namespace internal
  template <typename MatrixType_>
  class CompleteOrthogonalDecomposition : public SolverBase<CompleteOrthogonalDecomposition<MatrixType_>> {
  public:
    typedef MatrixType_ MatrixType;
    typedef SolverBase<CompleteOrthogonalDecomposition> Base;
    template <typename Derived>
    friend struct internal::solve_assertion;
    typedef typename Eigen::internal::traits<CompleteOrthogonalDecomposition>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<CompleteOrthogonalDecomposition>::type Nested;
    typedef typename Eigen::internal::traits<CompleteOrthogonalDecomposition>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<CompleteOrthogonalDecomposition>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<CompleteOrthogonalDecomposition>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<CompleteOrthogonalDecomposition>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<CompleteOrthogonalDecomposition>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    enum {
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename internal::plain_diag_type<MatrixType>::type HCoeffsType;
    typedef PermutationMatrix<ColsAtCompileTime, MaxColsAtCompileTime> PermutationType;
    typedef typename internal::plain_row_type<MatrixType, Index>::type IntRowVectorType;
    typedef typename internal::plain_row_type<MatrixType>::type RowVectorType;
    typedef typename internal::plain_row_type<MatrixType, RealScalar>::type RealRowVectorType;
    typedef HouseholderSequence<MatrixType, internal::remove_all_t<typename HCoeffsType::ConjugateReturnType>>
        HouseholderSequenceType;
    typedef typename MatrixType::PlainObject PlainObject;

  private:
    typedef typename PermutationType::Index PermIndexType;

  public:
    CompleteOrthogonalDecomposition() : m_cpqr(), m_zCoeffs(), m_temp() {}
    CompleteOrthogonalDecomposition(Index rows, Index cols)
        : m_cpqr(rows, cols), m_zCoeffs((std::min)(rows, cols)), m_temp(cols) {}
    template <typename InputType>
    explicit CompleteOrthogonalDecomposition(const EigenBase<InputType>& matrix)
        : m_cpqr(matrix.rows(), matrix.cols()),
          m_zCoeffs((std::min)(matrix.rows(), matrix.cols())),
          m_temp(matrix.cols()) {
      compute(matrix.derived());
    }
    template <typename InputType>
    explicit CompleteOrthogonalDecomposition(EigenBase<InputType>& matrix)
        : m_cpqr(matrix.derived()), m_zCoeffs((std::min)(matrix.rows(), matrix.cols())), m_temp(matrix.cols()) {
      computeInPlace();
    }
    HouseholderSequenceType householderQ(void) const;
    HouseholderSequenceType matrixQ(void) const { return m_cpqr.householderQ(); }
    MatrixType matrixZ() const {
      MatrixType Z = MatrixType::Identity(m_cpqr.cols(), m_cpqr.cols());
      applyZOnTheLeftInPlace<false>(Z);
      return Z;
    }
    const MatrixType& matrixQTZ() const { return m_cpqr.matrixQR(); }
    const MatrixType& matrixT() const { return m_cpqr.matrixQR(); }
    template <typename InputType>
    CompleteOrthogonalDecomposition& compute(const EigenBase<InputType>& matrix) {
      m_cpqr.compute(matrix);
      computeInPlace();
      return *this;
    }
    const PermutationType& colsPermutation() const { return m_cpqr.colsPermutation(); }
    typename MatrixType::Scalar determinant() const;
    typename MatrixType::RealScalar absDeterminant() const;
    typename MatrixType::RealScalar logAbsDeterminant() const;
    inline Index rank() const { return m_cpqr.rank(); }
    inline Index dimensionOfKernel() const { return m_cpqr.dimensionOfKernel(); }
    inline bool isInjective() const { return m_cpqr.isInjective(); }
    inline bool isSurjective() const { return m_cpqr.isSurjective(); }
    inline bool isInvertible() const { return m_cpqr.isInvertible(); }
    inline const Inverse<CompleteOrthogonalDecomposition> pseudoInverse() const {
      (static_cast<bool>(m_cpqr.m_isInitialized && "CompleteOrthogonalDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_cpqr.m_isInitialized && \"CompleteOrthogonalDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/CompleteOrthogonalDecomposition.h",
                           297,
                           __extension__ __PRETTY_FUNCTION__));
      return Inverse<CompleteOrthogonalDecomposition>(*this);
    }
    inline Index rows() const { return m_cpqr.rows(); }
    inline Index cols() const { return m_cpqr.cols(); }
    inline const HCoeffsType& hCoeffs() const { return m_cpqr.hCoeffs(); }
    const HCoeffsType& zCoeffs() const { return m_zCoeffs; }
    CompleteOrthogonalDecomposition& setThreshold(const RealScalar& threshold) {
      m_cpqr.setThreshold(threshold);
      return *this;
    }
    CompleteOrthogonalDecomposition& setThreshold(Default_t) {
      m_cpqr.setThreshold(Default);
      return *this;
    }
    RealScalar threshold() const { return m_cpqr.threshold(); }
    inline Index nonzeroPivots() const { return m_cpqr.nonzeroPivots(); }
    inline RealScalar maxPivot() const { return m_cpqr.maxPivot(); }
    ComputationInfo info() const {
      (static_cast<bool>(m_cpqr.m_isInitialized && "Decomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_cpqr.m_isInitialized && \"Decomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/CompleteOrthogonalDecomposition.h",
                           384,
                           __extension__ __PRETTY_FUNCTION__));
      return Success;
    }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    template <bool Transpose_, typename Rhs>
    void _check_solve_assertion(const Rhs& b) const {
      ;
      (static_cast<bool>(m_cpqr.m_isInitialized && "CompleteOrthogonalDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_cpqr.m_isInitialized && \"CompleteOrthogonalDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/QR/CompleteOrthogonalDecomposition.h",
                           402,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(
           (Transpose_ ? derived().cols() : derived().rows()) == b.rows() &&
           "CompleteOrthogonalDecomposition::solve(): invalid number of rows of the right hand side matrix b")
           ? void(0)
           : __assert_fail(
                 "(Transpose_?derived().cols():derived().rows())==b.rows() && "
                 "\"CompleteOrthogonalDecomposition::solve(): invalid number of rows of the right hand side matrix b\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "QR/CompleteOrthogonalDecomposition.h",
                 403,
                 __extension__ __PRETTY_FUNCTION__));
    }
    void computeInPlace();
    template <bool Conjugate, typename Rhs>
    void applyZOnTheLeftInPlace(Rhs& rhs) const;
    template <typename Rhs>
    void applyZAdjointOnTheLeftInPlace(Rhs& rhs) const;
    ColPivHouseholderQR<MatrixType> m_cpqr;
    HCoeffsType m_zCoeffs;
    RowVectorType m_temp;
  };
  template <typename MatrixType>
  typename MatrixType::Scalar CompleteOrthogonalDecomposition<MatrixType>::determinant() const {
    return m_cpqr.determinant();
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar CompleteOrthogonalDecomposition<MatrixType>::absDeterminant() const {
    return m_cpqr.absDeterminant();
  }
  template <typename MatrixType>
  typename MatrixType::RealScalar CompleteOrthogonalDecomposition<MatrixType>::logAbsDeterminant() const {
    return m_cpqr.logAbsDeterminant();
  }
  template <typename MatrixType>
  void CompleteOrthogonalDecomposition<MatrixType>::computeInPlace() {
    (static_cast<bool>(m_cpqr.cols() <= NumTraits<int>::highest())
         ? void(0)
         : __assert_fail("m_cpqr.cols() <= NumTraits<int>::highest()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/QR/CompleteOrthogonalDecomposition.h",
                         454,
                         __extension__ __PRETTY_FUNCTION__));
    const Index rank = m_cpqr.rank();
    const Index cols = m_cpqr.cols();
    const Index rows = m_cpqr.rows();
    m_zCoeffs.resize((std::min)(rows, cols));
    m_temp.resize(cols);
    if (rank < cols) {
      for (Index k = rank - 1; k >= 0; --k) {
        if (k != rank - 1) {
          m_cpqr.m_qr.col(k).head(k + 1).swap(m_cpqr.m_qr.col(rank - 1).head(k + 1));
        }
        RealScalar beta;
        m_cpqr.m_qr.row(k).tail(cols - rank + 1).makeHouseholderInPlace(m_zCoeffs(k), beta);
        m_cpqr.m_qr(k, rank - 1) = beta;
        if (k > 0) {
          m_cpqr.m_qr.topRightCorner(k, cols - rank + 1)
              .applyHouseholderOnTheRight(m_cpqr.m_qr.row(k).tail(cols - rank).adjoint(), m_zCoeffs(k), &m_temp(0));
        }
        if (k != rank - 1) {
          m_cpqr.m_qr.col(k).head(k + 1).swap(m_cpqr.m_qr.col(rank - 1).head(k + 1));
        }
      }
    }
  }
  template <typename MatrixType>
  template <bool Conjugate, typename Rhs>
  void CompleteOrthogonalDecomposition<MatrixType>::applyZOnTheLeftInPlace(Rhs& rhs) const {
    const Index cols = this->cols();
    const Index nrhs = rhs.cols();
    const Index rank = this->rank();
    Matrix<typename Rhs::Scalar, Dynamic, 1> temp((std::max)(cols, nrhs));
    for (Index k = rank - 1; k >= 0; --k) {
      if (k != rank - 1) {
        rhs.row(k).swap(rhs.row(rank - 1));
      }
      rhs.middleRows(rank - 1, cols - rank + 1)
          .applyHouseholderOnTheLeft(
              matrixQTZ().row(k).tail(cols - rank).transpose().template conjugateIf<!Conjugate>(),
              zCoeffs().template conjugateIf<Conjugate>()(k),
              &temp(0));
      if (k != rank - 1) {
        rhs.row(k).swap(rhs.row(rank - 1));
      }
    }
  }
  template <typename MatrixType>
  template <typename Rhs>
  void CompleteOrthogonalDecomposition<MatrixType>::applyZAdjointOnTheLeftInPlace(Rhs& rhs) const {
    const Index cols = this->cols();
    const Index nrhs = rhs.cols();
    const Index rank = this->rank();
    Matrix<typename Rhs::Scalar, Dynamic, 1> temp((std::max)(cols, nrhs));
    for (Index k = 0; k < rank; ++k) {
      if (k != rank - 1) {
        rhs.row(k).swap(rhs.row(rank - 1));
      }
      rhs.middleRows(rank - 1, cols - rank + 1)
          .applyHouseholderOnTheLeft(matrixQTZ().row(k).tail(cols - rank).adjoint(), zCoeffs()(k), &temp(0));
      if (k != rank - 1) {
        rhs.row(k).swap(rhs.row(rank - 1));
      }
    }
  }
  template <typename MatrixType_>
  template <typename RhsType, typename DstType>
  void CompleteOrthogonalDecomposition<MatrixType_>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    const Index rank = this->rank();
    if (rank == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(rhs);
    c.applyOnTheLeft(matrixQ().setLength(rank).adjoint());
    dst.topRows(rank) = matrixT().topLeftCorner(rank, rank).template triangularView<Upper>().solve(c.topRows(rank));
    const Index cols = this->cols();
    if (rank < cols) {
      dst.bottomRows(cols - rank).setZero();
      applyZAdjointOnTheLeftInPlace(dst);
    }
    dst = colsPermutation() * dst;
  }
  template <typename MatrixType_>
  template <bool Conjugate, typename RhsType, typename DstType>
  void CompleteOrthogonalDecomposition<MatrixType_>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    const Index rank = this->rank();
    if (rank == 0) {
      dst.setZero();
      return;
    }
    typename RhsType::PlainObject c(colsPermutation().transpose() * rhs);
    if (rank < cols()) {
      applyZOnTheLeftInPlace<!Conjugate>(c);
    }
    matrixT()
        .topLeftCorner(rank, rank)
        .template triangularView<Upper>()
        .transpose()
        .template conjugateIf<Conjugate>()
        .solveInPlace(c.topRows(rank));
    dst.topRows(rank) = c.topRows(rank);
    dst.bottomRows(rows() - rank).setZero();
    dst.applyOnTheLeft(householderQ().setLength(rank).template conjugateIf<!Conjugate>());
  }
  namespace internal {
    template <typename MatrixType>
    struct traits<Inverse<CompleteOrthogonalDecomposition<MatrixType>>>
        : traits<typename Transpose<typename MatrixType::PlainObject>::PlainObject> {
      enum { Flags = 0 };
    };
    template <typename DstXprType, typename MatrixType>
    struct Assignment<
        DstXprType,
        Inverse<CompleteOrthogonalDecomposition<MatrixType>>,
        internal::assign_op<typename DstXprType::Scalar, typename CompleteOrthogonalDecomposition<MatrixType>::Scalar>,
        Dense2Dense> {
      typedef CompleteOrthogonalDecomposition<MatrixType> CodType;
      typedef Inverse<CodType> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<typename DstXprType::Scalar, typename CodType::Scalar>&) {
        typedef Matrix<typename CodType::Scalar,
                       CodType::RowsAtCompileTime,
                       CodType::RowsAtCompileTime,
                       0,
                       CodType::MaxRowsAtCompileTime,
                       CodType::MaxRowsAtCompileTime>
            IdentityMatrixType;
        dst = src.nestedExpression().solve(IdentityMatrixType::Identity(src.cols(), src.cols()));
      }
    };
  }  // namespace internal
  template <typename MatrixType>
  typename CompleteOrthogonalDecomposition<MatrixType>::HouseholderSequenceType
  CompleteOrthogonalDecomposition<MatrixType>::householderQ() const {
    return m_cpqr.householderQ();
  }
  template <typename Derived>
  const CompleteOrthogonalDecomposition<typename MatrixBase<Derived>::PlainObject>
  MatrixBase<Derived>::completeOrthogonalDecomposition() const {
    return CompleteOrthogonalDecomposition<PlainObject>(eval());
  }
}  // namespace Eigen
#pragma clang diagnostic pop
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <typename MatrixType, typename RealScalar, typename Index>
    void real_2x2_jacobi_svd(const MatrixType& matrix,
                             Index p,
                             Index q,
                             JacobiRotation<RealScalar>* j_left,
                             JacobiRotation<RealScalar>* j_right) {
      using std::abs;
      using std::sqrt;
      Matrix<RealScalar, 2, 2> m;
      m << numext::real(matrix.coeff(p, p)), numext::real(matrix.coeff(p, q)), numext::real(matrix.coeff(q, p)),
          numext::real(matrix.coeff(q, q));
      JacobiRotation<RealScalar> rot1;
      RealScalar t = m.coeff(0, 0) + m.coeff(1, 1);
      RealScalar d = m.coeff(1, 0) - m.coeff(0, 1);
      if (abs(d) < (std::numeric_limits<RealScalar>::min)()) {
        rot1.s() = RealScalar(0);
        rot1.c() = RealScalar(1);
      } else {
        RealScalar u = t / d;
        RealScalar tmp = sqrt(RealScalar(1) + numext::abs2(u));
        rot1.s() = RealScalar(1) / tmp;
        rot1.c() = u / tmp;
      }
      m.applyOnTheLeft(0, 1, rot1);
      j_right->makeJacobi(m, 0, 1);
      *j_left = rot1 * j_right->transpose();
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType_>
    class UpperBidiagonalization {
    public:
      typedef MatrixType_ MatrixType;
      enum {
        RowsAtCompileTime = MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = MatrixType::ColsAtCompileTime,
        ColsAtCompileTimeMinusOne = internal::decrement_size<ColsAtCompileTime>::ret
      };
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      typedef Eigen::Index Index;
      typedef Matrix<Scalar, 1, ColsAtCompileTime> RowVectorType;
      typedef Matrix<Scalar, RowsAtCompileTime, 1> ColVectorType;
      typedef BandMatrix<RealScalar, ColsAtCompileTime, ColsAtCompileTime, 1, 0, RowMajor> BidiagonalType;
      typedef Matrix<Scalar, ColsAtCompileTime, 1> DiagVectorType;
      typedef Matrix<Scalar, ColsAtCompileTimeMinusOne, 1> SuperDiagVectorType;
      typedef HouseholderSequence<
          const MatrixType,
          const internal::remove_all_t<typename Diagonal<const MatrixType, 0>::ConjugateReturnType>>
          HouseholderUSequenceType;
      typedef HouseholderSequence<const internal::remove_all_t<typename MatrixType::ConjugateReturnType>,
                                  Diagonal<const MatrixType, 1>,
                                  OnTheRight>
          HouseholderVSequenceType;
      UpperBidiagonalization() : m_householder(), m_bidiagonal(0, 0), m_isInitialized(false) {}
      explicit UpperBidiagonalization(const MatrixType& matrix)
          : m_householder(matrix.rows(), matrix.cols()),
            m_bidiagonal(matrix.cols(), matrix.cols()),
            m_isInitialized(false) {
        compute(matrix);
      }
      UpperBidiagonalization(Index rows, Index cols)
          : m_householder(rows, cols), m_bidiagonal(cols, cols), m_isInitialized(false) {}
      UpperBidiagonalization& compute(const MatrixType& matrix);
      UpperBidiagonalization& computeUnblocked(const MatrixType& matrix);
      const MatrixType& householder() const { return m_householder; }
      const BidiagonalType& bidiagonal() const { return m_bidiagonal; }
      const HouseholderUSequenceType householderU() const {
        (static_cast<bool>(m_isInitialized && "UpperBidiagonalization is not initialized.")
             ? void(0)
             : __assert_fail("m_isInitialized && \"UpperBidiagonalization is not initialized.\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/SVD/UpperBidiagonalization.h",
                             80,
                             __extension__ __PRETTY_FUNCTION__));
        return HouseholderUSequenceType(m_householder, m_householder.diagonal().conjugate());
      }
      const HouseholderVSequenceType householderV() {
        (static_cast<bool>(m_isInitialized && "UpperBidiagonalization is not initialized.")
             ? void(0)
             : __assert_fail("m_isInitialized && \"UpperBidiagonalization is not initialized.\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/SVD/UpperBidiagonalization.h",
                             86,
                             __extension__ __PRETTY_FUNCTION__));
        return HouseholderVSequenceType(m_householder.conjugate(), m_householder.const_derived().template diagonal<1>())
            .setLength(m_householder.cols() - 1)
            .setShift(1);
      }

    protected:
      MatrixType m_householder;
      BidiagonalType m_bidiagonal;
      bool m_isInitialized;
    };
    template <typename MatrixType>
    void upperbidiagonalization_inplace_unblocked(MatrixType& mat,
                                                  typename MatrixType::RealScalar* diagonal,
                                                  typename MatrixType::RealScalar* upper_diagonal,
                                                  typename MatrixType::Scalar* tempData = 0) {
      typedef typename MatrixType::Scalar Scalar;
      Index rows = mat.rows();
      Index cols = mat.cols();
      typedef Matrix<Scalar, Dynamic, 1, ColMajor, MatrixType::MaxRowsAtCompileTime, 1> TempType;
      TempType tempVector;
      if (tempData == 0) {
        tempVector.resize(rows);
        tempData = tempVector.data();
      }
      for (Index k = 0;; ++k) {
        Index remainingRows = rows - k;
        Index remainingCols = cols - k - 1;
        mat.col(k).tail(remainingRows).makeHouseholderInPlace(mat.coeffRef(k, k), diagonal[k]);
        mat.bottomRightCorner(remainingRows, remainingCols)
            .applyHouseholderOnTheLeft(mat.col(k).tail(remainingRows - 1), mat.coeff(k, k), tempData);
        if (k == cols - 1)
          break;
        mat.row(k).tail(remainingCols).makeHouseholderInPlace(mat.coeffRef(k, k + 1), upper_diagonal[k]);
        mat.bottomRightCorner(remainingRows - 1, remainingCols)
            .applyHouseholderOnTheRight(mat.row(k).tail(remainingCols - 1).adjoint(), mat.coeff(k, k + 1), tempData);
      }
    }
    template <typename MatrixType>
    void upperbidiagonalization_blocked_helper(
        MatrixType& A,
        typename MatrixType::RealScalar* diagonal,
        typename MatrixType::RealScalar* upper_diagonal,
        Index bs,
        Ref<Matrix<typename MatrixType::Scalar, Dynamic, Dynamic, traits<MatrixType>::Flags & RowMajorBit>> X,
        Ref<Matrix<typename MatrixType::Scalar, Dynamic, Dynamic, traits<MatrixType>::Flags & RowMajorBit>> Y) {
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      typedef typename NumTraits<RealScalar>::Literal Literal;
      static constexpr int StorageOrder = (traits<MatrixType>::Flags & RowMajorBit) ? RowMajor : ColMajor;
      typedef InnerStride<StorageOrder == ColMajor ? 1 : Dynamic> ColInnerStride;
      typedef InnerStride<StorageOrder == ColMajor ? Dynamic : 1> RowInnerStride;
      typedef Ref<Matrix<Scalar, Dynamic, 1>, 0, ColInnerStride> SubColumnType;
      typedef Ref<Matrix<Scalar, 1, Dynamic>, 0, RowInnerStride> SubRowType;
      typedef Ref<Matrix<Scalar, Dynamic, Dynamic, StorageOrder>> SubMatType;
      Index brows = A.rows();
      Index bcols = A.cols();
      Scalar tau_u, tau_u_prev(0), tau_v;
      for (Index k = 0; k < bs; ++k) {
        Index remainingRows = brows - k;
        Index remainingCols = bcols - k - 1;
        SubMatType X_k1(X.block(k, 0, remainingRows, k));
        SubMatType V_k1(A.block(k, 0, remainingRows, k));
        SubColumnType v_k = A.col(k).tail(remainingRows);
        v_k -= V_k1 * Y.row(k).head(k).adjoint();
        if (k)
          v_k -= X_k1 * A.col(k).head(k);
        v_k.makeHouseholderInPlace(tau_v, diagonal[k]);
        if (k + 1 < bcols) {
          SubMatType Y_k(Y.block(k + 1, 0, remainingCols, k + 1));
          SubMatType U_k1(A.block(0, k + 1, k, remainingCols));
          A(k, k) = Scalar(1);
          {
            SubColumnType y_k(Y.col(k).tail(remainingCols));
            SubColumnType tmp(Y.col(k).head(k));
            y_k.noalias() = A.block(k, k + 1, remainingRows, remainingCols).adjoint() * v_k;
            tmp.noalias() = V_k1.adjoint() * v_k;
            y_k.noalias() -= Y_k.leftCols(k) * tmp;
            tmp.noalias() = X_k1.adjoint() * v_k;
            y_k.noalias() -= U_k1.adjoint() * tmp;
            y_k *= numext::conj(tau_v);
          }
          SubRowType u_k(A.row(k).tail(remainingCols));
          u_k = u_k.conjugate();
          {
            u_k -= Y_k * A.row(k).head(k + 1).adjoint();
            if (k)
              u_k -= U_k1.adjoint() * X.row(k).head(k).adjoint();
          }
          u_k.makeHouseholderInPlace(tau_u, upper_diagonal[k]);
          A(k, k + 1) = Scalar(1);
          {
            SubColumnType x_k(X.col(k).tail(remainingRows - 1));
            SubColumnType tmp0(X.col(k).head(k)), tmp1(X.col(k).head(k + 1));
            x_k.noalias() = A.block(k + 1, k + 1, remainingRows - 1, remainingCols) * u_k.transpose();
            tmp0.noalias() = U_k1 * u_k.transpose();
            x_k.noalias() -= X_k1.bottomRows(remainingRows - 1) * tmp0;
            tmp1.noalias() = Y_k.adjoint() * u_k.transpose();
            x_k.noalias() -= A.block(k + 1, 0, remainingRows - 1, k + 1) * tmp1;
            x_k *= numext::conj(tau_u);
            tau_u = numext::conj(tau_u);
            u_k = u_k.conjugate();
          }
          if (k > 0)
            A.coeffRef(k - 1, k) = tau_u_prev;
          tau_u_prev = tau_u;
        } else
          A.coeffRef(k - 1, k) = tau_u_prev;
        A.coeffRef(k, k) = tau_v;
      }
      if (bs < bcols)
        A.coeffRef(bs - 1, bs) = tau_u_prev;
      if (bcols > bs && brows > bs) {
        SubMatType A11(A.bottomRightCorner(brows - bs, bcols - bs));
        SubMatType A10(A.block(bs, 0, brows - bs, bs));
        SubMatType A01(A.block(0, bs, bs, bcols - bs));
        Scalar tmp = A01(bs - 1, 0);
        A01(bs - 1, 0) = Literal(1);
        A11.noalias() -= A10 * Y.topLeftCorner(bcols, bs).bottomRows(bcols - bs).adjoint();
        A11.noalias() -= X.topLeftCorner(brows, bs).bottomRows(brows - bs) * A01;
        A01(bs - 1, 0) = tmp;
      }
    }
    template <typename MatrixType, typename BidiagType>
    void upperbidiagonalization_inplace_blocked(MatrixType& A,
                                                BidiagType& bidiagonal,
                                                Index maxBlockSize = 32,
                                                typename MatrixType::Scalar* = 0) {
      typedef typename MatrixType::Scalar Scalar;
      typedef Block<MatrixType, Dynamic, Dynamic> BlockType;
      Index rows = A.rows();
      Index cols = A.cols();
      Index size = (std::min)(rows, cols);
      static constexpr int StorageOrder = (traits<MatrixType>::Flags & RowMajorBit) ? RowMajor : ColMajor;
      Matrix<Scalar, MatrixType::RowsAtCompileTime, Dynamic, StorageOrder, MatrixType::MaxRowsAtCompileTime> X(
          rows, maxBlockSize);
      Matrix<Scalar, MatrixType::ColsAtCompileTime, Dynamic, StorageOrder, MatrixType::MaxColsAtCompileTime> Y(
          cols, maxBlockSize);
      Index blockSize = (std::min)(maxBlockSize, size);
      Index k = 0;
      for (k = 0; k < size; k += blockSize) {
        Index bs = (std::min)(size - k, blockSize);
        Index brows = rows - k;
        Index bcols = cols - k;
        BlockType B = A.block(k, k, brows, bcols);
        if (k + bs == cols || bcols < 48) {
          upperbidiagonalization_inplace_unblocked(B,
                                                   &(bidiagonal.template diagonal<0>().coeffRef(k)),
                                                   &(bidiagonal.template diagonal<1>().coeffRef(k)),
                                                   X.data());
          break;
        } else {
          upperbidiagonalization_blocked_helper<BlockType>(B,
                                                           &(bidiagonal.template diagonal<0>().coeffRef(k)),
                                                           &(bidiagonal.template diagonal<1>().coeffRef(k)),
                                                           bs,
                                                           X.topLeftCorner(brows, bs),
                                                           Y.topLeftCorner(bcols, bs));
        }
      }
    }
    template <typename MatrixType_>
    UpperBidiagonalization<MatrixType_>& UpperBidiagonalization<MatrixType_>::computeUnblocked(
        const MatrixType_& matrix) {
      Index rows = matrix.rows();
      Index cols = matrix.cols();
      ;
      (static_cast<bool>(rows >= cols && "UpperBidiagonalization is only for Arices satisfying rows>=cols.")
           ? void(0)
           : __assert_fail("rows >= cols && \"UpperBidiagonalization is only for Arices satisfying rows>=cols.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/UpperBidiagonalization.h",
                           373,
                           __extension__ __PRETTY_FUNCTION__));
      m_householder = matrix;
      ColVectorType temp(rows);
      upperbidiagonalization_inplace_unblocked(m_householder,
                                               &(m_bidiagonal.template diagonal<0>().coeffRef(0)),
                                               &(m_bidiagonal.template diagonal<1>().coeffRef(0)),
                                               temp.data());
      m_isInitialized = true;
      return *this;
    }
    template <typename MatrixType_>
    UpperBidiagonalization<MatrixType_>& UpperBidiagonalization<MatrixType_>::compute(const MatrixType_& matrix) {
      Index rows = matrix.rows();
      Index cols = matrix.cols();
      ;
      ;
      (static_cast<bool>(rows >= cols && "UpperBidiagonalization is only for Arices satisfying rows>=cols.")
           ? void(0)
           : __assert_fail("rows >= cols && \"UpperBidiagonalization is only for Arices satisfying rows>=cols.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/UpperBidiagonalization.h",
                           396,
                           __extension__ __PRETTY_FUNCTION__));
      m_householder = matrix;
      upperbidiagonalization_inplace_blocked(m_householder, m_bidiagonal);
      m_isInitialized = true;
      return *this;
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    enum OptionsMasks {
      QRPreconditionerBits = NoQRPreconditioner | HouseholderQRPreconditioner | ColPivHouseholderQRPreconditioner |
                             FullPivHouseholderQRPreconditioner,
      ComputationOptionsBits = ComputeThinU | ComputeFullU | ComputeThinV | ComputeFullV
    };
    constexpr int get_qr_preconditioner(int options) { return options & QRPreconditionerBits; }
    constexpr int get_computation_options(int options) { return options & ComputationOptionsBits; }
    constexpr bool should_svd_compute_thin_u(int options) { return (options & ComputeThinU) != 0; }
    constexpr bool should_svd_compute_full_u(int options) { return (options & ComputeFullU) != 0; }
    constexpr bool should_svd_compute_thin_v(int options) { return (options & ComputeThinV) != 0; }
    constexpr bool should_svd_compute_full_v(int options) { return (options & ComputeFullV) != 0; }
    template <typename MatrixType, int Options>
    void check_svd_options_assertions(unsigned int computationOptions, Index rows, Index cols) {
      static_assert((Options & ComputationOptionsBits) == 0,
                    "\"SVDBase: Cannot request U or V using both static and runtime options, even if they match. \" "
                    "\"Requesting unitaries at runtime is DEPRECATED: \" \"Prefer requesting unitaries statically, "
                    "using the Options template parameter.\"");
      ;
      (static_cast<bool>(!(should_svd_compute_thin_u(computationOptions) && cols < rows &&
                           MatrixType::RowsAtCompileTime != Dynamic) &&
                         !(should_svd_compute_thin_v(computationOptions) && rows < cols &&
                           MatrixType::ColsAtCompileTime != Dynamic) &&
                         "SVDBase: If thin U is requested at runtime, your matrix must have more rows than columns or "
                         "a dynamic number of rows."
                         "Similarly, if thin V is requested at runtime, you matrix must have more columns than rows or "
                         "a dynamic number of columns.")
           ? void(0)
           : __assert_fail(
                 "!(should_svd_compute_thin_u(computationOptions) && cols < rows && MatrixType::RowsAtCompileTime != "
                 "Dynamic) && !(should_svd_compute_thin_v(computationOptions) && rows < cols && "
                 "MatrixType::ColsAtCompileTime != Dynamic) && \"SVDBase: If thin U is requested at runtime, your "
                 "matrix must have more rows than columns or a dynamic number of rows.\" \"Similarly, if thin V is "
                 "requested at runtime, you matrix must have more columns than rows or a dynamic number of columns.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "SVD/SVDBase.h",
                 49,
                 __extension__ __PRETTY_FUNCTION__));
      (void)computationOptions;
      (void)rows;
      (void)cols;
    }
    template <typename Derived>
    struct traits<SVDBase<Derived>> : traits<Derived> {
      typedef MatrixXpr XprKind;
      typedef SolverStorage StorageKind;
      typedef int StorageIndex;
      enum { Flags = 0 };
    };
    template <typename MatrixType, int Options_>
    struct svd_traits : traits<MatrixType> {
      static constexpr int Options = Options_;
      static constexpr bool ShouldComputeFullU = internal::should_svd_compute_full_u(Options);
      static constexpr bool ShouldComputeThinU = internal::should_svd_compute_thin_u(Options);
      static constexpr bool ShouldComputeFullV = internal::should_svd_compute_full_v(Options);
      static constexpr bool ShouldComputeThinV = internal::should_svd_compute_thin_v(Options);
      enum {
        DiagSizeAtCompileTime =
            internal::min_size_prefer_dynamic(MatrixType::RowsAtCompileTime, MatrixType::ColsAtCompileTime),
        MaxDiagSizeAtCompileTime =
            internal::min_size_prefer_dynamic(MatrixType::MaxRowsAtCompileTime, MatrixType::MaxColsAtCompileTime),
        MatrixUColsAtCompileTime = ShouldComputeThinU ? DiagSizeAtCompileTime : MatrixType::RowsAtCompileTime,
        MatrixVColsAtCompileTime = ShouldComputeThinV ? DiagSizeAtCompileTime : MatrixType::ColsAtCompileTime,
        MatrixUMaxColsAtCompileTime = ShouldComputeThinU ? MaxDiagSizeAtCompileTime : MatrixType::MaxRowsAtCompileTime,
        MatrixVMaxColsAtCompileTime = ShouldComputeThinV ? MaxDiagSizeAtCompileTime : MatrixType::MaxColsAtCompileTime
      };
    };
  }  // namespace internal
  template <typename Derived>
  class SVDBase : public SolverBase<SVDBase<Derived>> {
  public:
    template <typename Derived_>
    friend struct internal::solve_assertion;
    typedef typename internal::traits<Derived>::MatrixType MatrixType;
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<typename MatrixType::Scalar>::Real RealScalar;
    typedef typename Eigen::internal::traits<SVDBase>::StorageIndex StorageIndex;
    typedef Eigen::Index Index;
    static constexpr bool ShouldComputeFullU = internal::traits<Derived>::ShouldComputeFullU;
    static constexpr bool ShouldComputeThinU = internal::traits<Derived>::ShouldComputeThinU;
    static constexpr bool ShouldComputeFullV = internal::traits<Derived>::ShouldComputeFullV;
    static constexpr bool ShouldComputeThinV = internal::traits<Derived>::ShouldComputeThinV;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      DiagSizeAtCompileTime = internal::min_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime),
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
      MaxDiagSizeAtCompileTime = internal::min_size_prefer_fixed(MaxRowsAtCompileTime, MaxColsAtCompileTime),
      MatrixOptions = MatrixType::Options,
      MatrixUColsAtCompileTime = internal::traits<Derived>::MatrixUColsAtCompileTime,
      MatrixVColsAtCompileTime = internal::traits<Derived>::MatrixVColsAtCompileTime,
      MatrixUMaxColsAtCompileTime = internal::traits<Derived>::MatrixUMaxColsAtCompileTime,
      MatrixVMaxColsAtCompileTime = internal::traits<Derived>::MatrixVMaxColsAtCompileTime
    };
    static_assert(!(ShouldComputeFullU && ShouldComputeThinU), "\"SVDBase: Cannot request both full and thin U\"");
    static_assert(!(ShouldComputeFullV && ShouldComputeThinV), "\"SVDBase: Cannot request both full and thin V\"");
    typedef typename internal::make_proper_matrix_type<Scalar,
                                                       RowsAtCompileTime,
                                                       MatrixUColsAtCompileTime,
                                                       MatrixOptions,
                                                       MaxRowsAtCompileTime,
                                                       MatrixUMaxColsAtCompileTime>::type MatrixUType;
    typedef typename internal::make_proper_matrix_type<Scalar,
                                                       ColsAtCompileTime,
                                                       MatrixVColsAtCompileTime,
                                                       MatrixOptions,
                                                       MaxColsAtCompileTime,
                                                       MatrixVMaxColsAtCompileTime>::type MatrixVType;
    typedef typename internal::plain_diag_type<MatrixType, RealScalar>::type SingularValuesType;
    Derived& derived() { return *static_cast<Derived*>(this); }
    const Derived& derived() const { return *static_cast<const Derived*>(this); }
    const MatrixUType& matrixU() const {
      _check_compute_assertions();
      (static_cast<bool>(computeU() && "This SVD decomposition didn't compute U. Did you ask for it?")
           ? void(0)
           : __assert_fail("computeU() && \"This SVD decomposition didn't compute U. Did you ask for it?\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           178,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrixU;
    }
    const MatrixVType& matrixV() const {
      _check_compute_assertions();
      (static_cast<bool>(computeV() && "This SVD decomposition didn't compute V. Did you ask for it?")
           ? void(0)
           : __assert_fail("computeV() && \"This SVD decomposition didn't compute V. Did you ask for it?\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           194,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrixV;
    }
    const SingularValuesType& singularValues() const {
      _check_compute_assertions();
      return m_singularValues;
    }
    Index nonzeroSingularValues() const {
      _check_compute_assertions();
      return m_nonzeroSingularValues;
    }
    inline Index rank() const {
      using std::abs;
      _check_compute_assertions();
      if (m_singularValues.size() == 0)
        return 0;
      RealScalar premultiplied_threshold =
          numext::maxi<RealScalar>(m_singularValues.coeff(0) * threshold(), (std::numeric_limits<RealScalar>::min)());
      Index i = m_nonzeroSingularValues - 1;
      while (i >= 0 && m_singularValues.coeff(i) < premultiplied_threshold)
        --i;
      return i + 1;
    }
    Derived& setThreshold(const RealScalar& threshold) {
      m_usePrescribedThreshold = true;
      m_prescribedThreshold = threshold;
      return derived();
    }
    Derived& setThreshold(Default_t) {
      m_usePrescribedThreshold = false;
      return derived();
    }
    RealScalar threshold() const {
      (static_cast<bool>(m_isInitialized || m_usePrescribedThreshold)
           ? void(0)
           : __assert_fail("m_isInitialized || m_usePrescribedThreshold",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           274,
                           __extension__ __PRETTY_FUNCTION__));
      Index diagSize = (std::max<Index>)(1, m_diagSize);
      return m_usePrescribedThreshold ? m_prescribedThreshold : RealScalar(diagSize) * NumTraits<Scalar>::epsilon();
    }
    inline bool computeU() const { return m_computeFullU || m_computeThinU; }
    inline bool computeV() const { return m_computeFullV || m_computeThinV; }
    inline Index rows() const { return m_rows; }
    inline Index cols() const { return m_cols; }
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "SVD is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SVD is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           312,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    template <typename RhsType, typename DstType>
    void _solve_impl(const RhsType& rhs, DstType& dst) const;
    template <bool Conjugate, typename RhsType, typename DstType>
    void _solve_impl_transposed(const RhsType& rhs, DstType& dst) const;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    void _check_compute_assertions() const {
      (static_cast<bool>(m_isInitialized && "SVD is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SVD is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           329,
                           __extension__ __PRETTY_FUNCTION__));
    }
    template <bool Transpose_, typename Rhs>
    void _check_solve_assertion(const Rhs& b) const {
      ;
      _check_compute_assertions();
      (static_cast<bool>(
           computeU() && computeV() &&
           "SVDBase::solve(): Both unitaries U and V are required to be computed (thin unitaries suffice).")
           ? void(0)
           : __assert_fail("computeU() && computeV() && \"SVDBase::solve(): Both unitaries U and V are required to be "
                           "computed (thin unitaries suffice).\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           336,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>((Transpose_ ? cols() : rows()) == b.rows() &&
                         "SVDBase::solve(): invalid number of rows of the right hand side matrix b")
           ? void(0)
           : __assert_fail("(Transpose_?cols():rows())==b.rows() && \"SVDBase::solve(): invalid number of rows of the "
                           "right hand side matrix b\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/SVDBase.h",
                           337,
                           __extension__ __PRETTY_FUNCTION__));
    }
    bool allocate(Index rows, Index cols, unsigned int computationOptions);
    MatrixUType m_matrixU;
    MatrixVType m_matrixV;
    SingularValuesType m_singularValues;
    ComputationInfo m_info;
    bool m_isInitialized, m_isAllocated, m_usePrescribedThreshold;
    bool m_computeFullU, m_computeThinU;
    bool m_computeFullV, m_computeThinV;
    unsigned int m_computationOptions;
    Index m_nonzeroSingularValues, m_rows, m_cols, m_diagSize;
    RealScalar m_prescribedThreshold;
    SVDBase()
        : m_info(Success),
          m_isInitialized(false),
          m_isAllocated(false),
          m_usePrescribedThreshold(false),
          m_computeFullU(false),
          m_computeThinU(false),
          m_computeFullV(false),
          m_computeThinV(false),
          m_computationOptions(0),
          m_rows(-1),
          m_cols(-1),
          m_diagSize(0) {}
  };
  template <typename Derived>
  template <typename RhsType, typename DstType>
  void SVDBase<Derived>::_solve_impl(const RhsType& rhs, DstType& dst) const {
    Matrix<typename RhsType::Scalar,
           Dynamic,
           RhsType::ColsAtCompileTime,
           0,
           MatrixType::MaxRowsAtCompileTime,
           RhsType::MaxColsAtCompileTime>
        tmp;
    Index l_rank = rank();
    tmp.noalias() = m_matrixU.leftCols(l_rank).adjoint() * rhs;
    tmp = m_singularValues.head(l_rank).asDiagonal().inverse() * tmp;
    dst = m_matrixV.leftCols(l_rank) * tmp;
  }
  template <typename Derived>
  template <bool Conjugate, typename RhsType, typename DstType>
  void SVDBase<Derived>::_solve_impl_transposed(const RhsType& rhs, DstType& dst) const {
    Matrix<typename RhsType::Scalar,
           Dynamic,
           RhsType::ColsAtCompileTime,
           0,
           MatrixType::MaxRowsAtCompileTime,
           RhsType::MaxColsAtCompileTime>
        tmp;
    Index l_rank = rank();
    tmp.noalias() = m_matrixV.leftCols(l_rank).transpose().template conjugateIf<Conjugate>() * rhs;
    tmp = m_singularValues.head(l_rank).asDiagonal().inverse() * tmp;
    dst = m_matrixU.template conjugateIf<!Conjugate>().leftCols(l_rank) * tmp;
  }
  template <typename Derived>
  bool SVDBase<Derived>::allocate(Index rows, Index cols, unsigned int computationOptions) {
    (static_cast<bool>(rows >= 0 && cols >= 0)
         ? void(0)
         : __assert_fail("rows >= 0 && cols >= 0",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/SVD/SVDBase.h",
                         406,
                         __extension__ __PRETTY_FUNCTION__));
    if (m_isAllocated && rows == m_rows && cols == m_cols && computationOptions == m_computationOptions) {
      return true;
    }
    m_rows = rows;
    m_cols = cols;
    m_info = Success;
    m_isInitialized = false;
    m_isAllocated = true;
    m_computationOptions = computationOptions;
    m_computeFullU = ShouldComputeFullU || internal::should_svd_compute_full_u(computationOptions);
    m_computeThinU = ShouldComputeThinU || internal::should_svd_compute_thin_u(computationOptions);
    m_computeFullV = ShouldComputeFullV || internal::should_svd_compute_full_v(computationOptions);
    m_computeThinV = ShouldComputeThinV || internal::should_svd_compute_thin_v(computationOptions);
    (static_cast<bool>(!(m_computeFullU && m_computeThinU) && "SVDBase: you can't ask for both full and thin U")
         ? void(0)
         : __assert_fail("!(m_computeFullU && m_computeThinU) && \"SVDBase: you can't ask for both full and thin U\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/SVD/SVDBase.h",
                         427,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(!(m_computeFullV && m_computeThinV) && "SVDBase: you can't ask for both full and thin V")
         ? void(0)
         : __assert_fail("!(m_computeFullV && m_computeThinV) && \"SVDBase: you can't ask for both full and thin V\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/SVD/SVDBase.h",
                         428,
                         __extension__ __PRETTY_FUNCTION__));
    m_diagSize = (std::min)(m_rows, m_cols);
    m_singularValues.resize(m_diagSize);
    if (RowsAtCompileTime == Dynamic)
      m_matrixU.resize(m_rows, m_computeFullU ? m_rows : m_computeThinU ? m_diagSize : 0);
    if (ColsAtCompileTime == Dynamic)
      m_matrixV.resize(m_cols, m_computeFullV ? m_cols : m_computeThinV ? m_diagSize : 0);
    return false;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, int Options, bool IsComplex = NumTraits<typename MatrixType::Scalar>::IsComplex>
    struct svd_precondition_2x2_block_to_be_real {};
    enum { PreconditionIfMoreColsThanRows, PreconditionIfMoreRowsThanCols };
    template <typename MatrixType, int QRPreconditioner, int Case>
    struct qr_preconditioner_should_do_anything {
      enum {
        a = MatrixType::RowsAtCompileTime != Dynamic && MatrixType::ColsAtCompileTime != Dynamic &&
            MatrixType::ColsAtCompileTime <= MatrixType::RowsAtCompileTime,
        b = MatrixType::RowsAtCompileTime != Dynamic && MatrixType::ColsAtCompileTime != Dynamic &&
            MatrixType::RowsAtCompileTime <= MatrixType::ColsAtCompileTime,
        ret = !((QRPreconditioner == NoQRPreconditioner) || (Case == PreconditionIfMoreColsThanRows && bool(a)) ||
                (Case == PreconditionIfMoreRowsThanCols && bool(b)))
      };
    };
    template <typename MatrixType,
              int Options,
              int QRPreconditioner,
              int Case,
              bool DoAnything = qr_preconditioner_should_do_anything<MatrixType, QRPreconditioner, Case>::ret>
    struct qr_preconditioner_impl {};
    template <typename MatrixType, int Options, int QRPreconditioner, int Case>
    class qr_preconditioner_impl<MatrixType, Options, QRPreconditioner, Case, false> {
    public:
      void allocate(const JacobiSVD<MatrixType, Options>&) {}
      bool run(JacobiSVD<MatrixType, Options>&, const MatrixType&) { return false; }
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType,
                                 Options,
                                 FullPivHouseholderQRPreconditioner,
                                 PreconditionIfMoreRowsThanCols,
                                 true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum { WorkspaceSize = MatrixType::RowsAtCompileTime, MaxWorkspaceSize = MatrixType::MaxRowsAtCompileTime };
      typedef Matrix<Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize> WorkspaceType;
      void allocate(const SVDType& svd) {
        if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.rows(), svd.cols());
        }
        if (svd.m_computeFullU)
          m_workspace.resize(svd.rows());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.rows() > matrix.cols()) {
          m_qr.compute(matrix);
          svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView<Upper>();
          if (svd.m_computeFullU)
            m_qr.matrixQ().evalTo(svd.m_matrixU, m_workspace);
          if (svd.computeV())
            svd.m_matrixV = m_qr.colsPermutation();
          return true;
        }
        return false;
      }

    private:
      typedef FullPivHouseholderQR<MatrixType> QRType;
      QRType m_qr;
      WorkspaceType m_workspace;
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType,
                                 Options,
                                 FullPivHouseholderQRPreconditioner,
                                 PreconditionIfMoreColsThanRows,
                                 true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum {
        RowsAtCompileTime = MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
        MatrixOptions = MatrixType::Options
      };
      typedef typename internal::make_proper_matrix_type<Scalar,
                                                         ColsAtCompileTime,
                                                         RowsAtCompileTime,
                                                         MatrixOptions,
                                                         MaxColsAtCompileTime,
                                                         MaxRowsAtCompileTime>::type TransposeTypeWithSameStorageOrder;
      void allocate(const SVDType& svd) {
        if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.cols(), svd.rows());
        }
        m_adjoint.resize(svd.cols(), svd.rows());
        if (svd.m_computeFullV)
          m_workspace.resize(svd.cols());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.cols() > matrix.rows()) {
          m_adjoint = matrix.adjoint();
          m_qr.compute(m_adjoint);
          svd.m_workMatrix =
              m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView<Upper>().adjoint();
          if (svd.m_computeFullV)
            m_qr.matrixQ().evalTo(svd.m_matrixV, m_workspace);
          if (svd.computeU())
            svd.m_matrixU = m_qr.colsPermutation();
          return true;
        } else
          return false;
      }

    private:
      typedef FullPivHouseholderQR<TransposeTypeWithSameStorageOrder> QRType;
      QRType m_qr;
      TransposeTypeWithSameStorageOrder m_adjoint;
      typename plain_row_type<MatrixType>::type m_workspace;
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType,
                                 Options,
                                 ColPivHouseholderQRPreconditioner,
                                 PreconditionIfMoreRowsThanCols,
                                 true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum {
        WorkspaceSize = internal::traits<SVDType>::MatrixUColsAtCompileTime,
        MaxWorkspaceSize = internal::traits<SVDType>::MatrixUMaxColsAtCompileTime
      };
      typedef Matrix<Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize> WorkspaceType;
      void allocate(const SVDType& svd) {
        if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.rows(), svd.cols());
        }
        if (svd.m_computeFullU)
          m_workspace.resize(svd.rows());
        else if (svd.m_computeThinU)
          m_workspace.resize(svd.cols());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.rows() > matrix.cols()) {
          m_qr.compute(matrix);
          svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView<Upper>();
          if (svd.m_computeFullU)
            m_qr.householderQ().evalTo(svd.m_matrixU, m_workspace);
          else if (svd.m_computeThinU) {
            svd.m_matrixU.setIdentity(matrix.rows(), matrix.cols());
            m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixU, m_workspace);
          }
          if (svd.computeV())
            svd.m_matrixV = m_qr.colsPermutation();
          return true;
        }
        return false;
      }

    private:
      typedef ColPivHouseholderQR<MatrixType> QRType;
      QRType m_qr;
      WorkspaceType m_workspace;
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType,
                                 Options,
                                 ColPivHouseholderQRPreconditioner,
                                 PreconditionIfMoreColsThanRows,
                                 true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum {
        RowsAtCompileTime = MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
        MatrixOptions = MatrixType::Options,
        WorkspaceSize = internal::traits<SVDType>::MatrixVColsAtCompileTime,
        MaxWorkspaceSize = internal::traits<SVDType>::MatrixVMaxColsAtCompileTime
      };
      typedef Matrix<Scalar, WorkspaceSize, 1, ColMajor, MaxWorkspaceSize, 1> WorkspaceType;
      typedef typename internal::make_proper_matrix_type<Scalar,
                                                         ColsAtCompileTime,
                                                         RowsAtCompileTime,
                                                         MatrixOptions,
                                                         MaxColsAtCompileTime,
                                                         MaxRowsAtCompileTime>::type TransposeTypeWithSameStorageOrder;
      void allocate(const SVDType& svd) {
        if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.cols(), svd.rows());
        }
        if (svd.m_computeFullV)
          m_workspace.resize(svd.cols());
        else if (svd.m_computeThinV)
          m_workspace.resize(svd.rows());
        m_adjoint.resize(svd.cols(), svd.rows());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.cols() > matrix.rows()) {
          m_adjoint = matrix.adjoint();
          m_qr.compute(m_adjoint);
          svd.m_workMatrix =
              m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView<Upper>().adjoint();
          if (svd.m_computeFullV)
            m_qr.householderQ().evalTo(svd.m_matrixV, m_workspace);
          else if (svd.m_computeThinV) {
            svd.m_matrixV.setIdentity(matrix.cols(), matrix.rows());
            m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixV, m_workspace);
          }
          if (svd.computeU())
            svd.m_matrixU = m_qr.colsPermutation();
          return true;
        } else
          return false;
      }

    private:
      typedef ColPivHouseholderQR<TransposeTypeWithSameStorageOrder> QRType;
      QRType m_qr;
      TransposeTypeWithSameStorageOrder m_adjoint;
      WorkspaceType m_workspace;
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType, Options, HouseholderQRPreconditioner, PreconditionIfMoreRowsThanCols, true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum {
        WorkspaceSize = internal::traits<SVDType>::MatrixUColsAtCompileTime,
        MaxWorkspaceSize = internal::traits<SVDType>::MatrixUMaxColsAtCompileTime
      };
      typedef Matrix<Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize> WorkspaceType;
      void allocate(const SVDType& svd) {
        if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.rows(), svd.cols());
        }
        if (svd.m_computeFullU)
          m_workspace.resize(svd.rows());
        else if (svd.m_computeThinU)
          m_workspace.resize(svd.cols());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.rows() > matrix.cols()) {
          m_qr.compute(matrix);
          svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView<Upper>();
          if (svd.m_computeFullU)
            m_qr.householderQ().evalTo(svd.m_matrixU, m_workspace);
          else if (svd.m_computeThinU) {
            svd.m_matrixU.setIdentity(matrix.rows(), matrix.cols());
            m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixU, m_workspace);
          }
          if (svd.computeV())
            svd.m_matrixV.setIdentity(matrix.cols(), matrix.cols());
          return true;
        }
        return false;
      }

    private:
      typedef HouseholderQR<MatrixType> QRType;
      QRType m_qr;
      WorkspaceType m_workspace;
    };
    template <typename MatrixType, int Options>
    class qr_preconditioner_impl<MatrixType, Options, HouseholderQRPreconditioner, PreconditionIfMoreColsThanRows, true> {
    public:
      typedef typename MatrixType::Scalar Scalar;
      typedef JacobiSVD<MatrixType, Options> SVDType;
      enum {
        RowsAtCompileTime = MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
        MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
        MatrixOptions = MatrixType::Options,
        WorkspaceSize = internal::traits<SVDType>::MatrixVColsAtCompileTime,
        MaxWorkspaceSize = internal::traits<SVDType>::MatrixVMaxColsAtCompileTime
      };
      typedef Matrix<Scalar, WorkspaceSize, 1, ColMajor, MaxWorkspaceSize, 1> WorkspaceType;
      typedef typename internal::make_proper_matrix_type<Scalar,
                                                         ColsAtCompileTime,
                                                         RowsAtCompileTime,
                                                         MatrixOptions,
                                                         MaxColsAtCompileTime,
                                                         MaxRowsAtCompileTime>::type TransposeTypeWithSameStorageOrder;
      void allocate(const SVDType& svd) {
        if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {
          internal::destroy_at(&m_qr);
          internal::construct_at(&m_qr, svd.cols(), svd.rows());
        }
        if (svd.m_computeFullV)
          m_workspace.resize(svd.cols());
        else if (svd.m_computeThinV)
          m_workspace.resize(svd.rows());
        m_adjoint.resize(svd.cols(), svd.rows());
      }
      bool run(SVDType& svd, const MatrixType& matrix) {
        if (matrix.cols() > matrix.rows()) {
          m_adjoint = matrix.adjoint();
          m_qr.compute(m_adjoint);
          svd.m_workMatrix =
              m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView<Upper>().adjoint();
          if (svd.m_computeFullV)
            m_qr.householderQ().evalTo(svd.m_matrixV, m_workspace);
          else if (svd.m_computeThinV) {
            svd.m_matrixV.setIdentity(matrix.cols(), matrix.rows());
            m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixV, m_workspace);
          }
          if (svd.computeU())
            svd.m_matrixU.setIdentity(matrix.rows(), matrix.rows());
          return true;
        } else
          return false;
      }

    private:
      typedef HouseholderQR<TransposeTypeWithSameStorageOrder> QRType;
      QRType m_qr;
      TransposeTypeWithSameStorageOrder m_adjoint;
      WorkspaceType m_workspace;
    };
    template <typename MatrixType, int Options>
    struct svd_precondition_2x2_block_to_be_real<MatrixType, Options, false> {
      typedef JacobiSVD<MatrixType, Options> SVD;
      typedef typename MatrixType::RealScalar RealScalar;
      static bool run(typename SVD::WorkMatrixType&, SVD&, Index, Index, RealScalar&) { return true; }
    };
    template <typename MatrixType, int Options>
    struct svd_precondition_2x2_block_to_be_real<MatrixType, Options, true> {
      typedef JacobiSVD<MatrixType, Options> SVD;
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      static bool run(typename SVD::WorkMatrixType& work_matrix, SVD& svd, Index p, Index q, RealScalar& maxDiagEntry) {
        using std::abs;
        using std::sqrt;
        Scalar z;
        JacobiRotation<Scalar> rot;
        RealScalar n = sqrt(numext::abs2(work_matrix.coeff(p, p)) + numext::abs2(work_matrix.coeff(q, p)));
        const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
        const RealScalar precision = NumTraits<Scalar>::epsilon();
        if (numext::is_exactly_zero(n)) {
          work_matrix.coeffRef(p, p) = work_matrix.coeffRef(q, p) = Scalar(0);
          if (abs(numext::imag(work_matrix.coeff(p, q))) > considerAsZero) {
            z = abs(work_matrix.coeff(p, q)) / work_matrix.coeff(p, q);
            work_matrix.row(p) *= z;
            if (svd.computeU())
              svd.m_matrixU.col(p) *= conj(z);
          }
          if (abs(numext::imag(work_matrix.coeff(q, q))) > considerAsZero) {
            z = abs(work_matrix.coeff(q, q)) / work_matrix.coeff(q, q);
            work_matrix.row(q) *= z;
            if (svd.computeU())
              svd.m_matrixU.col(q) *= conj(z);
          }
        } else {
          rot.c() = conj(work_matrix.coeff(p, p)) / n;
          rot.s() = work_matrix.coeff(q, p) / n;
          work_matrix.applyOnTheLeft(p, q, rot);
          if (svd.computeU())
            svd.m_matrixU.applyOnTheRight(p, q, rot.adjoint());
          if (abs(numext::imag(work_matrix.coeff(p, q))) > considerAsZero) {
            z = abs(work_matrix.coeff(p, q)) / work_matrix.coeff(p, q);
            work_matrix.col(q) *= z;
            if (svd.computeV())
              svd.m_matrixV.col(q) *= z;
          }
          if (abs(numext::imag(work_matrix.coeff(q, q))) > considerAsZero) {
            z = abs(work_matrix.coeff(q, q)) / work_matrix.coeff(q, q);
            work_matrix.row(q) *= z;
            if (svd.computeU())
              svd.m_matrixU.col(q) *= conj(z);
          }
        }
        maxDiagEntry = numext::maxi<RealScalar>(
            maxDiagEntry, numext::maxi<RealScalar>(abs(work_matrix.coeff(p, p)), abs(work_matrix.coeff(q, q))));
        RealScalar threshold = numext::maxi<RealScalar>(considerAsZero, precision * maxDiagEntry);
        return abs(work_matrix.coeff(p, q)) > threshold || abs(work_matrix.coeff(q, p)) > threshold;
      }
    };
    template <typename MatrixType_, int Options>
    struct traits<JacobiSVD<MatrixType_, Options>> : svd_traits<MatrixType_, Options> {
      typedef MatrixType_ MatrixType;
    };
  }  // namespace internal
  template <typename MatrixType_, int Options_>
  class JacobiSVD : public SVDBase<JacobiSVD<MatrixType_, Options_>> {
    typedef SVDBase<JacobiSVD> Base;

  public:
    typedef MatrixType_ MatrixType;
    typedef typename Base::Scalar Scalar;
    typedef typename Base::RealScalar RealScalar;
    typedef typename Base::Index Index;
    enum {
      Options = Options_,
      QRPreconditioner = internal::get_qr_preconditioner(Options),
      RowsAtCompileTime = Base::RowsAtCompileTime,
      ColsAtCompileTime = Base::ColsAtCompileTime,
      DiagSizeAtCompileTime = Base::DiagSizeAtCompileTime,
      MaxRowsAtCompileTime = Base::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = Base::MaxColsAtCompileTime,
      MaxDiagSizeAtCompileTime = Base::MaxDiagSizeAtCompileTime,
      MatrixOptions = Base::MatrixOptions
    };
    typedef typename Base::MatrixUType MatrixUType;
    typedef typename Base::MatrixVType MatrixVType;
    typedef typename Base::SingularValuesType SingularValuesType;
    typedef Matrix<Scalar,
                   DiagSizeAtCompileTime,
                   DiagSizeAtCompileTime,
                   MatrixOptions,
                   MaxDiagSizeAtCompileTime,
                   MaxDiagSizeAtCompileTime>
        WorkMatrixType;
    JacobiSVD() {}
    JacobiSVD(Index rows, Index cols) { allocate(rows, cols, internal::get_computation_options(Options)); }
    __attribute__((deprecated)) JacobiSVD(Index rows, Index cols, unsigned int computationOptions) {
      internal::check_svd_options_assertions<MatrixType, Options>(computationOptions, rows, cols);
      allocate(rows, cols, computationOptions);
    }
    explicit JacobiSVD(const MatrixType& matrix) { compute_impl(matrix, internal::get_computation_options(Options)); }
    JacobiSVD(const MatrixType& matrix, unsigned int computationOptions) {
      internal::check_svd_options_assertions<MatrixType, Options>(computationOptions, matrix.rows(), matrix.cols());
      compute_impl(matrix, computationOptions);
    }
    JacobiSVD& compute(const MatrixType& matrix) { return compute_impl(matrix, m_computationOptions); }
    __attribute__((deprecated)) JacobiSVD& compute(const MatrixType& matrix, unsigned int computationOptions) {
      internal::check_svd_options_assertions<MatrixType, Options>(m_computationOptions, matrix.rows(), matrix.cols());
      return compute_impl(matrix, computationOptions);
    }
    using Base::cols;
    using Base::computeU;
    using Base::computeV;
    using Base::rank;
    using Base::rows;

  private:
    void allocate(Index rows, Index cols, unsigned int computationOptions);
    JacobiSVD& compute_impl(const MatrixType& matrix, unsigned int computationOptions);

  protected:
    using Base::m_cols;
    using Base::m_computationOptions;
    using Base::m_computeFullU;
    using Base::m_computeFullV;
    using Base::m_computeThinU;
    using Base::m_computeThinV;
    using Base::m_diagSize;
    using Base::m_info;
    using Base::m_isAllocated;
    using Base::m_isInitialized;
    using Base::m_matrixU;
    using Base::m_matrixV;
    using Base::m_nonzeroSingularValues;
    using Base::m_prescribedThreshold;
    using Base::m_rows;
    using Base::m_singularValues;
    using Base::m_usePrescribedThreshold;
    using Base::ShouldComputeThinU;
    using Base::ShouldComputeThinV;
    static_assert(!(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &&
                      !(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)),
                  "\"JacobiSVD: can't compute thin U or thin V with the FullPivHouseholderQR preconditioner. \" \"Use "
                  "the ColPivHouseholderQR preconditioner instead.\"");
    template <typename MatrixType__, int Options__, bool IsComplex_>
    friend struct internal::svd_precondition_2x2_block_to_be_real;
    template <typename MatrixType__, int Options__, int QRPreconditioner_, int Case_, bool DoAnything_>
    friend struct internal::qr_preconditioner_impl;
    internal::qr_preconditioner_impl<MatrixType, Options, QRPreconditioner, internal::PreconditionIfMoreColsThanRows>
        m_qr_precond_morecols;
    internal::qr_preconditioner_impl<MatrixType, Options, QRPreconditioner, internal::PreconditionIfMoreRowsThanCols>
        m_qr_precond_morerows;
    WorkMatrixType m_workMatrix;
    MatrixType m_scaledMatrix;
  };
  template <typename MatrixType, int Options>
  void JacobiSVD<MatrixType, Options>::allocate(Index rows, Index cols, unsigned int computationOptions) {
    if (Base::allocate(rows, cols, computationOptions))
      return;
    (static_cast<bool>(!(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &&
                       !(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &&
                       "JacobiSVD: can't compute thin U or thin V with the FullPivHouseholderQR preconditioner. "
                       "Use the ColPivHouseholderQR preconditioner instead.")
         ? void(0)
         : __assert_fail("!(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) && "
                         "!(ShouldComputeThinU && int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) && "
                         "\"JacobiSVD: can't compute thin U or thin V with the FullPivHouseholderQR preconditioner. \" "
                         "\"Use the ColPivHouseholderQR preconditioner instead.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/SVD/JacobiSVD.h",
                         680,
                         __extension__ __PRETTY_FUNCTION__));
    m_workMatrix.resize(m_diagSize, m_diagSize);
    if (m_cols > m_rows)
      m_qr_precond_morecols.allocate(*this);
    if (m_rows > m_cols)
      m_qr_precond_morerows.allocate(*this);
    if (m_rows != m_cols)
      m_scaledMatrix.resize(rows, cols);
  }
  template <typename MatrixType, int Options>
  JacobiSVD<MatrixType, Options>& JacobiSVD<MatrixType, Options>::compute_impl(const MatrixType& matrix,
                                                                               unsigned int computationOptions) {
    using std::abs;
    allocate(matrix.rows(), matrix.cols(), computationOptions);
    const RealScalar precision = RealScalar(2) * NumTraits<Scalar>::epsilon();
    const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
    RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
    if (!(numext::isfinite)(scale)) {
      m_isInitialized = true;
      m_info = InvalidInput;
      return *this;
    }
    if (numext::is_exactly_zero(scale))
      scale = RealScalar(1);
    if (m_rows != m_cols) {
      m_scaledMatrix = matrix / scale;
      m_qr_precond_morecols.run(*this, m_scaledMatrix);
      m_qr_precond_morerows.run(*this, m_scaledMatrix);
    } else {
      m_workMatrix = matrix.block(0, 0, m_diagSize, m_diagSize) / scale;
      if (m_computeFullU)
        m_matrixU.setIdentity(m_rows, m_rows);
      if (m_computeThinU)
        m_matrixU.setIdentity(m_rows, m_diagSize);
      if (m_computeFullV)
        m_matrixV.setIdentity(m_cols, m_cols);
      if (m_computeThinV)
        m_matrixV.setIdentity(m_cols, m_diagSize);
    }
    RealScalar maxDiagEntry = m_workMatrix.cwiseAbs().diagonal().maxCoeff();
    bool finished = false;
    while (!finished) {
      finished = true;
      for (Index p = 1; p < m_diagSize; ++p) {
        for (Index q = 0; q < p; ++q) {
          RealScalar threshold = numext::maxi<RealScalar>(considerAsZero, precision * maxDiagEntry);
          if (abs(m_workMatrix.coeff(p, q)) > threshold || abs(m_workMatrix.coeff(q, p)) > threshold) {
            finished = false;
            if (internal::svd_precondition_2x2_block_to_be_real<MatrixType, Options>::run(
                    m_workMatrix, *this, p, q, maxDiagEntry)) {
              JacobiRotation<RealScalar> j_left, j_right;
              internal::real_2x2_jacobi_svd(m_workMatrix, p, q, &j_left, &j_right);
              m_workMatrix.applyOnTheLeft(p, q, j_left);
              if (computeU())
                m_matrixU.applyOnTheRight(p, q, j_left.transpose());
              m_workMatrix.applyOnTheRight(p, q, j_right);
              if (computeV())
                m_matrixV.applyOnTheRight(p, q, j_right);
              maxDiagEntry = numext::maxi<RealScalar>(
                  maxDiagEntry, numext::maxi<RealScalar>(abs(m_workMatrix.coeff(p, p)), abs(m_workMatrix.coeff(q, q))));
            }
          }
        }
      }
    }
    for (Index i = 0; i < m_diagSize; ++i) {
      if (NumTraits<Scalar>::IsComplex && abs(numext::imag(m_workMatrix.coeff(i, i))) > considerAsZero) {
        RealScalar a = abs(m_workMatrix.coeff(i, i));
        m_singularValues.coeffRef(i) = abs(a);
        if (computeU())
          m_matrixU.col(i) *= m_workMatrix.coeff(i, i) / a;
      } else {
        RealScalar a = numext::real(m_workMatrix.coeff(i, i));
        m_singularValues.coeffRef(i) = abs(a);
        if (computeU() && (a < RealScalar(0)))
          m_matrixU.col(i) = -m_matrixU.col(i);
      }
    }
    m_singularValues *= scale;
    m_nonzeroSingularValues = m_diagSize;
    for (Index i = 0; i < m_diagSize; i++) {
      Index pos;
      RealScalar maxRemainingSingularValue = m_singularValues.tail(m_diagSize - i).maxCoeff(&pos);
      if (numext::is_exactly_zero(maxRemainingSingularValue)) {
        m_nonzeroSingularValues = i;
        break;
      }
      if (pos) {
        pos += i;
        std::swap(m_singularValues.coeffRef(i), m_singularValues.coeffRef(pos));
        if (computeU())
          m_matrixU.col(pos).swap(m_matrixU.col(i));
        if (computeV())
          m_matrixV.col(pos).swap(m_matrixV.col(i));
      }
    }
    m_isInitialized = true;
    return *this;
  }
  template <typename Derived>
  template <int Options>
  JacobiSVD<typename MatrixBase<Derived>::PlainObject, Options> MatrixBase<Derived>::jacobiSvd() const {
    return JacobiSVD<PlainObject, Options>(*this);
  }
  template <typename Derived>
  template <int Options>
  JacobiSVD<typename MatrixBase<Derived>::PlainObject, Options> MatrixBase<Derived>::jacobiSvd(
      unsigned int computationOptions) const {
    return JacobiSVD<PlainObject, Options>(*this, computationOptions);
  }
}  // namespace Eigen
namespace Eigen {
  template <typename MatrixType_, int Options>
  class BDCSVD;
  namespace internal {
    template <typename MatrixType_, int Options>
    struct traits<BDCSVD<MatrixType_, Options>> : svd_traits<MatrixType_, Options> {
      typedef MatrixType_ MatrixType;
    };
    template <typename MatrixType, int Options>
    struct allocate_small_svd {
      static void run(JacobiSVD<MatrixType, Options>& smallSvd,
                      Index rows,
                      Index cols,
                      unsigned int computationOptions) {
        (void)computationOptions;
        smallSvd = JacobiSVD<MatrixType, Options>(rows, cols);
      }
    };
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
    template <typename MatrixType>
    struct allocate_small_svd<MatrixType, 0> {
      static void run(JacobiSVD<MatrixType>& smallSvd, Index rows, Index cols, unsigned int computationOptions) {
        smallSvd = JacobiSVD<MatrixType>(rows, cols, computationOptions);
      }
    };
#pragma GCC diagnostic pop
  }  // namespace internal
  template <typename MatrixType_, int Options_>
  class BDCSVD : public SVDBase<BDCSVD<MatrixType_, Options_>> {
    typedef SVDBase<BDCSVD> Base;

  public:
    using Base::cols;
    using Base::computeU;
    using Base::computeV;
    using Base::rows;
    typedef MatrixType_ MatrixType;
    typedef typename Base::Scalar Scalar;
    typedef typename Base::RealScalar RealScalar;
    typedef typename NumTraits<RealScalar>::Literal Literal;
    typedef typename Base::Index Index;
    enum {
      Options = Options_,
      QRDecomposition = Options & internal::QRPreconditionerBits,
      ComputationOptions = Options & internal::ComputationOptionsBits,
      RowsAtCompileTime = Base::RowsAtCompileTime,
      ColsAtCompileTime = Base::ColsAtCompileTime,
      DiagSizeAtCompileTime = Base::DiagSizeAtCompileTime,
      MaxRowsAtCompileTime = Base::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = Base::MaxColsAtCompileTime,
      MaxDiagSizeAtCompileTime = Base::MaxDiagSizeAtCompileTime,
      MatrixOptions = Base::MatrixOptions
    };
    typedef typename Base::MatrixUType MatrixUType;
    typedef typename Base::MatrixVType MatrixVType;
    typedef typename Base::SingularValuesType SingularValuesType;
    typedef Matrix<Scalar, Dynamic, Dynamic, ColMajor> MatrixX;
    typedef Matrix<RealScalar, Dynamic, Dynamic, ColMajor> MatrixXr;
    typedef Matrix<RealScalar, Dynamic, 1> VectorType;
    typedef Array<RealScalar, Dynamic, 1> ArrayXr;
    typedef Array<Index, 1, Dynamic> ArrayXi;
    typedef Ref<ArrayXr> ArrayRef;
    typedef Ref<ArrayXi> IndicesRef;
    BDCSVD() : m_algoswap(16), m_isTranspose(false), m_compU(false), m_compV(false), m_numIters(0) {}
    BDCSVD(Index rows, Index cols) : m_algoswap(16), m_numIters(0) {
      allocate(rows, cols, internal::get_computation_options(Options));
    }
    __attribute__((deprecated)) BDCSVD(Index rows, Index cols, unsigned int computationOptions)
        : m_algoswap(16), m_numIters(0) {
      internal::check_svd_options_assertions<MatrixType, Options>(computationOptions, rows, cols);
      allocate(rows, cols, computationOptions);
    }
    BDCSVD(const MatrixType& matrix) : m_algoswap(16), m_numIters(0) {
      compute_impl(matrix, internal::get_computation_options(Options));
    }
    __attribute__((deprecated)) BDCSVD(const MatrixType& matrix, unsigned int computationOptions)
        : m_algoswap(16), m_numIters(0) {
      internal::check_svd_options_assertions<MatrixType, Options>(computationOptions, matrix.rows(), matrix.cols());
      compute_impl(matrix, computationOptions);
    }
    ~BDCSVD() {}
    BDCSVD& compute(const MatrixType& matrix) { return compute_impl(matrix, m_computationOptions); }
    __attribute__((deprecated)) BDCSVD& compute(const MatrixType& matrix, unsigned int computationOptions) {
      internal::check_svd_options_assertions<MatrixType, Options>(computationOptions, matrix.rows(), matrix.cols());
      return compute_impl(matrix, computationOptions);
    }
    void setSwitchSize(int s) {
      (static_cast<bool>(s >= 3 && "BDCSVD the size of the algo switch has to be at least 3.")
           ? void(0)
           : __assert_fail("s>=3 && \"BDCSVD the size of the algo switch has to be at least 3.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/SVD/BDCSVD.h",
                           234,
                           __extension__ __PRETTY_FUNCTION__));
      m_algoswap = s;
    }

  private:
    void allocate(Index rows, Index cols, unsigned int computationOptions);
    BDCSVD& compute_impl(const MatrixType& matrix, unsigned int computationOptions);
    void divide(Index firstCol, Index lastCol, Index firstRowW, Index firstColW, Index shift);
    void computeSVDofM(Index firstCol, Index n, MatrixXr& U, VectorType& singVals, MatrixXr& V);
    void computeSingVals(const ArrayRef& col0,
                         const ArrayRef& diag,
                         const IndicesRef& perm,
                         VectorType& singVals,
                         ArrayRef shifts,
                         ArrayRef mus);
    void perturbCol0(const ArrayRef& col0,
                     const ArrayRef& diag,
                     const IndicesRef& perm,
                     const VectorType& singVals,
                     const ArrayRef& shifts,
                     const ArrayRef& mus,
                     ArrayRef zhat);
    void computeSingVecs(const ArrayRef& zhat,
                         const ArrayRef& diag,
                         const IndicesRef& perm,
                         const VectorType& singVals,
                         const ArrayRef& shifts,
                         const ArrayRef& mus,
                         MatrixXr& U,
                         MatrixXr& V);
    void deflation43(Index firstCol, Index shift, Index i, Index size);
    void deflation44(Index firstColu, Index firstColm, Index firstRowW, Index firstColW, Index i, Index j, Index size);
    void deflation(Index firstCol, Index lastCol, Index k, Index firstRowW, Index firstColW, Index shift);
    template <typename HouseholderU, typename HouseholderV, typename NaiveU, typename NaiveV>
    void copyUV(const HouseholderU& householderU,
                const HouseholderV& householderV,
                const NaiveU& naiveU,
                const NaiveV& naivev);
    void structured_update(Block<MatrixXr, Dynamic, Dynamic> A, const MatrixXr& B, Index n1);
    static RealScalar secularEq(RealScalar x,
                                const ArrayRef& col0,
                                const ArrayRef& diag,
                                const IndicesRef& perm,
                                const ArrayRef& diagShifted,
                                RealScalar shift);
    template <typename SVDType>
    void computeBaseCase(SVDType& svd, Index n, Index firstCol, Index firstRowW, Index firstColW, Index shift);

  protected:
    MatrixXr m_naiveU, m_naiveV;
    MatrixXr m_computed;
    Index m_nRec;
    ArrayXr m_workspace;
    ArrayXi m_workspaceI;
    int m_algoswap;
    bool m_isTranspose, m_compU, m_compV, m_useQrDecomp;
    JacobiSVD<MatrixType, ComputationOptions> smallSvd;
    HouseholderQR<MatrixX> qrDecomp;
    internal::UpperBidiagonalization<MatrixX> bid;
    MatrixX copyWorkspace;
    MatrixX reducedTriangle;
    using Base::m_computationOptions;
    using Base::m_computeThinU;
    using Base::m_computeThinV;
    using Base::m_diagSize;
    using Base::m_info;
    using Base::m_isInitialized;
    using Base::m_matrixU;
    using Base::m_matrixV;
    using Base::m_nonzeroSingularValues;
    using Base::m_singularValues;

  public:
    int m_numIters;
  };
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::allocate(Index rows, Index cols, unsigned int computationOptions) {
    if (Base::allocate(rows, cols, computationOptions))
      return;
    if (cols < m_algoswap)
      internal::allocate_small_svd<MatrixType, ComputationOptions>::run(smallSvd, rows, cols, computationOptions);
    m_computed = MatrixXr::Zero(m_diagSize + 1, m_diagSize);
    m_compU = computeV();
    m_compV = computeU();
    m_isTranspose = (cols > rows);
    if (m_isTranspose)
      std::swap(m_compU, m_compV);
    constexpr Index kMinAspectRatio = 4;
    constexpr bool disableQrDecomp = static_cast<int>(QRDecomposition) == static_cast<int>(DisableQRDecomposition);
    m_useQrDecomp = !disableQrDecomp && ((rows / kMinAspectRatio > cols) || (cols / kMinAspectRatio > rows));
    if (m_useQrDecomp) {
      qrDecomp = HouseholderQR<MatrixX>((std::max)(rows, cols), (std::min)(rows, cols));
      reducedTriangle = MatrixX(m_diagSize, m_diagSize);
    }
    copyWorkspace = MatrixX(m_isTranspose ? cols : rows, m_isTranspose ? rows : cols);
    bid = internal::UpperBidiagonalization<MatrixX>(m_useQrDecomp ? m_diagSize : copyWorkspace.rows(),
                                                    m_useQrDecomp ? m_diagSize : copyWorkspace.cols());
    if (m_compU)
      m_naiveU = MatrixXr::Zero(m_diagSize + 1, m_diagSize + 1);
    else
      m_naiveU = MatrixXr::Zero(2, m_diagSize + 1);
    if (m_compV)
      m_naiveV = MatrixXr::Zero(m_diagSize, m_diagSize);
    m_workspace.resize((m_diagSize + 1) * (m_diagSize + 1) * 3);
    m_workspaceI.resize(3 * m_diagSize);
  }
  template <typename MatrixType, int Options>
  BDCSVD<MatrixType, Options>& BDCSVD<MatrixType, Options>::compute_impl(const MatrixType& matrix,
                                                                         unsigned int computationOptions) {
    using std::abs;
    allocate(matrix.rows(), matrix.cols(), computationOptions);
    const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
    if (matrix.cols() < m_algoswap) {
      smallSvd.compute(matrix);
      m_isInitialized = true;
      m_info = smallSvd.info();
      if (m_info == Success || m_info == NoConvergence) {
        if (computeU())
          m_matrixU = smallSvd.matrixU();
        if (computeV())
          m_matrixV = smallSvd.matrixV();
        m_singularValues = smallSvd.singularValues();
        m_nonzeroSingularValues = smallSvd.nonzeroSingularValues();
      }
      return *this;
    }
    RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
    if (!(numext::isfinite)(scale)) {
      m_isInitialized = true;
      m_info = InvalidInput;
      return *this;
    }
    if (numext::is_exactly_zero(scale))
      scale = Literal(1);
    if (m_isTranspose)
      copyWorkspace = matrix.adjoint() / scale;
    else
      copyWorkspace = matrix / scale;
    if (m_useQrDecomp) {
      qrDecomp.compute(copyWorkspace);
      reducedTriangle = qrDecomp.matrixQR().topRows(m_diagSize);
      reducedTriangle.template triangularView<StrictlyLower>().setZero();
      bid.compute(reducedTriangle);
    } else {
      bid.compute(copyWorkspace);
    }
    m_naiveU.setZero();
    m_naiveV.setZero();
    m_computed.topRows(m_diagSize) = bid.bidiagonal().toDenseMatrix().transpose();
    m_computed.template bottomRows<1>().setZero();
    divide(0, m_diagSize - 1, 0, 0, 0);
    if (m_info != Success && m_info != NoConvergence) {
      m_isInitialized = true;
      return *this;
    }
    for (int i = 0; i < m_diagSize; i++) {
      RealScalar a = abs(m_computed.coeff(i, i));
      m_singularValues.coeffRef(i) = a * scale;
      if (a < considerZero) {
        m_nonzeroSingularValues = i;
        m_singularValues.tail(m_diagSize - i - 1).setZero();
        break;
      } else if (i == m_diagSize - 1) {
        m_nonzeroSingularValues = i + 1;
        break;
      }
    }
    if (m_isTranspose)
      copyUV(bid.householderV(), bid.householderU(), m_naiveV, m_naiveU);
    else
      copyUV(bid.householderU(), bid.householderV(), m_naiveU, m_naiveV);
    if (m_useQrDecomp) {
      if (m_isTranspose && computeV())
        m_matrixV.applyOnTheLeft(qrDecomp.householderQ());
      else if (!m_isTranspose && computeU())
        m_matrixU.applyOnTheLeft(qrDecomp.householderQ());
    }
    m_isInitialized = true;
    return *this;
  }
  template <typename MatrixType, int Options>
  template <typename HouseholderU, typename HouseholderV, typename NaiveU, typename NaiveV>
  void BDCSVD<MatrixType, Options>::copyUV(const HouseholderU& householderU,
                                           const HouseholderV& householderV,
                                           const NaiveU& naiveU,
                                           const NaiveV& naiveV) {
    if (computeU()) {
      Index Ucols = m_computeThinU ? m_diagSize : rows();
      m_matrixU = MatrixX::Identity(rows(), Ucols);
      m_matrixU.topLeftCorner(m_diagSize, m_diagSize) =
          naiveV.template cast<Scalar>().topLeftCorner(m_diagSize, m_diagSize);
      if (m_useQrDecomp)
        m_matrixU.topLeftCorner(householderU.cols(), m_diagSize).applyOnTheLeft(householderU);
      else
        m_matrixU.applyOnTheLeft(householderU);
    }
    if (computeV()) {
      Index Vcols = m_computeThinV ? m_diagSize : cols();
      m_matrixV = MatrixX::Identity(cols(), Vcols);
      m_matrixV.topLeftCorner(m_diagSize, m_diagSize) =
          naiveU.template cast<Scalar>().topLeftCorner(m_diagSize, m_diagSize);
      if (m_useQrDecomp)
        m_matrixV.topLeftCorner(householderV.cols(), m_diagSize).applyOnTheLeft(householderV);
      else
        m_matrixV.applyOnTheLeft(householderV);
    }
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::structured_update(Block<MatrixXr, Dynamic, Dynamic> A,
                                                      const MatrixXr& B,
                                                      Index n1) {
    Index n = A.rows();
    if (n > 100) {
      Index n2 = n - n1;
      Map<MatrixXr> A1(m_workspace.data(), n1, n);
      Map<MatrixXr> A2(m_workspace.data() + n1 * n, n2, n);
      Map<MatrixXr> B1(m_workspace.data() + n * n, n, n);
      Map<MatrixXr> B2(m_workspace.data() + 2 * n * n, n, n);
      Index k1 = 0, k2 = 0;
      for (Index j = 0; j < n; ++j) {
        if ((A.col(j).head(n1).array() != Literal(0)).any()) {
          A1.col(k1) = A.col(j).head(n1);
          B1.row(k1) = B.row(j);
          ++k1;
        }
        if ((A.col(j).tail(n2).array() != Literal(0)).any()) {
          A2.col(k2) = A.col(j).tail(n2);
          B2.row(k2) = B.row(j);
          ++k2;
        }
      }
      A.topRows(n1).noalias() = A1.leftCols(k1) * B1.topRows(k1);
      A.bottomRows(n2).noalias() = A2.leftCols(k2) * B2.topRows(k2);
    } else {
      Map<MatrixXr, Aligned> tmp(m_workspace.data(), n, n);
      tmp.noalias() = A * B;
      A = tmp;
    }
  }
  template <typename MatrixType, int Options>
  template <typename SVDType>
  void BDCSVD<MatrixType, Options>::computeBaseCase(
      SVDType& svd, Index n, Index firstCol, Index firstRowW, Index firstColW, Index shift) {
    svd.compute(m_computed.block(firstCol, firstCol, n + 1, n));
    m_info = svd.info();
    if (m_info != Success && m_info != NoConvergence)
      return;
    if (m_compU)
      m_naiveU.block(firstCol, firstCol, n + 1, n + 1).real() = svd.matrixU();
    else {
      m_naiveU.row(0).segment(firstCol, n + 1).real() = svd.matrixU().row(0);
      m_naiveU.row(1).segment(firstCol, n + 1).real() = svd.matrixU().row(n);
    }
    if (m_compV)
      m_naiveV.block(firstRowW, firstColW, n, n).real() = svd.matrixV();
    m_computed.block(firstCol + shift, firstCol + shift, n + 1, n).setZero();
    m_computed.diagonal().segment(firstCol + shift, n) = svd.singularValues().head(n);
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::divide(
      Index firstCol, Index lastCol, Index firstRowW, Index firstColW, Index shift) {
    using std::abs;
    using std::pow;
    using std::sqrt;
    const Index n = lastCol - firstCol + 1;
    const Index k = n / 2;
    const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
    RealScalar alphaK;
    RealScalar betaK;
    RealScalar r0;
    RealScalar lambda, phi, c0, s0;
    VectorType l, f;
    if (n < m_algoswap) {
      if (m_compV) {
        JacobiSVD<MatrixXr, ComputeFullU | ComputeFullV> baseSvd;
        computeBaseCase(baseSvd, n, firstCol, firstRowW, firstColW, shift);
      } else {
        JacobiSVD<MatrixXr, ComputeFullU> baseSvd;
        computeBaseCase(baseSvd, n, firstCol, firstRowW, firstColW, shift);
      }
      return;
    }
    alphaK = m_computed(firstCol + k, firstCol + k);
    betaK = m_computed(firstCol + k + 1, firstCol + k);
    divide(k + 1 + firstCol, lastCol, k + 1 + firstRowW, k + 1 + firstColW, shift);
    if (m_info != Success && m_info != NoConvergence)
      return;
    divide(firstCol, k - 1 + firstCol, firstRowW, firstColW + 1, shift + 1);
    if (m_info != Success && m_info != NoConvergence)
      return;
    if (m_compU) {
      lambda = m_naiveU(firstCol + k, firstCol + k);
      phi = m_naiveU(firstCol + k + 1, lastCol + 1);
    } else {
      lambda = m_naiveU(1, firstCol + k);
      phi = m_naiveU(0, lastCol + 1);
    }
    r0 = sqrt((abs(alphaK * lambda) * abs(alphaK * lambda)) + abs(betaK * phi) * abs(betaK * phi));
    if (m_compU) {
      l = m_naiveU.row(firstCol + k).segment(firstCol, k);
      f = m_naiveU.row(firstCol + k + 1).segment(firstCol + k + 1, n - k - 1);
    } else {
      l = m_naiveU.row(1).segment(firstCol, k);
      f = m_naiveU.row(0).segment(firstCol + k + 1, n - k - 1);
    }
    if (m_compV)
      m_naiveV(firstRowW + k, firstColW) = Literal(1);
    if (r0 < considerZero) {
      c0 = Literal(1);
      s0 = Literal(0);
    } else {
      c0 = alphaK * lambda / r0;
      s0 = betaK * phi / r0;
    }
    if (m_compU) {
      MatrixXr q1(m_naiveU.col(firstCol + k).segment(firstCol, k + 1));
      for (Index i = firstCol + k - 1; i >= firstCol; i--)
        m_naiveU.col(i + 1).segment(firstCol, k + 1) = m_naiveU.col(i).segment(firstCol, k + 1);
      m_naiveU.col(firstCol).segment(firstCol, k + 1) = (q1 * c0);
      m_naiveU.col(lastCol + 1).segment(firstCol, k + 1) = (q1 * (-s0));
      m_naiveU.col(firstCol).segment(firstCol + k + 1, n - k) =
          m_naiveU.col(lastCol + 1).segment(firstCol + k + 1, n - k) * s0;
      m_naiveU.col(lastCol + 1).segment(firstCol + k + 1, n - k) *= c0;
    } else {
      RealScalar q1 = m_naiveU(0, firstCol + k);
      for (Index i = firstCol + k - 1; i >= firstCol; i--)
        m_naiveU(0, i + 1) = m_naiveU(0, i);
      m_naiveU(0, firstCol) = (q1 * c0);
      m_naiveU(0, lastCol + 1) = (q1 * (-s0));
      m_naiveU(1, firstCol) = m_naiveU(1, lastCol + 1) * s0;
      m_naiveU(1, lastCol + 1) *= c0;
      m_naiveU.row(1).segment(firstCol + 1, k).setZero();
      m_naiveU.row(0).segment(firstCol + k + 1, n - k - 1).setZero();
    }
    m_computed(firstCol + shift, firstCol + shift) = r0;
    m_computed.col(firstCol + shift).segment(firstCol + shift + 1, k) = alphaK * l.transpose().real();
    m_computed.col(firstCol + shift).segment(firstCol + shift + k + 1, n - k - 1) = betaK * f.transpose().real();
    deflation(firstCol, lastCol, k, firstRowW, firstColW, shift);
    MatrixXr UofSVD, VofSVD;
    VectorType singVals;
    computeSVDofM(firstCol + shift, n, UofSVD, singVals, VofSVD);
    if (m_compU)
      structured_update(m_naiveU.block(firstCol, firstCol, n + 1, n + 1), UofSVD, (n + 2) / 2);
    else {
      Map<Matrix<RealScalar, 2, Dynamic>, Aligned> tmp(m_workspace.data(), 2, n + 1);
      tmp.noalias() = m_naiveU.middleCols(firstCol, n + 1) * UofSVD;
      m_naiveU.middleCols(firstCol, n + 1) = tmp;
    }
    if (m_compV)
      structured_update(m_naiveV.block(firstRowW, firstColW, n, n), VofSVD, (n + 1) / 2);
    m_computed.block(firstCol + shift, firstCol + shift, n, n).setZero();
    m_computed.block(firstCol + shift, firstCol + shift, n, n).diagonal() = singVals;
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::computeSVDofM(
      Index firstCol, Index n, MatrixXr& U, VectorType& singVals, MatrixXr& V) {
    const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
    using std::abs;
    ArrayRef col0 = m_computed.col(firstCol).segment(firstCol, n);
    m_workspace.head(n) = m_computed.block(firstCol, firstCol, n, n).diagonal();
    ArrayRef diag = m_workspace.head(n);
    diag(0) = Literal(0);
    singVals.resize(n);
    U.resize(n + 1, n + 1);
    if (m_compV)
      V.resize(n, n);
    Index actual_n = n;
    while (actual_n > 1 && numext::is_exactly_zero(diag(actual_n - 1))) {
      --actual_n;
      ;
    }
    Index m = 0;
    for (Index k = 0; k < actual_n; ++k)
      if (abs(col0(k)) > considerZero)
        m_workspaceI(m++) = k;
    Map<ArrayXi> perm(m_workspaceI.data(), m);
    Map<ArrayXr> shifts(m_workspace.data() + 1 * n, n);
    Map<ArrayXr> mus(m_workspace.data() + 2 * n, n);
    Map<ArrayXr> zhat(m_workspace.data() + 3 * n, n);
    computeSingVals(col0, diag, perm, singVals, shifts, mus);
    perturbCol0(col0, diag, perm, singVals, shifts, mus, zhat);
    computeSingVecs(zhat, diag, perm, singVals, shifts, mus, U, V);
    for (Index i = 0; i < actual_n - 1; ++i) {
      if (singVals(i) > singVals(i + 1)) {
        using std::swap;
        swap(singVals(i), singVals(i + 1));
        U.col(i).swap(U.col(i + 1));
        if (m_compV)
          V.col(i).swap(V.col(i + 1));
      }
    }
    singVals.head(actual_n).reverseInPlace();
    U.leftCols(actual_n).rowwise().reverseInPlace();
    if (m_compV)
      V.leftCols(actual_n).rowwise().reverseInPlace();
  }
  template <typename MatrixType, int Options>
  typename BDCSVD<MatrixType, Options>::RealScalar BDCSVD<MatrixType, Options>::secularEq(RealScalar mu,
                                                                                          const ArrayRef& col0,
                                                                                          const ArrayRef& diag,
                                                                                          const IndicesRef& perm,
                                                                                          const ArrayRef& diagShifted,
                                                                                          RealScalar shift) {
    Index m = perm.size();
    RealScalar res = Literal(1);
    for (Index i = 0; i < m; ++i) {
      Index j = perm(i);
      res += (col0(j) / (diagShifted(j) - mu)) * (col0(j) / (diag(j) + shift + mu));
    }
    return res;
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::computeSingVals(const ArrayRef& col0,
                                                    const ArrayRef& diag,
                                                    const IndicesRef& perm,
                                                    VectorType& singVals,
                                                    ArrayRef shifts,
                                                    ArrayRef mus) {
    using std::abs;
    using std::sqrt;
    using std::swap;
    Index n = col0.size();
    Index actual_n = n;
    while (actual_n > 1 && numext::is_exactly_zero(col0(actual_n - 1)))
      --actual_n;
    for (Index k = 0; k < n; ++k) {
      if (numext::is_exactly_zero(col0(k)) || actual_n == 1) {
        singVals(k) = k == 0 ? col0(0) : diag(k);
        mus(k) = Literal(0);
        shifts(k) = k == 0 ? col0(0) : diag(k);
        continue;
      }
      RealScalar left = diag(k);
      RealScalar right;
      if (k == actual_n - 1)
        right = (diag(actual_n - 1) + col0.matrix().norm());
      else {
        Index l = k + 1;
        while (numext::is_exactly_zero(col0(l))) {
          ++l;
          ;
        }
        right = diag(l);
      }
      RealScalar mid = left + (right - left) / Literal(2);
      RealScalar fMid = secularEq(mid, col0, diag, perm, diag, Literal(0));
      RealScalar shift = (k == actual_n - 1 || fMid > Literal(0)) ? left : right;
      Map<ArrayXr> diagShifted(m_workspace.data() + 4 * n, n);
      diagShifted = diag - shift;
      if (k != actual_n - 1) {
        RealScalar midShifted = (right - left) / RealScalar(2);
        if (numext::equal_strict(shift, right))
          midShifted = -midShifted;
        RealScalar fMidShifted = secularEq(midShifted, col0, diag, perm, diagShifted, shift);
        if (fMidShifted > 0) {
          shift = fMidShifted > Literal(0) ? left : right;
          diagShifted = diag - shift;
        }
      }
      RealScalar muPrev, muCur;
      if (numext::equal_strict(shift, left)) {
        muPrev = (right - left) * RealScalar(0.1);
        if (k == actual_n - 1)
          muCur = right - left;
        else
          muCur = (right - left) * RealScalar(0.5);
      } else {
        muPrev = -(right - left) * RealScalar(0.1);
        muCur = -(right - left) * RealScalar(0.5);
      }
      RealScalar fPrev = secularEq(muPrev, col0, diag, perm, diagShifted, shift);
      RealScalar fCur = secularEq(muCur, col0, diag, perm, diagShifted, shift);
      if (abs(fPrev) < abs(fCur)) {
        swap(fPrev, fCur);
        swap(muPrev, muCur);
      }
      bool useBisection = fPrev * fCur > Literal(0);
      while (!numext::is_exactly_zero(fCur) &&
             abs(muCur - muPrev) >
                 Literal(8) * NumTraits<RealScalar>::epsilon() * numext::maxi<RealScalar>(abs(muCur), abs(muPrev)) &&
             abs(fCur - fPrev) > NumTraits<RealScalar>::epsilon() && !useBisection) {
        ++m_numIters;
        RealScalar a = (fCur - fPrev) / (Literal(1) / muCur - Literal(1) / muPrev);
        RealScalar b = fCur - a / muCur;
        RealScalar muZero = -a / b;
        RealScalar fZero = secularEq(muZero, col0, diag, perm, diagShifted, shift);
        muPrev = muCur;
        fPrev = fCur;
        muCur = muZero;
        fCur = fZero;
        if (numext::equal_strict(shift, left) && (muCur < Literal(0) || muCur > right - left))
          useBisection = true;
        if (numext::equal_strict(shift, right) && (muCur < -(right - left) || muCur > Literal(0)))
          useBisection = true;
        if (abs(fCur) > abs(fPrev))
          useBisection = true;
      }
      if (useBisection) {
        RealScalar leftShifted, rightShifted;
        if (numext::equal_strict(shift, left)) {
          leftShifted =
              numext::maxi<RealScalar>((std::numeric_limits<RealScalar>::min)(),
                                       Literal(2) * abs(col0(k)) / sqrt((std::numeric_limits<RealScalar>::max)()));
          ;
          rightShifted = (k == actual_n - 1) ? right : ((right - left) * RealScalar(0.51));
        } else {
          leftShifted = -(right - left) * RealScalar(0.51);
          if (k + 1 < n)
            rightShifted = -numext::maxi<RealScalar>((std::numeric_limits<RealScalar>::min)(),
                                                     abs(col0(k + 1)) / sqrt((std::numeric_limits<RealScalar>::max)()));
          else
            rightShifted = -(std::numeric_limits<RealScalar>::min)();
        }
        RealScalar fLeft = secularEq(leftShifted, col0, diag, perm, diagShifted, shift);
        ;
        ;
        if (fLeft < Literal(0)) {
          while (rightShifted - leftShifted > Literal(2) * NumTraits<RealScalar>::epsilon() *
                                                  numext::maxi<RealScalar>(abs(leftShifted), abs(rightShifted))) {
            RealScalar midShifted = (leftShifted + rightShifted) / Literal(2);
            fMid = secularEq(midShifted, col0, diag, perm, diagShifted, shift);
            ;
            if (fLeft * fMid < Literal(0)) {
              rightShifted = midShifted;
            } else {
              leftShifted = midShifted;
              fLeft = fMid;
            }
          }
          muCur = (leftShifted + rightShifted) / Literal(2);
        } else {
          muCur = (right - left) * RealScalar(0.5);
          if (numext::equal_strict(shift, right))
            muCur = -muCur;
        }
      }
      singVals[k] = shift + muCur;
      shifts[k] = shift;
      mus[k] = muCur;
    }
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::perturbCol0(const ArrayRef& col0,
                                                const ArrayRef& diag,
                                                const IndicesRef& perm,
                                                const VectorType& singVals,
                                                const ArrayRef& shifts,
                                                const ArrayRef& mus,
                                                ArrayRef zhat) {
    using std::sqrt;
    Index n = col0.size();
    Index m = perm.size();
    if (m == 0) {
      zhat.setZero();
      return;
    }
    Index lastIdx = perm(m - 1);
    for (Index k = 0; k < n; ++k) {
      if (numext::is_exactly_zero(col0(k)))
        zhat(k) = Literal(0);
      else {
        RealScalar dk = diag(k);
        RealScalar prod = (singVals(lastIdx) + dk) * (mus(lastIdx) + (shifts(lastIdx) - dk));
        for (Index l = 0; l < m; ++l) {
          Index i = perm(l);
          if (i != k) {
            if (i >= k && l == 0) {
              m_info = NumericalIssue;
              prod = 0;
              break;
            }
            Index j = i < k ? i : l > 0 ? perm(l - 1) : i;
            prod *= ((singVals(j) + dk) / ((diag(i) + dk))) * ((mus(j) + (shifts(j) - dk)) / ((diag(i) - dk)));
          }
        }
        RealScalar tmp = sqrt(prod);
        zhat(k) = col0(k) > Literal(0) ? RealScalar(tmp) : RealScalar(-tmp);
      }
    }
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::computeSingVecs(const ArrayRef& zhat,
                                                    const ArrayRef& diag,
                                                    const IndicesRef& perm,
                                                    const VectorType& singVals,
                                                    const ArrayRef& shifts,
                                                    const ArrayRef& mus,
                                                    MatrixXr& U,
                                                    MatrixXr& V) {
    Index n = zhat.size();
    Index m = perm.size();
    for (Index k = 0; k < n; ++k) {
      if (numext::is_exactly_zero(zhat(k))) {
        U.col(k) = VectorType::Unit(n + 1, k);
        if (m_compV)
          V.col(k) = VectorType::Unit(n, k);
      } else {
        U.col(k).setZero();
        for (Index l = 0; l < m; ++l) {
          Index i = perm(l);
          U(i, k) = zhat(i) / (((diag(i) - shifts(k)) - mus(k))) / ((diag(i) + singVals[k]));
        }
        U(n, k) = Literal(0);
        U.col(k).normalize();
        if (m_compV) {
          V.col(k).setZero();
          for (Index l = 1; l < m; ++l) {
            Index i = perm(l);
            V(i, k) = diag(i) * zhat(i) / (((diag(i) - shifts(k)) - mus(k))) / ((diag(i) + singVals[k]));
          }
          V(0, k) = Literal(-1);
          V.col(k).normalize();
        }
      }
    }
    U.col(n) = VectorType::Unit(n + 1, n);
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::deflation43(Index firstCol, Index shift, Index i, Index size) {
    using std::abs;
    using std::pow;
    using std::sqrt;
    Index start = firstCol + shift;
    RealScalar c = m_computed(start, start);
    RealScalar s = m_computed(start + i, start);
    RealScalar r = numext::hypot(c, s);
    if (numext::is_exactly_zero(r)) {
      m_computed(start + i, start + i) = Literal(0);
      return;
    }
    m_computed(start, start) = r;
    m_computed(start + i, start) = Literal(0);
    m_computed(start + i, start + i) = Literal(0);
    JacobiRotation<RealScalar> J(c / r, -s / r);
    if (m_compU)
      m_naiveU.middleRows(firstCol, size + 1).applyOnTheRight(firstCol, firstCol + i, J);
    else
      m_naiveU.applyOnTheRight(firstCol, firstCol + i, J);
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::deflation44(
      Index firstColu, Index firstColm, Index firstRowW, Index firstColW, Index i, Index j, Index size) {
    using std::abs;
    using std::conj;
    using std::pow;
    using std::sqrt;
    RealScalar c = m_computed(firstColm + i, firstColm);
    RealScalar s = m_computed(firstColm + j, firstColm);
    RealScalar r = sqrt(numext::abs2(c) + numext::abs2(s));
    if (numext::is_exactly_zero(r)) {
      m_computed(firstColm + i, firstColm + i) = m_computed(firstColm + j, firstColm + j);
      return;
    }
    c /= r;
    s /= r;
    m_computed(firstColm + i, firstColm) = r;
    m_computed(firstColm + j, firstColm + j) = m_computed(firstColm + i, firstColm + i);
    m_computed(firstColm + j, firstColm) = Literal(0);
    JacobiRotation<RealScalar> J(c, -s);
    if (m_compU)
      m_naiveU.middleRows(firstColu, size + 1).applyOnTheRight(firstColu + i, firstColu + j, J);
    else
      m_naiveU.applyOnTheRight(firstColu + i, firstColu + j, J);
    if (m_compV)
      m_naiveV.middleRows(firstRowW, size).applyOnTheRight(firstColW + i, firstColW + j, J);
  }
  template <typename MatrixType, int Options>
  void BDCSVD<MatrixType, Options>::deflation(
      Index firstCol, Index lastCol, Index k, Index firstRowW, Index firstColW, Index shift) {
    using std::abs;
    using std::sqrt;
    const Index length = lastCol + 1 - firstCol;
    Block<MatrixXr, Dynamic, 1> col0(m_computed, firstCol + shift, firstCol + shift, length, 1);
    Diagonal<MatrixXr> fulldiag(m_computed);
    VectorBlock<Diagonal<MatrixXr>, Dynamic> diag(fulldiag, firstCol + shift, length);
    const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
    RealScalar maxDiag = diag.tail((std::max)(Index(1), length - 1)).cwiseAbs().maxCoeff();
    RealScalar epsilon_strict = numext::maxi<RealScalar>(considerZero, NumTraits<RealScalar>::epsilon() * maxDiag);
    RealScalar epsilon_coarse =
        Literal(8) * NumTraits<RealScalar>::epsilon() * numext::maxi<RealScalar>(col0.cwiseAbs().maxCoeff(), maxDiag);
    if (diag(0) < epsilon_coarse) {
      diag(0) = epsilon_coarse;
    }
    for (Index i = 1; i < length; ++i)
      if (abs(col0(i)) < epsilon_strict) {
        col0(i) = Literal(0);
      }
    for (Index i = 1; i < length; i++)
      if (diag(i) < epsilon_coarse) {
        deflation43(firstCol, shift, i, length);
      }
    {
      const bool total_deflation = (col0.tail(length - 1).array().abs() < considerZero).all();
      Index* permutation = m_workspaceI.data();
      {
        permutation[0] = 0;
        Index p = 1;
        for (Index i = 1; i < length; ++i)
          if (abs(diag(i)) < considerZero)
            permutation[p++] = i;
        Index i = 1, j = k + 1;
        for (; p < length; ++p) {
          if (i > k)
            permutation[p] = j++;
          else if (j >= length)
            permutation[p] = i++;
          else if (diag(i) < diag(j))
            permutation[p] = j++;
          else
            permutation[p] = i++;
        }
      }
      if (total_deflation) {
        for (Index i = 1; i < length; ++i) {
          Index pi = permutation[i];
          if (abs(diag(pi)) < considerZero || diag(0) < diag(pi))
            permutation[i - 1] = permutation[i];
          else {
            permutation[i - 1] = 0;
            break;
          }
        }
      }
      Index* realInd = m_workspaceI.data() + length;
      Index* realCol = m_workspaceI.data() + 2 * length;
      for (int pos = 0; pos < length; pos++) {
        realCol[pos] = pos;
        realInd[pos] = pos;
      }
      for (Index i = total_deflation ? 0 : 1; i < length; i++) {
        const Index pi = permutation[length - (total_deflation ? i + 1 : i)];
        const Index J = realCol[pi];
        using std::swap;
        swap(diag(i), diag(J));
        if (i != 0 && J != 0)
          swap(col0(i), col0(J));
        if (m_compU)
          m_naiveU.col(firstCol + i)
              .segment(firstCol, length + 1)
              .swap(m_naiveU.col(firstCol + J).segment(firstCol, length + 1));
        else
          m_naiveU.col(firstCol + i).segment(0, 2).swap(m_naiveU.col(firstCol + J).segment(0, 2));
        if (m_compV)
          m_naiveV.col(firstColW + i)
              .segment(firstRowW, length)
              .swap(m_naiveV.col(firstColW + J).segment(firstRowW, length));
        const Index realI = realInd[i];
        realCol[realI] = J;
        realCol[pi] = i;
        realInd[J] = realI;
        realInd[i] = pi;
      }
    }
    {
      Index i = length - 1;
      while (i > 0 && (abs(diag(i)) < considerZero || abs(col0(i)) < considerZero))
        --i;
      for (; i > 1; --i)
        if ((diag(i) - diag(i - 1)) < NumTraits<RealScalar>::epsilon() * maxDiag) {
          ;
          deflation44(firstCol, firstCol + shift, firstRowW, firstColW, i - 1, i, length);
        }
    }
  }
  template <typename Derived>
  template <int Options>
  BDCSVD<typename MatrixBase<Derived>::PlainObject, Options> MatrixBase<Derived>::bdcSvd() const {
    return BDCSVD<PlainObject, Options>(*this);
  }
  template <typename Derived>
  template <int Options>
  BDCSVD<typename MatrixBase<Derived>::PlainObject, Options> MatrixBase<Derived>::bdcSvd(
      unsigned int computationOptions) const {
    return BDCSVD<PlainObject, Options>(*this, computationOptions);
  }
}  // namespace Eigen
#pragma clang diagnostic pop
#include <limits> /* clang -E -fkeep-system-includes */
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  template <typename Derived>
  template <typename OtherDerived>
  inline typename MatrixBase<Derived>::template cross_product_return_type<OtherDerived>::type
  MatrixBase<Derived>::cross(const MatrixBase<OtherDerived>& other) const {
    static_assert(Derived::IsVectorAtCompileTime && Derived::SizeAtCompileTime == 3,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == 3,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    typename internal::nested_eval<Derived, 2>::type lhs(derived());
    typename internal::nested_eval<OtherDerived, 2>::type rhs(other.derived());
    return typename cross_product_return_type<OtherDerived>::type(
        numext::conj(lhs.coeff(1) * rhs.coeff(2) - lhs.coeff(2) * rhs.coeff(1)),
        numext::conj(lhs.coeff(2) * rhs.coeff(0) - lhs.coeff(0) * rhs.coeff(2)),
        numext::conj(lhs.coeff(0) * rhs.coeff(1) - lhs.coeff(1) * rhs.coeff(0)));
  }
  namespace internal {
    template <int Arch,
              typename VectorLhs,
              typename VectorRhs,
              typename Scalar = typename VectorLhs::Scalar,
              bool Vectorizable = bool((VectorLhs::Flags & VectorRhs::Flags) & PacketAccessBit)>
    struct cross3_impl {
      static inline typename internal::plain_matrix_type<VectorLhs>::type run(const VectorLhs& lhs,
                                                                              const VectorRhs& rhs) {
        return typename internal::plain_matrix_type<VectorLhs>::type(
            numext::conj(lhs.coeff(1) * rhs.coeff(2) - lhs.coeff(2) * rhs.coeff(1)),
            numext::conj(lhs.coeff(2) * rhs.coeff(0) - lhs.coeff(0) * rhs.coeff(2)),
            numext::conj(lhs.coeff(0) * rhs.coeff(1) - lhs.coeff(1) * rhs.coeff(0)),
            0);
      }
    };
  }  // namespace internal
  template <typename Derived>
  template <typename OtherDerived>
  inline typename MatrixBase<Derived>::PlainObject MatrixBase<Derived>::cross3(
      const MatrixBase<OtherDerived>& other) const {
    static_assert(Derived::IsVectorAtCompileTime && Derived::SizeAtCompileTime == 4,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == 4,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    typedef typename internal::nested_eval<Derived, 2>::type DerivedNested;
    typedef typename internal::nested_eval<OtherDerived, 2>::type OtherDerivedNested;
    DerivedNested lhs(derived());
    OtherDerivedNested rhs(other.derived());
    return internal::cross3_impl<Architecture::Target,
                                 internal::remove_all_t<DerivedNested>,
                                 internal::remove_all_t<OtherDerivedNested>>::run(lhs, rhs);
  }
  template <typename ExpressionType, int Direction>
  template <typename OtherDerived>
  const typename VectorwiseOp<ExpressionType, Direction>::CrossReturnType
  VectorwiseOp<ExpressionType, Direction>::cross(const MatrixBase<OtherDerived>& other) const {
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == 3,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    static_assert((internal::is_same<Scalar, typename OtherDerived::Scalar>::value),
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    typename internal::nested_eval<ExpressionType, 2>::type mat(_expression());
    typename internal::nested_eval<OtherDerived, 2>::type vec(other.derived());
    CrossReturnType res(_expression().rows(), _expression().cols());
    if (Direction == Vertical) {
      (static_cast<bool>(CrossReturnType::RowsAtCompileTime == 3 && "the matrix must have exactly 3 rows")
           ? void(0)
           : __assert_fail("CrossReturnType::RowsAtCompileTime==3 && \"the matrix must have exactly 3 rows\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/OrthoMethods.h",
                           125,
                           __extension__ __PRETTY_FUNCTION__));
      res.row(0) = (mat.row(1) * vec.coeff(2) - mat.row(2) * vec.coeff(1)).conjugate();
      res.row(1) = (mat.row(2) * vec.coeff(0) - mat.row(0) * vec.coeff(2)).conjugate();
      res.row(2) = (mat.row(0) * vec.coeff(1) - mat.row(1) * vec.coeff(0)).conjugate();
    } else {
      (static_cast<bool>(CrossReturnType::ColsAtCompileTime == 3 && "the matrix must have exactly 3 columns")
           ? void(0)
           : __assert_fail("CrossReturnType::ColsAtCompileTime==3 && \"the matrix must have exactly 3 columns\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/OrthoMethods.h",
                           132,
                           __extension__ __PRETTY_FUNCTION__));
      res.col(0) = (mat.col(1) * vec.coeff(2) - mat.col(2) * vec.coeff(1)).conjugate();
      res.col(1) = (mat.col(2) * vec.coeff(0) - mat.col(0) * vec.coeff(2)).conjugate();
      res.col(2) = (mat.col(0) * vec.coeff(1) - mat.col(1) * vec.coeff(0)).conjugate();
    }
    return res;
  }
  namespace internal {
    template <typename Derived, int Size = Derived::SizeAtCompileTime>
    struct unitOrthogonal_selector {
      typedef typename plain_matrix_type<Derived>::type VectorType;
      typedef typename traits<Derived>::Scalar Scalar;
      typedef typename NumTraits<Scalar>::Real RealScalar;
      typedef Matrix<Scalar, 2, 1> Vector2;
      static inline VectorType run(const Derived& src) {
        VectorType perp = VectorType::Zero(src.size());
        Index maxi = 0;
        Index sndi = 0;
        src.cwiseAbs().maxCoeff(&maxi);
        if (maxi == 0)
          sndi = 1;
        RealScalar invnm = RealScalar(1) / (Vector2() << src.coeff(sndi), src.coeff(maxi)).finished().norm();
        perp.coeffRef(maxi) = -numext::conj(src.coeff(sndi)) * invnm;
        perp.coeffRef(sndi) = numext::conj(src.coeff(maxi)) * invnm;
        return perp;
      }
    };
    template <typename Derived>
    struct unitOrthogonal_selector<Derived, 3> {
      typedef typename plain_matrix_type<Derived>::type VectorType;
      typedef typename traits<Derived>::Scalar Scalar;
      typedef typename NumTraits<Scalar>::Real RealScalar;
      static inline VectorType run(const Derived& src) {
        VectorType perp;
        if ((!isMuchSmallerThan(src.x(), src.z())) || (!isMuchSmallerThan(src.y(), src.z()))) {
          RealScalar invnm = RealScalar(1) / src.template head<2>().norm();
          perp.coeffRef(0) = -numext::conj(src.y()) * invnm;
          perp.coeffRef(1) = numext::conj(src.x()) * invnm;
          perp.coeffRef(2) = 0;
        } else {
          RealScalar invnm = RealScalar(1) / src.template tail<2>().norm();
          perp.coeffRef(0) = 0;
          perp.coeffRef(1) = -numext::conj(src.z()) * invnm;
          perp.coeffRef(2) = numext::conj(src.y()) * invnm;
        }
        return perp;
      }
    };
    template <typename Derived>
    struct unitOrthogonal_selector<Derived, 2> {
      typedef typename plain_matrix_type<Derived>::type VectorType;
      static inline VectorType run(const Derived& src) {
        return VectorType(-numext::conj(src.y()), numext::conj(src.x())).normalized();
      }
    };
  }  // namespace internal
  template <typename Derived>
  typename MatrixBase<Derived>::PlainObject MatrixBase<Derived>::unitOrthogonal() const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    return internal::unitOrthogonal_selector<Derived>::run(derived());
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Derived>
  inline Matrix<typename MatrixBase<Derived>::Scalar, 3, 1> MatrixBase<Derived>::eulerAngles(Index a0,
                                                                                             Index a1,
                                                                                             Index a2) const {
    using std::atan2;
    using std::cos;
    using std::sin;
    static_assert(Derived::RowsAtCompileTime == 3 && Derived::ColsAtCompileTime == 3,
                  "THIS_METHOD_IS_ONLY_FOR_MATRICES_OF_A_SPECIFIC_SIZE");
    Matrix<Scalar, 3, 1> res;
    typedef Matrix<typename Derived::Scalar, 2, 1> Vector2;
    const Index odd = ((a0 + 1) % 3 == a1) ? 0 : 1;
    const Index i = a0;
    const Index j = (a0 + 1 + odd) % 3;
    const Index k = (a0 + 2 - odd) % 3;
    if (a0 == a2) {
      res[0] = atan2(coeff(j, i), coeff(k, i));
      if ((odd && res[0] < Scalar(0)) || ((!odd) && res[0] > Scalar(0))) {
        if (res[0] > Scalar(0)) {
          res[0] -= Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L);
        } else {
          res[0] += Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L);
        }
        Scalar s2 = Vector2(coeff(j, i), coeff(k, i)).norm();
        res[1] = -atan2(s2, coeff(i, i));
      } else {
        Scalar s2 = Vector2(coeff(j, i), coeff(k, i)).norm();
        res[1] = atan2(s2, coeff(i, i));
      }
      Scalar s1 = sin(res[0]);
      Scalar c1 = cos(res[0]);
      res[2] = atan2(c1 * coeff(j, k) - s1 * coeff(k, k), c1 * coeff(j, j) - s1 * coeff(k, j));
    } else {
      res[0] = atan2(coeff(j, k), coeff(k, k));
      Scalar c2 = Vector2(coeff(i, i), coeff(i, j)).norm();
      if ((odd && res[0] < Scalar(0)) || ((!odd) && res[0] > Scalar(0))) {
        if (res[0] > Scalar(0)) {
          res[0] -= Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L);
        } else {
          res[0] += Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L);
        }
        res[1] = atan2(-coeff(i, k), -c2);
      } else
        res[1] = atan2(-coeff(i, k), c2);
      Scalar s1 = sin(res[0]);
      Scalar c1 = cos(res[0]);
      res[2] = atan2(s1 * coeff(k, i) - c1 * coeff(j, i), c1 * coeff(j, j) - s1 * coeff(k, j));
    }
    if (!odd)
      res = -res;
    return res;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, int Direction>
    struct traits<Homogeneous<MatrixType, Direction>> : traits<MatrixType> {
      typedef typename traits<MatrixType>::StorageKind StorageKind;
      typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
      typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNested_;
      enum {
        RowsPlusOne = (MatrixType::RowsAtCompileTime != Dynamic) ? int(MatrixType::RowsAtCompileTime) + 1 : Dynamic,
        ColsPlusOne = (MatrixType::ColsAtCompileTime != Dynamic) ? int(MatrixType::ColsAtCompileTime) + 1 : Dynamic,
        RowsAtCompileTime = Direction == Vertical ? RowsPlusOne : MatrixType::RowsAtCompileTime,
        ColsAtCompileTime = Direction == Horizontal ? ColsPlusOne : MatrixType::ColsAtCompileTime,
        MaxRowsAtCompileTime = RowsAtCompileTime,
        MaxColsAtCompileTime = ColsAtCompileTime,
        TmpFlags = MatrixTypeNested_::Flags & HereditaryBits,
        Flags = ColsAtCompileTime == 1   ? (TmpFlags & ~RowMajorBit)
                : RowsAtCompileTime == 1 ? (TmpFlags | RowMajorBit)
                                         : TmpFlags
      };
    };
    template <typename MatrixType, typename Lhs>
    struct homogeneous_left_product_impl;
    template <typename MatrixType, typename Rhs>
    struct homogeneous_right_product_impl;
  }  // namespace internal
  template <typename MatrixType, int Direction_>
  class Homogeneous : public MatrixBase<Homogeneous<MatrixType, Direction_>>, internal::no_assignment_operator {
  public:
    typedef MatrixType NestedExpression;
    enum { Direction = Direction_ };
    typedef MatrixBase<Homogeneous> Base;
    typedef typename Eigen::internal::traits<Homogeneous>::Scalar Scalar;
    typedef typename Eigen::NumTraits<Scalar>::Real RealScalar;
    typedef typename Base::CoeffReturnType CoeffReturnType;
    typedef typename Eigen::internal::ref_selector<Homogeneous>::type Nested;
    typedef typename Eigen::internal::traits<Homogeneous>::StorageKind StorageKind;
    typedef typename Eigen::internal::traits<Homogeneous>::StorageIndex StorageIndex;
    enum CompileTimeTraits {
      RowsAtCompileTime = Eigen::internal::traits<Homogeneous>::RowsAtCompileTime,
      ColsAtCompileTime = Eigen::internal::traits<Homogeneous>::ColsAtCompileTime,
      Flags = Eigen::internal::traits<Homogeneous>::Flags,
      SizeAtCompileTime = Base::SizeAtCompileTime,
      MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,
      IsVectorAtCompileTime = Base::IsVectorAtCompileTime
    };
    using Base::const_cast_derived;
    using Base::derived;
    typedef typename Base::PacketScalar PacketScalar;
    explicit inline Homogeneous(const MatrixType& matrix) : m_matrix(matrix) {}
    constexpr inline Index rows() const noexcept { return m_matrix.rows() + (int(Direction) == Vertical ? 1 : 0); }
    constexpr inline Index cols() const noexcept { return m_matrix.cols() + (int(Direction) == Horizontal ? 1 : 0); }
    const NestedExpression& nestedExpression() const { return m_matrix; }
    template <typename Rhs>
    inline const Product<Homogeneous, Rhs> operator*(const MatrixBase<Rhs>& rhs) const {
      (static_cast<bool>(int(Direction) == Horizontal)
           ? void(0)
           : __assert_fail("int(Direction)==Horizontal",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/Homogeneous.h",
                           88,
                           __extension__ __PRETTY_FUNCTION__));
      return Product<Homogeneous, Rhs>(*this, rhs.derived());
    }
    template <typename Lhs>
    friend inline const Product<Lhs, Homogeneous> operator*(const MatrixBase<Lhs>& lhs, const Homogeneous& rhs) {
      (static_cast<bool>(int(Direction) == Vertical)
           ? void(0)
           : __assert_fail("int(Direction)==Vertical",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/Homogeneous.h",
                           96,
                           __extension__ __PRETTY_FUNCTION__));
      return Product<Lhs, Homogeneous>(lhs.derived(), rhs);
    }
    template <typename Scalar, int Dim, int Mode, int Options>
    friend inline const Product<Transform<Scalar, Dim, Mode, Options>, Homogeneous> operator*(
        const Transform<Scalar, Dim, Mode, Options>& lhs, const Homogeneous& rhs) {
      (static_cast<bool>(int(Direction) == Vertical)
           ? void(0)
           : __assert_fail("int(Direction)==Vertical",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/Homogeneous.h",
                           104,
                           __extension__ __PRETTY_FUNCTION__));
      return Product<Transform<Scalar, Dim, Mode, Options>, Homogeneous>(lhs, rhs);
    }
    template <typename Func>
    inline typename internal::result_of<Func(Scalar, Scalar)>::type redux(const Func& func) const {
      return func(m_matrix.redux(func), Scalar(1));
    }

  protected:
    typename MatrixType::Nested m_matrix;
  };
  template <typename Derived>
  inline typename MatrixBase<Derived>::HomogeneousReturnType MatrixBase<Derived>::homogeneous() const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return HomogeneousReturnType(derived());
  }
  template <typename ExpressionType, int Direction>
  inline Homogeneous<ExpressionType, Direction> VectorwiseOp<ExpressionType, Direction>::homogeneous() const {
    return HomogeneousReturnType(_expression());
  }
  template <typename Derived>
  inline const typename MatrixBase<Derived>::HNormalizedReturnType MatrixBase<Derived>::hnormalized() const {
    static_assert(Derived::IsVectorAtCompileTime, "YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX");
    ;
    return ConstStartMinusOne(
               derived(), 0, 0, ColsAtCompileTime == 1 ? size() - 1 : 1, ColsAtCompileTime == 1 ? 1 : size() - 1) /
           coeff(size() - 1);
  }
  template <typename ExpressionType, int Direction>
  inline const typename VectorwiseOp<ExpressionType, Direction>::HNormalizedReturnType
  VectorwiseOp<ExpressionType, Direction>::hnormalized() const {
    return HNormalized_Block(_expression(),
                             0,
                             0,
                             Direction == Vertical ? _expression().rows() - 1 : _expression().rows(),
                             Direction == Horizontal ? _expression().cols() - 1 : _expression().cols())
        .cwiseQuotient(Replicate < HNormalized_Factors,
                       Direction == Vertical ? HNormalized_SizeMinusOne : 1,
                       Direction == Horizontal
                           ? HNormalized_SizeMinusOne
                           : 1 > (HNormalized_Factors(_expression(),
                                                      Direction == Vertical ? _expression().rows() - 1 : 0,
                                                      Direction == Horizontal ? _expression().cols() - 1 : 0,
                                                      Direction == Vertical ? 1 : _expression().rows(),
                                                      Direction == Horizontal ? 1 : _expression().cols()),
                                  Direction == Vertical ? _expression().rows() - 1 : 1,
                                  Direction == Horizontal ? _expression().cols() - 1 : 1));
  }
  namespace internal {
    template <typename MatrixOrTransformType>
    struct take_matrix_for_product {
      typedef MatrixOrTransformType type;
      static const type& run(const type& x) { return x; }
    };
    template <typename Scalar, int Dim, int Mode, int Options>
    struct take_matrix_for_product<Transform<Scalar, Dim, Mode, Options>> {
      typedef Transform<Scalar, Dim, Mode, Options> TransformType;
      typedef std::add_const_t<typename TransformType::ConstAffinePart> type;
      static type run(const TransformType& x) { return x.affine(); }
    };
    template <typename Scalar, int Dim, int Options>
    struct take_matrix_for_product<Transform<Scalar, Dim, Projective, Options>> {
      typedef Transform<Scalar, Dim, Projective, Options> TransformType;
      typedef typename TransformType::MatrixType type;
      static const type& run(const TransformType& x) { return x.matrix(); }
    };
    template <typename MatrixType, typename Lhs>
    struct traits<homogeneous_left_product_impl<Homogeneous<MatrixType, Vertical>, Lhs>> {
      typedef typename take_matrix_for_product<Lhs>::type LhsMatrixType;
      typedef remove_all_t<MatrixType> MatrixTypeCleaned;
      typedef remove_all_t<LhsMatrixType> LhsMatrixTypeCleaned;
      typedef typename make_proper_matrix_type<typename traits<MatrixTypeCleaned>::Scalar,
                                               LhsMatrixTypeCleaned::RowsAtCompileTime,
                                               MatrixTypeCleaned::ColsAtCompileTime,
                                               MatrixTypeCleaned::PlainObject::Options,
                                               LhsMatrixTypeCleaned::MaxRowsAtCompileTime,
                                               MatrixTypeCleaned::MaxColsAtCompileTime>::type ReturnType;
    };
    template <typename MatrixType, typename Lhs>
    struct homogeneous_left_product_impl<Homogeneous<MatrixType, Vertical>, Lhs>
        : public ReturnByValue<homogeneous_left_product_impl<Homogeneous<MatrixType, Vertical>, Lhs>> {
      typedef typename traits<homogeneous_left_product_impl>::LhsMatrixType LhsMatrixType;
      typedef remove_all_t<LhsMatrixType> LhsMatrixTypeCleaned;
      typedef remove_all_t<typename LhsMatrixTypeCleaned::Nested> LhsMatrixTypeNested;
      homogeneous_left_product_impl(const Lhs& lhs, const MatrixType& rhs)
          : m_lhs(take_matrix_for_product<Lhs>::run(lhs)), m_rhs(rhs) {}
      constexpr inline Index rows() const noexcept { return m_lhs.rows(); }
      constexpr inline Index cols() const noexcept { return m_rhs.cols(); }
      template <typename Dest>
      void evalTo(Dest& dst) const {
        dst = Block < const LhsMatrixTypeNested, LhsMatrixTypeNested::RowsAtCompileTime,
        LhsMatrixTypeNested::ColsAtCompileTime == Dynamic
            ? Dynamic
            : LhsMatrixTypeNested::ColsAtCompileTime - 1 > (m_lhs, 0, 0, m_lhs.rows(), m_lhs.cols() - 1) * m_rhs;
        dst += m_lhs.col(m_lhs.cols() - 1).rowwise().template replicate<MatrixType::ColsAtCompileTime>(m_rhs.cols());
      }
      typename LhsMatrixTypeCleaned::Nested m_lhs;
      typename MatrixType::Nested m_rhs;
    };
    template <typename MatrixType, typename Rhs>
    struct traits<homogeneous_right_product_impl<Homogeneous<MatrixType, Horizontal>, Rhs>> {
      typedef typename make_proper_matrix_type<typename traits<MatrixType>::Scalar,
                                               MatrixType::RowsAtCompileTime,
                                               Rhs::ColsAtCompileTime,
                                               MatrixType::PlainObject::Options,
                                               MatrixType::MaxRowsAtCompileTime,
                                               Rhs::MaxColsAtCompileTime>::type ReturnType;
    };
    template <typename MatrixType, typename Rhs>
    struct homogeneous_right_product_impl<Homogeneous<MatrixType, Horizontal>, Rhs>
        : public ReturnByValue<homogeneous_right_product_impl<Homogeneous<MatrixType, Horizontal>, Rhs>> {
      typedef remove_all_t<typename Rhs::Nested> RhsNested;
      homogeneous_right_product_impl(const MatrixType& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {}
      constexpr inline Index rows() const noexcept { return m_lhs.rows(); }
      constexpr inline Index cols() const noexcept { return m_rhs.cols(); }
      template <typename Dest>
      void evalTo(Dest& dst) const {
        dst = m_lhs * Block < const RhsNested,
        RhsNested::RowsAtCompileTime == Dynamic ? Dynamic : RhsNested::RowsAtCompileTime - 1,
        RhsNested::ColsAtCompileTime > (m_rhs, 0, 0, m_rhs.rows() - 1, m_rhs.cols());
        dst += m_rhs.row(m_rhs.rows() - 1).colwise().template replicate<MatrixType::RowsAtCompileTime>(m_lhs.rows());
      }
      typename MatrixType::Nested m_lhs;
      typename Rhs::Nested m_rhs;
    };
    template <typename ArgType, int Direction>
    struct evaluator_traits<Homogeneous<ArgType, Direction>> {
      typedef typename storage_kind_to_evaluator_kind<typename ArgType::StorageKind>::Kind Kind;
      typedef HomogeneousShape Shape;
    };
    template <>
    struct AssignmentKind<DenseShape, HomogeneousShape> {
      typedef Dense2Dense Kind;
    };
    template <typename ArgType, int Direction>
    struct unary_evaluator<Homogeneous<ArgType, Direction>, IndexBased>
        : evaluator<typename Homogeneous<ArgType, Direction>::PlainObject> {
      typedef Homogeneous<ArgType, Direction> XprType;
      typedef typename XprType::PlainObject PlainObject;
      typedef evaluator<PlainObject> Base;
      explicit unary_evaluator(const XprType& op) : Base(), m_temp(op) { internal::construct_at<Base>(this, m_temp); }

    protected:
      PlainObject m_temp;
    };
    template <typename DstXprType, typename ArgType, typename Scalar>
    struct Assignment<DstXprType,
                      Homogeneous<ArgType, Vertical>,
                      internal::assign_op<Scalar, typename ArgType::Scalar>,
                      Dense2Dense> {
      typedef Homogeneous<ArgType, Vertical> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<Scalar, typename ArgType::Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        dst.template topRows<ArgType::RowsAtCompileTime>(src.nestedExpression().rows()) = src.nestedExpression();
        dst.row(dst.rows() - 1).setOnes();
      }
    };
    template <typename DstXprType, typename ArgType, typename Scalar>
    struct Assignment<DstXprType,
                      Homogeneous<ArgType, Horizontal>,
                      internal::assign_op<Scalar, typename ArgType::Scalar>,
                      Dense2Dense> {
      typedef Homogeneous<ArgType, Horizontal> SrcXprType;
      static void run(DstXprType& dst,
                      const SrcXprType& src,
                      const internal::assign_op<Scalar, typename ArgType::Scalar>&) {
        Index dstRows = src.rows();
        Index dstCols = src.cols();
        if ((dst.rows() != dstRows) || (dst.cols() != dstCols))
          dst.resize(dstRows, dstCols);
        dst.template leftCols<ArgType::ColsAtCompileTime>(src.nestedExpression().cols()) = src.nestedExpression();
        dst.col(dst.cols() - 1).setOnes();
      }
    };
    template <typename LhsArg, typename Rhs, int ProductTag>
    struct generic_product_impl<Homogeneous<LhsArg, Horizontal>, Rhs, HomogeneousShape, DenseShape, ProductTag> {
      template <typename Dest>
      static void evalTo(Dest& dst, const Homogeneous<LhsArg, Horizontal>& lhs, const Rhs& rhs) {
        homogeneous_right_product_impl<Homogeneous<LhsArg, Horizontal>, Rhs>(lhs.nestedExpression(), rhs).evalTo(dst);
      }
    };
    template <typename Lhs, typename Rhs>
    struct homogeneous_right_product_refactoring_helper {
      enum { Dim = Lhs::ColsAtCompileTime, Rows = Lhs::RowsAtCompileTime };
      typedef typename Rhs::template ConstNRowsBlockXpr<Dim>::Type LinearBlockConst;
      typedef std::remove_const_t<LinearBlockConst> LinearBlock;
      typedef typename Rhs::ConstRowXpr ConstantColumn;
      typedef Replicate<const ConstantColumn, Rows, 1> ConstantBlock;
      typedef Product<Lhs, LinearBlock, LazyProduct> LinearProduct;
      typedef CwiseBinaryOp<internal::scalar_sum_op<typename Lhs::Scalar, typename Rhs::Scalar>,
                            const LinearProduct,
                            const ConstantBlock>
          Xpr;
    };
    template <typename Lhs, typename Rhs, int ProductTag>
    struct product_evaluator<Product<Lhs, Rhs, LazyProduct>, ProductTag, HomogeneousShape, DenseShape>
        : public evaluator<
              typename homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression, Rhs>::Xpr> {
      typedef Product<Lhs, Rhs, LazyProduct> XprType;
      typedef homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression, Rhs> helper;
      typedef typename helper::ConstantBlock ConstantBlock;
      typedef typename helper::Xpr RefactoredXpr;
      typedef evaluator<RefactoredXpr> Base;
      explicit product_evaluator(const XprType& xpr)
          : Base(xpr.lhs().nestedExpression().lazyProduct(
                     xpr.rhs().template topRows<helper::Dim>(xpr.lhs().nestedExpression().cols())) +
                 ConstantBlock(xpr.rhs().row(xpr.rhs().rows() - 1), xpr.lhs().rows(), 1)) {}
    };
    template <typename Lhs, typename RhsArg, int ProductTag>
    struct generic_product_impl<Lhs, Homogeneous<RhsArg, Vertical>, DenseShape, HomogeneousShape, ProductTag> {
      template <typename Dest>
      static void evalTo(Dest& dst, const Lhs& lhs, const Homogeneous<RhsArg, Vertical>& rhs) {
        homogeneous_left_product_impl<Homogeneous<RhsArg, Vertical>, Lhs>(lhs, rhs.nestedExpression()).evalTo(dst);
      }
    };
    template <typename Lhs, typename RhsArg, int ProductTag>
    struct generic_product_impl<Lhs, Homogeneous<RhsArg, Vertical>, TriangularShape, HomogeneousShape, ProductTag> {
      template <typename Dest>
      static void evalTo(Dest& dst, const Lhs& lhs, const Homogeneous<RhsArg, Vertical>& rhs) {
        dst.noalias() = lhs * rhs.eval();
      }
    };
    template <typename Lhs, typename Rhs>
    struct homogeneous_left_product_refactoring_helper {
      enum { Dim = Rhs::RowsAtCompileTime, Cols = Rhs::ColsAtCompileTime };
      typedef typename Lhs::template ConstNColsBlockXpr<Dim>::Type LinearBlockConst;
      typedef std::remove_const_t<LinearBlockConst> LinearBlock;
      typedef typename Lhs::ConstColXpr ConstantColumn;
      typedef Replicate<const ConstantColumn, 1, Cols> ConstantBlock;
      typedef Product<LinearBlock, Rhs, LazyProduct> LinearProduct;
      typedef CwiseBinaryOp<internal::scalar_sum_op<typename Lhs::Scalar, typename Rhs::Scalar>,
                            const LinearProduct,
                            const ConstantBlock>
          Xpr;
    };
    template <typename Lhs, typename Rhs, int ProductTag>
    struct product_evaluator<Product<Lhs, Rhs, LazyProduct>, ProductTag, DenseShape, HomogeneousShape>
        : public evaluator<
              typename homogeneous_left_product_refactoring_helper<Lhs, typename Rhs::NestedExpression>::Xpr> {
      typedef Product<Lhs, Rhs, LazyProduct> XprType;
      typedef homogeneous_left_product_refactoring_helper<Lhs, typename Rhs::NestedExpression> helper;
      typedef typename helper::ConstantBlock ConstantBlock;
      typedef typename helper::Xpr RefactoredXpr;
      typedef evaluator<RefactoredXpr> Base;
      explicit product_evaluator(const XprType& xpr)
          : Base(xpr.lhs()
                     .template leftCols<helper::Dim>(xpr.rhs().nestedExpression().rows())
                     .lazyProduct(xpr.rhs().nestedExpression()) +
                 ConstantBlock(xpr.lhs().col(xpr.lhs().cols() - 1), 1, xpr.rhs().cols())) {}
    };
    template <typename Scalar, int Dim, int Mode, int Options, typename RhsArg, int ProductTag>
    struct generic_product_impl<Transform<Scalar, Dim, Mode, Options>,
                                Homogeneous<RhsArg, Vertical>,
                                DenseShape,
                                HomogeneousShape,
                                ProductTag> {
      typedef Transform<Scalar, Dim, Mode, Options> TransformType;
      template <typename Dest>
      static void evalTo(Dest& dst, const TransformType& lhs, const Homogeneous<RhsArg, Vertical>& rhs) {
        homogeneous_left_product_impl<Homogeneous<RhsArg, Vertical>, TransformType>(lhs, rhs.nestedExpression())
            .evalTo(dst);
      }
    };
    template <typename ExpressionType, int Side, bool Transposed>
    struct permutation_matrix_product<ExpressionType, Side, Transposed, HomogeneousShape>
        : public permutation_matrix_product<ExpressionType, Side, Transposed, DenseShape> {};
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename RotationDerived, typename MatrixType, bool IsVector = MatrixType::IsVectorAtCompileTime>
    struct rotation_base_generic_product_selector;
  }
  template <typename Derived, int Dim_>
  class RotationBase {
  public:
    enum { Dim = Dim_ };
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef Matrix<Scalar, Dim, Dim> RotationMatrixType;
    typedef Matrix<Scalar, Dim, 1> VectorType;

  public:
    inline const Derived& derived() const { return *static_cast<const Derived*>(this); }
    inline Derived& derived() { return *static_cast<Derived*>(this); }
    inline RotationMatrixType toRotationMatrix() const { return derived().toRotationMatrix(); }
    inline RotationMatrixType matrix() const { return derived().toRotationMatrix(); }
    inline Derived inverse() const { return derived().inverse(); }
    inline Transform<Scalar, Dim, Isometry> operator*(const Translation<Scalar, Dim>& t) const {
      return Transform<Scalar, Dim, Isometry>(*this) * t;
    }
    inline RotationMatrixType operator*(const UniformScaling<Scalar>& s) const {
      return toRotationMatrix() * s.factor();
    }
    template <typename OtherDerived>
    inline typename internal::
        rotation_base_generic_product_selector<Derived, OtherDerived, OtherDerived::IsVectorAtCompileTime>::ReturnType
        operator*(const EigenBase<OtherDerived>& e) const {
      return internal::rotation_base_generic_product_selector<Derived, OtherDerived>::run(derived(), e.derived());
    }
    template <typename OtherDerived>
    friend inline RotationMatrixType operator*(const EigenBase<OtherDerived>& l, const Derived& r) {
      return l.derived() * r.toRotationMatrix();
    }
    friend inline Transform<Scalar, Dim, Affine> operator*(const DiagonalMatrix<Scalar, Dim>& l, const Derived& r) {
      Transform<Scalar, Dim, Affine> res(r);
      res.linear().applyOnTheLeft(l);
      return res;
    }
    template <int Mode, int Options>
    inline Transform<Scalar, Dim, Mode> operator*(const Transform<Scalar, Dim, Mode, Options>& t) const {
      return toRotationMatrix() * t;
    }
    template <typename OtherVectorType>
    inline VectorType _transformVector(const OtherVectorType& v) const {
      return toRotationMatrix() * v;
    }
  };
  namespace internal {
    template <typename RotationDerived, typename MatrixType>
    struct rotation_base_generic_product_selector<RotationDerived, MatrixType, false> {
      enum { Dim = RotationDerived::Dim };
      typedef Matrix<typename RotationDerived::Scalar, Dim, Dim> ReturnType;
      static inline ReturnType run(const RotationDerived& r, const MatrixType& m) { return r.toRotationMatrix() * m; }
    };
    template <typename RotationDerived, typename Scalar, int Dim, int MaxDim>
    struct rotation_base_generic_product_selector<RotationDerived, DiagonalMatrix<Scalar, Dim, MaxDim>, false> {
      typedef Transform<Scalar, Dim, Affine> ReturnType;
      static inline ReturnType run(const RotationDerived& r, const DiagonalMatrix<Scalar, Dim, MaxDim>& m) {
        ReturnType res(r);
        res.linear() *= m;
        return res;
      }
    };
    template <typename RotationDerived, typename OtherVectorType>
    struct rotation_base_generic_product_selector<RotationDerived, OtherVectorType, true> {
      enum { Dim = RotationDerived::Dim };
      typedef Matrix<typename RotationDerived::Scalar, Dim, 1> ReturnType;
      static inline ReturnType run(const RotationDerived& r, const OtherVectorType& v) { return r._transformVector(v); }
    };
  }  // namespace internal
  template <typename Scalar_, int Rows_, int Cols_, int Storage_, int MaxRows_, int MaxCols_>
  template <typename OtherDerived>
  Matrix<Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_>::Matrix(
      const RotationBase<OtherDerived, ColsAtCompileTime>& r) {
    static_assert(
        Matrix::RowsAtCompileTime == int(OtherDerived::Dim) && Matrix::ColsAtCompileTime == int(OtherDerived::Dim),
        "THIS_METHOD_IS_ONLY_FOR_MATRICES_OF_A_SPECIFIC_SIZE");
    *this = r.toRotationMatrix();
  }
  template <typename Scalar_, int Rows_, int Cols_, int Storage_, int MaxRows_, int MaxCols_>
  template <typename OtherDerived>
  Matrix<Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_>&
  Matrix<Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_>::operator=(
      const RotationBase<OtherDerived, ColsAtCompileTime>& r) {
    static_assert(
        Matrix::RowsAtCompileTime == int(OtherDerived::Dim) && Matrix::ColsAtCompileTime == int(OtherDerived::Dim),
        "THIS_METHOD_IS_ONLY_FOR_MATRICES_OF_A_SPECIFIC_SIZE");
    return *this = r.toRotationMatrix();
  }
  namespace internal {
    template <typename Scalar, int Dim>
    static inline Matrix<Scalar, 2, 2> toRotationMatrix(const Scalar& s) {
      static_assert(Dim == 2, "YOU_MADE_A_PROGRAMMING_MISTAKE");
      return Rotation2D<Scalar>(s).toRotationMatrix();
    }
    template <typename Scalar, int Dim, typename OtherDerived>
    static inline Matrix<Scalar, Dim, Dim> toRotationMatrix(const RotationBase<OtherDerived, Dim>& r) {
      return r.toRotationMatrix();
    }
    template <typename Scalar, int Dim, typename OtherDerived>
    static inline const MatrixBase<OtherDerived>& toRotationMatrix(const MatrixBase<OtherDerived>& mat) {
      static_assert(OtherDerived::RowsAtCompileTime == Dim && OtherDerived::ColsAtCompileTime == Dim,
                    "YOU_MADE_A_PROGRAMMING_MISTAKE");
      return mat;
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar_>
    struct traits<Rotation2D<Scalar_>> {
      typedef Scalar_ Scalar;
    };
  }  // namespace internal
  template <typename Scalar_>
  class Rotation2D : public RotationBase<Rotation2D<Scalar_>, 2> {
    typedef RotationBase<Rotation2D<Scalar_>, 2> Base;

  public:
    using Base::operator*;
    enum { Dim = 2 };
    typedef Scalar_ Scalar;
    typedef Matrix<Scalar, 2, 1> Vector2;
    typedef Matrix<Scalar, 2, 2> Matrix2;

  protected:
    Scalar m_angle;

  public:
    explicit inline Rotation2D(const Scalar& a) : m_angle(a) {}
    Rotation2D() {}
    template <typename Derived>
    explicit Rotation2D(const MatrixBase<Derived>& m) {
      fromRotationMatrix(m.derived());
    }
    inline Scalar angle() const { return m_angle; }
    inline Scalar& angle() { return m_angle; }
    inline Scalar smallestPositiveAngle() const {
      Scalar tmp = numext::fmod(
          m_angle, Scalar(2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L));
      return tmp < Scalar(0)
                 ? tmp + Scalar(2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L)
                 : tmp;
    }
    inline Scalar smallestAngle() const {
      Scalar tmp = numext::fmod(
          m_angle, Scalar(2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L));
      if (tmp > Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L))
        tmp -= Scalar(2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L);
      else if (tmp < -Scalar(3.141592653589793238462643383279502884197169399375105820974944592307816406L))
        tmp += Scalar(2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L);
      return tmp;
    }
    inline Rotation2D inverse() const { return Rotation2D(-m_angle); }
    inline Rotation2D operator*(const Rotation2D& other) const { return Rotation2D(m_angle + other.m_angle); }
    inline Rotation2D& operator*=(const Rotation2D& other) {
      m_angle += other.m_angle;
      return *this;
    }
    Vector2 operator*(const Vector2& vec) const { return toRotationMatrix() * vec; }
    template <typename Derived>
    Rotation2D& fromRotationMatrix(const MatrixBase<Derived>& m);
    Matrix2 toRotationMatrix() const;
    template <typename Derived>
    Rotation2D& operator=(const MatrixBase<Derived>& m) {
      return fromRotationMatrix(m.derived());
    }
    inline Rotation2D slerp(const Scalar& t, const Rotation2D& other) const {
      Scalar dist = Rotation2D(other.m_angle - m_angle).smallestAngle();
      return Rotation2D(m_angle + dist * t);
    }
    template <typename NewScalarType>
    inline typename internal::cast_return_type<Rotation2D, Rotation2D<NewScalarType>>::type cast() const {
      return typename internal::cast_return_type<Rotation2D, Rotation2D<NewScalarType>>::type(*this);
    }
    template <typename OtherScalarType>
    inline explicit Rotation2D(const Rotation2D<OtherScalarType>& other) {
      m_angle = Scalar(other.angle());
    }
    static inline Rotation2D Identity() { return Rotation2D(0); }
    bool isApprox(const Rotation2D& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return internal::isApprox(m_angle, other.m_angle, prec);
    }
  };
  typedef Rotation2D<float> Rotation2Df;
  typedef Rotation2D<double> Rotation2Dd;
  template <typename Scalar>
  template <typename Derived>
  Rotation2D<Scalar>& Rotation2D<Scalar>::fromRotationMatrix(const MatrixBase<Derived>& mat) {
    using std::atan2;
    static_assert(Derived::RowsAtCompileTime == 2 && Derived::ColsAtCompileTime == 2, "YOU_MADE_A_PROGRAMMING_MISTAKE");
    m_angle = atan2(mat.coeff(1, 0), mat.coeff(0, 0));
    return *this;
  }
  template <typename Scalar>
  typename Rotation2D<Scalar>::Matrix2 Rotation2D<Scalar>::toRotationMatrix(void) const {
    using std::cos;
    using std::sin;
    Scalar sinA = sin(m_angle);
    Scalar cosA = cos(m_angle);
    return (Matrix2() << cosA, -sinA, sinA, cosA).finished();
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Other, int OtherRows = Other::RowsAtCompileTime, int OtherCols = Other::ColsAtCompileTime>
    struct quaternionbase_assign_impl;
  }
  template <class Derived>
  class QuaternionBase : public RotationBase<Derived, 3> {
  public:
    typedef RotationBase<Derived, 3> Base;
    using Base::operator*;
    using Base::derived;
    typedef typename internal::traits<Derived>::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef typename internal::traits<Derived>::Coefficients Coefficients;
    typedef typename Coefficients::CoeffReturnType CoeffReturnType;
    typedef std::conditional_t<bool(internal::traits<Derived>::Flags& LvalueBit), Scalar&, CoeffReturnType>
        NonConstCoeffReturnType;
    enum { Flags = Eigen::internal::traits<Derived>::Flags };
    typedef Matrix<Scalar, 3, 1> Vector3;
    typedef Matrix<Scalar, 3, 3> Matrix3;
    typedef AngleAxis<Scalar> AngleAxisType;
    inline CoeffReturnType x() const { return this->derived().coeffs().coeff(0); }
    inline CoeffReturnType y() const { return this->derived().coeffs().coeff(1); }
    inline CoeffReturnType z() const { return this->derived().coeffs().coeff(2); }
    inline CoeffReturnType w() const { return this->derived().coeffs().coeff(3); }
    inline NonConstCoeffReturnType x() { return this->derived().coeffs().x(); }
    inline NonConstCoeffReturnType y() { return this->derived().coeffs().y(); }
    inline NonConstCoeffReturnType z() { return this->derived().coeffs().z(); }
    inline NonConstCoeffReturnType w() { return this->derived().coeffs().w(); }
    inline const VectorBlock<const Coefficients, 3> vec() const { return coeffs().template head<3>(); }
    inline VectorBlock<Coefficients, 3> vec() { return coeffs().template head<3>(); }
    inline const typename internal::traits<Derived>::Coefficients& coeffs() const { return derived().coeffs(); }
    inline typename internal::traits<Derived>::Coefficients& coeffs() { return derived().coeffs(); }
    inline QuaternionBase<Derived>& operator=(const QuaternionBase<Derived>& other);
    template <class OtherDerived>
    inline Derived& operator=(const QuaternionBase<OtherDerived>& other);
    Derived& operator=(const AngleAxisType& aa);
    template <class OtherDerived>
    Derived& operator=(const MatrixBase<OtherDerived>& m);
    static inline Quaternion<Scalar> Identity() {
      return Quaternion<Scalar>(Scalar(1), Scalar(0), Scalar(0), Scalar(0));
    }
    inline QuaternionBase& setIdentity() {
      coeffs() << Scalar(0), Scalar(0), Scalar(0), Scalar(1);
      return *this;
    }
    inline Scalar squaredNorm() const { return coeffs().squaredNorm(); }
    inline Scalar norm() const { return coeffs().norm(); }
    inline void normalize() { coeffs().normalize(); }
    inline Quaternion<Scalar> normalized() const { return Quaternion<Scalar>(coeffs().normalized()); }
    template <class OtherDerived>
    inline Scalar dot(const QuaternionBase<OtherDerived>& other) const {
      return coeffs().dot(other.coeffs());
    }
    template <class OtherDerived>
    Scalar angularDistance(const QuaternionBase<OtherDerived>& other) const;
    inline Matrix3 toRotationMatrix() const;
    template <typename Derived1, typename Derived2>
    Derived& setFromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b);
    template <class OtherDerived>
    inline Quaternion<Scalar> operator*(const QuaternionBase<OtherDerived>& q) const;
    template <class OtherDerived>
    inline Derived& operator*=(const QuaternionBase<OtherDerived>& q);
    Quaternion<Scalar> inverse() const;
    Quaternion<Scalar> conjugate() const;
    template <class OtherDerived>
    Quaternion<Scalar> slerp(const Scalar& t, const QuaternionBase<OtherDerived>& other) const;
    template <class OtherDerived>
    inline bool operator==(const QuaternionBase<OtherDerived>& other) const {
      return coeffs() == other.coeffs();
    }
    template <class OtherDerived>
    inline bool operator!=(const QuaternionBase<OtherDerived>& other) const {
      return coeffs() != other.coeffs();
    }
    template <class OtherDerived>
    bool isApprox(const QuaternionBase<OtherDerived>& other,
                  const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const {
      return coeffs().isApprox(other.coeffs(), prec);
    }
    inline Vector3 _transformVector(const Vector3& v) const;
    template <typename NewScalarType>
    inline std::enable_if_t<internal::is_same<Scalar, NewScalarType>::value, const Derived&> cast() const {
      return derived();
    }
    template <typename NewScalarType>
    inline std::enable_if_t<!internal::is_same<Scalar, NewScalarType>::value, Quaternion<NewScalarType>> cast() const {
      return Quaternion<NewScalarType>(coeffs().template cast<NewScalarType>());
    }
    friend std::ostream& operator<<(std::ostream& s, const QuaternionBase<Derived>& q) {
      s << q.x() << "i + " << q.y() << "j + " << q.z() << "k"
        << " + " << q.w();
      return s;
    }

  protected:
    QuaternionBase(const QuaternionBase&) = default;
    QuaternionBase() = default;
    ~QuaternionBase() = default;
  };
  namespace internal {
    template <typename Scalar_, int Options_>
    struct traits<Quaternion<Scalar_, Options_>> {
      typedef Quaternion<Scalar_, Options_> PlainObject;
      typedef Scalar_ Scalar;
      typedef Matrix<Scalar_, 4, 1, Options_> Coefficients;
      enum { Alignment = internal::traits<Coefficients>::Alignment, Flags = LvalueBit };
    };
  }  // namespace internal
  template <typename Scalar_, int Options_>
  class Quaternion : public QuaternionBase<Quaternion<Scalar_, Options_>> {
  public:
    typedef QuaternionBase<Quaternion<Scalar_, Options_>> Base;
    enum { NeedsAlignment = internal::traits<Quaternion>::Alignment > 0 };
    typedef Scalar_ Scalar;
    using Base::operator=;
    inline Quaternion& operator=(const Quaternion& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Quaternion& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Quaternion(const Quaternion&) = default;
    using Base::operator*=;
    typedef typename internal::traits<Quaternion>::Coefficients Coefficients;
    typedef typename Base::AngleAxisType AngleAxisType;
    inline Quaternion() {}
    inline Quaternion(const Scalar& w, const Scalar& x, const Scalar& y, const Scalar& z) : m_coeffs(x, y, z, w) {}
    explicit inline Quaternion(const Scalar* data) : m_coeffs(data) {}
    template <class Derived>
    inline Quaternion(const QuaternionBase<Derived>& other) {
      this->Base::operator=(other);
    }
    explicit inline Quaternion(const AngleAxisType& aa) { *this = aa; }
    template <typename Derived>
    explicit inline Quaternion(const MatrixBase<Derived>& other) {
      *this = other;
    }
    template <typename OtherScalar, int OtherOptions>
    explicit inline Quaternion(const Quaternion<OtherScalar, OtherOptions>& other) {
      m_coeffs = other.coeffs().template cast<Scalar>();
    }
    inline Quaternion(Quaternion&& other) noexcept(std::is_nothrow_move_constructible<Scalar>::value)
        : m_coeffs(std::move(other.coeffs())) {}
    Quaternion& operator=(Quaternion&& other) noexcept(std::is_nothrow_move_assignable<Scalar>::value) {
      m_coeffs = std::move(other.coeffs());
      return *this;
    }
    static Quaternion UnitRandom();
    template <typename Derived1, typename Derived2>
    static Quaternion FromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b);
    inline Coefficients& coeffs() { return m_coeffs; }
    inline const Coefficients& coeffs() const { return m_coeffs; }

  protected:
    Coefficients m_coeffs;
    static_assert((Options_ & DontAlign) == Options_, "INVALID_MATRIX_TEMPLATE_PARAMETERS");
  };
  typedef Quaternion<float> Quaternionf;
  typedef Quaternion<double> Quaterniond;
  namespace internal {
    template <typename Scalar_, int Options_>
    struct traits<Map<Quaternion<Scalar_>, Options_>>
        : traits<Quaternion<Scalar_, (int(Options_) & Aligned) == Aligned ? AutoAlign : DontAlign>> {
      typedef Map<Matrix<Scalar_, 4, 1>, Options_> Coefficients;
    };
  }  // namespace internal
  namespace internal {
    template <typename Scalar_, int Options_>
    struct traits<Map<const Quaternion<Scalar_>, Options_>>
        : traits<Quaternion<Scalar_, (int(Options_) & Aligned) == Aligned ? AutoAlign : DontAlign>> {
      typedef Map<const Matrix<Scalar_, 4, 1>, Options_> Coefficients;
      typedef traits<Quaternion<Scalar_, (int(Options_) & Aligned) == Aligned ? AutoAlign : DontAlign>> TraitsBase;
      enum { Flags = TraitsBase::Flags & ~LvalueBit };
    };
  }  // namespace internal
  template <typename Scalar_, int Options_>
  class Map<const Quaternion<Scalar_>, Options_> : public QuaternionBase<Map<const Quaternion<Scalar_>, Options_>> {
  public:
    typedef QuaternionBase<Map<const Quaternion<Scalar_>, Options_>> Base;
    typedef Scalar_ Scalar;
    typedef typename internal::traits<Map>::Coefficients Coefficients;
    using Base::operator=;
    inline Map& operator=(const Map& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Map& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Map(const Map&) = default;
    using Base::operator*=;
    explicit inline Map(const Scalar* coeffs) : m_coeffs(coeffs) {}
    inline const Coefficients& coeffs() const { return m_coeffs; }

  protected:
    const Coefficients m_coeffs;
  };
  template <typename Scalar_, int Options_>
  class Map<Quaternion<Scalar_>, Options_> : public QuaternionBase<Map<Quaternion<Scalar_>, Options_>> {
  public:
    typedef QuaternionBase<Map<Quaternion<Scalar_>, Options_>> Base;
    typedef Scalar_ Scalar;
    typedef typename internal::traits<Map>::Coefficients Coefficients;
    using Base::operator=;
    inline Map& operator=(const Map& other) {
      Base::operator=(other);
      return *this;
    }
    template <typename OtherDerived>
    inline Map& operator=(const DenseBase<OtherDerived>& other) {
      Base::operator=(other.derived());
      return *this;
    }
    Map(const Map&) = default;
    using Base::operator*=;
    explicit inline Map(Scalar* coeffs) : m_coeffs(coeffs) {}
    inline Coefficients& coeffs() { return m_coeffs; }
    inline const Coefficients& coeffs() const { return m_coeffs; }

  protected:
    Coefficients m_coeffs;
  };
  typedef Map<Quaternion<float>, 0> QuaternionMapf;
  typedef Map<Quaternion<double>, 0> QuaternionMapd;
  typedef Map<Quaternion<float>, Aligned> QuaternionMapAlignedf;
  typedef Map<Quaternion<double>, Aligned> QuaternionMapAlignedd;
  namespace internal {
    template <int Arch, class Derived1, class Derived2, typename Scalar>
    struct quat_product {
      static inline Quaternion<Scalar> run(const QuaternionBase<Derived1>& a, const QuaternionBase<Derived2>& b) {
        return Quaternion<Scalar>(a.w() * b.w() - a.x() * b.x() - a.y() * b.y() - a.z() * b.z(),
                                  a.w() * b.x() + a.x() * b.w() + a.y() * b.z() - a.z() * b.y(),
                                  a.w() * b.y() + a.y() * b.w() + a.z() * b.x() - a.x() * b.z(),
                                  a.w() * b.z() + a.z() * b.w() + a.x() * b.y() - a.y() * b.x());
      }
    };
  }  // namespace internal
  template <class Derived>
  template <class OtherDerived>
  inline Quaternion<typename internal::traits<Derived>::Scalar> QuaternionBase<Derived>::operator*(
      const QuaternionBase<OtherDerived>& other) const {
    static_assert((internal::is_same<typename Derived::Scalar, typename OtherDerived::Scalar>::value),
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    return internal::
        quat_product<Architecture::Target, Derived, OtherDerived, typename internal::traits<Derived>::Scalar>::run(
            *this, other);
  }
  template <class Derived>
  template <class OtherDerived>
  inline Derived& QuaternionBase<Derived>::operator*=(const QuaternionBase<OtherDerived>& other) {
    derived() = derived() * other.derived();
    return derived();
  }
  template <class Derived>
  inline typename QuaternionBase<Derived>::Vector3 QuaternionBase<Derived>::_transformVector(const Vector3& v) const {
    Vector3 uv = this->vec().cross(v);
    uv += uv;
    return v + this->w() * uv + this->vec().cross(uv);
  }
  template <class Derived>
  inline QuaternionBase<Derived>& QuaternionBase<Derived>::operator=(const QuaternionBase<Derived>& other) {
    coeffs() = other.coeffs();
    return derived();
  }
  template <class Derived>
  template <class OtherDerived>
  inline Derived& QuaternionBase<Derived>::operator=(const QuaternionBase<OtherDerived>& other) {
    coeffs() = other.coeffs();
    return derived();
  }
  template <class Derived>
  inline Derived& QuaternionBase<Derived>::operator=(const AngleAxisType& aa) {
    using std::cos;
    using std::sin;
    Scalar ha = Scalar(0.5) * aa.angle();
    this->w() = cos(ha);
    this->vec() = sin(ha) * aa.axis();
    return derived();
  }
  template <class Derived>
  template <class MatrixDerived>
  inline Derived& QuaternionBase<Derived>::operator=(const MatrixBase<MatrixDerived>& xpr) {
    static_assert((internal::is_same<typename Derived::Scalar, typename MatrixDerived::Scalar>::value),
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    internal::quaternionbase_assign_impl<MatrixDerived>::run(*this, xpr.derived());
    return derived();
  }
  template <class Derived>
  inline typename QuaternionBase<Derived>::Matrix3 QuaternionBase<Derived>::toRotationMatrix(void) const {
    Matrix3 res;
    const Scalar tx = Scalar(2) * this->x();
    const Scalar ty = Scalar(2) * this->y();
    const Scalar tz = Scalar(2) * this->z();
    const Scalar twx = tx * this->w();
    const Scalar twy = ty * this->w();
    const Scalar twz = tz * this->w();
    const Scalar txx = tx * this->x();
    const Scalar txy = ty * this->x();
    const Scalar txz = tz * this->x();
    const Scalar tyy = ty * this->y();
    const Scalar tyz = tz * this->y();
    const Scalar tzz = tz * this->z();
    res.coeffRef(0, 0) = Scalar(1) - (tyy + tzz);
    res.coeffRef(0, 1) = txy - twz;
    res.coeffRef(0, 2) = txz + twy;
    res.coeffRef(1, 0) = txy + twz;
    res.coeffRef(1, 1) = Scalar(1) - (txx + tzz);
    res.coeffRef(1, 2) = tyz - twx;
    res.coeffRef(2, 0) = txz - twy;
    res.coeffRef(2, 1) = tyz + twx;
    res.coeffRef(2, 2) = Scalar(1) - (txx + tyy);
    return res;
  }
  template <class Derived>
  template <typename Derived1, typename Derived2>
  inline Derived& QuaternionBase<Derived>::setFromTwoVectors(const MatrixBase<Derived1>& a,
                                                             const MatrixBase<Derived2>& b) {
    using std::sqrt;
    Vector3 v0 = a.normalized();
    Vector3 v1 = b.normalized();
    Scalar c = v1.dot(v0);
    if (c < Scalar(-1) + NumTraits<Scalar>::dummy_precision()) {
      c = numext::maxi(c, Scalar(-1));
      Matrix<Scalar, 2, 3> m;
      m << v0.transpose(), v1.transpose();
      JacobiSVD<Matrix<Scalar, 2, 3>, ComputeFullV> svd(m);
      Vector3 axis = svd.matrixV().col(2);
      Scalar w2 = (Scalar(1) + c) * Scalar(0.5);
      this->w() = sqrt(w2);
      this->vec() = axis * sqrt(Scalar(1) - w2);
      return derived();
    }
    Vector3 axis = v0.cross(v1);
    Scalar s = sqrt((Scalar(1) + c) * Scalar(2));
    Scalar invs = Scalar(1) / s;
    this->vec() = axis * invs;
    this->w() = s * Scalar(0.5);
    return derived();
  }
  template <typename Scalar, int Options>
  Quaternion<Scalar, Options> Quaternion<Scalar, Options>::UnitRandom() {
    using std::cos;
    using std::sin;
    using std::sqrt;
    const Scalar u1 = internal::random<Scalar>(0, 1),
                 u2 = internal::random<Scalar>(
                     0, 2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L),
                 u3 = internal::random<Scalar>(
                     0, 2 * 3.141592653589793238462643383279502884197169399375105820974944592307816406L);
    const Scalar a = sqrt(Scalar(1) - u1), b = sqrt(u1);
    return Quaternion(a * sin(u2), a * cos(u2), b * sin(u3), b * cos(u3));
  }
  template <typename Scalar, int Options>
  template <typename Derived1, typename Derived2>
  Quaternion<Scalar, Options> Quaternion<Scalar, Options>::FromTwoVectors(const MatrixBase<Derived1>& a,
                                                                          const MatrixBase<Derived2>& b) {
    Quaternion quat;
    quat.setFromTwoVectors(a, b);
    return quat;
  }
  template <class Derived>
  inline Quaternion<typename internal::traits<Derived>::Scalar> QuaternionBase<Derived>::inverse() const {
    Scalar n2 = this->squaredNorm();
    if (n2 > Scalar(0))
      return Quaternion<Scalar>(conjugate().coeffs() / n2);
    else {
      return Quaternion<Scalar>(Coefficients::Zero());
    }
  }
  namespace internal {
    template <int Arch, class Derived, typename Scalar>
    struct quat_conj {
      static inline Quaternion<Scalar> run(const QuaternionBase<Derived>& q) {
        return Quaternion<Scalar>(q.w(), -q.x(), -q.y(), -q.z());
      }
    };
  }  // namespace internal
  template <class Derived>
  inline Quaternion<typename internal::traits<Derived>::Scalar> QuaternionBase<Derived>::conjugate() const {
    return internal::quat_conj<Architecture::Target, Derived, typename internal::traits<Derived>::Scalar>::run(*this);
  }
  template <class Derived>
  template <class OtherDerived>
  inline typename internal::traits<Derived>::Scalar QuaternionBase<Derived>::angularDistance(
      const QuaternionBase<OtherDerived>& other) const {
    using std::atan2;
    Quaternion<Scalar> d = (*this) * other.conjugate();
    return Scalar(2) * atan2(d.vec().norm(), numext::abs(d.w()));
  }
  template <class Derived>
  template <class OtherDerived>
  Quaternion<typename internal::traits<Derived>::Scalar> QuaternionBase<Derived>::slerp(
      const Scalar& t, const QuaternionBase<OtherDerived>& other) const {
    using std::acos;
    using std::sin;
    const Scalar one = Scalar(1) - NumTraits<Scalar>::epsilon();
    Scalar d = this->dot(other);
    Scalar absD = numext::abs(d);
    Scalar scale0;
    Scalar scale1;
    if (absD >= one) {
      scale0 = Scalar(1) - t;
      scale1 = t;
    } else {
      Scalar theta = acos(absD);
      Scalar sinTheta = sin(theta);
      scale0 = sin((Scalar(1) - t) * theta) / sinTheta;
      scale1 = sin((t * theta)) / sinTheta;
    }
    if (d < Scalar(0))
      scale1 = -scale1;
    return Quaternion<Scalar>(scale0 * coeffs() + scale1 * other.coeffs());
  }
  namespace internal {
    template <typename Other>
    struct quaternionbase_assign_impl<Other, 3, 3> {
      typedef typename Other::Scalar Scalar;
      template <class Derived>
      static inline void run(QuaternionBase<Derived>& q, const Other& a_mat) {
        const typename internal::nested_eval<Other, 2>::type mat(a_mat);
        using std::sqrt;
        Scalar t = mat.trace();
        if (t > Scalar(0)) {
          t = sqrt(t + Scalar(1.0));
          q.w() = Scalar(0.5) * t;
          t = Scalar(0.5) / t;
          q.x() = (mat.coeff(2, 1) - mat.coeff(1, 2)) * t;
          q.y() = (mat.coeff(0, 2) - mat.coeff(2, 0)) * t;
          q.z() = (mat.coeff(1, 0) - mat.coeff(0, 1)) * t;
        } else {
          Index i = 0;
          if (mat.coeff(1, 1) > mat.coeff(0, 0))
            i = 1;
          if (mat.coeff(2, 2) > mat.coeff(i, i))
            i = 2;
          Index j = (i + 1) % 3;
          Index k = (j + 1) % 3;
          t = sqrt(mat.coeff(i, i) - mat.coeff(j, j) - mat.coeff(k, k) + Scalar(1.0));
          q.coeffs().coeffRef(i) = Scalar(0.5) * t;
          t = Scalar(0.5) / t;
          q.w() = (mat.coeff(k, j) - mat.coeff(j, k)) * t;
          q.coeffs().coeffRef(j) = (mat.coeff(j, i) + mat.coeff(i, j)) * t;
          q.coeffs().coeffRef(k) = (mat.coeff(k, i) + mat.coeff(i, k)) * t;
        }
      }
    };
    template <typename Other>
    struct quaternionbase_assign_impl<Other, 4, 1> {
      typedef typename Other::Scalar Scalar;
      template <class Derived>
      static inline void run(QuaternionBase<Derived>& q, const Other& vec) {
        q.coeffs() = vec;
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar_>
    struct traits<AngleAxis<Scalar_>> {
      typedef Scalar_ Scalar;
    };
  }  // namespace internal
  template <typename Scalar_>
  class AngleAxis : public RotationBase<AngleAxis<Scalar_>, 3> {
    typedef RotationBase<AngleAxis<Scalar_>, 3> Base;

  public:
    using Base::operator*;
    enum { Dim = 3 };
    typedef Scalar_ Scalar;
    typedef Matrix<Scalar, 3, 3> Matrix3;
    typedef Matrix<Scalar, 3, 1> Vector3;
    typedef Quaternion<Scalar> QuaternionType;

  protected:
    Vector3 m_axis;
    Scalar m_angle;

  public:
    AngleAxis() {}
    template <typename Derived>
    inline AngleAxis(const Scalar& angle, const MatrixBase<Derived>& axis) : m_axis(axis), m_angle(angle) {}
    template <typename QuatDerived>
    inline explicit AngleAxis(const QuaternionBase<QuatDerived>& q) {
      *this = q;
    }
    template <typename Derived>
    inline explicit AngleAxis(const MatrixBase<Derived>& m) {
      *this = m;
    }
    Scalar angle() const { return m_angle; }
    Scalar& angle() { return m_angle; }
    const Vector3& axis() const { return m_axis; }
    Vector3& axis() { return m_axis; }
    inline QuaternionType operator*(const AngleAxis& other) const {
      return QuaternionType(*this) * QuaternionType(other);
    }
    inline QuaternionType operator*(const QuaternionType& other) const { return QuaternionType(*this) * other; }
    friend inline QuaternionType operator*(const QuaternionType& a, const AngleAxis& b) {
      return a * QuaternionType(b);
    }
    AngleAxis inverse() const { return AngleAxis(-m_angle, m_axis); }
    template <class QuatDerived>
    AngleAxis& operator=(const QuaternionBase<QuatDerived>& q);
    template <typename Derived>
    AngleAxis& operator=(const MatrixBase<Derived>& m);
    template <typename Derived>
    AngleAxis& fromRotationMatrix(const MatrixBase<Derived>& m);
    Matrix3 toRotationMatrix(void) const;
    template <typename NewScalarType>
    inline typename internal::cast_return_type<AngleAxis, AngleAxis<NewScalarType>>::type cast() const {
      return typename internal::cast_return_type<AngleAxis, AngleAxis<NewScalarType>>::type(*this);
    }
    template <typename OtherScalarType>
    inline explicit AngleAxis(const AngleAxis<OtherScalarType>& other) {
      m_axis = other.axis().template cast<Scalar>();
      m_angle = Scalar(other.angle());
    }
    static inline const AngleAxis Identity() { return AngleAxis(Scalar(0), Vector3::UnitX()); }
    bool isApprox(const AngleAxis& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return m_axis.isApprox(other.m_axis, prec) && internal::isApprox(m_angle, other.m_angle, prec);
    }
  };
  typedef AngleAxis<float> AngleAxisf;
  typedef AngleAxis<double> AngleAxisd;
  template <typename Scalar>
  template <typename QuatDerived>
  AngleAxis<Scalar>& AngleAxis<Scalar>::operator=(const QuaternionBase<QuatDerived>& q) {
    using std::abs;
    using std::atan2;
    Scalar n = q.vec().norm();
    if (n < NumTraits<Scalar>::epsilon())
      n = q.vec().stableNorm();
    if (n != Scalar(0)) {
      m_angle = Scalar(2) * atan2(n, abs(q.w()));
      if (q.w() < Scalar(0))
        n = -n;
      m_axis = q.vec() / n;
    } else {
      m_angle = Scalar(0);
      m_axis << Scalar(1), Scalar(0), Scalar(0);
    }
    return *this;
  }
  template <typename Scalar>
  template <typename Derived>
  AngleAxis<Scalar>& AngleAxis<Scalar>::operator=(const MatrixBase<Derived>& mat) {
    return *this = QuaternionType(mat);
  }
  template <typename Scalar>
  template <typename Derived>
  AngleAxis<Scalar>& AngleAxis<Scalar>::fromRotationMatrix(const MatrixBase<Derived>& mat) {
    return *this = QuaternionType(mat);
  }
  template <typename Scalar>
  typename AngleAxis<Scalar>::Matrix3 AngleAxis<Scalar>::toRotationMatrix(void) const {
    using std::cos;
    using std::sin;
    Matrix3 res;
    Vector3 sin_axis = sin(m_angle) * m_axis;
    Scalar c = cos(m_angle);
    Vector3 cos1_axis = (Scalar(1) - c) * m_axis;
    Scalar tmp;
    tmp = cos1_axis.x() * m_axis.y();
    res.coeffRef(0, 1) = tmp - sin_axis.z();
    res.coeffRef(1, 0) = tmp + sin_axis.z();
    tmp = cos1_axis.x() * m_axis.z();
    res.coeffRef(0, 2) = tmp + sin_axis.y();
    res.coeffRef(2, 0) = tmp - sin_axis.y();
    tmp = cos1_axis.y() * m_axis.z();
    res.coeffRef(1, 2) = tmp - sin_axis.x();
    res.coeffRef(2, 1) = tmp + sin_axis.x();
    res.diagonal() = (cos1_axis.cwiseProduct(m_axis)).array() + c;
    return res;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Transform>
    struct transform_traits {
      enum {
        Dim = Transform::Dim,
        HDim = Transform::HDim,
        Mode = Transform::Mode,
        IsProjective = (int(Mode) == int(Projective))
      };
    };
    template <typename TransformType,
              typename MatrixType,
              int Case = transform_traits<TransformType>::IsProjective                                      ? 0
                         : int(MatrixType::RowsAtCompileTime) == int(transform_traits<TransformType>::HDim) ? 1
                                                                                                            : 2,
              int RhsCols = MatrixType::ColsAtCompileTime>
    struct transform_right_product_impl;
    template <typename Other,
              int Mode,
              int Options,
              int Dim,
              int HDim,
              int OtherRows = Other::RowsAtCompileTime,
              int OtherCols = Other::ColsAtCompileTime>
    struct transform_left_product_impl;
    template <typename Lhs,
              typename Rhs,
              bool AnyProjective = transform_traits<Lhs>::IsProjective || transform_traits<Rhs>::IsProjective>
    struct transform_transform_product_impl;
    template <typename Other,
              int Mode,
              int Options,
              int Dim,
              int HDim,
              int OtherRows = Other::RowsAtCompileTime,
              int OtherCols = Other::ColsAtCompileTime>
    struct transform_construct_from_matrix;
    template <typename TransformType>
    struct transform_take_affine_part;
    template <typename Scalar_, int Dim_, int Mode_, int Options_>
    struct traits<Transform<Scalar_, Dim_, Mode_, Options_>> {
      typedef Scalar_ Scalar;
      typedef Eigen::Index StorageIndex;
      typedef Dense StorageKind;
      enum {
        Dim1 = Dim_ == Dynamic ? Dim_ : Dim_ + 1,
        RowsAtCompileTime = Mode_ == Projective ? Dim1 : Dim_,
        ColsAtCompileTime = Dim1,
        MaxRowsAtCompileTime = RowsAtCompileTime,
        MaxColsAtCompileTime = ColsAtCompileTime,
        Flags = 0
      };
    };
    template <int Mode>
    struct transform_make_affine;
  }  // namespace internal
  template <typename Scalar_, int Dim_, int Mode_, int Options_>
  class Transform {
  public:
    enum {
      Mode = Mode_,
      Options = Options_,
      Dim = Dim_,
      HDim = Dim_ + 1,
      Rows = int(Mode) == (AffineCompact) ? Dim : HDim
    };
    typedef Scalar_ Scalar;
    typedef Eigen::Index StorageIndex;
    typedef Eigen::Index Index;
    typedef typename internal::make_proper_matrix_type<Scalar, Rows, HDim, Options>::type MatrixType;
    typedef const MatrixType ConstMatrixType;
    typedef Matrix<Scalar, Dim, Dim, Options> LinearMatrixType;
    typedef Block<MatrixType, Dim, Dim, int(Mode) == (AffineCompact) && (int(Options) & RowMajor) == 0> LinearPart;
    typedef const Block<ConstMatrixType, Dim, Dim, int(Mode) == (AffineCompact) && (int(Options) & RowMajor) == 0>
        ConstLinearPart;
    typedef std::conditional_t<int(Mode) == int(AffineCompact), MatrixType&, Block<MatrixType, Dim, HDim>> AffinePart;
    typedef std::
        conditional_t<int(Mode) == int(AffineCompact), const MatrixType&, const Block<const MatrixType, Dim, HDim>>
            ConstAffinePart;
    typedef Matrix<Scalar, Dim, 1> VectorType;
    typedef Block<MatrixType, Dim, 1, !(internal::traits<MatrixType>::Flags & RowMajorBit)> TranslationPart;
    typedef const Block<ConstMatrixType, Dim, 1, !(internal::traits<MatrixType>::Flags & RowMajorBit)>
        ConstTranslationPart;
    typedef Translation<Scalar, Dim> TranslationType;
    enum { TransformTimeDiagonalMode = ((Mode == int(Isometry)) ? Affine : int(Mode)) };
    typedef Transform<Scalar, Dim, TransformTimeDiagonalMode> TransformTimeDiagonalReturnType;

  protected:
    MatrixType m_matrix;

  public:
    inline Transform() {
      check_template_params();
      internal::transform_make_affine<(int(Mode) == Affine || int(Mode) == Isometry) ? Affine : AffineCompact>::run(
          m_matrix);
    }
    inline explicit Transform(const TranslationType& t) {
      check_template_params();
      *this = t;
    }
    inline explicit Transform(const UniformScaling<Scalar>& s) {
      check_template_params();
      *this = s;
    }
    template <typename Derived>
    inline explicit Transform(const RotationBase<Derived, Dim>& r) {
      check_template_params();
      *this = r;
    }
    typedef internal::transform_take_affine_part<Transform> take_affine_part;
    template <typename OtherDerived>
    inline explicit Transform(const EigenBase<OtherDerived>& other) {
      static_assert((internal::is_same<Scalar, typename OtherDerived::Scalar>::value),
                    "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                    "TYPES_EXPLICITLY");
      ;
      check_template_params();
      internal::transform_construct_from_matrix<OtherDerived, Mode, Options, Dim, HDim>::run(this, other.derived());
    }
    template <typename OtherDerived>
    inline Transform& operator=(const EigenBase<OtherDerived>& other) {
      static_assert((internal::is_same<Scalar, typename OtherDerived::Scalar>::value),
                    "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                    "TYPES_EXPLICITLY");
      ;
      internal::transform_construct_from_matrix<OtherDerived, Mode, Options, Dim, HDim>::run(this, other.derived());
      return *this;
    }
    template <int OtherOptions>
    inline Transform(const Transform<Scalar, Dim, Mode, OtherOptions>& other) {
      check_template_params();
      m_matrix = other.matrix();
    }
    template <int OtherMode, int OtherOptions>
    inline Transform(const Transform<Scalar, Dim, OtherMode, OtherOptions>& other) {
      check_template_params();
      static_assert(internal::check_implication(OtherMode == int(Projective), Mode == int(Projective)),
                    "YOU_PERFORMED_AN_INVALID_TRANSFORMATION_CONVERSION");
      static_assert(internal::check_implication(OtherMode == int(Affine) || OtherMode == int(AffineCompact),
                                                Mode != int(Isometry)),
                    "YOU_PERFORMED_AN_INVALID_TRANSFORMATION_CONVERSION");
      enum {
        ModeIsAffineCompact = Mode == int(AffineCompact),
        OtherModeIsAffineCompact = OtherMode == int(AffineCompact)
      };
      if (ModeIsAffineCompact == OtherModeIsAffineCompact) {
        m_matrix.template block<Dim, Dim + 1>(0, 0) = other.matrix().template block<Dim, Dim + 1>(0, 0);
        makeAffine();
      } else if (OtherModeIsAffineCompact) {
        typedef typename Transform<Scalar, Dim, OtherMode, OtherOptions>::MatrixType OtherMatrixType;
        internal::transform_construct_from_matrix<OtherMatrixType, Mode, Options, Dim, HDim>::run(this, other.matrix());
      } else {
        linear() = other.linear();
        translation() = other.translation();
      }
    }
    template <typename OtherDerived>
    Transform(const ReturnByValue<OtherDerived>& other) {
      check_template_params();
      other.evalTo(*this);
    }
    template <typename OtherDerived>
    Transform& operator=(const ReturnByValue<OtherDerived>& other) {
      other.evalTo(*this);
      return *this;
    }
    constexpr Index rows() const noexcept {
      return int(Mode) == int(Projective) ? m_matrix.cols() : (m_matrix.cols() - 1);
    }
    constexpr Index cols() const noexcept { return m_matrix.cols(); }
    inline Scalar operator()(Index row, Index col) const { return m_matrix(row, col); }
    inline Scalar& operator()(Index row, Index col) { return m_matrix(row, col); }
    inline const MatrixType& matrix() const { return m_matrix; }
    inline MatrixType& matrix() { return m_matrix; }
    inline ConstLinearPart linear() const { return ConstLinearPart(m_matrix, 0, 0); }
    inline LinearPart linear() { return LinearPart(m_matrix, 0, 0); }
    inline ConstAffinePart affine() const { return take_affine_part::run(m_matrix); }
    inline AffinePart affine() { return take_affine_part::run(m_matrix); }
    inline ConstTranslationPart translation() const { return ConstTranslationPart(m_matrix, 0, Dim); }
    inline TranslationPart translation() { return TranslationPart(m_matrix, 0, Dim); }
    template <typename OtherDerived>
    inline const typename internal::transform_right_product_impl<Transform, OtherDerived>::ResultType operator*(
        const EigenBase<OtherDerived>& other) const {
      return internal::transform_right_product_impl<Transform, OtherDerived>::run(*this, other.derived());
    }
    template <typename OtherDerived>
    friend inline const typename internal::transform_left_product_impl<OtherDerived, Mode, Options, Dim_, Dim_ + 1>::
        ResultType
        operator*(const EigenBase<OtherDerived>& a, const Transform& b) {
      return internal::transform_left_product_impl<OtherDerived, Mode, Options, Dim, HDim>::run(a.derived(), b);
    }
    template <typename DiagonalDerived>
    inline const TransformTimeDiagonalReturnType operator*(const DiagonalBase<DiagonalDerived>& b) const {
      TransformTimeDiagonalReturnType res(*this);
      res.linearExt() *= b;
      return res;
    }
    template <typename DiagonalDerived>
    friend inline TransformTimeDiagonalReturnType operator*(const DiagonalBase<DiagonalDerived>& a,
                                                            const Transform& b) {
      TransformTimeDiagonalReturnType res;
      res.linear().noalias() = a * b.linear();
      res.translation().noalias() = a * b.translation();
      if (Mode != int(AffineCompact))
        res.matrix().row(Dim) = b.matrix().row(Dim);
      return res;
    }
    template <typename OtherDerived>
    inline Transform& operator*=(const EigenBase<OtherDerived>& other) {
      return *this = *this * other;
    }
    inline const Transform operator*(const Transform& other) const {
      return internal::transform_transform_product_impl<Transform, Transform>::run(*this, other);
    }
    template <int OtherMode, int OtherOptions>
    inline
        typename internal::transform_transform_product_impl<Transform,
                                                            Transform<Scalar, Dim, OtherMode, OtherOptions>>::ResultType
        operator*(const Transform<Scalar, Dim, OtherMode, OtherOptions>& other) const {
      return internal::transform_transform_product_impl<Transform, Transform<Scalar, Dim, OtherMode, OtherOptions>>::run(
          *this, other);
    }
    void setIdentity() { m_matrix.setIdentity(); }
    static const Transform Identity() { return Transform(MatrixType::Identity()); }
    template <typename OtherDerived>
    inline Transform& scale(const MatrixBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Transform& prescale(const MatrixBase<OtherDerived>& other);
    inline Transform& scale(const Scalar& s);
    inline Transform& prescale(const Scalar& s);
    template <typename OtherDerived>
    inline Transform& translate(const MatrixBase<OtherDerived>& other);
    template <typename OtherDerived>
    inline Transform& pretranslate(const MatrixBase<OtherDerived>& other);
    template <typename RotationType>
    inline Transform& rotate(const RotationType& rotation);
    template <typename RotationType>
    inline Transform& prerotate(const RotationType& rotation);
    Transform& shear(const Scalar& sx, const Scalar& sy);
    Transform& preshear(const Scalar& sx, const Scalar& sy);
    inline Transform& operator=(const TranslationType& t);
    inline Transform& operator*=(const TranslationType& t) { return translate(t.vector()); }
    inline Transform operator*(const TranslationType& t) const;
    inline Transform& operator=(const UniformScaling<Scalar>& t);
    inline Transform& operator*=(const UniformScaling<Scalar>& s) { return scale(s.factor()); }
    inline TransformTimeDiagonalReturnType operator*(const UniformScaling<Scalar>& s) const {
      TransformTimeDiagonalReturnType res = *this;
      res.scale(s.factor());
      return res;
    }
    inline Transform& operator*=(const DiagonalMatrix<Scalar, Dim>& s) {
      linearExt() *= s;
      return *this;
    }
    template <typename Derived>
    inline Transform& operator=(const RotationBase<Derived, Dim>& r);
    template <typename Derived>
    inline Transform& operator*=(const RotationBase<Derived, Dim>& r) {
      return rotate(r.toRotationMatrix());
    }
    template <typename Derived>
    inline Transform operator*(const RotationBase<Derived, Dim>& r) const;
    typedef std::conditional_t<int(Mode) == Isometry, ConstLinearPart, const LinearMatrixType> RotationReturnType;
    RotationReturnType rotation() const;
    template <typename RotationMatrixType, typename ScalingMatrixType>
    void computeRotationScaling(RotationMatrixType* rotation, ScalingMatrixType* scaling) const;
    template <typename ScalingMatrixType, typename RotationMatrixType>
    void computeScalingRotation(ScalingMatrixType* scaling, RotationMatrixType* rotation) const;
    template <typename PositionDerived, typename OrientationType, typename ScaleDerived>
    Transform& fromPositionOrientationScale(const MatrixBase<PositionDerived>& position,
                                            const OrientationType& orientation,
                                            const MatrixBase<ScaleDerived>& scale);
    inline Transform inverse(TransformTraits traits = (TransformTraits)Mode) const;
    const Scalar* data() const { return m_matrix.data(); }
    Scalar* data() { return m_matrix.data(); }
    template <typename NewScalarType>
    inline typename internal::cast_return_type<Transform, Transform<NewScalarType, Dim, Mode, Options>>::type cast()
        const {
      return typename internal::cast_return_type<Transform, Transform<NewScalarType, Dim, Mode, Options>>::type(*this);
    }
    template <typename OtherScalarType>
    inline explicit Transform(const Transform<OtherScalarType, Dim, Mode, Options>& other) {
      check_template_params();
      m_matrix = other.matrix().template cast<Scalar>();
    }
    bool isApprox(const Transform& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return m_matrix.isApprox(other.m_matrix, prec);
    }
    void makeAffine() { internal::transform_make_affine<int(Mode)>::run(m_matrix); }
    inline Block<MatrixType, int(Mode) == int(Projective) ? HDim : Dim, Dim> linearExt() {
      return m_matrix.template block < int(Mode) == int(Projective) ? HDim : Dim, Dim > (0, 0);
    }
    inline const Block<MatrixType, int(Mode) == int(Projective) ? HDim : Dim, Dim> linearExt() const {
      return m_matrix.template block < int(Mode) == int(Projective) ? HDim : Dim, Dim > (0, 0);
    }
    inline Block<MatrixType, int(Mode) == int(Projective) ? HDim : Dim, 1> translationExt() {
      return m_matrix.template block < int(Mode) == int(Projective) ? HDim : Dim, 1 > (0, Dim);
    }
    inline const Block<MatrixType, int(Mode) == int(Projective) ? HDim : Dim, 1> translationExt() const {
      return m_matrix.template block < int(Mode) == int(Projective) ? HDim : Dim, 1 > (0, Dim);
    }

  protected:
    static inline void check_template_params() {
      static_assert((Options & (DontAlign | RowMajor)) == Options, "INVALID_MATRIX_TEMPLATE_PARAMETERS");
    }
  };
  typedef Transform<float, 2, Isometry> Isometry2f;
  typedef Transform<float, 3, Isometry> Isometry3f;
  typedef Transform<double, 2, Isometry> Isometry2d;
  typedef Transform<double, 3, Isometry> Isometry3d;
  typedef Transform<float, 2, Affine> Affine2f;
  typedef Transform<float, 3, Affine> Affine3f;
  typedef Transform<double, 2, Affine> Affine2d;
  typedef Transform<double, 3, Affine> Affine3d;
  typedef Transform<float, 2, AffineCompact> AffineCompact2f;
  typedef Transform<float, 3, AffineCompact> AffineCompact3f;
  typedef Transform<double, 2, AffineCompact> AffineCompact2d;
  typedef Transform<double, 3, AffineCompact> AffineCompact3d;
  typedef Transform<float, 2, Projective> Projective2f;
  typedef Transform<float, 3, Projective> Projective3f;
  typedef Transform<double, 2, Projective> Projective2d;
  typedef Transform<double, 3, Projective> Projective3d;
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename OtherDerived>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::scale(
      const MatrixBase<OtherDerived>& other) {
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == int(Dim),
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    linearExt().noalias() = (linearExt() * other.asDiagonal());
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  inline Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::scale(const Scalar& s) {
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    linearExt() *= s;
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename OtherDerived>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::prescale(
      const MatrixBase<OtherDerived>& other) {
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == int(Dim),
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    affine().noalias() = (other.asDiagonal() * affine());
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  inline Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::prescale(const Scalar& s) {
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    m_matrix.template topRows<Dim>() *= s;
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename OtherDerived>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::translate(
      const MatrixBase<OtherDerived>& other) {
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == int(Dim),
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    translationExt() += linearExt() * other;
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename OtherDerived>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::pretranslate(
      const MatrixBase<OtherDerived>& other) {
    static_assert(OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime == int(Dim),
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    if (int(Mode) == int(Projective))
      affine() += other * m_matrix.row(Dim);
    else
      translation() += other;
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename RotationType>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::rotate(const RotationType& rotation) {
    linearExt() *= internal::toRotationMatrix<Scalar, Dim>(rotation);
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename RotationType>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::prerotate(const RotationType& rotation) {
    m_matrix.template block<Dim, HDim>(0, 0) =
        internal::toRotationMatrix<Scalar, Dim>(rotation) * m_matrix.template block<Dim, HDim>(0, 0);
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::shear(const Scalar& sx,
                                                                                      const Scalar& sy) {
    static_assert(int(Dim) == 2, "YOU_MADE_A_PROGRAMMING_MISTAKE");
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    VectorType tmp = linear().col(0) * sy + linear().col(1);
    linear() << linear().col(0) + linear().col(1) * sx, tmp;
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::preshear(const Scalar& sx,
                                                                                         const Scalar& sy) {
    static_assert(int(Dim) == 2, "YOU_MADE_A_PROGRAMMING_MISTAKE");
    static_assert(Mode != int(Isometry), "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
    m_matrix.template block<Dim, HDim>(0, 0) =
        LinearMatrixType(1, sx, sy, 1) * m_matrix.template block<Dim, HDim>(0, 0);
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  inline Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::operator=(
      const TranslationType& t) {
    linear().setIdentity();
    translation() = t.vector();
    makeAffine();
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  inline Transform<Scalar, Dim, Mode, Options> Transform<Scalar, Dim, Mode, Options>::operator*(
      const TranslationType& t) const {
    Transform res = *this;
    res.translate(t.vector());
    return res;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  inline Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::operator=(
      const UniformScaling<Scalar>& s) {
    m_matrix.setZero();
    linear().diagonal().fill(s.factor());
    makeAffine();
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename Derived>
  inline Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::operator=(
      const RotationBase<Derived, Dim>& r) {
    linear() = internal::toRotationMatrix<Scalar, Dim>(r);
    translation().setZero();
    makeAffine();
    return *this;
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename Derived>
  inline Transform<Scalar, Dim, Mode, Options> Transform<Scalar, Dim, Mode, Options>::operator*(
      const RotationBase<Derived, Dim>& r) const {
    Transform res = *this;
    res.rotate(r.derived());
    return res;
  }
  namespace internal {
    template <int Mode>
    struct transform_rotation_impl {
      template <typename TransformType>
      static inline const typename TransformType::LinearMatrixType run(const TransformType& t) {
        typedef typename TransformType::LinearMatrixType LinearMatrixType;
        LinearMatrixType result;
        t.computeRotationScaling(&result, (LinearMatrixType*)0);
        return result;
      }
    };
    template <>
    struct transform_rotation_impl<Isometry> {
      template <typename TransformType>
      static inline typename TransformType::ConstLinearPart run(const TransformType& t) {
        return t.linear();
      }
    };
  }  // namespace internal
  template <typename Scalar, int Dim, int Mode, int Options>
  typename Transform<Scalar, Dim, Mode, Options>::RotationReturnType Transform<Scalar, Dim, Mode, Options>::rotation()
      const {
    return internal::transform_rotation_impl<Mode>::run(*this);
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename RotationMatrixType, typename ScalingMatrixType>
  void Transform<Scalar, Dim, Mode, Options>::computeRotationScaling(RotationMatrixType* rotation,
                                                                     ScalingMatrixType* scaling) const {
    JacobiSVD<LinearMatrixType, ComputeFullU | ComputeFullV> svd(linear());
    Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1);
    VectorType sv(svd.singularValues());
    sv.coeffRef(Dim - 1) *= x;
    if (scaling)
      *scaling = svd.matrixV() * sv.asDiagonal() * svd.matrixV().adjoint();
    if (rotation) {
      LinearMatrixType m(svd.matrixU());
      m.col(Dim - 1) *= x;
      *rotation = m * svd.matrixV().adjoint();
    }
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename ScalingMatrixType, typename RotationMatrixType>
  void Transform<Scalar, Dim, Mode, Options>::computeScalingRotation(ScalingMatrixType* scaling,
                                                                     RotationMatrixType* rotation) const {
    JacobiSVD<LinearMatrixType, ComputeFullU | ComputeFullV> svd(linear());
    Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1);
    VectorType sv(svd.singularValues());
    sv.coeffRef(Dim - 1) *= x;
    if (scaling)
      *scaling = svd.matrixU() * sv.asDiagonal() * svd.matrixU().adjoint();
    if (rotation) {
      LinearMatrixType m(svd.matrixU());
      m.col(Dim - 1) *= x;
      *rotation = m * svd.matrixV().adjoint();
    }
  }
  template <typename Scalar, int Dim, int Mode, int Options>
  template <typename PositionDerived, typename OrientationType, typename ScaleDerived>
  Transform<Scalar, Dim, Mode, Options>& Transform<Scalar, Dim, Mode, Options>::fromPositionOrientationScale(
      const MatrixBase<PositionDerived>& position,
      const OrientationType& orientation,
      const MatrixBase<ScaleDerived>& scale) {
    linear() = internal::toRotationMatrix<Scalar, Dim>(orientation);
    linear() *= scale.asDiagonal();
    translation() = position;
    makeAffine();
    return *this;
  }
  namespace internal {
    template <int Mode>
    struct transform_make_affine {
      template <typename MatrixType>
      static void run(MatrixType& mat) {
        static const int Dim = MatrixType::ColsAtCompileTime - 1;
        mat.template block<1, Dim>(Dim, 0).setZero();
        mat.coeffRef(Dim, Dim) = typename MatrixType::Scalar(1);
      }
    };
    template <>
    struct transform_make_affine<AffineCompact> {
      template <typename MatrixType>
      static void run(MatrixType&) {}
    };
    template <typename TransformType, int Mode = TransformType::Mode>
    struct projective_transform_inverse {
      static inline void run(const TransformType&, TransformType&) {}
    };
    template <typename TransformType>
    struct projective_transform_inverse<TransformType, Projective> {
      static inline void run(const TransformType& m, TransformType& res) { res.matrix() = m.matrix().inverse(); }
    };
  }  // namespace internal
  template <typename Scalar, int Dim, int Mode, int Options>
  Transform<Scalar, Dim, Mode, Options> Transform<Scalar, Dim, Mode, Options>::inverse(TransformTraits hint) const {
    Transform res;
    if (hint == Projective) {
      internal::projective_transform_inverse<Transform>::run(*this, res);
    } else {
      if (hint == Isometry) {
        res.matrix().template topLeftCorner<Dim, Dim>() = linear().transpose();
      } else if (hint & Affine) {
        res.matrix().template topLeftCorner<Dim, Dim>() = linear().inverse();
      } else {
        (static_cast<bool>(false && "Invalid transform traits in Transform::Inverse")
             ? void(0)
             : __assert_fail("false && \"Invalid transform traits in Transform::Inverse\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Geometry/Transform.h",
                             1249,
                             __extension__ __PRETTY_FUNCTION__));
      }
      res.matrix().template topRightCorner<Dim, 1>() = -res.matrix().template topLeftCorner<Dim, Dim>() * translation();
      res.makeAffine();
    }
    return res;
  }
  namespace internal {
    template <typename TransformType>
    struct transform_take_affine_part {
      typedef typename TransformType::MatrixType MatrixType;
      typedef typename TransformType::AffinePart AffinePart;
      typedef typename TransformType::ConstAffinePart ConstAffinePart;
      static inline AffinePart run(MatrixType& m) {
        return m.template block<TransformType::Dim, TransformType::HDim>(0, 0);
      }
      static inline ConstAffinePart run(const MatrixType& m) {
        return m.template block<TransformType::Dim, TransformType::HDim>(0, 0);
      }
    };
    template <typename Scalar, int Dim, int Options>
    struct transform_take_affine_part<Transform<Scalar, Dim, AffineCompact, Options>> {
      typedef typename Transform<Scalar, Dim, AffineCompact, Options>::MatrixType MatrixType;
      static inline MatrixType& run(MatrixType& m) { return m; }
      static inline const MatrixType& run(const MatrixType& m) { return m; }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_construct_from_matrix<Other, Mode, Options, Dim, HDim, Dim, Dim> {
      static inline void run(Transform<typename Other::Scalar, Dim, Mode, Options>* transform, const Other& other) {
        transform->linear() = other;
        transform->translation().setZero();
        transform->makeAffine();
      }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_construct_from_matrix<Other, Mode, Options, Dim, HDim, Dim, HDim> {
      static inline void run(Transform<typename Other::Scalar, Dim, Mode, Options>* transform, const Other& other) {
        transform->affine() = other;
        transform->makeAffine();
      }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_construct_from_matrix<Other, Mode, Options, Dim, HDim, HDim, HDim> {
      static inline void run(Transform<typename Other::Scalar, Dim, Mode, Options>* transform, const Other& other) {
        transform->matrix() = other;
      }
    };
    template <typename Other, int Options, int Dim, int HDim>
    struct transform_construct_from_matrix<Other, AffineCompact, Options, Dim, HDim, HDim, HDim> {
      static inline void run(Transform<typename Other::Scalar, Dim, AffineCompact, Options>* transform,
                             const Other& other) {
        transform->matrix() = other.template block<Dim, HDim>(0, 0);
      }
    };
    template <int LhsMode, int RhsMode>
    struct transform_product_result {
      enum {
        Mode = (LhsMode == (int)Projective || RhsMode == (int)Projective)         ? Projective
               : (LhsMode == (int)Affine || RhsMode == (int)Affine)               ? Affine
               : (LhsMode == (int)AffineCompact || RhsMode == (int)AffineCompact) ? AffineCompact
               : (LhsMode == (int)Isometry || RhsMode == (int)Isometry)           ? Isometry
                                                                                  : Projective
      };
    };
    template <typename TransformType, typename MatrixType, int RhsCols>
    struct transform_right_product_impl<TransformType, MatrixType, 0, RhsCols> {
      typedef typename MatrixType::PlainObject ResultType;
      static inline ResultType run(const TransformType& T, const MatrixType& other) { return T.matrix() * other; }
    };
    template <typename TransformType, typename MatrixType, int RhsCols>
    struct transform_right_product_impl<TransformType, MatrixType, 1, RhsCols> {
      enum {
        Dim = TransformType::Dim,
        HDim = TransformType::HDim,
        OtherRows = MatrixType::RowsAtCompileTime,
        OtherCols = MatrixType::ColsAtCompileTime
      };
      typedef typename MatrixType::PlainObject ResultType;
      static inline ResultType run(const TransformType& T, const MatrixType& other) {
        static_assert(OtherRows == HDim, "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
        ;
        typedef Block<ResultType, Dim, OtherCols, int(MatrixType::RowsAtCompileTime) == Dim> TopLeftLhs;
        ResultType res(other.rows(), other.cols());
        TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() = T.affine() * other;
        res.row(OtherRows - 1) = other.row(OtherRows - 1);
        return res;
      }
    };
    template <typename TransformType, typename MatrixType, int RhsCols>
    struct transform_right_product_impl<TransformType, MatrixType, 2, RhsCols> {
      enum {
        Dim = TransformType::Dim,
        HDim = TransformType::HDim,
        OtherRows = MatrixType::RowsAtCompileTime,
        OtherCols = MatrixType::ColsAtCompileTime
      };
      typedef typename MatrixType::PlainObject ResultType;
      static inline ResultType run(const TransformType& T, const MatrixType& other) {
        static_assert(OtherRows == Dim, "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
        ;
        typedef Block<ResultType, Dim, OtherCols, true> TopLeftLhs;
        ResultType res(
            Replicate<typename TransformType::ConstTranslationPart, 1, OtherCols>(T.translation(), 1, other.cols()));
        TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() += T.linear() * other;
        return res;
      }
    };
    template <typename TransformType, typename MatrixType>
    struct transform_right_product_impl<TransformType, MatrixType, 2, 1> {
      typedef typename TransformType::MatrixType TransformMatrix;
      enum {
        Dim = TransformType::Dim,
        HDim = TransformType::HDim,
        OtherRows = MatrixType::RowsAtCompileTime,
        WorkingRows = plain_enum_min(TransformMatrix::RowsAtCompileTime, HDim)
      };
      typedef typename MatrixType::PlainObject ResultType;
      static inline ResultType run(const TransformType& T, const MatrixType& other) {
        static_assert(OtherRows == Dim, "YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES");
        ;
        Matrix<typename ResultType::Scalar, Dim + 1, 1> rhs;
        rhs.template head<Dim>() = other;
        rhs[Dim] = typename ResultType::Scalar(1);
        Matrix<typename ResultType::Scalar, WorkingRows, 1> res(T.matrix() * rhs);
        return res.template head<Dim>();
      }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_left_product_impl<Other, Mode, Options, Dim, HDim, HDim, HDim> {
      typedef Transform<typename Other::Scalar, Dim, Mode, Options> TransformType;
      typedef typename TransformType::MatrixType MatrixType;
      typedef Transform<typename Other::Scalar, Dim, Projective, Options> ResultType;
      static ResultType run(const Other& other, const TransformType& tr) { return ResultType(other * tr.matrix()); }
    };
    template <typename Other, int Options, int Dim, int HDim>
    struct transform_left_product_impl<Other, AffineCompact, Options, Dim, HDim, HDim, HDim> {
      typedef Transform<typename Other::Scalar, Dim, AffineCompact, Options> TransformType;
      typedef typename TransformType::MatrixType MatrixType;
      typedef Transform<typename Other::Scalar, Dim, Projective, Options> ResultType;
      static ResultType run(const Other& other, const TransformType& tr) {
        ResultType res;
        res.matrix().noalias() = other.template block<HDim, Dim>(0, 0) * tr.matrix();
        res.matrix().col(Dim) += other.col(Dim);
        return res;
      }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_left_product_impl<Other, Mode, Options, Dim, HDim, Dim, HDim> {
      typedef Transform<typename Other::Scalar, Dim, Mode, Options> TransformType;
      typedef typename TransformType::MatrixType MatrixType;
      typedef TransformType ResultType;
      static ResultType run(const Other& other, const TransformType& tr) {
        ResultType res;
        res.affine().noalias() = other * tr.matrix();
        res.matrix().row(Dim) = tr.matrix().row(Dim);
        return res;
      }
    };
    template <typename Other, int Options, int Dim, int HDim>
    struct transform_left_product_impl<Other, AffineCompact, Options, Dim, HDim, Dim, HDim> {
      typedef Transform<typename Other::Scalar, Dim, AffineCompact, Options> TransformType;
      typedef typename TransformType::MatrixType MatrixType;
      typedef TransformType ResultType;
      static ResultType run(const Other& other, const TransformType& tr) {
        ResultType res;
        res.matrix().noalias() = other.template block<Dim, Dim>(0, 0) * tr.matrix();
        res.translation() += other.col(Dim);
        return res;
      }
    };
    template <typename Other, int Mode, int Options, int Dim, int HDim>
    struct transform_left_product_impl<Other, Mode, Options, Dim, HDim, Dim, Dim> {
      typedef Transform<typename Other::Scalar, Dim, Mode, Options> TransformType;
      typedef typename TransformType::MatrixType MatrixType;
      typedef TransformType ResultType;
      static ResultType run(const Other& other, const TransformType& tr) {
        TransformType res;
        if (Mode != int(AffineCompact))
          res.matrix().row(Dim) = tr.matrix().row(Dim);
        res.matrix().template topRows<Dim>().noalias() = other * tr.matrix().template topRows<Dim>();
        return res;
      }
    };
    template <typename Scalar, int Dim, int LhsMode, int LhsOptions, int RhsMode, int RhsOptions>
    struct transform_transform_product_impl<Transform<Scalar, Dim, LhsMode, LhsOptions>,
                                            Transform<Scalar, Dim, RhsMode, RhsOptions>,
                                            false> {
      enum { ResultMode = transform_product_result<LhsMode, RhsMode>::Mode };
      typedef Transform<Scalar, Dim, LhsMode, LhsOptions> Lhs;
      typedef Transform<Scalar, Dim, RhsMode, RhsOptions> Rhs;
      typedef Transform<Scalar, Dim, ResultMode, LhsOptions> ResultType;
      static ResultType run(const Lhs& lhs, const Rhs& rhs) {
        ResultType res;
        res.linear() = lhs.linear() * rhs.linear();
        res.translation() = lhs.linear() * rhs.translation() + lhs.translation();
        res.makeAffine();
        return res;
      }
    };
    template <typename Scalar, int Dim, int LhsMode, int LhsOptions, int RhsMode, int RhsOptions>
    struct transform_transform_product_impl<Transform<Scalar, Dim, LhsMode, LhsOptions>,
                                            Transform<Scalar, Dim, RhsMode, RhsOptions>,
                                            true> {
      typedef Transform<Scalar, Dim, LhsMode, LhsOptions> Lhs;
      typedef Transform<Scalar, Dim, RhsMode, RhsOptions> Rhs;
      typedef Transform<Scalar, Dim, Projective> ResultType;
      static ResultType run(const Lhs& lhs, const Rhs& rhs) { return ResultType(lhs.matrix() * rhs.matrix()); }
    };
    template <typename Scalar, int Dim, int LhsOptions, int RhsOptions>
    struct transform_transform_product_impl<Transform<Scalar, Dim, AffineCompact, LhsOptions>,
                                            Transform<Scalar, Dim, Projective, RhsOptions>,
                                            true> {
      typedef Transform<Scalar, Dim, AffineCompact, LhsOptions> Lhs;
      typedef Transform<Scalar, Dim, Projective, RhsOptions> Rhs;
      typedef Transform<Scalar, Dim, Projective> ResultType;
      static ResultType run(const Lhs& lhs, const Rhs& rhs) {
        ResultType res;
        res.matrix().template topRows<Dim>() = lhs.matrix() * rhs.matrix();
        res.matrix().row(Dim) = rhs.matrix().row(Dim);
        return res;
      }
    };
    template <typename Scalar, int Dim, int LhsOptions, int RhsOptions>
    struct transform_transform_product_impl<Transform<Scalar, Dim, Projective, LhsOptions>,
                                            Transform<Scalar, Dim, AffineCompact, RhsOptions>,
                                            true> {
      typedef Transform<Scalar, Dim, Projective, LhsOptions> Lhs;
      typedef Transform<Scalar, Dim, AffineCompact, RhsOptions> Rhs;
      typedef Transform<Scalar, Dim, Projective> ResultType;
      static ResultType run(const Lhs& lhs, const Rhs& rhs) {
        ResultType res(lhs.matrix().template leftCols<Dim>() * rhs.matrix());
        res.matrix().col(Dim) += lhs.matrix().col(Dim);
        return res;
      }
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar_, int Dim_>
  class Translation {
  public:
    enum { Dim = Dim_ };
    typedef Scalar_ Scalar;
    typedef Matrix<Scalar, Dim, 1> VectorType;
    typedef Matrix<Scalar, Dim, Dim> LinearMatrixType;
    typedef Transform<Scalar, Dim, Affine> AffineTransformType;
    typedef Transform<Scalar, Dim, Isometry> IsometryTransformType;

  protected:
    VectorType m_coeffs;

  public:
    Translation() {}
    inline Translation(const Scalar& sx, const Scalar& sy) {
      (static_cast<bool>(Dim == 2)
           ? void(0)
           : __assert_fail("Dim==2",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/Translation.h",
                           60,
                           __extension__ __PRETTY_FUNCTION__));
      m_coeffs.x() = sx;
      m_coeffs.y() = sy;
    }
    inline Translation(const Scalar& sx, const Scalar& sy, const Scalar& sz) {
      (static_cast<bool>(Dim == 3)
           ? void(0)
           : __assert_fail("Dim==3",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Geometry/Translation.h",
                           67,
                           __extension__ __PRETTY_FUNCTION__));
      m_coeffs.x() = sx;
      m_coeffs.y() = sy;
      m_coeffs.z() = sz;
    }
    explicit inline Translation(const VectorType& vector) : m_coeffs(vector) {}
    inline Scalar x() const { return m_coeffs.x(); }
    inline Scalar y() const { return m_coeffs.y(); }
    inline Scalar z() const { return m_coeffs.z(); }
    inline Scalar& x() { return m_coeffs.x(); }
    inline Scalar& y() { return m_coeffs.y(); }
    inline Scalar& z() { return m_coeffs.z(); }
    const VectorType& vector() const { return m_coeffs; }
    VectorType& vector() { return m_coeffs; }
    const VectorType& translation() const { return m_coeffs; }
    VectorType& translation() { return m_coeffs; }
    inline Translation operator*(const Translation& other) const { return Translation(m_coeffs + other.m_coeffs); }
    inline AffineTransformType operator*(const UniformScaling<Scalar>& other) const;
    template <typename OtherDerived>
    inline AffineTransformType operator*(const EigenBase<OtherDerived>& linear) const;
    template <typename Derived>
    inline IsometryTransformType operator*(const RotationBase<Derived, Dim>& r) const {
      return *this * IsometryTransformType(r);
    }
    template <typename OtherDerived>
    friend inline AffineTransformType operator*(const EigenBase<OtherDerived>& linear, const Translation& t) {
      AffineTransformType res;
      res.matrix().setZero();
      res.linear() = linear.derived();
      res.translation() = linear.derived() * t.m_coeffs;
      res.matrix().row(Dim).setZero();
      res(Dim, Dim) = Scalar(1);
      return res;
    }
    template <int Mode, int Options>
    inline Transform<Scalar, Dim, Mode> operator*(const Transform<Scalar, Dim, Mode, Options>& t) const {
      Transform<Scalar, Dim, Mode> res = t;
      res.pretranslate(m_coeffs);
      return res;
    }
    template <typename Derived>
    inline std::enable_if_t<Derived::IsVectorAtCompileTime, VectorType> operator*(const MatrixBase<Derived>& vec) const {
      return m_coeffs + vec.derived();
    }
    Translation inverse() const { return Translation(-m_coeffs); }
    static const Translation Identity() { return Translation(VectorType::Zero()); }
    template <typename NewScalarType>
    inline typename internal::cast_return_type<Translation, Translation<NewScalarType, Dim>>::type cast() const {
      return typename internal::cast_return_type<Translation, Translation<NewScalarType, Dim>>::type(*this);
    }
    template <typename OtherScalarType>
    inline explicit Translation(const Translation<OtherScalarType, Dim>& other) {
      m_coeffs = other.vector().template cast<Scalar>();
    }
    bool isApprox(const Translation& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return m_coeffs.isApprox(other.m_coeffs, prec);
    }
  };
  typedef Translation<float, 2> Translation2f;
  typedef Translation<double, 2> Translation2d;
  typedef Translation<float, 3> Translation3f;
  typedef Translation<double, 3> Translation3d;
  template <typename Scalar, int Dim>
  inline typename Translation<Scalar, Dim>::AffineTransformType Translation<Scalar, Dim>::operator*(
      const UniformScaling<Scalar>& other) const {
    AffineTransformType res;
    res.matrix().setZero();
    res.linear().diagonal().fill(other.factor());
    res.translation() = m_coeffs;
    res(Dim, Dim) = Scalar(1);
    return res;
  }
  template <typename Scalar, int Dim>
  template <typename OtherDerived>
  inline typename Translation<Scalar, Dim>::AffineTransformType Translation<Scalar, Dim>::operator*(
      const EigenBase<OtherDerived>& linear) const {
    AffineTransformType res;
    res.matrix().setZero();
    res.linear() = linear.derived();
    res.translation() = m_coeffs;
    res.matrix().row(Dim).setZero();
    res(Dim, Dim) = Scalar(1);
    return res;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Scalar, int Dim, int Mode>
    struct uniformscaling_times_affine_returntype {
      enum { NewMode = int(Mode) == int(Isometry) ? Affine : Mode };
      typedef Transform<Scalar, Dim, NewMode> type;
    };
  }  // namespace internal
  template <typename Scalar_>
  class UniformScaling {
  public:
    typedef Scalar_ Scalar;

  protected:
    Scalar m_factor;

  public:
    UniformScaling() {}
    explicit inline UniformScaling(const Scalar& s) : m_factor(s) {}
    inline const Scalar& factor() const { return m_factor; }
    inline Scalar& factor() { return m_factor; }
    inline UniformScaling operator*(const UniformScaling& other) const {
      return UniformScaling(m_factor * other.factor());
    }
    template <int Dim>
    inline Transform<Scalar, Dim, Affine> operator*(const Translation<Scalar, Dim>& t) const;
    template <int Dim, int Mode, int Options>
    inline typename internal::uniformscaling_times_affine_returntype<Scalar, Dim, Mode>::type operator*(
        const Transform<Scalar, Dim, Mode, Options>& t) const {
      typename internal::uniformscaling_times_affine_returntype<Scalar, Dim, Mode>::type res = t;
      res.prescale(factor());
      return res;
    }
    template <typename Derived>
    inline typename Eigen::internal::plain_matrix_type<Derived>::type operator*(const MatrixBase<Derived>& other) const {
      return other * m_factor;
    }
    template <typename Derived, int Dim>
    inline Matrix<Scalar, Dim, Dim> operator*(const RotationBase<Derived, Dim>& r) const {
      return r.toRotationMatrix() * m_factor;
    }
    inline UniformScaling inverse() const { return UniformScaling(Scalar(1) / m_factor); }
    template <typename NewScalarType>
    inline UniformScaling<NewScalarType> cast() const {
      return UniformScaling<NewScalarType>(NewScalarType(m_factor));
    }
    template <typename OtherScalarType>
    inline explicit UniformScaling(const UniformScaling<OtherScalarType>& other) {
      m_factor = Scalar(other.factor());
    }
    bool isApprox(const UniformScaling& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return internal::isApprox(m_factor, other.factor(), prec);
    }
  };
  template <typename Derived, typename Scalar>
  CwiseBinaryOp<internal::scalar_product_op<typename internal::traits<Derived>::Scalar, Scalar>,
                const Derived,
                const typename internal::plain_constant_type<Derived, Scalar>::type>
  operator*(const MatrixBase<Derived>& matrix, const UniformScaling<Scalar>& s) {
    return matrix.derived() * s.factor();
  }
  inline UniformScaling<float> Scaling(float s) { return UniformScaling<float>(s); }
  inline UniformScaling<double> Scaling(double s) { return UniformScaling<double>(s); }
  template <typename RealScalar>
  inline UniformScaling<std::complex<RealScalar>> Scaling(const std::complex<RealScalar>& s) {
    return UniformScaling<std::complex<RealScalar>>(s);
  }
  template <typename Scalar>
  inline DiagonalMatrix<Scalar, 2> Scaling(const Scalar& sx, const Scalar& sy) {
    return DiagonalMatrix<Scalar, 2>(sx, sy);
  }
  template <typename Scalar>
  inline DiagonalMatrix<Scalar, 3> Scaling(const Scalar& sx, const Scalar& sy, const Scalar& sz) {
    return DiagonalMatrix<Scalar, 3>(sx, sy, sz);
  }
  template <typename Derived>
  inline const DiagonalWrapper<const Derived> Scaling(const MatrixBase<Derived>& coeffs) {
    return coeffs.asDiagonal();
  }
  template <typename Derived>
  inline typename DiagonalWrapper<const Derived>::PlainObject Scaling(MatrixBase<Derived>&& coeffs) {
    return typename DiagonalWrapper<const Derived>::PlainObject(std::move(coeffs.derived()));
  }
  typedef DiagonalMatrix<float, 2> AlignedScaling2f;
  typedef DiagonalMatrix<double, 2> AlignedScaling2d;
  typedef DiagonalMatrix<float, 3> AlignedScaling3f;
  typedef DiagonalMatrix<double, 3> AlignedScaling3d;
  template <typename Scalar>
  template <int Dim>
  inline Transform<Scalar, Dim, Affine> UniformScaling<Scalar>::operator*(const Translation<Scalar, Dim>& t) const {
    Transform<Scalar, Dim, Affine> res;
    res.matrix().setZero();
    res.linear().diagonal().fill(factor());
    res.translation() = factor() * t.vector();
    res(Dim, Dim) = Scalar(1);
    return res;
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar_, int AmbientDim_, int Options_>
  class Hyperplane {
  public:
    enum { AmbientDimAtCompileTime = AmbientDim_, Options = Options_ };
    typedef Scalar_ Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef Matrix<Scalar, AmbientDimAtCompileTime, 1> VectorType;
    typedef Matrix<Scalar,
                   Index(AmbientDimAtCompileTime) == Dynamic ? Dynamic : Index(AmbientDimAtCompileTime) + 1,
                   1,
                   Options>
        Coefficients;
    typedef Block<Coefficients, AmbientDimAtCompileTime, 1> NormalReturnType;
    typedef const Block<const Coefficients, AmbientDimAtCompileTime, 1> ConstNormalReturnType;
    inline Hyperplane() {}
    template <int OtherOptions>
    Hyperplane(const Hyperplane<Scalar, AmbientDimAtCompileTime, OtherOptions>& other) : m_coeffs(other.coeffs()) {}
    inline explicit Hyperplane(Index _dim) : m_coeffs(_dim + 1) {}
    inline Hyperplane(const VectorType& n, const VectorType& e) : m_coeffs(n.size() + 1) {
      normal() = n;
      offset() = -n.dot(e);
    }
    inline Hyperplane(const VectorType& n, const Scalar& d) : m_coeffs(n.size() + 1) {
      normal() = n;
      offset() = d;
    }
    static inline Hyperplane Through(const VectorType& p0, const VectorType& p1) {
      Hyperplane result(p0.size());
      result.normal() = (p1 - p0).unitOrthogonal();
      result.offset() = -p0.dot(result.normal());
      return result;
    }
    static inline Hyperplane Through(const VectorType& p0, const VectorType& p1, const VectorType& p2) {
      static_assert(VectorType::IsVectorAtCompileTime && VectorType::SizeAtCompileTime == 3,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      Hyperplane result(p0.size());
      VectorType v0(p2 - p0), v1(p1 - p0);
      result.normal() = v0.cross(v1);
      RealScalar norm = result.normal().norm();
      if (norm <= v0.norm() * v1.norm() * NumTraits<RealScalar>::epsilon()) {
        Matrix<Scalar, 2, 3> m;
        m << v0.transpose(), v1.transpose();
        JacobiSVD<Matrix<Scalar, 2, 3>, ComputeFullV> svd(m);
        result.normal() = svd.matrixV().col(2);
      } else
        result.normal() /= norm;
      result.offset() = -p0.dot(result.normal());
      return result;
    }
    explicit Hyperplane(const ParametrizedLine<Scalar, AmbientDimAtCompileTime>& parametrized) {
      normal() = parametrized.direction().unitOrthogonal();
      offset() = -parametrized.origin().dot(normal());
    }
    ~Hyperplane() {}
    inline Index dim() const {
      return AmbientDimAtCompileTime == Dynamic ? m_coeffs.size() - 1 : Index(AmbientDimAtCompileTime);
    }
    void normalize(void) { m_coeffs /= normal().norm(); }
    inline Scalar signedDistance(const VectorType& p) const { return normal().dot(p) + offset(); }
    inline Scalar absDistance(const VectorType& p) const { return numext::abs(signedDistance(p)); }
    inline VectorType projection(const VectorType& p) const { return p - signedDistance(p) * normal(); }
    inline ConstNormalReturnType normal() const { return ConstNormalReturnType(m_coeffs, 0, 0, dim(), 1); }
    inline NormalReturnType normal() { return NormalReturnType(m_coeffs, 0, 0, dim(), 1); }
    inline const Scalar& offset() const { return m_coeffs.coeff(dim()); }
    inline Scalar& offset() { return m_coeffs(dim()); }
    inline const Coefficients& coeffs() const { return m_coeffs; }
    inline Coefficients& coeffs() { return m_coeffs; }
    VectorType intersection(const Hyperplane& other) const {
      static_assert(VectorType::IsVectorAtCompileTime && VectorType::SizeAtCompileTime == 2,
                    "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      Scalar det = coeffs().coeff(0) * other.coeffs().coeff(1) - coeffs().coeff(1) * other.coeffs().coeff(0);
      if (internal::isMuchSmallerThan(det, Scalar(1))) {
        if (numext::abs(coeffs().coeff(1)) > numext::abs(coeffs().coeff(0)))
          return VectorType(coeffs().coeff(1), -coeffs().coeff(2) / coeffs().coeff(1) - coeffs().coeff(0));
        else
          return VectorType(-coeffs().coeff(2) / coeffs().coeff(0) - coeffs().coeff(1), coeffs().coeff(0));
      } else {
        Scalar invdet = Scalar(1) / det;
        return VectorType(
            invdet * (coeffs().coeff(1) * other.coeffs().coeff(2) - other.coeffs().coeff(1) * coeffs().coeff(2)),
            invdet * (other.coeffs().coeff(0) * coeffs().coeff(2) - coeffs().coeff(0) * other.coeffs().coeff(2)));
      }
    }
    template <typename XprType>
    inline Hyperplane& transform(const MatrixBase<XprType>& mat, TransformTraits traits = Affine) {
      if (traits == Affine) {
        normal() = mat.inverse().transpose() * normal();
        m_coeffs /= normal().norm();
      } else if (traits == Isometry)
        normal() = mat * normal();
      else {
        (static_cast<bool>(0 && "invalid traits value in Hyperplane::transform()")
             ? void(0)
             : __assert_fail("0 && \"invalid traits value in Hyperplane::transform()\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Geometry/Hyperplane.h",
                             230,
                             __extension__ __PRETTY_FUNCTION__));
      }
      return *this;
    }
    template <int TrOptions>
    inline Hyperplane& transform(const Transform<Scalar, AmbientDimAtCompileTime, Affine, TrOptions>& t,
                                 TransformTraits traits = Affine) {
      transform(t.linear(), traits);
      offset() -= normal().dot(t.translation());
      return *this;
    }
    template <typename NewScalarType>
    inline
        typename internal::cast_return_type<Hyperplane, Hyperplane<NewScalarType, AmbientDimAtCompileTime, Options>>::type
        cast() const {
      return
          typename internal::cast_return_type<Hyperplane,
                                              Hyperplane<NewScalarType, AmbientDimAtCompileTime, Options>>::type(*this);
    }
    template <typename OtherScalarType, int OtherOptions>
    inline explicit Hyperplane(const Hyperplane<OtherScalarType, AmbientDimAtCompileTime, OtherOptions>& other) {
      m_coeffs = other.coeffs().template cast<Scalar>();
    }
    template <int OtherOptions>
    bool isApprox(const Hyperplane<Scalar, AmbientDimAtCompileTime, OtherOptions>& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return m_coeffs.isApprox(other.m_coeffs, prec);
    }

  protected:
    Coefficients m_coeffs;
  };
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar_, int AmbientDim_, int Options_>
  class ParametrizedLine {
  public:
    enum { AmbientDimAtCompileTime = AmbientDim_, Options = Options_ };
    typedef Scalar_ Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef Matrix<Scalar, AmbientDimAtCompileTime, 1, Options> VectorType;
    inline ParametrizedLine() {}
    template <int OtherOptions>
    ParametrizedLine(const ParametrizedLine<Scalar, AmbientDimAtCompileTime, OtherOptions>& other)
        : m_origin(other.origin()), m_direction(other.direction()) {}
    inline explicit ParametrizedLine(Index _dim) : m_origin(_dim), m_direction(_dim) {}
    ParametrizedLine(const VectorType& origin, const VectorType& direction)
        : m_origin(origin), m_direction(direction) {}
    template <int OtherOptions>
    explicit ParametrizedLine(const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane);
    static inline ParametrizedLine Through(const VectorType& p0, const VectorType& p1) {
      return ParametrizedLine(p0, (p1 - p0).normalized());
    }
    ~ParametrizedLine() {}
    inline Index dim() const { return m_direction.size(); }
    const VectorType& origin() const { return m_origin; }
    VectorType& origin() { return m_origin; }
    const VectorType& direction() const { return m_direction; }
    VectorType& direction() { return m_direction; }
    RealScalar squaredDistance(const VectorType& p) const {
      VectorType diff = p - origin();
      return (diff - direction().dot(diff) * direction()).squaredNorm();
    }
    RealScalar distance(const VectorType& p) const {
      using std::sqrt;
      return sqrt(squaredDistance(p));
    }
    VectorType projection(const VectorType& p) const { return origin() + direction().dot(p - origin()) * direction(); }
    VectorType pointAt(const Scalar& t) const;
    template <int OtherOptions>
    Scalar intersectionParameter(const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const;
    template <int OtherOptions>
    Scalar intersection(const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const;
    template <int OtherOptions>
    VectorType intersectionPoint(const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const;
    template <typename XprType>
    inline ParametrizedLine& transform(const MatrixBase<XprType>& mat, TransformTraits traits = Affine) {
      if (traits == Affine)
        direction() = (mat * direction()).normalized();
      else if (traits == Isometry)
        direction() = mat * direction();
      else {
        (static_cast<bool>(0 && "invalid traits value in ParametrizedLine::transform()")
             ? void(0)
             : __assert_fail("0 && \"invalid traits value in ParametrizedLine::transform()\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Geometry/ParametrizedLine.h",
                             124,
                             __extension__ __PRETTY_FUNCTION__));
      }
      origin() = mat * origin();
      return *this;
    }
    template <int TrOptions>
    inline ParametrizedLine& transform(const Transform<Scalar, AmbientDimAtCompileTime, Affine, TrOptions>& t,
                                       TransformTraits traits = Affine) {
      transform(t.linear(), traits);
      origin() += t.translation();
      return *this;
    }
    template <typename NewScalarType>
    inline typename internal::cast_return_type<ParametrizedLine,
                                               ParametrizedLine<NewScalarType, AmbientDimAtCompileTime, Options>>::type
    cast() const {
      return typename internal::
          cast_return_type<ParametrizedLine, ParametrizedLine<NewScalarType, AmbientDimAtCompileTime, Options>>::type(
              *this);
    }
    template <typename OtherScalarType, int OtherOptions>
    inline explicit ParametrizedLine(
        const ParametrizedLine<OtherScalarType, AmbientDimAtCompileTime, OtherOptions>& other) {
      m_origin = other.origin().template cast<Scalar>();
      m_direction = other.direction().template cast<Scalar>();
    }
    bool isApprox(const ParametrizedLine& other,
                  const typename NumTraits<Scalar>::Real& prec = NumTraits<Scalar>::dummy_precision()) const {
      return m_origin.isApprox(other.m_origin, prec) && m_direction.isApprox(other.m_direction, prec);
    }

  protected:
    VectorType m_origin, m_direction;
  };
  template <typename Scalar_, int AmbientDim_, int Options_>
  template <int OtherOptions>
  inline ParametrizedLine<Scalar_, AmbientDim_, Options_>::ParametrizedLine(
      const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) {
    static_assert(VectorType::IsVectorAtCompileTime && VectorType::SizeAtCompileTime == 2,
                  "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
    direction() = hyperplane.normal().unitOrthogonal();
    origin() = -hyperplane.normal() * hyperplane.offset();
  }
  template <typename Scalar_, int AmbientDim_, int Options_>
  inline typename ParametrizedLine<Scalar_, AmbientDim_, Options_>::VectorType
  ParametrizedLine<Scalar_, AmbientDim_, Options_>::pointAt(const Scalar_& t) const {
    return origin() + (direction() * t);
  }
  template <typename Scalar_, int AmbientDim_, int Options_>
  template <int OtherOptions>
  inline Scalar_ ParametrizedLine<Scalar_, AmbientDim_, Options_>::intersectionParameter(
      const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const {
    return -(hyperplane.offset() + hyperplane.normal().dot(origin())) / hyperplane.normal().dot(direction());
  }
  template <typename Scalar_, int AmbientDim_, int Options_>
  template <int OtherOptions>
  inline Scalar_ ParametrizedLine<Scalar_, AmbientDim_, Options_>::intersection(
      const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const {
    return intersectionParameter(hyperplane);
  }
  template <typename Scalar_, int AmbientDim_, int Options_>
  template <int OtherOptions>
  inline typename ParametrizedLine<Scalar_, AmbientDim_, Options_>::VectorType
  ParametrizedLine<Scalar_, AmbientDim_, Options_>::intersectionPoint(
      const Hyperplane<Scalar_, AmbientDim_, OtherOptions>& hyperplane) const {
    return pointAt(intersectionParameter(hyperplane));
  }
}  // namespace Eigen

namespace Eigen {
  template <typename Scalar_, int AmbientDim_>
  class AlignedBox {
  public:
    enum { AmbientDimAtCompileTime = AmbientDim_ };
    typedef Scalar_ Scalar;
    typedef NumTraits<Scalar> ScalarTraits;
    typedef Eigen::Index Index;
    typedef typename ScalarTraits::Real RealScalar;
    typedef typename ScalarTraits::NonInteger NonInteger;
    typedef Matrix<Scalar, AmbientDimAtCompileTime, 1> VectorType;
    typedef CwiseBinaryOp<internal::scalar_sum_op<Scalar>, const VectorType, const VectorType> VectorTypeSum;
    enum CornerType {
      Min = 0,
      Max = 1,
      BottomLeft = 0,
      BottomRight = 1,
      TopLeft = 2,
      TopRight = 3,
      BottomLeftFloor = 0,
      BottomRightFloor = 1,
      TopLeftFloor = 2,
      TopRightFloor = 3,
      BottomLeftCeil = 4,
      BottomRightCeil = 5,
      TopLeftCeil = 6,
      TopRightCeil = 7
    };
    inline AlignedBox() {
      if (AmbientDimAtCompileTime != Dynamic)
        setEmpty();
    }
    inline explicit AlignedBox(Index _dim) : m_min(_dim), m_max(_dim) { setEmpty(); }
    template <typename OtherVectorType1, typename OtherVectorType2>
    inline AlignedBox(const OtherVectorType1& _min, const OtherVectorType2& _max) : m_min(_min), m_max(_max) {}
    template <typename Derived>
    inline explicit AlignedBox(const MatrixBase<Derived>& p) : m_min(p), m_max(m_min) {}
    ~AlignedBox() {}
    inline Index dim() const {
      return AmbientDimAtCompileTime == Dynamic ? m_min.size() : Index(AmbientDimAtCompileTime);
    }
    inline bool isNull() const { return isEmpty(); }
    inline void setNull() { setEmpty(); }
    inline bool isEmpty() const { return (m_min.array() > m_max.array()).any(); }
    inline void setEmpty() {
      m_min.setConstant(ScalarTraits::highest());
      m_max.setConstant(ScalarTraits::lowest());
    }
    inline const VectorType&(min)() const { return m_min; }
    inline VectorType&(min)() { return m_min; }
    inline const VectorType&(max)() const { return m_max; }
    inline VectorType&(max)() { return m_max; }
    inline const CwiseBinaryOp<internal::scalar_quotient_op<typename internal::traits<VectorTypeSum>::Scalar, RealScalar>,
                               const VectorTypeSum,
                               const typename internal::plain_constant_type<VectorTypeSum, RealScalar>::type>
    center() const {
      return (m_min + m_max) / RealScalar(2);
    }
    inline const CwiseBinaryOp<internal::scalar_difference_op<Scalar, Scalar>, const VectorType, const VectorType>
    sizes() const {
      return m_max - m_min;
    }
    inline Scalar volume() const { return sizes().prod(); }
    inline CwiseBinaryOp<internal::scalar_difference_op<Scalar, Scalar>, const VectorType, const VectorType> diagonal()
        const {
      return sizes();
    }
    inline VectorType corner(CornerType corner) const {
      static_assert(AmbientDim_ <= 3, "THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE");
      ;
      VectorType res;
      Index mult = 1;
      for (Index d = 0; d < dim(); ++d) {
        if (mult & corner)
          res[d] = m_max[d];
        else
          res[d] = m_min[d];
        mult *= 2;
      }
      return res;
    }
    inline VectorType sample() const {
      VectorType r(dim());
      for (Index d = 0; d < dim(); ++d) {
        if (!ScalarTraits::IsInteger) {
          r[d] = m_min[d] + (m_max[d] - m_min[d]) * internal::random<Scalar>(Scalar(0), Scalar(1));
        } else
          r[d] = internal::random(m_min[d], m_max[d]);
      }
      return r;
    }
    template <typename Derived>
    inline bool contains(const MatrixBase<Derived>& p) const {
      typename internal::nested_eval<Derived, 2>::type p_n(p.derived());
      return (m_min.array() <= p_n.array()).all() && (p_n.array() <= m_max.array()).all();
    }
    inline bool contains(const AlignedBox& b) const {
      return (m_min.array() <= (b.min)().array()).all() && ((b.max)().array() <= m_max.array()).all();
    }
    inline bool intersects(const AlignedBox& b) const {
      return (m_min.array() <= (b.max)().array()).all() && ((b.min)().array() <= m_max.array()).all();
    }
    template <typename Derived>
    inline AlignedBox& extend(const MatrixBase<Derived>& p) {
      typename internal::nested_eval<Derived, 2>::type p_n(p.derived());
      m_min = m_min.cwiseMin(p_n);
      m_max = m_max.cwiseMax(p_n);
      return *this;
    }
    inline AlignedBox& extend(const AlignedBox& b) {
      m_min = m_min.cwiseMin(b.m_min);
      m_max = m_max.cwiseMax(b.m_max);
      return *this;
    }
    inline AlignedBox& clamp(const AlignedBox& b) {
      m_min = m_min.cwiseMax(b.m_min);
      m_max = m_max.cwiseMin(b.m_max);
      return *this;
    }
    inline AlignedBox intersection(const AlignedBox& b) const {
      return AlignedBox(m_min.cwiseMax(b.m_min), m_max.cwiseMin(b.m_max));
    }
    inline AlignedBox merged(const AlignedBox& b) const {
      return AlignedBox(m_min.cwiseMin(b.m_min), m_max.cwiseMax(b.m_max));
    }
    template <typename Derived>
    inline AlignedBox& translate(const MatrixBase<Derived>& a_t) {
      const typename internal::nested_eval<Derived, 2>::type t(a_t.derived());
      m_min += t;
      m_max += t;
      return *this;
    }
    template <typename Derived>
    inline AlignedBox translated(const MatrixBase<Derived>& a_t) const {
      AlignedBox result(m_min, m_max);
      result.translate(a_t);
      return result;
    }
    template <typename Derived>
    inline Scalar squaredExteriorDistance(const MatrixBase<Derived>& p) const;
    inline Scalar squaredExteriorDistance(const AlignedBox& b) const;
    template <typename Derived>
    inline NonInteger exteriorDistance(const MatrixBase<Derived>& p) const {
      using std::sqrt;
      return sqrt(NonInteger(squaredExteriorDistance(p)));
    }
    inline NonInteger exteriorDistance(const AlignedBox& b) const {
      using std::sqrt;
      return sqrt(NonInteger(squaredExteriorDistance(b)));
    }
    template <int Mode, int Options>
    inline void transform(
        const typename Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>::TranslationType& translation) {
      this->translate(translation);
    }
    template <int Mode, int Options>
    inline void transform(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform) {
      static_assert(Mode == Affine || Mode == AffineCompact || Mode == Isometry,
                    "THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS");
      ;
      const VectorType rotated_extent_2 = transform.linear().cwiseAbs() * sizes();
      const VectorType rotated_center_2 =
          transform.linear() * (this->m_max + this->m_min) + Scalar(2) * transform.translation();
      this->m_max = (rotated_center_2 + rotated_extent_2) / Scalar(2);
      this->m_min = (rotated_center_2 - rotated_extent_2) / Scalar(2);
    }
    template <int Mode, int Options>
    AlignedBox transformed(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform) const {
      AlignedBox result(m_min, m_max);
      result.transform(transform);
      return result;
    }
    template <typename NewScalarType>
    inline typename internal::cast_return_type<AlignedBox, AlignedBox<NewScalarType, AmbientDimAtCompileTime>>::type
    cast() const {
      return typename internal::cast_return_type<AlignedBox, AlignedBox<NewScalarType, AmbientDimAtCompileTime>>::type(
          *this);
    }
    template <typename OtherScalarType>
    inline explicit AlignedBox(const AlignedBox<OtherScalarType, AmbientDimAtCompileTime>& other) {
      m_min = (other.min)().template cast<Scalar>();
      m_max = (other.max)().template cast<Scalar>();
    }
    bool isApprox(const AlignedBox& other, const RealScalar& prec = ScalarTraits::dummy_precision()) const {
      return m_min.isApprox(other.m_min, prec) && m_max.isApprox(other.m_max, prec);
    }

  protected:
    VectorType m_min, m_max;
  };
  template <typename Scalar, int AmbientDim>
  template <typename Derived>
  inline Scalar AlignedBox<Scalar, AmbientDim>::squaredExteriorDistance(const MatrixBase<Derived>& a_p) const {
    typename internal::nested_eval<Derived, 2 * AmbientDim>::type p(a_p.derived());
    Scalar dist2(0);
    Scalar aux;
    for (Index k = 0; k < dim(); ++k) {
      if (m_min[k] > p[k]) {
        aux = m_min[k] - p[k];
        dist2 += aux * aux;
      } else if (p[k] > m_max[k]) {
        aux = p[k] - m_max[k];
        dist2 += aux * aux;
      }
    }
    return dist2;
  }
  template <typename Scalar, int AmbientDim>
  inline Scalar AlignedBox<Scalar, AmbientDim>::squaredExteriorDistance(const AlignedBox& b) const {
    Scalar dist2(0);
    Scalar aux;
    for (Index k = 0; k < dim(); ++k) {
      if (m_min[k] > b.m_max[k]) {
        aux = m_min[k] - b.m_max[k];
        dist2 += aux * aux;
      } else if (b.m_min[k] > m_max[k]) {
        aux = b.m_min[k] - m_max[k];
        dist2 += aux * aux;
      }
    }
    return dist2;
  }
  typedef AlignedBox<int, 1> AlignedBox1i;
  typedef AlignedBox<int, 2> AlignedBox2i;
  typedef AlignedBox<int, 3> AlignedBox3i;
  typedef AlignedBox<int, 4> AlignedBox4i;
  typedef AlignedBox<int, Dynamic> AlignedBoxXi;
  typedef AlignedBox<float, 1> AlignedBox1f;
  typedef AlignedBox<float, 2> AlignedBox2f;
  typedef AlignedBox<float, 3> AlignedBox3f;
  typedef AlignedBox<float, 4> AlignedBox4f;
  typedef AlignedBox<float, Dynamic> AlignedBoxXf;
  typedef AlignedBox<double, 1> AlignedBox1d;
  typedef AlignedBox<double, 2> AlignedBox2d;
  typedef AlignedBox<double, 3> AlignedBox3d;
  typedef AlignedBox<double, 4> AlignedBox4d;
  typedef AlignedBox<double, Dynamic> AlignedBoxXd;
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, typename OtherMatrixType>
    struct umeyama_transform_matrix_type {
      enum {
        MinRowsAtCompileTime =
            internal::min_size_prefer_dynamic(MatrixType::RowsAtCompileTime, OtherMatrixType::RowsAtCompileTime),
        HomogeneousDimension = int(MinRowsAtCompileTime) == Dynamic ? Dynamic : int(MinRowsAtCompileTime) + 1
      };
      typedef Matrix<typename traits<MatrixType>::Scalar,
                     HomogeneousDimension,
                     HomogeneousDimension,
                     AutoAlign | (traits<MatrixType>::Flags & RowMajorBit ? RowMajor : ColMajor),
                     HomogeneousDimension,
                     HomogeneousDimension>
          type;
    };
  }  // namespace internal
  template <typename Derived, typename OtherDerived>
  typename internal::umeyama_transform_matrix_type<Derived, OtherDerived>::type umeyama(
      const MatrixBase<Derived>& src, const MatrixBase<OtherDerived>& dst, bool with_scaling = true) {
    typedef typename internal::umeyama_transform_matrix_type<Derived, OtherDerived>::type TransformationMatrixType;
    typedef typename internal::traits<TransformationMatrixType>::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    static_assert(!NumTraits<Scalar>::IsComplex, "NUMERIC_TYPE_MUST_BE_REAL");
    static_assert((internal::is_same<Scalar, typename internal::traits<OtherDerived>::Scalar>::value),
                  "YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_"
                  "TYPES_EXPLICITLY");
    enum { Dimension = internal::min_size_prefer_dynamic(Derived::RowsAtCompileTime, OtherDerived::RowsAtCompileTime) };
    typedef Matrix<Scalar, Dimension, 1> VectorType;
    typedef Matrix<Scalar, Dimension, Dimension> MatrixType;
    typedef typename internal::plain_matrix_type_row_major<Derived>::type RowMajorMatrixType;
    const Index m = src.rows();
    const Index n = src.cols();
    const RealScalar one_over_n = RealScalar(1) / static_cast<RealScalar>(n);
    const VectorType src_mean = src.rowwise().sum() * one_over_n;
    const VectorType dst_mean = dst.rowwise().sum() * one_over_n;
    const RowMajorMatrixType src_demean = src.colwise() - src_mean;
    const RowMajorMatrixType dst_demean = dst.colwise() - dst_mean;
    const MatrixType sigma = one_over_n * dst_demean * src_demean.transpose();
    JacobiSVD<MatrixType, ComputeFullU | ComputeFullV> svd(sigma);
    TransformationMatrixType Rt = TransformationMatrixType::Identity(m + 1, m + 1);
    VectorType S = VectorType::Ones(m);
    if (svd.matrixU().determinant() * svd.matrixV().determinant() < 0)
      S(m - 1) = -1;
    Rt.block(0, 0, m, m).noalias() = svd.matrixU() * S.asDiagonal() * svd.matrixV().transpose();
    if (with_scaling) {
      const Scalar src_var = src_demean.rowwise().squaredNorm().sum() * one_over_n;
      const Scalar c = Scalar(1) / src_var * svd.singularValues().dot(S);
      Rt.col(m).head(m) = dst_mean;
      Rt.col(m).head(m).noalias() -= c * Rt.topLeftCorner(m, m) * src_mean;
      Rt.block(0, 0, m, m) *= c;
    } else {
      Rt.col(m).head(m) = dst_mean;
      Rt.col(m).head(m).noalias() -= Rt.topLeftCorner(m, m) * src_mean;
    }
    return Rt;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <class Derived, class OtherDerived>
    struct quat_product<Architecture::Target, Derived, OtherDerived, float> {
      enum {
        AAlignment = traits<Derived>::Alignment,
        BAlignment = traits<OtherDerived>::Alignment,
        ResAlignment = traits<Quaternion<float>>::Alignment
      };
      static inline Quaternion<float> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b) {
        evaluator<typename Derived::Coefficients> ae(_a.coeffs());
        evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
        Quaternion<float> res;
        const float neg_zero = numext::bit_cast<float>(0x80000000u);
        const float arr[4] = {0.f, 0.f, 0.f, neg_zero};
        const Packet4f mask = ploadu<Packet4f>(arr);
        Packet4f a = ae.template packet<AAlignment, Packet4f>(0);
        Packet4f b = be.template packet<BAlignment, Packet4f>(0);
        Packet4f s1 = pmul(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(a)), (int)((shuffle_mask<1, 2, 0, 2>::mask)))))),
                           Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<2, 0, 1, 2>::mask)))))));
        Packet4f s2 = pmul(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(a)), (int)((shuffle_mask<3, 3, 3, 1>::mask)))))),
                           Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<0, 1, 2, 1>::mask)))))));
        pstoret<float, Packet4f, ResAlignment>(
            &res.x(),
            padd(psub(pmul(a,
                           Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<3, 3, 3, 3>::mask))))))),
                      pmul(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(a)), (int)((shuffle_mask<2, 0, 1, 0>::mask)))))),
                           Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                               (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<1, 2, 0, 0>::mask)))))))),
                 pxor(mask, padd(s1, s2))));
        return res;
      }
    };
    template <class Derived>
    struct quat_conj<Architecture::Target, Derived, float> {
      enum { ResAlignment = traits<Quaternion<float>>::Alignment };
      static inline Quaternion<float> run(const QuaternionBase<Derived>& q) {
        evaluator<typename Derived::Coefficients> qe(q.coeffs());
        Quaternion<float> res;
        const float neg_zero = numext::bit_cast<float>(0x80000000u);
        const float arr[4] = {neg_zero, neg_zero, neg_zero, 0.f};
        const Packet4f mask = ploadu<Packet4f>(arr);
        pstoret<float, Packet4f, ResAlignment>(&res.x(),
                                               pxor(mask, qe.template packet<traits<Derived>::Alignment, Packet4f>(0)));
        return res;
      }
    };
    template <typename VectorLhs, typename VectorRhs>
    struct cross3_impl<Architecture::Target, VectorLhs, VectorRhs, float, true> {
      enum { ResAlignment = traits<typename plain_matrix_type<VectorLhs>::type>::Alignment };
      static inline typename plain_matrix_type<VectorLhs>::type run(const VectorLhs& lhs, const VectorRhs& rhs) {
        evaluator<VectorLhs> lhs_eval(lhs);
        evaluator<VectorRhs> rhs_eval(rhs);
        Packet4f a = lhs_eval.template packet<traits<VectorLhs>::Alignment, Packet4f>(0);
        Packet4f b = rhs_eval.template packet<traits<VectorRhs>::Alignment, Packet4f>(0);
        Packet4f mul1 = pmul(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                                 (__v4si)(__m128i)(_mm_castps_si128(a)), (int)((shuffle_mask<1, 2, 0, 3>::mask)))))),
                             Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                                 (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<2, 0, 1, 3>::mask)))))));
        Packet4f mul2 = pmul(Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                                 (__v4si)(__m128i)(_mm_castps_si128(a)), (int)((shuffle_mask<2, 0, 1, 3>::mask)))))),
                             Packet4f(_mm_castsi128_ps(((__m128i)__builtin_ia32_pshufd(
                                 (__v4si)(__m128i)(_mm_castps_si128(b)), (int)((shuffle_mask<1, 2, 0, 3>::mask)))))));
        typename plain_matrix_type<VectorLhs>::type res;
        pstoret<float, Packet4f, ResAlignment>(&res.x(), psub(mul1, mul2));
        return res;
      }
    };
    template <class Derived, class OtherDerived>
    struct quat_product<Architecture::Target, Derived, OtherDerived, double> {
      enum { BAlignment = traits<OtherDerived>::Alignment, ResAlignment = traits<Quaternion<double>>::Alignment };
      static inline Quaternion<double> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b) {
        Quaternion<double> res;
        evaluator<typename Derived::Coefficients> ae(_a.coeffs());
        evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
        const double* a = _a.coeffs().data();
        Packet2d b_xy = be.template packet<BAlignment, Packet2d>(0);
        Packet2d b_zw = be.template packet<BAlignment, Packet2d>(2);
        Packet2d a_xx = pset1<Packet2d>(a[0]);
        Packet2d a_yy = pset1<Packet2d>(a[1]);
        Packet2d a_zz = pset1<Packet2d>(a[2]);
        Packet2d a_ww = pset1<Packet2d>(a[3]);
        Packet2d t1, t2;
        t1 = padd(pmul(a_ww, b_xy), pmul(a_yy, b_zw));
        t2 = psub(pmul(a_zz, b_xy), pmul(a_xx, b_zw));
        pstoret<double, Packet2d, ResAlignment>(&res.x(), paddsub(t1, preverse(t2)));
        t1 = psub(pmul(a_ww, b_zw), pmul(a_yy, b_xy));
        t2 = padd(pmul(a_zz, b_zw), pmul(a_xx, b_xy));
        pstoret<double, Packet2d, ResAlignment>(&res.z(), preverse(paddsub(preverse(t1), t2)));
        return res;
      }
    };
    template <class Derived>
    struct quat_conj<Architecture::Target, Derived, double> {
      enum { ResAlignment = traits<Quaternion<double>>::Alignment };
      static inline Quaternion<double> run(const QuaternionBase<Derived>& q) {
        evaluator<typename Derived::Coefficients> qe(q.coeffs());
        Quaternion<double> res;
        const double neg_zero = numext::bit_cast<double>(0x8000000000000000ull);
        const double arr1[2] = {neg_zero, neg_zero};
        const double arr2[2] = {neg_zero, 0.0};
        const Packet2d mask0 = ploadu<Packet2d>(arr1);
        const Packet2d mask2 = ploadu<Packet2d>(arr2);
        pstoret<double, Packet2d, ResAlignment>(
            &res.x(), pxor(mask0, qe.template packet<traits<Derived>::Alignment, Packet2d>(0)));
        pstoret<double, Packet2d, ResAlignment>(
            &res.z(), pxor(mask2, qe.template packet<traits<Derived>::Alignment, Packet2d>(2)));
        return res;
      }
    };
  }  // namespace internal
}  // namespace Eigen
#pragma clang diagnostic pop
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wconstant-logical-operand"
#pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"

namespace Eigen {
  namespace internal {
    template <typename MatrixType>
    struct TridiagonalizationMatrixTReturnType;
    template <typename MatrixType>
    struct traits<TridiagonalizationMatrixTReturnType<MatrixType>> : public traits<typename MatrixType::PlainObject> {
      typedef typename MatrixType::PlainObject ReturnType;
      enum { Flags = 0 };
    };
    template <typename MatrixType, typename CoeffVectorType>
    void tridiagonalization_inplace(MatrixType& matA, CoeffVectorType& hCoeffs);
  }  // namespace internal
  template <typename MatrixType_>
  class Tridiagonalization {
  public:
    typedef MatrixType_ MatrixType;
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    enum {
      Size = MatrixType::RowsAtCompileTime,
      SizeMinusOne = Size == Dynamic ? Dynamic : (Size > 1 ? Size - 1 : 1),
      Options = MatrixType::Options,
      MaxSize = MatrixType::MaxRowsAtCompileTime,
      MaxSizeMinusOne = MaxSize == Dynamic ? Dynamic : (MaxSize > 1 ? MaxSize - 1 : 1)
    };
    typedef Matrix<Scalar, SizeMinusOne, 1, Options & ~RowMajor, MaxSizeMinusOne, 1> CoeffVectorType;
    typedef typename internal::plain_col_type<MatrixType, RealScalar>::type DiagonalType;
    typedef Matrix<RealScalar, SizeMinusOne, 1, Options & ~RowMajor, MaxSizeMinusOne, 1> SubDiagonalType;
    typedef internal::remove_all_t<typename MatrixType::RealReturnType> MatrixTypeRealView;
    typedef internal::TridiagonalizationMatrixTReturnType<MatrixTypeRealView> MatrixTReturnType;
    typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
                               internal::add_const_on_value_type_t<typename Diagonal<const MatrixType>::RealReturnType>,
                               const Diagonal<const MatrixType>>
        DiagonalReturnType;
    typedef std::conditional_t<
        NumTraits<Scalar>::IsComplex,
        internal::add_const_on_value_type_t<typename Diagonal<const MatrixType, -1>::RealReturnType>,
        const Diagonal<const MatrixType, -1>>
        SubDiagonalReturnType;
    typedef HouseholderSequence<MatrixType, internal::remove_all_t<typename CoeffVectorType::ConjugateReturnType>>
        HouseholderSequenceType;
    explicit Tridiagonalization(Index size = Size == Dynamic ? 2 : Size)
        : m_matrix(size, size), m_hCoeffs(size > 1 ? size - 1 : 1), m_isInitialized(false) {}
    template <typename InputType>
    explicit Tridiagonalization(const EigenBase<InputType>& matrix)
        : m_matrix(matrix.derived()), m_hCoeffs(matrix.cols() > 1 ? matrix.cols() - 1 : 1), m_isInitialized(false) {
      internal::tridiagonalization_inplace(m_matrix, m_hCoeffs);
      m_isInitialized = true;
    }
    template <typename InputType>
    Tridiagonalization& compute(const EigenBase<InputType>& matrix) {
      m_matrix = matrix.derived();
      m_hCoeffs.resize(matrix.rows() - 1, 1);
      internal::tridiagonalization_inplace(m_matrix, m_hCoeffs);
      m_isInitialized = true;
      return *this;
    }
    inline CoeffVectorType householderCoefficients() const {
      (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           187,
                           __extension__ __PRETTY_FUNCTION__));
      return m_hCoeffs;
    }
    inline const MatrixType& packedMatrix() const {
      (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           224,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrix;
    }
    HouseholderSequenceType matrixQ() const {
      (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           245,
                           __extension__ __PRETTY_FUNCTION__));
      return HouseholderSequenceType(m_matrix, m_hCoeffs.conjugate()).setLength(m_matrix.rows() - 1).setShift(1);
    }
    MatrixTReturnType matrixT() const {
      (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           270,
                           __extension__ __PRETTY_FUNCTION__));
      return MatrixTReturnType(m_matrix.real());
    }
    DiagonalReturnType diagonal() const;
    SubDiagonalReturnType subDiagonal() const;

  protected:
    MatrixType m_matrix;
    CoeffVectorType m_hCoeffs;
    bool m_isInitialized;
  };
  template <typename MatrixType>
  typename Tridiagonalization<MatrixType>::DiagonalReturnType Tridiagonalization<MatrixType>::diagonal() const {
    (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/Tridiagonalization.h",
                         312,
                         __extension__ __PRETTY_FUNCTION__));
    return m_matrix.diagonal().real();
  }
  template <typename MatrixType>
  typename Tridiagonalization<MatrixType>::SubDiagonalReturnType Tridiagonalization<MatrixType>::subDiagonal() const {
    (static_cast<bool>(m_isInitialized && "Tridiagonalization is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"Tridiagonalization is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/Tridiagonalization.h",
                         320,
                         __extension__ __PRETTY_FUNCTION__));
    return m_matrix.template diagonal<-1>().real();
  }
  namespace internal {
    template <typename MatrixType, typename CoeffVectorType>
    void tridiagonalization_inplace(MatrixType& matA, CoeffVectorType& hCoeffs) {
      using numext::conj;
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      Index n = matA.rows();
      (static_cast<bool>(n == matA.cols())
           ? void(0)
           : __assert_fail("n==matA.cols()",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           357,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(n == hCoeffs.size() + 1 || n == 1)
           ? void(0)
           : __assert_fail("n==hCoeffs.size()+1 || n==1",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           358,
                           __extension__ __PRETTY_FUNCTION__));
      for (Index i = 0; i < n - 1; ++i) {
        Index remainingSize = n - i - 1;
        RealScalar beta;
        Scalar h;
        matA.col(i).tail(remainingSize).makeHouseholderInPlace(h, beta);
        matA.col(i).coeffRef(i + 1) = 1;
        hCoeffs.tail(n - i - 1).noalias() =
            (matA.bottomRightCorner(remainingSize, remainingSize).template selfadjointView<Lower>() *
             (conj(h) * matA.col(i).tail(remainingSize)));
        hCoeffs.tail(n - i - 1) +=
            (conj(h) * RealScalar(-0.5) * (hCoeffs.tail(remainingSize).dot(matA.col(i).tail(remainingSize)))) *
            matA.col(i).tail(n - i - 1);
        matA.bottomRightCorner(remainingSize, remainingSize)
            .template selfadjointView<Lower>()
            .rankUpdate(matA.col(i).tail(remainingSize), hCoeffs.tail(remainingSize), Scalar(-1));
        matA.col(i).coeffRef(i + 1) = beta;
        hCoeffs.coeffRef(i) = h;
      }
    }
    template <typename MatrixType,
              int Size = MatrixType::ColsAtCompileTime,
              bool IsComplex = NumTraits<typename MatrixType::Scalar>::IsComplex>
    struct tridiagonalization_inplace_selector;
    template <typename MatrixType, typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
    void tridiagonalization_inplace(
        MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType& hcoeffs, bool extractQ) {
      (static_cast<bool>(mat.cols() == mat.rows() && diag.size() == mat.rows() && subdiag.size() == mat.rows() - 1)
           ? void(0)
           : __assert_fail("mat.cols()==mat.rows() && diag.size()==mat.rows() && subdiag.size()==mat.rows()-1",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/Tridiagonalization.h",
                           435,
                           __extension__ __PRETTY_FUNCTION__));
      tridiagonalization_inplace_selector<MatrixType>::run(mat, diag, subdiag, hcoeffs, extractQ);
    }
    template <typename MatrixType, int Size, bool IsComplex>
    struct tridiagonalization_inplace_selector {
      typedef typename Tridiagonalization<MatrixType>::HouseholderSequenceType HouseholderSequenceType;
      template <typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
      static void run(
          MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType& hCoeffs, bool extractQ) {
        tridiagonalization_inplace(mat, hCoeffs);
        diag = mat.diagonal().real();
        subdiag = mat.template diagonal<-1>().real();
        if (extractQ)
          mat = HouseholderSequenceType(mat, hCoeffs.conjugate()).setLength(mat.rows() - 1).setShift(1);
      }
    };
    template <typename MatrixType>
    struct tridiagonalization_inplace_selector<MatrixType, 3, false> {
      typedef typename MatrixType::Scalar Scalar;
      typedef typename MatrixType::RealScalar RealScalar;
      template <typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
      static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType&, bool extractQ) {
        using std::sqrt;
        const RealScalar tol = (std::numeric_limits<RealScalar>::min)();
        diag[0] = mat(0, 0);
        RealScalar v1norm2 = numext::abs2(mat(2, 0));
        if (v1norm2 <= tol) {
          diag[1] = mat(1, 1);
          diag[2] = mat(2, 2);
          subdiag[0] = mat(1, 0);
          subdiag[1] = mat(2, 1);
          if (extractQ)
            mat.setIdentity();
        } else {
          RealScalar beta = sqrt(numext::abs2(mat(1, 0)) + v1norm2);
          RealScalar invBeta = RealScalar(1) / beta;
          Scalar m01 = mat(1, 0) * invBeta;
          Scalar m02 = mat(2, 0) * invBeta;
          Scalar q = RealScalar(2) * m01 * mat(2, 1) + m02 * (mat(2, 2) - mat(1, 1));
          diag[1] = mat(1, 1) + m02 * q;
          diag[2] = mat(2, 2) - m02 * q;
          subdiag[0] = beta;
          subdiag[1] = mat(2, 1) - m01 * q;
          if (extractQ) {
            mat << 1, 0, 0, 0, m01, m02, 0, m02, -m01;
          }
        }
      }
    };
    template <typename MatrixType, bool IsComplex>
    struct tridiagonalization_inplace_selector<MatrixType, 1, IsComplex> {
      typedef typename MatrixType::Scalar Scalar;
      template <typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
      static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType&, CoeffVectorType&, bool extractQ) {
        diag(0, 0) = numext::real(mat(0, 0));
        if (extractQ)
          mat(0, 0) = Scalar(1);
      }
    };
    template <typename MatrixType>
    struct TridiagonalizationMatrixTReturnType : public ReturnByValue<TridiagonalizationMatrixTReturnType<MatrixType>> {
    public:
      TridiagonalizationMatrixTReturnType(const MatrixType& mat) : m_matrix(mat) {}
      template <typename ResultType>
      inline void evalTo(ResultType& result) const {
        result.setZero();
        result.template diagonal<1>() = m_matrix.template diagonal<-1>().conjugate();
        result.diagonal() = m_matrix.diagonal();
        result.template diagonal<-1>() = m_matrix.template diagonal<-1>();
      }
      constexpr Index rows() const noexcept { return m_matrix.rows(); }
      constexpr Index cols() const noexcept { return m_matrix.cols(); }

    protected:
      typename MatrixType::Nested m_matrix;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType>
    struct HessenbergDecompositionMatrixHReturnType;
    template <typename MatrixType>
    struct traits<HessenbergDecompositionMatrixHReturnType<MatrixType>> {
      typedef MatrixType ReturnType;
    };
  }  // namespace internal
  template <typename MatrixType_>
  class HessenbergDecomposition {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      Size = MatrixType::RowsAtCompileTime,
      SizeMinusOne = Size == Dynamic ? Dynamic : Size - 1,
      Options = MatrixType::Options,
      MaxSize = MatrixType::MaxRowsAtCompileTime,
      MaxSizeMinusOne = MaxSize == Dynamic ? Dynamic : MaxSize - 1
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef Eigen::Index Index;
    typedef Matrix<Scalar, SizeMinusOne, 1, Options & ~RowMajor, MaxSizeMinusOne, 1> CoeffVectorType;
    typedef HouseholderSequence<MatrixType, internal::remove_all_t<typename CoeffVectorType::ConjugateReturnType>>
        HouseholderSequenceType;
    typedef internal::HessenbergDecompositionMatrixHReturnType<MatrixType> MatrixHReturnType;
    explicit HessenbergDecomposition(Index size = Size == Dynamic ? 2 : Size)
        : m_matrix(size, size), m_temp(size), m_isInitialized(false) {
      if (size > 1)
        m_hCoeffs.resize(size - 1);
    }
    template <typename InputType>
    explicit HessenbergDecomposition(const EigenBase<InputType>& matrix)
        : m_matrix(matrix.derived()), m_temp(matrix.rows()), m_isInitialized(false) {
      if (matrix.rows() < 2) {
        m_isInitialized = true;
        return;
      }
      m_hCoeffs.resize(matrix.rows() - 1, 1);
      _compute(m_matrix, m_hCoeffs, m_temp);
      m_isInitialized = true;
    }
    template <typename InputType>
    HessenbergDecomposition& compute(const EigenBase<InputType>& matrix) {
      m_matrix = matrix.derived();
      if (matrix.rows() < 2) {
        m_isInitialized = true;
        return *this;
      }
      m_hCoeffs.resize(matrix.rows() - 1, 1);
      _compute(m_matrix, m_hCoeffs, m_temp);
      m_isInitialized = true;
      return *this;
    }
    const CoeffVectorType& householderCoefficients() const {
      (static_cast<bool>(m_isInitialized && "HessenbergDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HessenbergDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/./HessenbergDecomposition.h",
                           183,
                           __extension__ __PRETTY_FUNCTION__));
      return m_hCoeffs;
    }
    const MatrixType& packedMatrix() const {
      (static_cast<bool>(m_isInitialized && "HessenbergDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HessenbergDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/./HessenbergDecomposition.h",
                           218,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matrix;
    }
    HouseholderSequenceType matrixQ() const {
      (static_cast<bool>(m_isInitialized && "HessenbergDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HessenbergDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/./HessenbergDecomposition.h",
                           238,
                           __extension__ __PRETTY_FUNCTION__));
      return HouseholderSequenceType(m_matrix, m_hCoeffs.conjugate()).setLength(m_matrix.rows() - 1).setShift(1);
    }
    MatrixHReturnType matrixH() const {
      (static_cast<bool>(m_isInitialized && "HessenbergDecomposition is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"HessenbergDecomposition is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/./HessenbergDecomposition.h",
                           266,
                           __extension__ __PRETTY_FUNCTION__));
      return MatrixHReturnType(*this);
    }

  private:
    typedef Matrix<Scalar, 1, Size, int(Options) | int(RowMajor), 1, MaxSize> VectorType;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    static void _compute(MatrixType& matA, CoeffVectorType& hCoeffs, VectorType& temp);

  protected:
    MatrixType m_matrix;
    CoeffVectorType m_hCoeffs;
    VectorType m_temp;
    bool m_isInitialized;
  };
  template <typename MatrixType>
  void HessenbergDecomposition<MatrixType>::_compute(MatrixType& matA, CoeffVectorType& hCoeffs, VectorType& temp) {
    (static_cast<bool>(matA.rows() == matA.cols())
         ? void(0)
         : __assert_fail("matA.rows()==matA.cols()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/./HessenbergDecomposition.h",
                         298,
                         __extension__ __PRETTY_FUNCTION__));
    Index n = matA.rows();
    temp.resize(n);
    for (Index i = 0; i < n - 1; ++i) {
      Index remainingSize = n - i - 1;
      RealScalar beta;
      Scalar h;
      matA.col(i).tail(remainingSize).makeHouseholderInPlace(h, beta);
      matA.col(i).coeffRef(i + 1) = beta;
      hCoeffs.coeffRef(i) = h;
      matA.bottomRightCorner(remainingSize, remainingSize)
          .applyHouseholderOnTheLeft(matA.col(i).tail(remainingSize - 1), h, &temp.coeffRef(0));
      matA.rightCols(remainingSize)
          .applyHouseholderOnTheRight(matA.col(i).tail(remainingSize - 1), numext::conj(h), &temp.coeffRef(0));
    }
  }
  namespace internal {
    template <typename MatrixType>
    struct HessenbergDecompositionMatrixHReturnType
        : public ReturnByValue<HessenbergDecompositionMatrixHReturnType<MatrixType>> {
    public:
      HessenbergDecompositionMatrixHReturnType(const HessenbergDecomposition<MatrixType>& hess) : m_hess(hess) {}
      template <typename ResultType>
      inline void evalTo(ResultType& result) const {
        result = m_hess.packedMatrix();
        Index n = result.rows();
        if (n > 2)
          result.bottomLeftCorner(n - 2, n - 2).template triangularView<Lower>().setZero();
      }
      Index rows() const { return m_hess.packedMatrix().rows(); }
      Index cols() const { return m_hess.packedMatrix().cols(); }

    protected:
      const HessenbergDecomposition<MatrixType>& m_hess;
    };
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class RealSchur {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef std::complex<typename NumTraits<Scalar>::Real> ComplexScalar;
    typedef Eigen::Index Index;
    typedef Matrix<ComplexScalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> EigenvalueType;
    typedef Matrix<Scalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> ColumnVectorType;
    explicit RealSchur(Index size = RowsAtCompileTime == Dynamic ? 1 : RowsAtCompileTime)
        : m_matT(size, size),
          m_matU(size, size),
          m_workspaceVector(size),
          m_hess(size),
          m_isInitialized(false),
          m_matUisUptodate(false),
          m_maxIters(-1) {}
    template <typename InputType>
    explicit RealSchur(const EigenBase<InputType>& matrix, bool computeU = true)
        : m_matT(matrix.rows(), matrix.cols()),
          m_matU(matrix.rows(), matrix.cols()),
          m_workspaceVector(matrix.rows()),
          m_hess(matrix.rows()),
          m_isInitialized(false),
          m_matUisUptodate(false),
          m_maxIters(-1) {
      compute(matrix.derived(), computeU);
    }
    const MatrixType& matrixU() const {
      (static_cast<bool>(m_isInitialized && "RealSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealSchur.h",
                           131,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_matUisUptodate && "The matrix U has not been computed during the RealSchur decomposition.")
           ? void(0)
           : __assert_fail(
                 "m_matUisUptodate && \"The matrix U has not been computed during the RealSchur decomposition.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/RealSchur.h",
                 132,
                 __extension__ __PRETTY_FUNCTION__));
      return m_matU;
    }
    const MatrixType& matrixT() const {
      (static_cast<bool>(m_isInitialized && "RealSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealSchur.h",
                           148,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matT;
    }
    template <typename InputType>
    RealSchur& compute(const EigenBase<InputType>& matrix, bool computeU = true);
    template <typename HessMatrixType, typename OrthMatrixType>
    RealSchur& computeFromHessenberg(const HessMatrixType& matrixH, const OrthMatrixType& matrixQ, bool computeU);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "RealSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealSchur.h",
                           199,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    RealSchur& setMaxIterations(Index maxIters) {
      m_maxIters = maxIters;
      return *this;
    }
    Index getMaxIterations() { return m_maxIters; }
    static const int m_maxIterationsPerRow = 40;

  private:
    MatrixType m_matT;
    MatrixType m_matU;
    ColumnVectorType m_workspaceVector;
    HessenbergDecomposition<MatrixType> m_hess;
    ComputationInfo m_info;
    bool m_isInitialized;
    bool m_matUisUptodate;
    Index m_maxIters;
    typedef Matrix<Scalar, 3, 1> Vector3s;
    Scalar computeNormOfT();
    Index findSmallSubdiagEntry(Index iu, const Scalar& considerAsZero);
    void splitOffTwoRows(Index iu, bool computeU, const Scalar& exshift);
    void computeShift(Index iu, Index iter, Scalar& exshift, Vector3s& shiftInfo);
    void initFrancisQRStep(Index il, Index iu, const Vector3s& shiftInfo, Index& im, Vector3s& firstHouseholderVector);
    void performFrancisQRStep(
        Index il, Index im, Index iu, bool computeU, const Vector3s& firstHouseholderVector, Scalar* workspace);
  };
  template <typename MatrixType>
  template <typename InputType>
  RealSchur<MatrixType>& RealSchur<MatrixType>::compute(const EigenBase<InputType>& matrix, bool computeU) {
    const Scalar considerAsZero = (std::numeric_limits<Scalar>::min)();
    (static_cast<bool>(matrix.cols() == matrix.rows())
         ? void(0)
         : __assert_fail("matrix.cols() == matrix.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/RealSchur.h",
                         255,
                         __extension__ __PRETTY_FUNCTION__));
    Index maxIters = m_maxIters;
    if (maxIters == -1)
      maxIters = m_maxIterationsPerRow * matrix.rows();
    Scalar scale = matrix.derived().cwiseAbs().maxCoeff();
    if (scale < considerAsZero) {
      m_matT.setZero(matrix.rows(), matrix.cols());
      if (computeU)
        m_matU.setIdentity(matrix.rows(), matrix.cols());
      m_info = Success;
      m_isInitialized = true;
      m_matUisUptodate = computeU;
      return *this;
    }
    m_hess.compute(matrix.derived() / scale);
    m_workspaceVector.resize(matrix.cols());
    if (computeU)
      m_hess.matrixQ().evalTo(m_matU, m_workspaceVector);
    computeFromHessenberg(m_hess.matrixH(), m_matU, computeU);
    m_matT *= scale;
    return *this;
  }
  template <typename MatrixType>
  template <typename HessMatrixType, typename OrthMatrixType>
  RealSchur<MatrixType>& RealSchur<MatrixType>::computeFromHessenberg(const HessMatrixType& matrixH,
                                                                      const OrthMatrixType& matrixQ,
                                                                      bool computeU) {
    using std::abs;
    m_matT = matrixH;
    m_workspaceVector.resize(m_matT.cols());
    if (computeU && !internal::is_same_dense(m_matU, matrixQ))
      m_matU = matrixQ;
    Index maxIters = m_maxIters;
    if (maxIters == -1)
      maxIters = m_maxIterationsPerRow * matrixH.rows();
    Scalar* workspace = &m_workspaceVector.coeffRef(0);
    Index iu = m_matT.cols() - 1;
    Index iter = 0;
    Index totalIter = 0;
    Scalar exshift(0);
    Scalar norm = computeNormOfT();
    Scalar considerAsZero =
        numext::maxi<Scalar>(norm * numext::abs2(NumTraits<Scalar>::epsilon()), (std::numeric_limits<Scalar>::min)());
    if (!numext::is_exactly_zero(norm)) {
      while (iu >= 0) {
        Index il = findSmallSubdiagEntry(iu, considerAsZero);
        if (il == iu) {
          m_matT.coeffRef(iu, iu) = m_matT.coeff(iu, iu) + exshift;
          if (iu > 0)
            m_matT.coeffRef(iu, iu - 1) = Scalar(0);
          iu--;
          iter = 0;
        } else if (il == iu - 1) {
          splitOffTwoRows(iu, computeU, exshift);
          iu -= 2;
          iter = 0;
        } else {
          Vector3s firstHouseholderVector = Vector3s::Zero(), shiftInfo;
          computeShift(iu, iter, exshift, shiftInfo);
          iter = iter + 1;
          totalIter = totalIter + 1;
          if (totalIter > maxIters)
            break;
          Index im;
          initFrancisQRStep(il, iu, shiftInfo, im, firstHouseholderVector);
          performFrancisQRStep(il, im, iu, computeU, firstHouseholderVector, workspace);
        }
      }
    }
    if (totalIter <= maxIters)
      m_info = Success;
    else
      m_info = NoConvergence;
    m_isInitialized = true;
    m_matUisUptodate = computeU;
    return *this;
  }
  template <typename MatrixType>
  inline typename MatrixType::Scalar RealSchur<MatrixType>::computeNormOfT() {
    const Index size = m_matT.cols();
    Scalar norm(0);
    for (Index j = 0; j < size; ++j)
      norm += m_matT.col(j).segment(0, (std::min)(size, j + 2)).cwiseAbs().sum();
    return norm;
  }
  template <typename MatrixType>
  inline Index RealSchur<MatrixType>::findSmallSubdiagEntry(Index iu, const Scalar& considerAsZero) {
    using std::abs;
    Index res = iu;
    while (res > 0) {
      Scalar s = abs(m_matT.coeff(res - 1, res - 1)) + abs(m_matT.coeff(res, res));
      s = numext::maxi<Scalar>(s * NumTraits<Scalar>::epsilon(), considerAsZero);
      if (abs(m_matT.coeff(res, res - 1)) <= s)
        break;
      res--;
    }
    return res;
  }
  template <typename MatrixType>
  inline void RealSchur<MatrixType>::splitOffTwoRows(Index iu, bool computeU, const Scalar& exshift) {
    using std::abs;
    using std::sqrt;
    const Index size = m_matT.cols();
    Scalar p = Scalar(0.5) * (m_matT.coeff(iu - 1, iu - 1) - m_matT.coeff(iu, iu));
    Scalar q = p * p + m_matT.coeff(iu, iu - 1) * m_matT.coeff(iu - 1, iu);
    m_matT.coeffRef(iu, iu) += exshift;
    m_matT.coeffRef(iu - 1, iu - 1) += exshift;
    if (q >= Scalar(0)) {
      Scalar z = sqrt(abs(q));
      JacobiRotation<Scalar> rot;
      if (p >= Scalar(0))
        rot.makeGivens(p + z, m_matT.coeff(iu, iu - 1));
      else
        rot.makeGivens(p - z, m_matT.coeff(iu, iu - 1));
      m_matT.rightCols(size - iu + 1).applyOnTheLeft(iu - 1, iu, rot.adjoint());
      m_matT.topRows(iu + 1).applyOnTheRight(iu - 1, iu, rot);
      m_matT.coeffRef(iu, iu - 1) = Scalar(0);
      if (computeU)
        m_matU.applyOnTheRight(iu - 1, iu, rot);
    }
    if (iu > 1)
      m_matT.coeffRef(iu - 1, iu - 2) = Scalar(0);
  }
  template <typename MatrixType>
  inline void RealSchur<MatrixType>::computeShift(Index iu, Index iter, Scalar& exshift, Vector3s& shiftInfo) {
    using std::abs;
    using std::sqrt;
    shiftInfo.coeffRef(0) = m_matT.coeff(iu, iu);
    shiftInfo.coeffRef(1) = m_matT.coeff(iu - 1, iu - 1);
    shiftInfo.coeffRef(2) = m_matT.coeff(iu, iu - 1) * m_matT.coeff(iu - 1, iu);
    if (iter == 10) {
      exshift += shiftInfo.coeff(0);
      for (Index i = 0; i <= iu; ++i)
        m_matT.coeffRef(i, i) -= shiftInfo.coeff(0);
      Scalar s = abs(m_matT.coeff(iu, iu - 1)) + abs(m_matT.coeff(iu - 1, iu - 2));
      shiftInfo.coeffRef(0) = Scalar(0.75) * s;
      shiftInfo.coeffRef(1) = Scalar(0.75) * s;
      shiftInfo.coeffRef(2) = Scalar(-0.4375) * s * s;
    }
    if (iter == 30) {
      Scalar s = (shiftInfo.coeff(1) - shiftInfo.coeff(0)) / Scalar(2.0);
      s = s * s + shiftInfo.coeff(2);
      if (s > Scalar(0)) {
        s = sqrt(s);
        if (shiftInfo.coeff(1) < shiftInfo.coeff(0))
          s = -s;
        s = s + (shiftInfo.coeff(1) - shiftInfo.coeff(0)) / Scalar(2.0);
        s = shiftInfo.coeff(0) - shiftInfo.coeff(2) / s;
        exshift += s;
        for (Index i = 0; i <= iu; ++i)
          m_matT.coeffRef(i, i) -= s;
        shiftInfo.setConstant(Scalar(0.964));
      }
    }
  }
  template <typename MatrixType>
  inline void RealSchur<MatrixType>::initFrancisQRStep(
      Index il, Index iu, const Vector3s& shiftInfo, Index& im, Vector3s& firstHouseholderVector) {
    using std::abs;
    Vector3s& v = firstHouseholderVector;
    for (im = iu - 2; im >= il; --im) {
      const Scalar Tmm = m_matT.coeff(im, im);
      const Scalar r = shiftInfo.coeff(0) - Tmm;
      const Scalar s = shiftInfo.coeff(1) - Tmm;
      v.coeffRef(0) = (r * s - shiftInfo.coeff(2)) / m_matT.coeff(im + 1, im) + m_matT.coeff(im, im + 1);
      v.coeffRef(1) = m_matT.coeff(im + 1, im + 1) - Tmm - r - s;
      v.coeffRef(2) = m_matT.coeff(im + 2, im + 1);
      if (im == il) {
        break;
      }
      const Scalar lhs = m_matT.coeff(im, im - 1) * (abs(v.coeff(1)) + abs(v.coeff(2)));
      const Scalar rhs =
          v.coeff(0) * (abs(m_matT.coeff(im - 1, im - 1)) + abs(Tmm) + abs(m_matT.coeff(im + 1, im + 1)));
      if (abs(lhs) < NumTraits<Scalar>::epsilon() * rhs)
        break;
    }
  }
  template <typename MatrixType>
  inline void RealSchur<MatrixType>::performFrancisQRStep(
      Index il, Index im, Index iu, bool computeU, const Vector3s& firstHouseholderVector, Scalar* workspace) {
    (static_cast<bool>(im >= il)
         ? void(0)
         : __assert_fail("im >= il",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/RealSchur.h",
                         501,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(im <= iu - 2)
         ? void(0)
         : __assert_fail("im <= iu-2",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/RealSchur.h",
                         502,
                         __extension__ __PRETTY_FUNCTION__));
    const Index size = m_matT.cols();
    for (Index k = im; k <= iu - 2; ++k) {
      bool firstIteration = (k == im);
      Vector3s v;
      if (firstIteration)
        v = firstHouseholderVector;
      else
        v = m_matT.template block<3, 1>(k, k - 1);
      Scalar tau, beta;
      Matrix<Scalar, 2, 1> ess;
      v.makeHouseholder(ess, tau, beta);
      if (!numext::is_exactly_zero(beta)) {
        if (firstIteration && k > il)
          m_matT.coeffRef(k, k - 1) = -m_matT.coeff(k, k - 1);
        else if (!firstIteration)
          m_matT.coeffRef(k, k - 1) = beta;
        m_matT.block(k, k, 3, size - k).applyHouseholderOnTheLeft(ess, tau, workspace);
        m_matT.block(0, k, (std::min)(iu, k + 3) + 1, 3).applyHouseholderOnTheRight(ess, tau, workspace);
        if (computeU)
          m_matU.block(0, k, size, 3).applyHouseholderOnTheRight(ess, tau, workspace);
      }
    }
    Matrix<Scalar, 2, 1> v = m_matT.template block<2, 1>(iu - 1, iu - 2);
    Scalar tau, beta;
    Matrix<Scalar, 1, 1> ess;
    v.makeHouseholder(ess, tau, beta);
    if (!numext::is_exactly_zero(beta)) {
      m_matT.coeffRef(iu - 1, iu - 2) = beta;
      m_matT.block(iu - 1, iu - 1, 2, size - iu + 1).applyHouseholderOnTheLeft(ess, tau, workspace);
      m_matT.block(0, iu - 1, iu + 1, 2).applyHouseholderOnTheRight(ess, tau, workspace);
      if (computeU)
        m_matU.block(0, iu - 1, size, 2).applyHouseholderOnTheRight(ess, tau, workspace);
    }
    for (Index i = im + 2; i <= iu; ++i) {
      m_matT.coeffRef(i, i - 2) = Scalar(0);
      if (i > im + 2)
        m_matT.coeffRef(i, i - 3) = Scalar(0);
    }
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class EigenSolver {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef std::complex<RealScalar> ComplexScalar;
    typedef Matrix<ComplexScalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> EigenvalueType;
    typedef Matrix<ComplexScalar, RowsAtCompileTime, ColsAtCompileTime, Options, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        EigenvectorsType;
    EigenSolver()
        : m_eivec(), m_eivalues(), m_isInitialized(false), m_eigenvectorsOk(false), m_realSchur(), m_matT(), m_tmp() {}
    explicit EigenSolver(Index size)
        : m_eivec(size, size),
          m_eivalues(size),
          m_isInitialized(false),
          m_eigenvectorsOk(false),
          m_realSchur(size),
          m_matT(size, size),
          m_tmp(size) {}
    template <typename InputType>
    explicit EigenSolver(const EigenBase<InputType>& matrix, bool computeEigenvectors = true)
        : m_eivec(matrix.rows(), matrix.cols()),
          m_eivalues(matrix.cols()),
          m_isInitialized(false),
          m_eigenvectorsOk(false),
          m_realSchur(matrix.cols()),
          m_matT(matrix.rows(), matrix.cols()),
          m_tmp(matrix.cols()) {
      compute(matrix.derived(), computeEigenvectors);
    }
    EigenvectorsType eigenvectors() const;
    const MatrixType& pseudoEigenvectors() const {
      (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/EigenSolver.h",
                           203,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
           ? void(0)
           : __assert_fail(
                 "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/EigenSolver.h",
                 204,
                 __extension__ __PRETTY_FUNCTION__));
      return m_eivec;
    }
    MatrixType pseudoEigenvalueMatrix() const;
    const EigenvalueType& eigenvalues() const {
      (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/EigenSolver.h",
                           248,
                           __extension__ __PRETTY_FUNCTION__));
      return m_eivalues;
    }
    template <typename InputType>
    EigenSolver& compute(const EigenBase<InputType>& matrix, bool computeEigenvectors = true);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/EigenSolver.h",
                           285,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    EigenSolver& setMaxIterations(Index maxIters) {
      m_realSchur.setMaxIterations(maxIters);
      return *this;
    }
    Index getMaxIterations() { return m_realSchur.getMaxIterations(); }

  private:
    void doComputeEigenvectors();

  protected:
    static void check_template_parameters() {
      static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
      ;
      static_assert(!NumTraits<Scalar>::IsComplex, "NUMERIC_TYPE_MUST_BE_REAL");
      ;
    }
    MatrixType m_eivec;
    EigenvalueType m_eivalues;
    bool m_isInitialized;
    bool m_eigenvectorsOk;
    ComputationInfo m_info;
    RealSchur<MatrixType> m_realSchur;
    MatrixType m_matT;
    typedef Matrix<Scalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> ColumnVectorType;
    ColumnVectorType m_tmp;
  };
  template <typename MatrixType>
  MatrixType EigenSolver<MatrixType>::pseudoEigenvalueMatrix() const {
    (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/EigenSolver.h",
                         328,
                         __extension__ __PRETTY_FUNCTION__));
    const RealScalar precision = RealScalar(2) * NumTraits<RealScalar>::epsilon();
    Index n = m_eivalues.rows();
    MatrixType matD = MatrixType::Zero(n, n);
    for (Index i = 0; i < n; ++i) {
      if (internal::isMuchSmallerThan(numext::imag(m_eivalues.coeff(i)), numext::real(m_eivalues.coeff(i)), precision))
        matD.coeffRef(i, i) = numext::real(m_eivalues.coeff(i));
      else {
        matD.template block<2, 2>(i, i) << numext::real(m_eivalues.coeff(i)), numext::imag(m_eivalues.coeff(i)),
            -numext::imag(m_eivalues.coeff(i)), numext::real(m_eivalues.coeff(i));
        ++i;
      }
    }
    return matD;
  }
  template <typename MatrixType>
  typename EigenSolver<MatrixType>::EigenvectorsType EigenSolver<MatrixType>::eigenvectors() const {
    (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
         ? void(0)
         : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/EigenSolver.h",
                         349,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
         ? void(0)
         : __assert_fail(
               "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
               "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
               "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
               "Eigenvalues/EigenSolver.h",
               350,
               __extension__ __PRETTY_FUNCTION__));
    const RealScalar precision = RealScalar(2) * NumTraits<RealScalar>::epsilon();
    Index n = m_eivec.cols();
    EigenvectorsType matV(n, n);
    for (Index j = 0; j < n; ++j) {
      if (internal::isMuchSmallerThan(
              numext::imag(m_eivalues.coeff(j)), numext::real(m_eivalues.coeff(j)), precision) ||
          j + 1 == n) {
        matV.col(j) = m_eivec.col(j).template cast<ComplexScalar>();
        matV.col(j).normalize();
      } else {
        for (Index i = 0; i < n; ++i) {
          matV.coeffRef(i, j) = ComplexScalar(m_eivec.coeff(i, j), m_eivec.coeff(i, j + 1));
          matV.coeffRef(i, j + 1) = ComplexScalar(m_eivec.coeff(i, j), -m_eivec.coeff(i, j + 1));
        }
        matV.col(j).normalize();
        matV.col(j + 1).normalize();
        ++j;
      }
    }
    return matV;
  }
  template <typename MatrixType>
  template <typename InputType>
  EigenSolver<MatrixType>& EigenSolver<MatrixType>::compute(const EigenBase<InputType>& matrix,
                                                            bool computeEigenvectors) {
    check_template_parameters();
    using numext::isfinite;
    using std::abs;
    using std::sqrt;
    (static_cast<bool>(matrix.cols() == matrix.rows())
         ? void(0)
         : __assert_fail("matrix.cols() == matrix.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/EigenSolver.h",
                         388,
                         __extension__ __PRETTY_FUNCTION__));
    m_realSchur.compute(matrix.derived(), computeEigenvectors);
    m_info = m_realSchur.info();
    if (m_info == Success) {
      m_matT = m_realSchur.matrixT();
      if (computeEigenvectors)
        m_eivec = m_realSchur.matrixU();
      m_eivalues.resize(matrix.cols());
      Index i = 0;
      while (i < matrix.cols()) {
        if (i == matrix.cols() - 1 || m_matT.coeff(i + 1, i) == Scalar(0)) {
          m_eivalues.coeffRef(i) = m_matT.coeff(i, i);
          if (!(isfinite)(m_eivalues.coeffRef(i))) {
            m_isInitialized = true;
            m_eigenvectorsOk = false;
            m_info = NumericalIssue;
            return *this;
          }
          ++i;
        } else {
          Scalar p = Scalar(0.5) * (m_matT.coeff(i, i) - m_matT.coeff(i + 1, i + 1));
          Scalar z;
          {
            Scalar t0 = m_matT.coeff(i + 1, i);
            Scalar t1 = m_matT.coeff(i, i + 1);
            Scalar maxval = numext::maxi<Scalar>(abs(p), numext::maxi<Scalar>(abs(t0), abs(t1)));
            t0 /= maxval;
            t1 /= maxval;
            Scalar p0 = p / maxval;
            z = maxval * sqrt(abs(p0 * p0 + t0 * t1));
          }
          m_eivalues.coeffRef(i) = ComplexScalar(m_matT.coeff(i + 1, i + 1) + p, z);
          m_eivalues.coeffRef(i + 1) = ComplexScalar(m_matT.coeff(i + 1, i + 1) + p, -z);
          if (!((isfinite)(m_eivalues.coeffRef(i)) && (isfinite)(m_eivalues.coeffRef(i + 1)))) {
            m_isInitialized = true;
            m_eigenvectorsOk = false;
            m_info = NumericalIssue;
            return *this;
          }
          i += 2;
        }
      }
      if (computeEigenvectors)
        doComputeEigenvectors();
    }
    m_isInitialized = true;
    m_eigenvectorsOk = computeEigenvectors;
    return *this;
  }
  template <typename MatrixType>
  void EigenSolver<MatrixType>::doComputeEigenvectors() {
    using std::abs;
    const Index size = m_eivec.cols();
    const Scalar eps = NumTraits<Scalar>::epsilon();
    Scalar norm(0);
    for (Index j = 0; j < size; ++j) {
      norm += m_matT.row(j).segment((std::max)(j - 1, Index(0)), size - (std::max)(j - 1, Index(0))).cwiseAbs().sum();
    }
    if (norm == Scalar(0)) {
      return;
    }
    for (Index n = size - 1; n >= 0; n--) {
      Scalar p = m_eivalues.coeff(n).real();
      Scalar q = m_eivalues.coeff(n).imag();
      if (q == Scalar(0)) {
        Scalar lastr(0), lastw(0);
        Index l = n;
        m_matT.coeffRef(n, n) = Scalar(1);
        for (Index i = n - 1; i >= 0; i--) {
          Scalar w = m_matT.coeff(i, i) - p;
          Scalar r = m_matT.row(i).segment(l, n - l + 1).dot(m_matT.col(n).segment(l, n - l + 1));
          if (m_eivalues.coeff(i).imag() < Scalar(0)) {
            lastw = w;
            lastr = r;
          } else {
            l = i;
            if (m_eivalues.coeff(i).imag() == Scalar(0)) {
              if (w != Scalar(0))
                m_matT.coeffRef(i, n) = -r / w;
              else
                m_matT.coeffRef(i, n) = -r / (eps * norm);
            } else {
              Scalar x = m_matT.coeff(i, i + 1);
              Scalar y = m_matT.coeff(i + 1, i);
              Scalar denom = (m_eivalues.coeff(i).real() - p) * (m_eivalues.coeff(i).real() - p) +
                             m_eivalues.coeff(i).imag() * m_eivalues.coeff(i).imag();
              Scalar t = (x * lastr - lastw * r) / denom;
              m_matT.coeffRef(i, n) = t;
              if (abs(x) > abs(lastw))
                m_matT.coeffRef(i + 1, n) = (-r - w * t) / x;
              else
                m_matT.coeffRef(i + 1, n) = (-lastr - y * t) / lastw;
            }
            Scalar t = abs(m_matT.coeff(i, n));
            if ((eps * t) * t > Scalar(1))
              m_matT.col(n).tail(size - i) /= t;
          }
        }
      } else if (q < Scalar(0) && n > 0) {
        Scalar lastra(0), lastsa(0), lastw(0);
        Index l = n - 1;
        if (abs(m_matT.coeff(n, n - 1)) > abs(m_matT.coeff(n - 1, n))) {
          m_matT.coeffRef(n - 1, n - 1) = q / m_matT.coeff(n, n - 1);
          m_matT.coeffRef(n - 1, n) = -(m_matT.coeff(n, n) - p) / m_matT.coeff(n, n - 1);
        } else {
          ComplexScalar cc =
              ComplexScalar(Scalar(0), -m_matT.coeff(n - 1, n)) / ComplexScalar(m_matT.coeff(n - 1, n - 1) - p, q);
          m_matT.coeffRef(n - 1, n - 1) = numext::real(cc);
          m_matT.coeffRef(n - 1, n) = numext::imag(cc);
        }
        m_matT.coeffRef(n, n - 1) = Scalar(0);
        m_matT.coeffRef(n, n) = Scalar(1);
        for (Index i = n - 2; i >= 0; i--) {
          Scalar ra = m_matT.row(i).segment(l, n - l + 1).dot(m_matT.col(n - 1).segment(l, n - l + 1));
          Scalar sa = m_matT.row(i).segment(l, n - l + 1).dot(m_matT.col(n).segment(l, n - l + 1));
          Scalar w = m_matT.coeff(i, i) - p;
          if (m_eivalues.coeff(i).imag() < Scalar(0)) {
            lastw = w;
            lastra = ra;
            lastsa = sa;
          } else {
            l = i;
            if (m_eivalues.coeff(i).imag() == RealScalar(0)) {
              ComplexScalar cc = ComplexScalar(-ra, -sa) / ComplexScalar(w, q);
              m_matT.coeffRef(i, n - 1) = numext::real(cc);
              m_matT.coeffRef(i, n) = numext::imag(cc);
            } else {
              Scalar x = m_matT.coeff(i, i + 1);
              Scalar y = m_matT.coeff(i + 1, i);
              Scalar vr = (m_eivalues.coeff(i).real() - p) * (m_eivalues.coeff(i).real() - p) +
                          m_eivalues.coeff(i).imag() * m_eivalues.coeff(i).imag() - q * q;
              Scalar vi = (m_eivalues.coeff(i).real() - p) * Scalar(2) * q;
              if ((vr == Scalar(0)) && (vi == Scalar(0)))
                vr = eps * norm * (abs(w) + abs(q) + abs(x) + abs(y) + abs(lastw));
              ComplexScalar cc = ComplexScalar(x * lastra - lastw * ra + q * sa, x * lastsa - lastw * sa - q * ra) /
                                 ComplexScalar(vr, vi);
              m_matT.coeffRef(i, n - 1) = numext::real(cc);
              m_matT.coeffRef(i, n) = numext::imag(cc);
              if (abs(x) > (abs(lastw) + abs(q))) {
                m_matT.coeffRef(i + 1, n - 1) = (-ra - w * m_matT.coeff(i, n - 1) + q * m_matT.coeff(i, n)) / x;
                m_matT.coeffRef(i + 1, n) = (-sa - w * m_matT.coeff(i, n) - q * m_matT.coeff(i, n - 1)) / x;
              } else {
                cc = ComplexScalar(-lastra - y * m_matT.coeff(i, n - 1), -lastsa - y * m_matT.coeff(i, n)) /
                     ComplexScalar(lastw, q);
                m_matT.coeffRef(i + 1, n - 1) = numext::real(cc);
                m_matT.coeffRef(i + 1, n) = numext::imag(cc);
              }
            }
            Scalar t = numext::maxi<Scalar>(abs(m_matT.coeff(i, n - 1)), abs(m_matT.coeff(i, n)));
            if ((eps * t) * t > Scalar(1))
              m_matT.block(i, n - 1, size - i, 2) /= t;
          }
        }
        n--;
      } else {
        (static_cast<bool>(0 && "Internal bug in EigenSolver (INF or NaN has not been detected)")
             ? void(0)
             : __assert_fail("0 && \"Internal bug in EigenSolver (INF or NaN has not been detected)\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Eigenvalues/EigenSolver.h",
                             610,
                             __extension__ __PRETTY_FUNCTION__));
      }
    }
    for (Index j = size - 1; j >= 0; j--) {
      m_tmp.noalias() = m_eivec.leftCols(j + 1) * m_matT.col(j).segment(0, j + 1);
      m_eivec.col(j) = m_tmp;
    }
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class GeneralizedSelfAdjointEigenSolver;
  namespace internal {
    template <typename SolverType, int Size, bool IsComplex>
    struct direct_selfadjoint_eigenvalues;
    template <typename MatrixType, typename DiagType, typename SubDiagType>
    ComputationInfo computeFromTridiagonal_impl(
        DiagType& diag, SubDiagType& subdiag, const Index maxIterations, bool computeEigenvectors, MatrixType& eivec);
  }  // namespace internal
  template <typename MatrixType_>
  class SelfAdjointEigenSolver {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      Size = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef Eigen::Index Index;
    typedef Matrix<Scalar, Size, Size, ColMajor, MaxColsAtCompileTime, MaxColsAtCompileTime> EigenvectorsType;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    friend struct internal::direct_selfadjoint_eigenvalues<SelfAdjointEigenSolver, Size, NumTraits<Scalar>::IsComplex>;
    typedef typename internal::plain_col_type<MatrixType, RealScalar>::type RealVectorType;
    typedef Tridiagonalization<MatrixType> TridiagonalizationType;
    typedef typename TridiagonalizationType::SubDiagonalType SubDiagonalType;
    SelfAdjointEigenSolver()
        : m_eivec(),
          m_eivalues(),
          m_subdiag(),
          m_hcoeffs(),
          m_info(InvalidInput),
          m_isInitialized(false),
          m_eigenvectorsOk(false) {}
    explicit SelfAdjointEigenSolver(Index size)
        : m_eivec(size, size),
          m_eivalues(size),
          m_subdiag(size > 1 ? size - 1 : 1),
          m_hcoeffs(size > 1 ? size - 1 : 1),
          m_isInitialized(false),
          m_eigenvectorsOk(false) {}
    template <typename InputType>
    explicit SelfAdjointEigenSolver(const EigenBase<InputType>& matrix, int options = ComputeEigenvectors)
        : m_eivec(matrix.rows(), matrix.cols()),
          m_eivalues(matrix.cols()),
          m_subdiag(matrix.rows() > 1 ? matrix.rows() - 1 : 1),
          m_hcoeffs(matrix.cols() > 1 ? matrix.cols() - 1 : 1),
          m_isInitialized(false),
          m_eigenvectorsOk(false) {
      compute(matrix.derived(), options);
    }
    template <typename InputType>
    SelfAdjointEigenSolver& compute(const EigenBase<InputType>& matrix, int options = ComputeEigenvectors);
    SelfAdjointEigenSolver& computeDirect(const MatrixType& matrix, int options = ComputeEigenvectors);
    SelfAdjointEigenSolver& computeFromTridiagonal(const RealVectorType& diag,
                                                   const SubDiagonalType& subdiag,
                                                   int options = ComputeEigenvectors);
    const EigenvectorsType& eigenvectors() const {
      (static_cast<bool>(m_isInitialized && "SelfAdjointEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SelfAdjointEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                           281,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
           ? void(0)
           : __assert_fail(
                 "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/SelfAdjointEigenSolver.h",
                 282,
                 __extension__ __PRETTY_FUNCTION__));
      return m_eivec;
    }
    const RealVectorType& eigenvalues() const {
      (static_cast<bool>(m_isInitialized && "SelfAdjointEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SelfAdjointEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                           304,
                           __extension__ __PRETTY_FUNCTION__));
      return m_eivalues;
    }
    MatrixType operatorSqrt() const {
      (static_cast<bool>(m_isInitialized && "SelfAdjointEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SelfAdjointEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                           328,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
           ? void(0)
           : __assert_fail(
                 "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/SelfAdjointEigenSolver.h",
                 329,
                 __extension__ __PRETTY_FUNCTION__));
      return m_eivec * m_eivalues.cwiseSqrt().asDiagonal() * m_eivec.adjoint();
    }
    MatrixType operatorInverseSqrt() const {
      (static_cast<bool>(m_isInitialized && "SelfAdjointEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SelfAdjointEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                           353,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
           ? void(0)
           : __assert_fail(
                 "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/SelfAdjointEigenSolver.h",
                 354,
                 __extension__ __PRETTY_FUNCTION__));
      return m_eivec * m_eivalues.cwiseInverse().cwiseSqrt().asDiagonal() * m_eivec.adjoint();
    }
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "SelfAdjointEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"SelfAdjointEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                           365,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    static const int m_maxIterations = 30;

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    EigenvectorsType m_eivec;
    RealVectorType m_eivalues;
    typename TridiagonalizationType::SubDiagonalType m_subdiag;
    typename TridiagonalizationType::CoeffVectorType m_hcoeffs;
    ComputationInfo m_info;
    bool m_isInitialized;
    bool m_eigenvectorsOk;
  };
  namespace internal {
    template <int StorageOrder, typename RealScalar, typename Scalar, typename Index>
    static void tridiagonal_qr_step(
        RealScalar* diag, RealScalar* subdiag, Index start, Index end, Scalar* matrixQ, Index n);
  }
  template <typename MatrixType>
  template <typename InputType>
  SelfAdjointEigenSolver<MatrixType>& SelfAdjointEigenSolver<MatrixType>::compute(const EigenBase<InputType>& a_matrix,
                                                                                  int options) {
    const InputType& matrix(a_matrix.derived());
    using std::abs;
    ;
    (static_cast<bool>(matrix.cols() == matrix.rows())
         ? void(0)
         : __assert_fail("matrix.cols() == matrix.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                         423,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>((options & ~(EigVecMask | GenEigMask)) == 0 && (options & EigVecMask) != EigVecMask &&
                       "invalid option parameter")
         ? void(0)
         : __assert_fail("(options&~(EigVecMask|GenEigMask))==0 && (options&EigVecMask)!=EigVecMask && \"invalid "
                         "option parameter\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                         426,
                         __extension__ __PRETTY_FUNCTION__));
    bool computeEigenvectors = (options & ComputeEigenvectors) == ComputeEigenvectors;
    Index n = matrix.cols();
    m_eivalues.resize(n, 1);
    if (n == 1) {
      m_eivec = matrix;
      m_eivalues.coeffRef(0, 0) = numext::real(m_eivec.coeff(0, 0));
      if (computeEigenvectors)
        m_eivec.setOnes(n, n);
      m_info = Success;
      m_isInitialized = true;
      m_eigenvectorsOk = computeEigenvectors;
      return *this;
    }
    RealVectorType& diag = m_eivalues;
    EigenvectorsType& mat = m_eivec;
    mat = matrix.template triangularView<Lower>();
    RealScalar scale = mat.cwiseAbs().maxCoeff();
    if (numext::is_exactly_zero(scale))
      scale = RealScalar(1);
    mat.template triangularView<Lower>() /= scale;
    m_subdiag.resize(n - 1);
    m_hcoeffs.resize(n - 1);
    internal::tridiagonalization_inplace(mat, diag, m_subdiag, m_hcoeffs, computeEigenvectors);
    m_info = internal::computeFromTridiagonal_impl(diag, m_subdiag, m_maxIterations, computeEigenvectors, m_eivec);
    m_eivalues *= scale;
    m_isInitialized = true;
    m_eigenvectorsOk = computeEigenvectors;
    return *this;
  }
  template <typename MatrixType>
  SelfAdjointEigenSolver<MatrixType>& SelfAdjointEigenSolver<MatrixType>::computeFromTridiagonal(
      const RealVectorType& diag, const SubDiagonalType& subdiag, int options) {
    bool computeEigenvectors = (options & ComputeEigenvectors) == ComputeEigenvectors;
    m_eivalues = diag;
    m_subdiag = subdiag;
    if (computeEigenvectors) {
      m_eivec.setIdentity(diag.size(), diag.size());
    }
    m_info =
        internal::computeFromTridiagonal_impl(m_eivalues, m_subdiag, m_maxIterations, computeEigenvectors, m_eivec);
    m_isInitialized = true;
    m_eigenvectorsOk = computeEigenvectors;
    return *this;
  }
  namespace internal {
    template <typename MatrixType, typename DiagType, typename SubDiagType>
    ComputationInfo computeFromTridiagonal_impl(
        DiagType& diag, SubDiagType& subdiag, const Index maxIterations, bool computeEigenvectors, MatrixType& eivec) {
      ComputationInfo info;
      typedef typename MatrixType::Scalar Scalar;
      Index n = diag.size();
      Index end = n - 1;
      Index start = 0;
      Index iter = 0;
      typedef typename DiagType::RealScalar RealScalar;
      const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
      const RealScalar precision_inv = RealScalar(1) / NumTraits<RealScalar>::epsilon();
      while (end > 0) {
        for (Index i = start; i < end; ++i) {
          if (numext::abs(subdiag[i]) < considerAsZero) {
            subdiag[i] = RealScalar(0);
          } else {
            const RealScalar scaled_subdiag = precision_inv * subdiag[i];
            if (scaled_subdiag * scaled_subdiag <= (numext::abs(diag[i]) + numext::abs(diag[i + 1]))) {
              subdiag[i] = RealScalar(0);
            }
          }
        }
        while (end > 0 && numext::is_exactly_zero(subdiag[end - 1])) {
          end--;
        }
        if (end <= 0)
          break;
        iter++;
        if (iter > maxIterations * n)
          break;
        start = end - 1;
        while (start > 0 && !numext::is_exactly_zero(subdiag[start - 1]))
          start--;
        internal::tridiagonal_qr_step<MatrixType::Flags & RowMajorBit ? RowMajor : ColMajor>(
            diag.data(), subdiag.data(), start, end, computeEigenvectors ? eivec.data() : (Scalar*)0, n);
      }
      if (iter <= maxIterations * n)
        info = Success;
      else
        info = NoConvergence;
      if (info == Success) {
        for (Index i = 0; i < n - 1; ++i) {
          Index k;
          diag.segment(i, n - i).minCoeff(&k);
          if (k > 0) {
            numext::swap(diag[i], diag[k + i]);
            if (computeEigenvectors)
              eivec.col(i).swap(eivec.col(k + i));
          }
        }
      }
      return info;
    }
    template <typename SolverType, int Size, bool IsComplex>
    struct direct_selfadjoint_eigenvalues {
      static inline void run(SolverType& eig, const typename SolverType::MatrixType& A, int options) {
        eig.compute(A, options);
      }
    };
    template <typename SolverType>
    struct direct_selfadjoint_eigenvalues<SolverType, 3, false> {
      typedef typename SolverType::MatrixType MatrixType;
      typedef typename SolverType::RealVectorType VectorType;
      typedef typename SolverType::Scalar Scalar;
      typedef typename SolverType::EigenvectorsType EigenvectorsType;
      static inline void computeRoots(const MatrixType& m, VectorType& roots) {
        using std::atan2;
        using std::cos;
        using std::sin;
        using std::sqrt;
        const Scalar s_inv3 = Scalar(1) / Scalar(3);
        const Scalar s_sqrt3 = sqrt(Scalar(3));
        Scalar c0 = m(0, 0) * m(1, 1) * m(2, 2) + Scalar(2) * m(1, 0) * m(2, 0) * m(2, 1) -
                    m(0, 0) * m(2, 1) * m(2, 1) - m(1, 1) * m(2, 0) * m(2, 0) - m(2, 2) * m(1, 0) * m(1, 0);
        Scalar c1 = m(0, 0) * m(1, 1) - m(1, 0) * m(1, 0) + m(0, 0) * m(2, 2) - m(2, 0) * m(2, 0) + m(1, 1) * m(2, 2) -
                    m(2, 1) * m(2, 1);
        Scalar c2 = m(0, 0) + m(1, 1) + m(2, 2);
        Scalar c2_over_3 = c2 * s_inv3;
        Scalar a_over_3 = (c2 * c2_over_3 - c1) * s_inv3;
        a_over_3 = numext::maxi(a_over_3, Scalar(0));
        Scalar half_b = Scalar(0.5) * (c0 + c2_over_3 * (Scalar(2) * c2_over_3 * c2_over_3 - c1));
        Scalar q = a_over_3 * a_over_3 * a_over_3 - half_b * half_b;
        q = numext::maxi(q, Scalar(0));
        Scalar rho = sqrt(a_over_3);
        Scalar theta = atan2(sqrt(q), half_b) * s_inv3;
        Scalar cos_theta = cos(theta);
        Scalar sin_theta = sin(theta);
        roots(0) = c2_over_3 - rho * (cos_theta + s_sqrt3 * sin_theta);
        roots(1) = c2_over_3 - rho * (cos_theta - s_sqrt3 * sin_theta);
        roots(2) = c2_over_3 + Scalar(2) * rho * cos_theta;
      }
      static inline bool extract_kernel(MatrixType& mat, Ref<VectorType> res, Ref<VectorType> representative) {
        using std::abs;
        ;
        using std::sqrt;
        ;
        Index i0;
        mat.diagonal().cwiseAbs().maxCoeff(&i0);
        representative = mat.col(i0);
        Scalar n0, n1;
        VectorType c0, c1;
        n0 = (c0 = representative.cross(mat.col((i0 + 1) % 3))).squaredNorm();
        n1 = (c1 = representative.cross(mat.col((i0 + 2) % 3))).squaredNorm();
        if (n0 > n1)
          res = c0 / sqrt(n0);
        else
          res = c1 / sqrt(n1);
        return true;
      }
      static inline void run(SolverType& solver, const MatrixType& mat, int options) {
        (static_cast<bool>(mat.cols() == 3 && mat.cols() == mat.rows())
             ? void(0)
             : __assert_fail("mat.cols() == 3 && mat.cols() == mat.rows()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                             653,
                             __extension__ __PRETTY_FUNCTION__));
        (static_cast<bool>((options & ~(EigVecMask | GenEigMask)) == 0 && (options & EigVecMask) != EigVecMask &&
                           "invalid option parameter")
             ? void(0)
             : __assert_fail("(options&~(EigVecMask|GenEigMask))==0 && (options&EigVecMask)!=EigVecMask && \"invalid "
                             "option parameter\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                             656,
                             __extension__ __PRETTY_FUNCTION__));
        bool computeEigenvectors = (options & ComputeEigenvectors) == ComputeEigenvectors;
        EigenvectorsType& eivecs = solver.m_eivec;
        VectorType& eivals = solver.m_eivalues;
        Scalar shift = mat.trace() / Scalar(3);
        MatrixType scaledMat = mat.template selfadjointView<Lower>();
        scaledMat.diagonal().array() -= shift;
        Scalar scale = scaledMat.cwiseAbs().maxCoeff();
        if (scale > 0)
          scaledMat /= scale;
        computeRoots(scaledMat, eivals);
        if (computeEigenvectors) {
          if ((eivals(2) - eivals(0)) <= Eigen::NumTraits<Scalar>::epsilon()) {
            eivecs.setIdentity();
          } else {
            MatrixType tmp;
            tmp = scaledMat;
            Scalar d0 = eivals(2) - eivals(1);
            Scalar d1 = eivals(1) - eivals(0);
            Index k(0), l(2);
            if (d0 > d1) {
              numext::swap(k, l);
              d0 = d1;
            }
            {
              tmp.diagonal().array() -= eivals(k);
              extract_kernel(tmp, eivecs.col(k), eivecs.col(l));
            }
            if (d0 <= 2 * Eigen::NumTraits<Scalar>::epsilon() * d1) {
              eivecs.col(l) -= eivecs.col(k).dot(eivecs.col(l)) * eivecs.col(l);
              eivecs.col(l).normalize();
            } else {
              tmp = scaledMat;
              tmp.diagonal().array() -= eivals(l);
              VectorType dummy;
              extract_kernel(tmp, eivecs.col(l), dummy);
            }
            eivecs.col(1) = eivecs.col(2).cross(eivecs.col(0)).normalized();
          }
        }
        eivals *= scale;
        eivals.array() += shift;
        solver.m_info = Success;
        solver.m_isInitialized = true;
        solver.m_eigenvectorsOk = computeEigenvectors;
      }
    };
    template <typename SolverType>
    struct direct_selfadjoint_eigenvalues<SolverType, 2, false> {
      typedef typename SolverType::MatrixType MatrixType;
      typedef typename SolverType::RealVectorType VectorType;
      typedef typename SolverType::Scalar Scalar;
      typedef typename SolverType::EigenvectorsType EigenvectorsType;
      static inline void computeRoots(const MatrixType& m, VectorType& roots) {
        using std::sqrt;
        ;
        const Scalar t0 = Scalar(0.5) * sqrt(numext::abs2(m(0, 0) - m(1, 1)) + Scalar(4) * numext::abs2(m(1, 0)));
        const Scalar t1 = Scalar(0.5) * (m(0, 0) + m(1, 1));
        roots(0) = t1 - t0;
        roots(1) = t1 + t0;
      }
      static inline void run(SolverType& solver, const MatrixType& mat, int options) {
        using std::sqrt;
        ;
        using std::abs;
        ;
        (static_cast<bool>(mat.cols() == 2 && mat.cols() == mat.rows())
             ? void(0)
             : __assert_fail("mat.cols() == 2 && mat.cols() == mat.rows()",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                             760,
                             __extension__ __PRETTY_FUNCTION__));
        (static_cast<bool>((options & ~(EigVecMask | GenEigMask)) == 0 && (options & EigVecMask) != EigVecMask &&
                           "invalid option parameter")
             ? void(0)
             : __assert_fail("(options&~(EigVecMask|GenEigMask))==0 && (options&EigVecMask)!=EigVecMask && \"invalid "
                             "option parameter\"",
                             "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                             "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                             "Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h",
                             763,
                             __extension__ __PRETTY_FUNCTION__));
        bool computeEigenvectors = (options & ComputeEigenvectors) == ComputeEigenvectors;
        EigenvectorsType& eivecs = solver.m_eivec;
        VectorType& eivals = solver.m_eivalues;
        Scalar shift = mat.trace() / Scalar(2);
        MatrixType scaledMat = mat;
        scaledMat.coeffRef(0, 1) = mat.coeff(1, 0);
        scaledMat.diagonal().array() -= shift;
        Scalar scale = scaledMat.cwiseAbs().maxCoeff();
        if (scale > Scalar(0))
          scaledMat /= scale;
        computeRoots(scaledMat, eivals);
        if (computeEigenvectors) {
          if ((eivals(1) - eivals(0)) <= abs(eivals(1)) * Eigen::NumTraits<Scalar>::epsilon()) {
            eivecs.setIdentity();
          } else {
            scaledMat.diagonal().array() -= eivals(1);
            Scalar a2 = numext::abs2(scaledMat(0, 0));
            Scalar c2 = numext::abs2(scaledMat(1, 1));
            Scalar b2 = numext::abs2(scaledMat(1, 0));
            if (a2 > c2) {
              eivecs.col(1) << -scaledMat(1, 0), scaledMat(0, 0);
              eivecs.col(1) /= sqrt(a2 + b2);
            } else {
              eivecs.col(1) << -scaledMat(1, 1), scaledMat(1, 0);
              eivecs.col(1) /= sqrt(c2 + b2);
            }
            eivecs.col(0) << eivecs.col(1).unitOrthogonal();
          }
        }
        eivals *= scale;
        eivals.array() += shift;
        solver.m_info = Success;
        solver.m_isInitialized = true;
        solver.m_eigenvectorsOk = computeEigenvectors;
      }
    };
  }  // namespace internal
  template <typename MatrixType>
  SelfAdjointEigenSolver<MatrixType>& SelfAdjointEigenSolver<MatrixType>::computeDirect(const MatrixType& matrix,
                                                                                        int options) {
    internal::direct_selfadjoint_eigenvalues<SelfAdjointEigenSolver, Size, NumTraits<Scalar>::IsComplex>::run(
        *this, matrix, options);
    return *this;
  }
  namespace internal {
    template <int StorageOrder, typename RealScalar, typename Scalar, typename Index>
    static void tridiagonal_qr_step(
        RealScalar* diag, RealScalar* subdiag, Index start, Index end, Scalar* matrixQ, Index n) {
      RealScalar td = (diag[end - 1] - diag[end]) * RealScalar(0.5);
      RealScalar e = subdiag[end - 1];
      RealScalar mu = diag[end];
      if (numext::is_exactly_zero(td)) {
        mu -= numext::abs(e);
      } else if (!numext::is_exactly_zero(e)) {
        const RealScalar e2 = numext::abs2(e);
        const RealScalar h = numext::hypot(td, e);
        if (numext::is_exactly_zero(e2)) {
          mu -= e / ((td + (td > RealScalar(0) ? h : -h)) / e);
        } else {
          mu -= e2 / (td + (td > RealScalar(0) ? h : -h));
        }
      }
      RealScalar x = diag[start] - mu;
      RealScalar z = subdiag[start];
      for (Index k = start; k < end && !numext::is_exactly_zero(z); ++k) {
        JacobiRotation<RealScalar> rot;
        rot.makeGivens(x, z);
        RealScalar sdk = rot.s() * diag[k] + rot.c() * subdiag[k];
        RealScalar dkp1 = rot.s() * subdiag[k] + rot.c() * diag[k + 1];
        diag[k] = rot.c() * (rot.c() * diag[k] - rot.s() * subdiag[k]) -
                  rot.s() * (rot.c() * subdiag[k] - rot.s() * diag[k + 1]);
        diag[k + 1] = rot.s() * sdk + rot.c() * dkp1;
        subdiag[k] = rot.c() * sdk - rot.s() * dkp1;
        if (k > start)
          subdiag[k - 1] = rot.c() * subdiag[k - 1] - rot.s() * z;
        x = subdiag[k];
        if (k < end - 1) {
          z = -rot.s() * subdiag[k + 1];
          subdiag[k + 1] = rot.c() * subdiag[k + 1];
        }
        if (matrixQ) {
          Map<Matrix<Scalar, Dynamic, Dynamic, StorageOrder>> q(matrixQ, n, n);
          q.applyOnTheRight(k, k + 1, rot);
        }
      }
    }
  }  // namespace internal
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class GeneralizedSelfAdjointEigenSolver : public SelfAdjointEigenSolver<MatrixType_> {
    typedef SelfAdjointEigenSolver<MatrixType_> Base;

  public:
    typedef MatrixType_ MatrixType;
    GeneralizedSelfAdjointEigenSolver() : Base() {}
    explicit GeneralizedSelfAdjointEigenSolver(Index size) : Base(size) {}
    GeneralizedSelfAdjointEigenSolver(const MatrixType& matA,
                                      const MatrixType& matB,
                                      int options = ComputeEigenvectors | Ax_lBx)
        : Base(matA.cols()) {
      compute(matA, matB, options);
    }
    GeneralizedSelfAdjointEigenSolver& compute(const MatrixType& matA,
                                               const MatrixType& matB,
                                               int options = ComputeEigenvectors | Ax_lBx);

  protected:
  };
  template <typename MatrixType>
  GeneralizedSelfAdjointEigenSolver<MatrixType>& GeneralizedSelfAdjointEigenSolver<MatrixType>::compute(
      const MatrixType& matA, const MatrixType& matB, int options) {
    (static_cast<bool>(matA.cols() == matA.rows() && matB.rows() == matA.rows() && matB.cols() == matB.rows())
         ? void(0)
         : __assert_fail("matA.cols()==matA.rows() && matB.rows()==matA.rows() && matB.cols()==matB.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h",
                         167,
                         __extension__ __PRETTY_FUNCTION__));
    (static_cast<bool>((options & ~(EigVecMask | GenEigMask)) == 0 && (options & EigVecMask) != EigVecMask &&
                       ((options & GenEigMask) == 0 || (options & GenEigMask) == Ax_lBx ||
                        (options & GenEigMask) == ABx_lx || (options & GenEigMask) == BAx_lx) &&
                       "invalid option parameter")
         ? void(0)
         : __assert_fail("(options&~(EigVecMask|GenEigMask))==0 && (options&EigVecMask)!=EigVecMask && "
                         "((options&GenEigMask)==0 || (options&GenEigMask)==Ax_lBx || (options&GenEigMask)==ABx_lx || "
                         "(options&GenEigMask)==BAx_lx) && \"invalid option parameter\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h",
                         172,
                         __extension__ __PRETTY_FUNCTION__));
    bool computeEigVecs = ((options & EigVecMask) == 0) || ((options & EigVecMask) == ComputeEigenvectors);
    LLT<MatrixType> cholB(matB);
    int type = (options & GenEigMask);
    if (type == 0)
      type = Ax_lBx;
    if (type == Ax_lBx) {
      MatrixType matC = matA.template selfadjointView<Lower>();
      cholB.matrixL().template solveInPlace<OnTheLeft>(matC);
      cholB.matrixU().template solveInPlace<OnTheRight>(matC);
      Base::compute(matC, computeEigVecs ? ComputeEigenvectors : EigenvaluesOnly);
      if (computeEigVecs)
        cholB.matrixU().solveInPlace(Base::m_eivec);
    } else if (type == ABx_lx) {
      MatrixType matC = matA.template selfadjointView<Lower>();
      matC = matC * cholB.matrixL();
      matC = cholB.matrixU() * matC;
      Base::compute(matC, computeEigVecs ? ComputeEigenvectors : EigenvaluesOnly);
      if (computeEigVecs)
        cholB.matrixU().solveInPlace(Base::m_eivec);
    } else if (type == BAx_lx) {
      MatrixType matC = matA.template selfadjointView<Lower>();
      matC = matC * cholB.matrixL();
      matC = cholB.matrixU() * matC;
      Base::compute(matC, computeEigVecs ? ComputeEigenvectors : EigenvaluesOnly);
      if (computeEigVecs)
        Base::m_eivec = cholB.matrixL() * Base::m_eivec;
    }
    return *this;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename MatrixType, bool IsComplex>
    struct complex_schur_reduce_to_hessenberg;
  }
  template <typename MatrixType_>
  class ComplexSchur {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef std::complex<RealScalar> ComplexScalar;
    typedef Matrix<ComplexScalar, RowsAtCompileTime, ColsAtCompileTime, Options, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        ComplexMatrixType;
    explicit ComplexSchur(Index size = RowsAtCompileTime == Dynamic ? 1 : RowsAtCompileTime)
        : m_matT(size, size),
          m_matU(size, size),
          m_hess(size),
          m_isInitialized(false),
          m_matUisUptodate(false),
          m_maxIters(-1) {}
    template <typename InputType>
    explicit ComplexSchur(const EigenBase<InputType>& matrix, bool computeU = true)
        : m_matT(matrix.rows(), matrix.cols()),
          m_matU(matrix.rows(), matrix.cols()),
          m_hess(matrix.rows()),
          m_isInitialized(false),
          m_matUisUptodate(false),
          m_maxIters(-1) {
      compute(matrix.derived(), computeU);
    }
    const ComplexMatrixType& matrixU() const {
      (static_cast<bool>(m_isInitialized && "ComplexSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexSchur.h",
                           142,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_matUisUptodate &&
                         "The matrix U has not been computed during the ComplexSchur decomposition.")
           ? void(0)
           : __assert_fail(
                 "m_matUisUptodate && \"The matrix U has not been computed during the ComplexSchur decomposition.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/ComplexSchur.h",
                 143,
                 __extension__ __PRETTY_FUNCTION__));
      return m_matU;
    }
    const ComplexMatrixType& matrixT() const {
      (static_cast<bool>(m_isInitialized && "ComplexSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexSchur.h",
                           166,
                           __extension__ __PRETTY_FUNCTION__));
      return m_matT;
    }
    template <typename InputType>
    ComplexSchur& compute(const EigenBase<InputType>& matrix, bool computeU = true);
    template <typename HessMatrixType, typename OrthMatrixType>
    ComplexSchur& computeFromHessenberg(const HessMatrixType& matrixH,
                                        const OrthMatrixType& matrixQ,
                                        bool computeU = true);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "ComplexSchur is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexSchur is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexSchur.h",
                           221,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    ComplexSchur& setMaxIterations(Index maxIters) {
      m_maxIters = maxIters;
      return *this;
    }
    Index getMaxIterations() { return m_maxIters; }
    static const int m_maxIterationsPerRow = 30;

  protected:
    ComplexMatrixType m_matT, m_matU;
    HessenbergDecomposition<MatrixType> m_hess;
    ComputationInfo m_info;
    bool m_isInitialized;
    bool m_matUisUptodate;
    Index m_maxIters;

  private:
    bool subdiagonalEntryIsNeglegible(Index i);
    ComplexScalar computeShift(Index iu, Index iter);
    void reduceToTriangularForm(bool computeU);
    friend struct internal::complex_schur_reduce_to_hessenberg<MatrixType, NumTraits<Scalar>::IsComplex>;
  };
  template <typename MatrixType>
  inline bool ComplexSchur<MatrixType>::subdiagonalEntryIsNeglegible(Index i) {
    RealScalar d = numext::norm1(m_matT.coeff(i, i)) + numext::norm1(m_matT.coeff(i + 1, i + 1));
    RealScalar sd = numext::norm1(m_matT.coeff(i + 1, i));
    if (internal::isMuchSmallerThan(sd, d, NumTraits<RealScalar>::epsilon())) {
      m_matT.coeffRef(i + 1, i) = ComplexScalar(0);
      return true;
    }
    return false;
  }
  template <typename MatrixType>
  typename ComplexSchur<MatrixType>::ComplexScalar ComplexSchur<MatrixType>::computeShift(Index iu, Index iter) {
    using std::abs;
    if (iter == 10 || iter == 20) {
      return abs(numext::real(m_matT.coeff(iu, iu - 1))) + abs(numext::real(m_matT.coeff(iu - 1, iu - 2)));
    }
    Matrix<ComplexScalar, 2, 2> t = m_matT.template block<2, 2>(iu - 1, iu - 1);
    RealScalar normt = t.cwiseAbs().sum();
    t /= normt;
    ComplexScalar b = t.coeff(0, 1) * t.coeff(1, 0);
    ComplexScalar c = t.coeff(0, 0) - t.coeff(1, 1);
    ComplexScalar disc = sqrt(c * c + RealScalar(4) * b);
    ComplexScalar det = t.coeff(0, 0) * t.coeff(1, 1) - b;
    ComplexScalar trace = t.coeff(0, 0) + t.coeff(1, 1);
    ComplexScalar eival1 = (trace + disc) / RealScalar(2);
    ComplexScalar eival2 = (trace - disc) / RealScalar(2);
    RealScalar eival1_norm = numext::norm1(eival1);
    RealScalar eival2_norm = numext::norm1(eival2);
    if (eival1_norm > eival2_norm)
      eival2 = det / eival1;
    else if (!numext::is_exactly_zero(eival2_norm))
      eival1 = det / eival2;
    if (numext::norm1(eival1 - t.coeff(1, 1)) < numext::norm1(eival2 - t.coeff(1, 1)))
      return normt * eival1;
    else
      return normt * eival2;
  }
  template <typename MatrixType>
  template <typename InputType>
  ComplexSchur<MatrixType>& ComplexSchur<MatrixType>::compute(const EigenBase<InputType>& matrix, bool computeU) {
    m_matUisUptodate = false;
    (static_cast<bool>(matrix.cols() == matrix.rows())
         ? void(0)
         : __assert_fail("matrix.cols() == matrix.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/ComplexSchur.h",
                         327,
                         __extension__ __PRETTY_FUNCTION__));
    if (matrix.cols() == 1) {
      m_matT = matrix.derived().template cast<ComplexScalar>();
      if (computeU)
        m_matU = ComplexMatrixType::Identity(1, 1);
      m_info = Success;
      m_isInitialized = true;
      m_matUisUptodate = computeU;
      return *this;
    }
    internal::complex_schur_reduce_to_hessenberg<MatrixType, NumTraits<Scalar>::IsComplex>::run(
        *this, matrix.derived(), computeU);
    computeFromHessenberg(m_matT, m_matU, computeU);
    return *this;
  }
  template <typename MatrixType>
  template <typename HessMatrixType, typename OrthMatrixType>
  ComplexSchur<MatrixType>& ComplexSchur<MatrixType>::computeFromHessenberg(const HessMatrixType& matrixH,
                                                                            const OrthMatrixType& matrixQ,
                                                                            bool computeU) {
    m_matT = matrixH;
    if (computeU)
      m_matU = matrixQ;
    reduceToTriangularForm(computeU);
    return *this;
  }
  namespace internal {
    template <typename MatrixType, bool IsComplex>
    struct complex_schur_reduce_to_hessenberg {
      static void run(ComplexSchur<MatrixType>& _this, const MatrixType& matrix, bool computeU) {
        _this.m_hess.compute(matrix);
        _this.m_matT = _this.m_hess.matrixH();
        if (computeU)
          _this.m_matU = _this.m_hess.matrixQ();
      }
    };
    template <typename MatrixType>
    struct complex_schur_reduce_to_hessenberg<MatrixType, false> {
      static void run(ComplexSchur<MatrixType>& _this, const MatrixType& matrix, bool computeU) {
        typedef typename ComplexSchur<MatrixType>::ComplexScalar ComplexScalar;
        _this.m_hess.compute(matrix);
        _this.m_matT = _this.m_hess.matrixH().template cast<ComplexScalar>();
        if (computeU) {
          MatrixType Q = _this.m_hess.matrixQ();
          _this.m_matU = Q.template cast<ComplexScalar>();
        }
      }
    };
  }  // namespace internal
  template <typename MatrixType>
  void ComplexSchur<MatrixType>::reduceToTriangularForm(bool computeU) {
    Index maxIters = m_maxIters;
    if (maxIters == -1)
      maxIters = m_maxIterationsPerRow * m_matT.rows();
    Index iu = m_matT.cols() - 1;
    Index il;
    Index iter = 0;
    Index totalIter = 0;
    while (true) {
      while (iu > 0) {
        if (!subdiagonalEntryIsNeglegible(iu - 1))
          break;
        iter = 0;
        --iu;
      }
      if (iu == 0)
        break;
      iter++;
      totalIter++;
      if (totalIter > maxIters)
        break;
      il = iu - 1;
      while (il > 0 && !subdiagonalEntryIsNeglegible(il - 1)) {
        --il;
      }
      ComplexScalar shift = computeShift(iu, iter);
      JacobiRotation<ComplexScalar> rot;
      rot.makeGivens(m_matT.coeff(il, il) - shift, m_matT.coeff(il + 1, il));
      m_matT.rightCols(m_matT.cols() - il).applyOnTheLeft(il, il + 1, rot.adjoint());
      m_matT.topRows((std::min)(il + 2, iu) + 1).applyOnTheRight(il, il + 1, rot);
      if (computeU)
        m_matU.applyOnTheRight(il, il + 1, rot);
      for (Index i = il + 1; i < iu; i++) {
        rot.makeGivens(m_matT.coeffRef(i, i - 1), m_matT.coeffRef(i + 1, i - 1), &m_matT.coeffRef(i, i - 1));
        m_matT.coeffRef(i + 1, i - 1) = ComplexScalar(0);
        m_matT.rightCols(m_matT.cols() - i).applyOnTheLeft(i, i + 1, rot.adjoint());
        m_matT.topRows((std::min)(i + 2, iu) + 1).applyOnTheRight(i, i + 1, rot);
        if (computeU)
          m_matU.applyOnTheRight(i, i + 1, rot);
      }
    }
    if (totalIter <= maxIters)
      m_info = Success;
    else
      m_info = NoConvergence;
    m_isInitialized = true;
    m_matUisUptodate = computeU;
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class ComplexEigenSolver {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef std::complex<RealScalar> ComplexScalar;
    typedef Matrix<ComplexScalar, ColsAtCompileTime, 1, Options & (~RowMajor), MaxColsAtCompileTime, 1> EigenvalueType;
    typedef Matrix<ComplexScalar, RowsAtCompileTime, ColsAtCompileTime, Options, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        EigenvectorType;
    ComplexEigenSolver()
        : m_eivec(), m_eivalues(), m_schur(), m_isInitialized(false), m_eigenvectorsOk(false), m_matX() {}
    explicit ComplexEigenSolver(Index size)
        : m_eivec(size, size),
          m_eivalues(size),
          m_schur(size),
          m_isInitialized(false),
          m_eigenvectorsOk(false),
          m_matX(size, size) {}
    template <typename InputType>
    explicit ComplexEigenSolver(const EigenBase<InputType>& matrix, bool computeEigenvectors = true)
        : m_eivec(matrix.rows(), matrix.cols()),
          m_eivalues(matrix.cols()),
          m_schur(matrix.rows()),
          m_isInitialized(false),
          m_eigenvectorsOk(false),
          m_matX(matrix.rows(), matrix.cols()) {
      compute(matrix.derived(), computeEigenvectors);
    }
    const EigenvectorType& eigenvectors() const {
      (static_cast<bool>(m_isInitialized && "ComplexEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexEigenSolver.h",
                           161,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_eigenvectorsOk && "The eigenvectors have not been computed together with the eigenvalues.")
           ? void(0)
           : __assert_fail(
                 "m_eigenvectorsOk && \"The eigenvectors have not been computed together with the eigenvalues.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/ComplexEigenSolver.h",
                 162,
                 __extension__ __PRETTY_FUNCTION__));
      return m_eivec;
    }
    const EigenvalueType& eigenvalues() const {
      (static_cast<bool>(m_isInitialized && "ComplexEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexEigenSolver.h",
                           186,
                           __extension__ __PRETTY_FUNCTION__));
      return m_eivalues;
    }
    template <typename InputType>
    ComplexEigenSolver& compute(const EigenBase<InputType>& matrix, bool computeEigenvectors = true);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "ComplexEigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"ComplexEigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/ComplexEigenSolver.h",
                           223,
                           __extension__ __PRETTY_FUNCTION__));
      return m_schur.info();
    }
    ComplexEigenSolver& setMaxIterations(Index maxIters) {
      m_schur.setMaxIterations(maxIters);
      return *this;
    }
    Index getMaxIterations() { return m_schur.getMaxIterations(); }

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    EigenvectorType m_eivec;
    EigenvalueType m_eivalues;
    ComplexSchur<MatrixType> m_schur;
    bool m_isInitialized;
    bool m_eigenvectorsOk;
    EigenvectorType m_matX;

  private:
    void doComputeEigenvectors(RealScalar matrixnorm);
    void sortEigenvalues(bool computeEigenvectors);
  };
  template <typename MatrixType>
  template <typename InputType>
  ComplexEigenSolver<MatrixType>& ComplexEigenSolver<MatrixType>::compute(const EigenBase<InputType>& matrix,
                                                                          bool computeEigenvectors) {
    (static_cast<bool>(matrix.cols() == matrix.rows())
         ? void(0)
         : __assert_fail("matrix.cols() == matrix.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/ComplexEigenSolver.h",
                         263,
                         __extension__ __PRETTY_FUNCTION__));
    m_schur.compute(matrix.derived(), computeEigenvectors);
    if (m_schur.info() == Success) {
      m_eivalues = m_schur.matrixT().diagonal();
      if (computeEigenvectors)
        doComputeEigenvectors(m_schur.matrixT().norm());
      sortEigenvalues(computeEigenvectors);
    }
    m_isInitialized = true;
    m_eigenvectorsOk = computeEigenvectors;
    return *this;
  }
  template <typename MatrixType>
  void ComplexEigenSolver<MatrixType>::doComputeEigenvectors(RealScalar matrixnorm) {
    const Index n = m_eivalues.size();
    matrixnorm = numext::maxi(matrixnorm, (std::numeric_limits<RealScalar>::min)());
    m_matX = EigenvectorType::Zero(n, n);
    for (Index k = n - 1; k >= 0; k--) {
      m_matX.coeffRef(k, k) = ComplexScalar(1.0, 0.0);
      for (Index i = k - 1; i >= 0; i--) {
        m_matX.coeffRef(i, k) = -m_schur.matrixT().coeff(i, k);
        if (k - i - 1 > 0)
          m_matX.coeffRef(i, k) -=
              (m_schur.matrixT().row(i).segment(i + 1, k - i - 1) * m_matX.col(k).segment(i + 1, k - i - 1)).value();
        ComplexScalar z = m_schur.matrixT().coeff(i, i) - m_schur.matrixT().coeff(k, k);
        if (z == ComplexScalar(0)) {
          numext::real_ref(z) = NumTraits<RealScalar>::epsilon() * matrixnorm;
        }
        m_matX.coeffRef(i, k) = m_matX.coeff(i, k) / z;
      }
    }
    m_eivec.noalias() = m_schur.matrixU() * m_matX;
    for (Index k = 0; k < n; k++) {
      m_eivec.col(k).normalize();
    }
  }
  template <typename MatrixType>
  void ComplexEigenSolver<MatrixType>::sortEigenvalues(bool computeEigenvectors) {
    const Index n = m_eivalues.size();
    for (Index i = 0; i < n; i++) {
      Index k;
      m_eivalues.cwiseAbs().tail(n - i).minCoeff(&k);
      if (k != 0) {
        k += i;
        std::swap(m_eivalues[k], m_eivalues[i]);
        if (computeEigenvectors)
          m_eivec.col(i).swap(m_eivec.col(k));
      }
    }
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class RealQZ {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef std::complex<typename NumTraits<Scalar>::Real> ComplexScalar;
    typedef Eigen::Index Index;
    typedef Matrix<ComplexScalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> EigenvalueType;
    typedef Matrix<Scalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> ColumnVectorType;
    explicit RealQZ(Index size = RowsAtCompileTime == Dynamic ? 1 : RowsAtCompileTime)
        : m_S(size, size),
          m_T(size, size),
          m_Q(size, size),
          m_Z(size, size),
          m_workspace(size * 2),
          m_maxIters(400),
          m_isInitialized(false),
          m_computeQZ(true) {}
    RealQZ(const MatrixType& A, const MatrixType& B, bool computeQZ = true)
        : m_S(A.rows(), A.cols()),
          m_T(A.rows(), A.cols()),
          m_Q(A.rows(), A.cols()),
          m_Z(A.rows(), A.cols()),
          m_workspace(A.rows() * 2),
          m_maxIters(400),
          m_isInitialized(false),
          m_computeQZ(true) {
      compute(A, B, computeQZ);
    }
    const MatrixType& matrixQ() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           125,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_computeQZ && "The matrices Q and Z have not been computed during the QZ decomposition.")
           ? void(0)
           : __assert_fail(
                 "m_computeQZ && \"The matrices Q and Z have not been computed during the QZ decomposition.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/RealQZ.h",
                 126,
                 __extension__ __PRETTY_FUNCTION__));
      return m_Q;
    }
    const MatrixType& matrixZ() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           135,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_computeQZ && "The matrices Q and Z have not been computed during the QZ decomposition.")
           ? void(0)
           : __assert_fail(
                 "m_computeQZ && \"The matrices Q and Z have not been computed during the QZ decomposition.\"",
                 "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                 "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/Eigen/src/"
                 "Eigenvalues/RealQZ.h",
                 136,
                 __extension__ __PRETTY_FUNCTION__));
      return m_Z;
    }
    const MatrixType& matrixS() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           145,
                           __extension__ __PRETTY_FUNCTION__));
      return m_S;
    }
    const MatrixType& matrixT() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           154,
                           __extension__ __PRETTY_FUNCTION__));
      return m_T;
    }
    RealQZ& compute(const MatrixType& A, const MatrixType& B, bool computeQZ = true);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           173,
                           __extension__ __PRETTY_FUNCTION__));
      return m_info;
    }
    Index iterations() const {
      (static_cast<bool>(m_isInitialized && "RealQZ is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"RealQZ is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/RealQZ.h",
                           181,
                           __extension__ __PRETTY_FUNCTION__));
      return m_global_iter;
    }
    RealQZ& setMaxIterations(Index maxIters) {
      m_maxIters = maxIters;
      return *this;
    }

  private:
    MatrixType m_S, m_T, m_Q, m_Z;
    Matrix<Scalar, Dynamic, 1> m_workspace;
    ComputationInfo m_info;
    Index m_maxIters;
    bool m_isInitialized;
    bool m_computeQZ;
    Scalar m_normOfT, m_normOfS;
    Index m_global_iter;
    typedef Matrix<Scalar, 3, 1> Vector3s;
    typedef Matrix<Scalar, 2, 1> Vector2s;
    typedef Matrix<Scalar, 2, 2> Matrix2s;
    typedef JacobiRotation<Scalar> JRs;
    void hessenbergTriangular();
    void computeNorms();
    Index findSmallSubdiagEntry(Index iu);
    Index findSmallDiagEntry(Index f, Index l);
    void splitOffTwoRows(Index i);
    void pushDownZero(Index z, Index f, Index l);
    void step(Index f, Index l, Index iter);
  };
  template <typename MatrixType>
  void RealQZ<MatrixType>::hessenbergTriangular() {
    const Index dim = m_S.cols();
    HouseholderQR<MatrixType> qrT(m_T);
    m_T = qrT.matrixQR();
    m_T.template triangularView<StrictlyLower>().setZero();
    m_Q = qrT.householderQ();
    m_S.applyOnTheLeft(m_Q.adjoint());
    if (m_computeQZ)
      m_Z = MatrixType::Identity(dim, dim);
    for (Index j = 0; j <= dim - 3; j++) {
      for (Index i = dim - 1; i >= j + 2; i--) {
        JRs G;
        if (!numext::is_exactly_zero(m_S.coeff(i, j))) {
          G.makeGivens(m_S.coeff(i - 1, j), m_S.coeff(i, j), &m_S.coeffRef(i - 1, j));
          m_S.coeffRef(i, j) = Scalar(0.0);
          m_S.rightCols(dim - j - 1).applyOnTheLeft(i - 1, i, G.adjoint());
          m_T.rightCols(dim - i + 1).applyOnTheLeft(i - 1, i, G.adjoint());
          if (m_computeQZ)
            m_Q.applyOnTheRight(i - 1, i, G);
        }
        if (!numext::is_exactly_zero(m_T.coeff(i, i - 1))) {
          G.makeGivens(m_T.coeff(i, i), m_T.coeff(i, i - 1), &m_T.coeffRef(i, i));
          m_T.coeffRef(i, i - 1) = Scalar(0.0);
          m_S.applyOnTheRight(i, i - 1, G);
          m_T.topRows(i).applyOnTheRight(i, i - 1, G);
          if (m_computeQZ)
            m_Z.applyOnTheLeft(i, i - 1, G.adjoint());
        }
      }
    }
  }
  template <typename MatrixType>
  inline void RealQZ<MatrixType>::computeNorms() {
    const Index size = m_S.cols();
    m_normOfS = Scalar(0.0);
    m_normOfT = Scalar(0.0);
    for (Index j = 0; j < size; ++j) {
      m_normOfS += m_S.col(j).segment(0, (std::min)(size, j + 2)).cwiseAbs().sum();
      m_normOfT += m_T.row(j).segment(j, size - j).cwiseAbs().sum();
    }
  }
  template <typename MatrixType>
  inline Index RealQZ<MatrixType>::findSmallSubdiagEntry(Index iu) {
    using std::abs;
    Index res = iu;
    while (res > 0) {
      Scalar s = abs(m_S.coeff(res - 1, res - 1)) + abs(m_S.coeff(res, res));
      if (numext::is_exactly_zero(s))
        s = m_normOfS;
      if (abs(m_S.coeff(res, res - 1)) < NumTraits<Scalar>::epsilon() * s)
        break;
      res--;
    }
    return res;
  }
  template <typename MatrixType>
  inline Index RealQZ<MatrixType>::findSmallDiagEntry(Index f, Index l) {
    using std::abs;
    Index res = l;
    while (res >= f) {
      if (abs(m_T.coeff(res, res)) <= NumTraits<Scalar>::epsilon() * m_normOfT)
        break;
      res--;
    }
    return res;
  }
  template <typename MatrixType>
  inline void RealQZ<MatrixType>::splitOffTwoRows(Index i) {
    using std::abs;
    using std::sqrt;
    const Index dim = m_S.cols();
    if (numext::is_exactly_zero(abs(m_S.coeff(i + 1, i))))
      return;
    Index j = findSmallDiagEntry(i, i + 1);
    if (j == i - 1) {
      Matrix2s STi = m_T.template block<2, 2>(i, i).template triangularView<Upper>().template solve<OnTheRight>(
          m_S.template block<2, 2>(i, i));
      Scalar p = Scalar(0.5) * (STi(0, 0) - STi(1, 1));
      Scalar q = p * p + STi(1, 0) * STi(0, 1);
      if (q >= 0) {
        Scalar z = sqrt(q);
        JRs G;
        if (p >= 0)
          G.makeGivens(p + z, STi(1, 0));
        else
          G.makeGivens(p - z, STi(1, 0));
        m_S.rightCols(dim - i).applyOnTheLeft(i, i + 1, G.adjoint());
        m_T.rightCols(dim - i).applyOnTheLeft(i, i + 1, G.adjoint());
        if (m_computeQZ)
          m_Q.applyOnTheRight(i, i + 1, G);
        G.makeGivens(m_T.coeff(i + 1, i + 1), m_T.coeff(i + 1, i));
        m_S.topRows(i + 2).applyOnTheRight(i + 1, i, G);
        m_T.topRows(i + 2).applyOnTheRight(i + 1, i, G);
        if (m_computeQZ)
          m_Z.applyOnTheLeft(i + 1, i, G.adjoint());
        m_S.coeffRef(i + 1, i) = Scalar(0.0);
        m_T.coeffRef(i + 1, i) = Scalar(0.0);
      }
    } else {
      pushDownZero(j, i, i + 1);
    }
  }
  template <typename MatrixType>
  inline void RealQZ<MatrixType>::pushDownZero(Index z, Index f, Index l) {
    JRs G;
    const Index dim = m_S.cols();
    for (Index zz = z; zz < l; zz++) {
      Index firstColS = zz > f ? (zz - 1) : zz;
      G.makeGivens(m_T.coeff(zz, zz + 1), m_T.coeff(zz + 1, zz + 1));
      m_S.rightCols(dim - firstColS).applyOnTheLeft(zz, zz + 1, G.adjoint());
      m_T.rightCols(dim - zz).applyOnTheLeft(zz, zz + 1, G.adjoint());
      m_T.coeffRef(zz + 1, zz + 1) = Scalar(0.0);
      if (m_computeQZ)
        m_Q.applyOnTheRight(zz, zz + 1, G);
      if (zz > f) {
        G.makeGivens(m_S.coeff(zz + 1, zz), m_S.coeff(zz + 1, zz - 1));
        m_S.topRows(zz + 2).applyOnTheRight(zz, zz - 1, G);
        m_T.topRows(zz + 1).applyOnTheRight(zz, zz - 1, G);
        m_S.coeffRef(zz + 1, zz - 1) = Scalar(0.0);
        if (m_computeQZ)
          m_Z.applyOnTheLeft(zz, zz - 1, G.adjoint());
      }
    }
    G.makeGivens(m_S.coeff(l, l), m_S.coeff(l, l - 1));
    m_S.applyOnTheRight(l, l - 1, G);
    m_T.applyOnTheRight(l, l - 1, G);
    m_S.coeffRef(l, l - 1) = Scalar(0.0);
    if (m_computeQZ)
      m_Z.applyOnTheLeft(l, l - 1, G.adjoint());
  }
  template <typename MatrixType>
  inline void RealQZ<MatrixType>::step(Index f, Index l, Index iter) {
    using std::abs;
    const Index dim = m_S.cols();
    Scalar x, y, z;
    if (iter == 10) {
      const Scalar a11 = m_S.coeff(f + 0, f + 0), a12 = m_S.coeff(f + 0, f + 1), a21 = m_S.coeff(f + 1, f + 0),
                   a22 = m_S.coeff(f + 1, f + 1), a32 = m_S.coeff(f + 2, f + 1), b12 = m_T.coeff(f + 0, f + 1),
                   b11i = Scalar(1.0) / m_T.coeff(f + 0, f + 0), b22i = Scalar(1.0) / m_T.coeff(f + 1, f + 1),
                   a87 = m_S.coeff(l - 1, l - 2), a98 = m_S.coeff(l - 0, l - 1),
                   b77i = Scalar(1.0) / m_T.coeff(l - 2, l - 2), b88i = Scalar(1.0) / m_T.coeff(l - 1, l - 1);
      Scalar ss = abs(a87 * b77i) + abs(a98 * b88i), lpl = Scalar(1.5) * ss, ll = ss * ss;
      x = ll + a11 * a11 * b11i * b11i - lpl * a11 * b11i + a12 * a21 * b11i * b22i -
          a11 * a21 * b12 * b11i * b11i * b22i;
      y = a11 * a21 * b11i * b11i - lpl * a21 * b11i + a21 * a22 * b11i * b22i - a21 * a21 * b12 * b11i * b11i * b22i;
      z = a21 * a32 * b11i * b22i;
    } else if (iter == 16) {
      x = m_S.coeff(f, f) / m_T.coeff(f, f) - m_S.coeff(l, l) / m_T.coeff(l, l) +
          m_S.coeff(l, l - 1) * m_T.coeff(l - 1, l) / (m_T.coeff(l - 1, l - 1) * m_T.coeff(l, l));
      y = m_S.coeff(f + 1, f) / m_T.coeff(f, f);
      z = 0;
    } else if (iter > 23 && !(iter % 8)) {
      x = internal::random<Scalar>(-1.0, 1.0);
      y = internal::random<Scalar>(-1.0, 1.0);
      z = internal::random<Scalar>(-1.0, 1.0);
    } else {
      const Scalar a11 = m_S.coeff(f, f), a12 = m_S.coeff(f, f + 1), a21 = m_S.coeff(f + 1, f),
                   a22 = m_S.coeff(f + 1, f + 1), a32 = m_S.coeff(f + 2, f + 1), a88 = m_S.coeff(l - 1, l - 1),
                   a89 = m_S.coeff(l - 1, l), a98 = m_S.coeff(l, l - 1), a99 = m_S.coeff(l, l), b11 = m_T.coeff(f, f),
                   b12 = m_T.coeff(f, f + 1), b22 = m_T.coeff(f + 1, f + 1), b88 = m_T.coeff(l - 1, l - 1),
                   b89 = m_T.coeff(l - 1, l), b99 = m_T.coeff(l, l);
      x = ((a88 / b88 - a11 / b11) * (a99 / b99 - a11 / b11) - (a89 / b99) * (a98 / b88) +
           (a98 / b88) * (b89 / b99) * (a11 / b11)) *
              (b11 / a21) +
          a12 / b22 - (a11 / b11) * (b12 / b22);
      y = (a22 / b22 - a11 / b11) - (a21 / b11) * (b12 / b22) - (a88 / b88 - a11 / b11) - (a99 / b99 - a11 / b11) +
          (a98 / b88) * (b89 / b99);
      z = a32 / b22;
    }
    JRs G;
    for (Index k = f; k <= l - 2; k++) {
      Vector2s essential2;
      Scalar tau, beta;
      Vector3s hr(x, y, z);
      hr.makeHouseholderInPlace(tau, beta);
      essential2 = hr.template bottomRows<2>();
      Index fc = (std::max)(k - 1, Index(0));
      m_S.template middleRows<3>(k).rightCols(dim - fc).applyHouseholderOnTheLeft(essential2, tau, m_workspace.data());
      m_T.template middleRows<3>(k).rightCols(dim - fc).applyHouseholderOnTheLeft(essential2, tau, m_workspace.data());
      if (m_computeQZ)
        m_Q.template middleCols<3>(k).applyHouseholderOnTheRight(essential2, tau, m_workspace.data());
      if (k > f)
        m_S.coeffRef(k + 2, k - 1) = m_S.coeffRef(k + 1, k - 1) = Scalar(0.0);
      hr << m_T.coeff(k + 2, k + 2), m_T.coeff(k + 2, k), m_T.coeff(k + 2, k + 1);
      hr.makeHouseholderInPlace(tau, beta);
      essential2 = hr.template bottomRows<2>();
      {
        Index lr = (std::min)(k + 4, dim);
        Map<Matrix<Scalar, Dynamic, 1>> tmp(m_workspace.data(), lr);
        tmp = m_S.template middleCols<2>(k).topRows(lr) * essential2;
        tmp += m_S.col(k + 2).head(lr);
        m_S.col(k + 2).head(lr) -= tau * tmp;
        m_S.template middleCols<2>(k).topRows(lr) -= (tau * tmp) * essential2.adjoint();
        tmp = m_T.template middleCols<2>(k).topRows(lr) * essential2;
        tmp += m_T.col(k + 2).head(lr);
        m_T.col(k + 2).head(lr) -= tau * tmp;
        m_T.template middleCols<2>(k).topRows(lr) -= (tau * tmp) * essential2.adjoint();
      }
      if (m_computeQZ) {
        Map<Matrix<Scalar, 1, Dynamic>> tmp(m_workspace.data(), dim);
        tmp = essential2.adjoint() * (m_Z.template middleRows<2>(k));
        tmp += m_Z.row(k + 2);
        m_Z.row(k + 2) -= tau * tmp;
        m_Z.template middleRows<2>(k) -= essential2 * (tau * tmp);
      }
      m_T.coeffRef(k + 2, k) = m_T.coeffRef(k + 2, k + 1) = Scalar(0.0);
      G.makeGivens(m_T.coeff(k + 1, k + 1), m_T.coeff(k + 1, k));
      m_S.applyOnTheRight(k + 1, k, G);
      m_T.applyOnTheRight(k + 1, k, G);
      if (m_computeQZ)
        m_Z.applyOnTheLeft(k + 1, k, G.adjoint());
      m_T.coeffRef(k + 1, k) = Scalar(0.0);
      x = m_S.coeff(k + 1, k);
      y = m_S.coeff(k + 2, k);
      if (k < l - 2)
        z = m_S.coeff(k + 3, k);
    }
    G.makeGivens(x, y);
    m_S.applyOnTheLeft(l - 1, l, G.adjoint());
    m_T.applyOnTheLeft(l - 1, l, G.adjoint());
    if (m_computeQZ)
      m_Q.applyOnTheRight(l - 1, l, G);
    m_S.coeffRef(l, l - 2) = Scalar(0.0);
    G.makeGivens(m_T.coeff(l, l), m_T.coeff(l, l - 1));
    m_S.applyOnTheRight(l, l - 1, G);
    m_T.applyOnTheRight(l, l - 1, G);
    if (m_computeQZ)
      m_Z.applyOnTheLeft(l, l - 1, G.adjoint());
    m_T.coeffRef(l, l - 1) = Scalar(0.0);
  }
  template <typename MatrixType>
  RealQZ<MatrixType>& RealQZ<MatrixType>::compute(const MatrixType& A_in, const MatrixType& B_in, bool computeQZ) {
    const Index dim = A_in.cols();
    (static_cast<bool>(A_in.rows() == dim && A_in.cols() == dim && B_in.rows() == dim && B_in.cols() == dim &&
                       "Need square matrices of the same dimension")
         ? void(0)
         : __assert_fail("A_in.rows()==dim && A_in.cols()==dim && B_in.rows()==dim && B_in.cols()==dim && \"Need "
                         "square matrices of the same dimension\"",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/RealQZ.h",
                         568,
                         __extension__ __PRETTY_FUNCTION__));
    m_isInitialized = true;
    m_computeQZ = computeQZ;
    m_S = A_in;
    m_T = B_in;
    m_workspace.resize(dim * 2);
    m_global_iter = 0;
    hessenbergTriangular();
    computeNorms();
    Index l = dim - 1, f, local_iter = 0;
    while (l > 0 && local_iter < m_maxIters) {
      f = findSmallSubdiagEntry(l);
      if (f > 0)
        m_S.coeffRef(f, f - 1) = Scalar(0.0);
      if (f == l) {
        l--;
        local_iter = 0;
      } else if (f == l - 1) {
        splitOffTwoRows(f);
        l -= 2;
        local_iter = 0;
      } else {
        Index z = findSmallDiagEntry(f, l);
        if (z >= f) {
          pushDownZero(z, f, l);
        } else {
          step(f, l, local_iter);
          local_iter++;
          m_global_iter++;
        }
      }
    }
    m_info = (local_iter < m_maxIters) ? Success : NoConvergence;
    if (m_info == Success) {
      for (Index i = 0; i < dim - 1; ++i) {
        if (!numext::is_exactly_zero(m_S.coeff(i + 1, i))) {
          JacobiRotation<Scalar> j_left, j_right;
          internal::real_2x2_jacobi_svd(m_T, i, i + 1, &j_left, &j_right);
          m_S.applyOnTheLeft(i, i + 1, j_left);
          m_S.applyOnTheRight(i, i + 1, j_right);
          m_T.applyOnTheLeft(i, i + 1, j_left);
          m_T.applyOnTheRight(i, i + 1, j_right);
          m_T(i + 1, i) = m_T(i, i + 1) = Scalar(0);
          if (m_computeQZ) {
            m_Q.applyOnTheRight(i, i + 1, j_left.transpose());
            m_Z.applyOnTheLeft(i, i + 1, j_right.transpose());
          }
          i++;
        }
      }
    }
    return *this;
  }
}  // namespace Eigen

namespace Eigen {
  template <typename MatrixType_>
  class GeneralizedEigenSolver {
  public:
    typedef MatrixType_ MatrixType;
    enum {
      RowsAtCompileTime = MatrixType::RowsAtCompileTime,
      ColsAtCompileTime = MatrixType::ColsAtCompileTime,
      Options = MatrixType::Options,
      MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
      MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
    };
    typedef typename MatrixType::Scalar Scalar;
    typedef typename NumTraits<Scalar>::Real RealScalar;
    typedef Eigen::Index Index;
    typedef std::complex<RealScalar> ComplexScalar;
    typedef Matrix<Scalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> VectorType;
    typedef Matrix<ComplexScalar, ColsAtCompileTime, 1, Options & ~RowMajor, MaxColsAtCompileTime, 1> ComplexVectorType;
    typedef CwiseBinaryOp<internal::scalar_quotient_op<ComplexScalar, Scalar>, ComplexVectorType, VectorType>
        EigenvalueType;
    typedef Matrix<ComplexScalar, RowsAtCompileTime, ColsAtCompileTime, Options, MaxRowsAtCompileTime, MaxColsAtCompileTime>
        EigenvectorsType;
    GeneralizedEigenSolver()
        : m_eivec(), m_alphas(), m_betas(), m_computeEigenvectors(false), m_isInitialized(false), m_realQZ() {}
    explicit GeneralizedEigenSolver(Index size)
        : m_eivec(size, size),
          m_alphas(size),
          m_betas(size),
          m_computeEigenvectors(false),
          m_isInitialized(false),
          m_realQZ(size),
          m_tmp(size) {}
    GeneralizedEigenSolver(const MatrixType& A, const MatrixType& B, bool computeEigenvectors = true)
        : m_eivec(A.rows(), A.cols()),
          m_alphas(A.cols()),
          m_betas(A.cols()),
          m_computeEigenvectors(false),
          m_isInitialized(false),
          m_realQZ(A.cols()),
          m_tmp(A.cols()) {
      compute(A, B, computeEigenvectors);
    }
    EigenvectorsType eigenvectors() const {
      (static_cast<bool>(info() == Success && "GeneralizedEigenSolver failed to compute eigenvectors")
           ? void(0)
           : __assert_fail("info() == Success && \"GeneralizedEigenSolver failed to compute eigenvectors\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           182,
                           __extension__ __PRETTY_FUNCTION__));
      (static_cast<bool>(m_computeEigenvectors && "Eigenvectors for GeneralizedEigenSolver were not calculated")
           ? void(0)
           : __assert_fail("m_computeEigenvectors && \"Eigenvectors for GeneralizedEigenSolver were not calculated\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           183,
                           __extension__ __PRETTY_FUNCTION__));
      return m_eivec;
    }
    EigenvalueType eigenvalues() const {
      (static_cast<bool>(info() == Success && "GeneralizedEigenSolver failed to compute eigenvalues.")
           ? void(0)
           : __assert_fail("info() == Success && \"GeneralizedEigenSolver failed to compute eigenvalues.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           207,
                           __extension__ __PRETTY_FUNCTION__));
      return EigenvalueType(m_alphas, m_betas);
    }
    const ComplexVectorType& alphas() const {
      (static_cast<bool>(info() == Success && "GeneralizedEigenSolver failed to compute alphas.")
           ? void(0)
           : __assert_fail("info() == Success && \"GeneralizedEigenSolver failed to compute alphas.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           218,
                           __extension__ __PRETTY_FUNCTION__));
      return m_alphas;
    }
    const VectorType& betas() const {
      (static_cast<bool>(info() == Success && "GeneralizedEigenSolver failed to compute betas.")
           ? void(0)
           : __assert_fail("info() == Success && \"GeneralizedEigenSolver failed to compute betas.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           229,
                           __extension__ __PRETTY_FUNCTION__));
      return m_betas;
    }
    GeneralizedEigenSolver& compute(const MatrixType& A, const MatrixType& B, bool computeEigenvectors = true);
    ComputationInfo info() const {
      (static_cast<bool>(m_isInitialized && "EigenSolver is not initialized.")
           ? void(0)
           : __assert_fail("m_isInitialized && \"EigenSolver is not initialized.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                           "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                           "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                           260,
                           __extension__ __PRETTY_FUNCTION__));
      return m_realQZ.info();
    }
    GeneralizedEigenSolver& setMaxIterations(Index maxIters) {
      m_realQZ.setMaxIterations(maxIters);
      return *this;
    }

  protected:
    static_assert(!Eigen::NumTraits<Scalar>::IsInteger, "THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES");
    static_assert(!NumTraits<Scalar>::IsComplex, "NUMERIC_TYPE_MUST_BE_REAL");
    EigenvectorsType m_eivec;
    ComplexVectorType m_alphas;
    VectorType m_betas;
    bool m_computeEigenvectors;
    bool m_isInitialized;
    RealQZ<MatrixType> m_realQZ;
    ComplexVectorType m_tmp;
  };
  template <typename MatrixType>
  GeneralizedEigenSolver<MatrixType>& GeneralizedEigenSolver<MatrixType>::compute(const MatrixType& A,
                                                                                  const MatrixType& B,
                                                                                  bool computeEigenvectors) {
    using std::abs;
    using std::sqrt;
    (static_cast<bool>(A.cols() == A.rows() && B.cols() == A.rows() && B.cols() == B.rows())
         ? void(0)
         : __assert_fail("A.cols() == A.rows() && B.cols() == A.rows() && B.cols() == B.rows()",
                         "/cvmfs/cms.cern.ch/el9_amd64_gcc12/external/eigen/"
                         "3bb6a48d8c171cf20b5f8e48bfb4e424fbd4f79e-39786ff94f8aa2f543922cad720e1b32/include/eigen3/"
                         "Eigen/src/Eigenvalues/GeneralizedEigenSolver.h",
                         292,
                         __extension__ __PRETTY_FUNCTION__));
    Index size = A.cols();
    m_realQZ.compute(A, B, computeEigenvectors);
    if (m_realQZ.info() == Success) {
      m_alphas.resize(size);
      m_betas.resize(size);
      if (computeEigenvectors) {
        m_eivec.resize(size, size);
        m_tmp.resize(size);
      }
      Map<VectorType> v(reinterpret_cast<Scalar*>(m_tmp.data()), size);
      ComplexVectorType& cv = m_tmp;
      const MatrixType& mS = m_realQZ.matrixS();
      const MatrixType& mT = m_realQZ.matrixT();
      Index i = 0;
      while (i < size) {
        if (i == size - 1 || mS.coeff(i + 1, i) == Scalar(0)) {
          m_alphas.coeffRef(i) = mS.diagonal().coeff(i);
          m_betas.coeffRef(i) = mT.diagonal().coeff(i);
          if (computeEigenvectors) {
            v.setConstant(Scalar(0.0));
            v.coeffRef(i) = Scalar(1.0);
            if (abs(m_betas.coeffRef(i)) >= (std::numeric_limits<RealScalar>::min)()) {
              const Scalar alpha = real(m_alphas.coeffRef(i));
              const Scalar beta = m_betas.coeffRef(i);
              for (Index j = i - 1; j >= 0; j--) {
                const Index st = j + 1;
                const Index sz = i - j;
                if (j > 0 && mS.coeff(j, j - 1) != Scalar(0)) {
                  Matrix<Scalar, 2, 1> rhs = (alpha * mT.template block<2, Dynamic>(j - 1, st, 2, sz) -
                                              beta * mS.template block<2, Dynamic>(j - 1, st, 2, sz))
                                                 .lazyProduct(v.segment(st, sz));
                  Matrix<Scalar, 2, 2> lhs =
                      beta * mS.template block<2, 2>(j - 1, j - 1) - alpha * mT.template block<2, 2>(j - 1, j - 1);
                  v.template segment<2>(j - 1) = lhs.partialPivLu().solve(rhs);
                  j--;
                } else {
                  v.coeffRef(j) = -v.segment(st, sz)
                                       .transpose()
                                       .cwiseProduct(beta * mS.block(j, st, 1, sz) - alpha * mT.block(j, st, 1, sz))
                                       .sum() /
                                  (beta * mS.coeffRef(j, j) - alpha * mT.coeffRef(j, j));
                }
              }
            }
            m_eivec.col(i).real().noalias() = m_realQZ.matrixZ().transpose() * v;
            m_eivec.col(i).real().normalize();
            m_eivec.col(i).imag().setConstant(0);
          }
          ++i;
        } else {
          RealScalar a = mT.diagonal().coeff(i), b = mT.diagonal().coeff(i + 1);
          const RealScalar beta = m_betas.coeffRef(i) = m_betas.coeffRef(i + 1) = a * b;
          Matrix<RealScalar, 2, 2> S2 = mS.template block<2, 2>(i, i) * Matrix<Scalar, 2, 1>(b, a).asDiagonal();
          Scalar p = Scalar(0.5) * (S2.coeff(0, 0) - S2.coeff(1, 1));
          Scalar z = sqrt(abs(p * p + S2.coeff(1, 0) * S2.coeff(0, 1)));
          const ComplexScalar alpha = ComplexScalar(S2.coeff(1, 1) + p, (beta > 0) ? z : -z);
          m_alphas.coeffRef(i) = conj(alpha);
          m_alphas.coeffRef(i + 1) = alpha;
          if (computeEigenvectors) {
            cv.setZero();
            cv.coeffRef(i + 1) = Scalar(1.0);
            cv.coeffRef(i) = -(static_cast<Scalar>(beta * mS.coeffRef(i, i + 1)) - alpha * mT.coeffRef(i, i + 1)) /
                             (static_cast<Scalar>(beta * mS.coeffRef(i, i)) - alpha * mT.coeffRef(i, i));
            for (Index j = i - 1; j >= 0; j--) {
              const Index st = j + 1;
              const Index sz = i + 1 - j;
              if (j > 0 && mS.coeff(j, j - 1) != Scalar(0)) {
                Matrix<ComplexScalar, 2, 1> rhs = (alpha * mT.template block<2, Dynamic>(j - 1, st, 2, sz) -
                                                   beta * mS.template block<2, Dynamic>(j - 1, st, 2, sz))
                                                      .lazyProduct(cv.segment(st, sz));
                Matrix<ComplexScalar, 2, 2> lhs =
                    beta * mS.template block<2, 2>(j - 1, j - 1) - alpha * mT.template block<2, 2>(j - 1, j - 1);
                cv.template segment<2>(j - 1) = lhs.partialPivLu().solve(rhs);
                j--;
              } else {
                cv.coeffRef(j) = cv.segment(st, sz)
                                     .transpose()
                                     .cwiseProduct(beta * mS.block(j, st, 1, sz) - alpha * mT.block(j, st, 1, sz))
                                     .sum() /
                                 (alpha * mT.coeffRef(j, j) - static_cast<Scalar>(beta * mS.coeffRef(j, j)));
              }
            }
            m_eivec.col(i + 1).noalias() = (m_realQZ.matrixZ().transpose() * cv);
            m_eivec.col(i + 1).normalize();
            m_eivec.col(i) = m_eivec.col(i + 1).conjugate();
          }
          i += 2;
        }
      }
    }
    m_computeEigenvectors = computeEigenvectors;
    m_isInitialized = true;
    return *this;
  }
}  // namespace Eigen

namespace Eigen {
  namespace internal {
    template <typename Derived, bool IsComplex>
    struct eigenvalues_selector {
      static inline typename MatrixBase<Derived>::EigenvaluesReturnType const run(const MatrixBase<Derived>& m) {
        typedef typename Derived::PlainObject PlainObject;
        PlainObject m_eval(m);
        return ComplexEigenSolver<PlainObject>(m_eval, false).eigenvalues();
      }
    };
    template <typename Derived>
    struct eigenvalues_selector<Derived, false> {
      static inline typename MatrixBase<Derived>::EigenvaluesReturnType const run(const MatrixBase<Derived>& m) {
        typedef typename Derived::PlainObject PlainObject;
        PlainObject m_eval(m);
        return EigenSolver<PlainObject>(m_eval, false).eigenvalues();
      }
    };
  }  // namespace internal
  template <typename Derived>
  inline typename MatrixBase<Derived>::EigenvaluesReturnType MatrixBase<Derived>::eigenvalues() const {
    return internal::eigenvalues_selector<Derived, NumTraits<Scalar>::IsComplex>::run(derived());
  }
  template <typename MatrixType, unsigned int UpLo>
  inline typename SelfAdjointView<MatrixType, UpLo>::EigenvaluesReturnType
  SelfAdjointView<MatrixType, UpLo>::eigenvalues() const {
    PlainObject thisAsMatrix(*this);
    return SelfAdjointEigenSolver<PlainObject>(thisAsMatrix, false).eigenvalues();
  }
  template <typename Derived>
  inline typename MatrixBase<Derived>::RealScalar MatrixBase<Derived>::operatorNorm() const {
    using std::sqrt;
    typename Derived::PlainObject m_eval(derived());
    return sqrt((m_eval * m_eval.adjoint()).eval().template selfadjointView<Lower>().eigenvalues().maxCoeff());
  }
  template <typename MatrixType, unsigned int UpLo>
  inline typename SelfAdjointView<MatrixType, UpLo>::RealScalar SelfAdjointView<MatrixType, UpLo>::operatorNorm() const {
    return eigenvalues().cwiseAbs().maxCoeff();
  }
}  // namespace Eigen
#pragma clang diagnostic pop

#include <iostream> /* clang -E -fkeep-system-includes */

#include <cassert> /* clang -E -fkeep-system-includes */

#include <cstdint>                /* clang -E -fkeep-system-includes */
#include <cassert>                /* clang -E -fkeep-system-includes */
#include <ostream>                /* clang -E -fkeep-system-includes */
#include <tuple>                  /* clang -E -fkeep-system-includes */
#include <type_traits>            /* clang -E -fkeep-system-includes */
#include <boost/preprocessor.hpp> /* clang -E -fkeep-system-includes */

typedef signed char cms_int8_t;
typedef unsigned char cms_uint8_t;
typedef short cms_int16_t;
typedef unsigned short cms_uint16_t;
typedef int cms_int32_t;
typedef unsigned int cms_uint32_t;
typedef long long cms_int64_t;
typedef unsigned long long cms_uint64_t;
namespace cms::soa {
  using size_type = cms_int32_t;
  using byte_size_type = std::size_t;
  enum class SoAColumnType { scalar = 0, column = 1, eigen = 2 };
  namespace RestrictQualify {
    constexpr bool enabled = true;
    constexpr bool disabled = false;
    constexpr bool Default = enabled;
  }  // namespace RestrictQualify
  namespace RangeChecking {
    constexpr bool enabled = true;
    constexpr bool disabled = false;
    constexpr bool Default = enabled;
  }  // namespace RangeChecking
  template <typename T, bool RESTRICT_QUALIFY>
  struct add_restrict {};
  template <typename T>
  struct add_restrict<T, RestrictQualify::enabled> {
    using Value = T;
    using Pointer = T* __restrict__;
    using Reference = T& __restrict__;
    using ConstValue = const T;
    using PointerToConst = const T* __restrict__;
    using ReferenceToConst = const T& __restrict__;
  };
  template <typename T>
  struct add_restrict<T, RestrictQualify::disabled> {
    using Value = T;
    using Pointer = T*;
    using Reference = T&;
    using ConstValue = const T;
    using PointerToConst = const T*;
    using ReferenceToConst = const T&;
  };
  template <SoAColumnType COLUMN_TYPE, typename T>
  struct SoAConstParametersImpl;
  template <SoAColumnType COLUMN_TYPE, typename T>
  struct SoAParametersImpl;
  template <SoAColumnType COLUMN_TYPE, typename T>
  struct SoAConstParametersImpl {
    static constexpr SoAColumnType columnType = COLUMN_TYPE;
    using ValueType = T;
    using ScalarType = T;
    using TupleOrPointerType = const ValueType*;
    SoAConstParametersImpl() = default;
    inline __attribute__((always_inline)) constexpr SoAConstParametersImpl(ValueType const* addr) : addr_(addr) {}
    inline __attribute__((always_inline)) constexpr SoAConstParametersImpl(
        SoAParametersImpl<columnType, ValueType> const& o)
        : addr_{o.addr_} {}
    static constexpr bool checkAlignment(ValueType* addr, byte_size_type alignment) {
      return reinterpret_cast<intptr_t>(addr) % alignment;
    }
    TupleOrPointerType tupleOrPointer() { return addr_; }

  public:
    ValueType const* addr_ = nullptr;
  };
  template <typename T>
  struct SoAConstParametersImpl<SoAColumnType::eigen, T> {
    static constexpr SoAColumnType columnType = SoAColumnType::eigen;
    using ValueType = T;
    using ScalarType = typename T::Scalar;
    using TupleOrPointerType = std::tuple<ScalarType*, byte_size_type>;
    SoAConstParametersImpl() = default;
    inline
        __attribute__((always_inline)) constexpr SoAConstParametersImpl(ScalarType const* addr, byte_size_type stride)
        : addr_(addr), stride_(stride) {}
    inline __attribute__((always_inline)) constexpr SoAConstParametersImpl(TupleOrPointerType const& tuple)
        : addr_(std::get<0>(tuple)), stride_(std::get<1>(tuple)) {}
    inline __attribute__((always_inline)) constexpr SoAConstParametersImpl(
        SoAParametersImpl<columnType, ValueType> const& o)
        : addr_{o.addr_}, stride_{o.stride_} {}
    static constexpr bool checkAlignment(TupleOrPointerType const& tuple, byte_size_type alignment) {
      const auto& [addr, stride] = tuple;
      return reinterpret_cast<intptr_t>(addr) % alignment;
    }
    TupleOrPointerType tupleOrPointer() { return {addr_, stride_}; }

  public:
    ScalarType const* addr_ = nullptr;
    byte_size_type stride_ = 0;
  };
  template <SoAColumnType COLUMN_TYPE>
  struct SoAConstParameters_ColumnType {
    template <typename T>
    using DataType = SoAConstParametersImpl<COLUMN_TYPE, T>;
  };
  template <SoAColumnType COLUMN_TYPE, typename T>
  struct SoAParametersImpl {
    static constexpr SoAColumnType columnType = COLUMN_TYPE;
    using ValueType = T;
    using ScalarType = T;
    using TupleOrPointerType = ValueType*;
    using ConstType = SoAConstParametersImpl<columnType, ValueType>;
    friend ConstType;
    SoAParametersImpl() = default;
    inline __attribute__((always_inline)) constexpr SoAParametersImpl(ValueType* addr) : addr_(addr) {}
    static constexpr bool checkAlignment(ValueType* addr, byte_size_type alignment) {
      return reinterpret_cast<intptr_t>(addr) % alignment;
    }
    TupleOrPointerType tupleOrPointer() { return addr_; }

  public:
    ValueType* addr_ = nullptr;
  };
  template <typename T>
  struct SoAParametersImpl<SoAColumnType::eigen, T> {
    static constexpr SoAColumnType columnType = SoAColumnType::eigen;
    using ValueType = T;
    using ScalarType = typename T::Scalar;
    using TupleOrPointerType = std::tuple<ScalarType*, byte_size_type>;
    using ConstType = SoAConstParametersImpl<columnType, ValueType>;
    friend ConstType;
    SoAParametersImpl() = default;
    inline __attribute__((always_inline)) constexpr SoAParametersImpl(ScalarType* addr, byte_size_type stride)
        : addr_(addr), stride_(stride) {}
    inline __attribute__((always_inline)) constexpr SoAParametersImpl(TupleOrPointerType const& tuple)
        : addr_(std::get<0>(tuple)), stride_(std::get<1>(tuple)) {}
    static constexpr bool checkAlignment(TupleOrPointerType const& tuple, byte_size_type alignment) {
      const auto& [addr, stride] = tuple;
      return reinterpret_cast<intptr_t>(addr) % alignment;
    }
    TupleOrPointerType tupleOrPointer() { return {addr_, stride_}; }

  public:
    ScalarType* addr_ = nullptr;
    byte_size_type stride_ = 0;
  };
  template <SoAColumnType COLUMN_TYPE>
  struct SoAParameters_ColumnType {
    template <typename T>
    using DataType = SoAParametersImpl<COLUMN_TYPE, T>;
  };
  namespace {
    template <typename T>
    constexpr inline std::remove_const_t<T>* non_const_ptr(T* p) {
      return const_cast<std::remove_const_t<T>*>(p);
    }
  }  // namespace
  template <SoAColumnType COLUMN_TYPE, typename T>
  inline __attribute__((always_inline)) constexpr SoAParametersImpl<COLUMN_TYPE, T> const_cast_SoAParametersImpl(
      SoAConstParametersImpl<COLUMN_TYPE, T> const& o) {
    return SoAParametersImpl<COLUMN_TYPE, T>{non_const_ptr(o.addr_)};
  }
  template <typename T>
  inline __attribute__((always_inline)) constexpr SoAParametersImpl<SoAColumnType::eigen, T>
  const_cast_SoAParametersImpl(SoAConstParametersImpl<SoAColumnType::eigen, T> const& o) {
    return SoAParametersImpl<SoAColumnType::eigen, T>{non_const_ptr(o.addr_), o.stride_};
  }
  template <SoAColumnType COLUMN_TYPE,
            typename T,
            byte_size_type ALIGNMENT,
            bool RESTRICT_QUALIFY = RestrictQualify::disabled>
  class SoAValue {
    static_assert(COLUMN_TYPE != SoAColumnType::eigen);

  public:
    using Restr = add_restrict<T, RESTRICT_QUALIFY>;
    using Val = typename Restr::Value;
    using Ptr = typename Restr::Pointer;
    using Ref = typename Restr::Reference;
    using PtrToConst = typename Restr::PointerToConst;
    using RefToConst = typename Restr::ReferenceToConst;
    inline __attribute__((always_inline)) SoAValue(size_type i, T* col) : idx_(i), col_(col) {}
    inline __attribute__((always_inline)) SoAValue(size_type i, SoAParametersImpl<COLUMN_TYPE, T> params)
        : idx_(i), col_(params.addr_) {}
    inline __attribute__((always_inline)) Ref operator()() {
      Ptr col = col_;
      return col[idx_];
    }
    inline __attribute__((always_inline)) RefToConst operator()() const {
      PtrToConst col = col_;
      return col[idx_];
    }
    inline __attribute__((always_inline)) Ptr operator&() { return &col_[idx_]; }
    inline __attribute__((always_inline)) PtrToConst operator&() const { return &col_[idx_]; }
    using valueType = Val;
    static constexpr auto valueSize = sizeof(T);

  private:
    size_type idx_;
    T* col_;
  };
  template <class C, byte_size_type ALIGNMENT, bool RESTRICT_QUALIFY>
  class SoAValue<SoAColumnType::eigen, C, ALIGNMENT, RESTRICT_QUALIFY> {
  public:
    using Type = C;
    using MapType = Eigen::Map<C, 0, Eigen::InnerStride<Eigen::Dynamic>>;
    using CMapType = const Eigen::Map<const C, 0, Eigen::InnerStride<Eigen::Dynamic>>;
    using Restr = add_restrict<typename C::Scalar, RESTRICT_QUALIFY>;
    using Val = typename Restr::Value;
    using Ptr = typename Restr::Pointer;
    using Ref = typename Restr::Reference;
    using PtrToConst = typename Restr::PointerToConst;
    using RefToConst = typename Restr::ReferenceToConst;
    inline __attribute__((always_inline)) SoAValue(size_type i, typename C::Scalar* col, byte_size_type stride)
        : val_(col + i, C::RowsAtCompileTime, C::ColsAtCompileTime, Eigen::InnerStride<Eigen::Dynamic>(stride)),
          crCol_(col),
          cVal_(crCol_ + i, C::RowsAtCompileTime, C::ColsAtCompileTime, Eigen::InnerStride<Eigen::Dynamic>(stride)),
          stride_(stride) {}
    inline __attribute__((always_inline)) SoAValue(size_type i, SoAParametersImpl<SoAColumnType::eigen, C> params)
        : val_(params.addr_ + i,
               C::RowsAtCompileTime,
               C::ColsAtCompileTime,
               Eigen::InnerStride<Eigen::Dynamic>(params.stride_)),
          crCol_(params.addr_),
          cVal_(crCol_ + i,
                C::RowsAtCompileTime,
                C::ColsAtCompileTime,
                Eigen::InnerStride<Eigen::Dynamic>(params.stride_)),
          stride_(params.stride_) {}
    inline __attribute__((always_inline)) MapType& operator()() { return val_; }
    inline __attribute__((always_inline)) const CMapType& operator()() const { return cVal_; }
    inline __attribute__((always_inline)) operator C() { return val_; }
    inline __attribute__((always_inline)) operator const C() const { return cVal_; }
    inline __attribute__((always_inline)) C* operator&() { return &val_; }
    inline __attribute__((always_inline)) const C* operator&() const { return &cVal_; }
    template <class C2>
    inline __attribute__((always_inline)) MapType& operator=(const C2& v) {
      return val_ = v;
    }
    using ValueType = typename C::Scalar;
    static constexpr auto valueSize = sizeof(typename C::Scalar);
    inline __attribute__((always_inline)) byte_size_type stride() const { return stride_; }

  private:
    MapType val_;
    const Ptr crCol_;
    CMapType cVal_;
    byte_size_type stride_;
  };
  template <SoAColumnType COLUMN_TYPE,
            typename T,
            byte_size_type ALIGNMENT,
            bool RESTRICT_QUALIFY = RestrictQualify::disabled>
  class SoAConstValue {
    static_assert(COLUMN_TYPE != SoAColumnType::eigen);

  public:
    using Restr = add_restrict<T, RESTRICT_QUALIFY>;
    using Val = typename Restr::Value;
    using Ptr = typename Restr::Pointer;
    using Ref = typename Restr::Reference;
    using PtrToConst = typename Restr::PointerToConst;
    using RefToConst = typename Restr::ReferenceToConst;
    using Params = SoAParametersImpl<COLUMN_TYPE, T>;
    using ConstParams = SoAConstParametersImpl<COLUMN_TYPE, T>;
    inline __attribute__((always_inline)) SoAConstValue(size_type i, const T* col) : idx_(i), col_(col) {}
    inline __attribute__((always_inline)) SoAConstValue(size_type i, SoAParametersImpl<COLUMN_TYPE, T> params)
        : idx_(i), col_(params.addr_) {}
    inline __attribute__((always_inline)) SoAConstValue(size_type i, SoAConstParametersImpl<COLUMN_TYPE, T> params)
        : idx_(i), col_(params.addr_) {}
    inline __attribute__((always_inline)) RefToConst operator()() const {
      PtrToConst col = col_;
      return col[idx_];
    }
    inline __attribute__((always_inline)) const T* operator&() const { return &col_[idx_]; }
    using valueType = T;
    static constexpr auto valueSize = sizeof(T);

  private:
    size_type idx_;
    const T* col_;
  };
  template <class C, byte_size_type ALIGNMENT, bool RESTRICT_QUALIFY>
  class SoAConstValue<SoAColumnType::eigen, C, ALIGNMENT, RESTRICT_QUALIFY> {
  public:
    using Type = C;
    using CMapType = Eigen::Map<const C, 0, Eigen::InnerStride<Eigen::Dynamic>>;
    using RefToConst = const CMapType&;
    using ConstParams = SoAConstParametersImpl<SoAColumnType::eigen, C>;
    inline __attribute__((always_inline)) SoAConstValue(size_type i, typename C::Scalar* col, byte_size_type stride)
        : crCol_(col),
          cVal_(crCol_ + i, C::RowsAtCompileTime, C::ColsAtCompileTime, Eigen::InnerStride<Eigen::Dynamic>(stride)),
          stride_(stride) {}
    inline __attribute__((always_inline)) SoAConstValue(size_type i,
                                                        SoAConstParametersImpl<SoAColumnType::eigen, C> params)
        : crCol_(params.addr_),
          cVal_(crCol_ + i,
                C::RowsAtCompileTime,
                C::ColsAtCompileTime,
                Eigen::InnerStride<Eigen::Dynamic>(params.stride_)),
          stride_(params.stride_) {}
    inline __attribute__((always_inline)) const CMapType& operator()() const { return cVal_; }
    inline __attribute__((always_inline)) operator const C() const { return cVal_; }
    inline __attribute__((always_inline)) const C* operator&() const { return &cVal_; }
    using ValueType = typename C::Scalar;
    static constexpr auto valueSize = sizeof(typename C::Scalar);
    inline __attribute__((always_inline)) byte_size_type stride() const { return stride_; }

  private:
    const typename C::Scalar* __restrict__ crCol_;
    CMapType cVal_;
    byte_size_type stride_;
  };
  template <class C>
  struct EigenConstMapMaker {
    using Type = Eigen::Map<const C, Eigen::AlignmentType::Unaligned, Eigen::InnerStride<Eigen::Dynamic>>;
    class DataHolder {
    public:
      DataHolder(const typename C::Scalar* data) : data_(data) {}
      EigenConstMapMaker::Type withStride(byte_size_type stride) {
        return EigenConstMapMaker::Type(
            data_, C::RowsAtCompileTime, C::ColsAtCompileTime, Eigen::InnerStride<Eigen::Dynamic>(stride));
      }

    private:
      const typename C::Scalar* const data_;
    };
    static DataHolder withData(const typename C::Scalar* data) { return DataHolder(data); }
  };
  constexpr inline byte_size_type alignSize(byte_size_type size, byte_size_type alignment) {
    return ((size + alignment - 1) / alignment) * alignment;
  }
}  // namespace cms::soa
namespace cms::soa {
  enum class SoAAccessType : bool { mutableAccess, constAccess };
  template <typename, SoAColumnType, SoAAccessType, byte_size_type, bool>
  struct SoAColumnAccessorsImpl {};
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::column, SoAAccessType::mutableAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAParametersImpl<SoAColumnType::column, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) T* operator()() { return params_.addr_; }
    using NoParamReturnType = T*;
    using ParamReturnType = T&;
    inline __attribute__((always_inline)) T& operator()(size_type index) { return params_.addr_[index]; }

  private:
    SoAParametersImpl<SoAColumnType::column, T> params_;
  };
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::column, SoAAccessType::constAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAConstParametersImpl<SoAColumnType::column, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) const T* operator()() const { return params_.addr_; }
    using NoParamReturnType = const T*;
    using ParamReturnType = const T&;
    inline __attribute__((always_inline)) T const& operator()(size_type index) const { return params_.addr_[index]; }

  private:
    SoAConstParametersImpl<SoAColumnType::column, T> params_;
  };
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::scalar, SoAAccessType::mutableAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAParametersImpl<SoAColumnType::scalar, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) T& operator()() { return *params_.addr_; }
    using NoParamReturnType = T&;
    using ParamReturnType = void;
    inline __attribute__((always_inline)) void operator()(size_type index) const {
      (static_cast<bool>(false && "Indexed access impossible for SoA scalars.")
           ? void(0)
           : __assert_fail("false && \"Indexed access impossible for SoA scalars.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_2_0_pre1/src/DataFormats/SoATemplate/"
                           "interface/SoACommon.h",
                           633,
                           __extension__ __PRETTY_FUNCTION__));
    }

  private:
    SoAParametersImpl<SoAColumnType::scalar, T> params_;
  };
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::scalar, SoAAccessType::constAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAConstParametersImpl<SoAColumnType::scalar, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) T const& operator()() const { return *params_.addr_; }
    using NoParamReturnType = T const&;
    using ParamReturnType = void;
    inline __attribute__((always_inline)) void operator()(size_type index) const {
      (static_cast<bool>(false && "Indexed access impossible for SoA scalars.")
           ? void(0)
           : __assert_fail("false && \"Indexed access impossible for SoA scalars.\"",
                           "/cvmfs/cms.cern.ch/el9_amd64_gcc12/cms/cmssw/CMSSW_14_2_0_pre1/src/DataFormats/SoATemplate/"
                           "interface/SoACommon.h",
                           649,
                           __extension__ __PRETTY_FUNCTION__));
    }

  private:
    SoAConstParametersImpl<SoAColumnType::scalar, T> params_;
  };
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::eigen, SoAAccessType::mutableAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAParametersImpl<SoAColumnType::eigen, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) typename T::Scalar* operator()() { return params_.addr_; }
    using NoParamReturnType = typename T::Scalar*;
    using ParamReturnType = typename SoAValue<SoAColumnType::eigen, T, alignment, restrictQualify>::MapType;
    inline __attribute__((always_inline)) ParamReturnType operator()(size_type index) {
      return SoAValue<SoAColumnType::eigen, T, alignment, restrictQualify>(index, params_)();
    }

  private:
    SoAParametersImpl<SoAColumnType::eigen, T> params_;
  };
  template <typename T, byte_size_type alignment, bool restrictQualify>
  struct SoAColumnAccessorsImpl<T, SoAColumnType::eigen, SoAAccessType::constAccess, alignment, restrictQualify> {
    inline __attribute__((always_inline)) SoAColumnAccessorsImpl(
        const SoAConstParametersImpl<SoAColumnType::eigen, T>& params)
        : params_(params) {}
    inline __attribute__((always_inline)) typename T::Scalar const* operator()() const { return params_.addr_; }
    using NoParamReturnType = typename T::Scalar const*;
    using ParamReturnType = typename SoAValue<SoAColumnType::eigen, T, alignment, restrictQualify>::CMapType;
    inline __attribute__((always_inline)) ParamReturnType operator()(size_type index) const {
      return SoAConstValue<SoAColumnType::eigen, T, alignment, restrictQualify>(index, params_)();
    }

  private:
    SoAConstParametersImpl<SoAColumnType::eigen, T> params_;
  };
  template <typename T>
  struct SoAAccessors {
    template <auto columnType>
    struct ColumnType {
      template <auto accessType>
      struct AccessType {
        template <auto alignment>
        struct Alignment {
          template <auto restrictQualify>
          struct RestrictQualifier
              : public SoAColumnAccessorsImpl<T, columnType, accessType, alignment, restrictQualify> {
            using SoAColumnAccessorsImpl<T, columnType, accessType, alignment, restrictQualify>::SoAColumnAccessorsImpl;
          };
        };
      };
    };
  };
  struct AlignmentEnforcement {
    static constexpr bool relaxed = false;
    static constexpr bool enforced = true;
  };
  struct CacheLineSize {
    static constexpr byte_size_type NvidiaGPU = 128;
    static constexpr byte_size_type IntelCPU = 64;
    static constexpr byte_size_type AMDCPU = 64;
    static constexpr byte_size_type ARMCPU = 64;
    static constexpr byte_size_type defaultSize = NvidiaGPU;
  };
}  // namespace cms::soa
template <typename SOA,
          typename SFINAE =
              typename std::enable_if_t<std::is_invocable_v<decltype(&SOA::soaToStreamInternal), SOA&, std::ostream&>>>
std::ostream& operator<<(std::ostream& os, const SOA& soa) {
  soa.soaToStreamInternal(os);
  return os;
}
namespace cms::soa {
  template <class C, SoAColumnType COLUMN_TYPE>
  struct ConstValueTraits : public C {
    using C::C;
  };
  template <class C>
  struct ConstValueTraits<C, SoAColumnType::scalar> {
    inline __attribute__((always_inline)) ConstValueTraits(size_type, const typename C::valueType*) {}
    inline __attribute__((always_inline)) ConstValueTraits(size_type, const typename C::Params&) {}
    inline __attribute__((always_inline)) ConstValueTraits(size_type, const typename C::ConstParams&) {}
  };
}  // namespace cms::soa
template <std::size_t ALIGNMENT = cms::soa::CacheLineSize::defaultSize,
          bool ALIGNMENT_ENFORCEMENT = cms::soa::AlignmentEnforcement::relaxed>
struct SoAHostDeviceLayoutTemplate {
  using self_type = SoAHostDeviceLayoutTemplate;
  using AlignmentEnforcement = cms::soa::AlignmentEnforcement;
  using size_type = cms::soa::size_type;
  using byte_size_type = cms::soa::byte_size_type;
  constexpr static byte_size_type defaultAlignment = 128;
  constexpr static byte_size_type alignment = ALIGNMENT;
  constexpr static bool alignmentEnforcement = ALIGNMENT_ENFORCEMENT;
  constexpr static byte_size_type conditionalAlignment =
      alignmentEnforcement == cms::soa::AlignmentEnforcement::enforced ? alignment : 0;
  template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
  using SoAValueWithConf = cms::soa::SoAValue<COLUMN_TYPE, C, conditionalAlignment>;
  template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
  using SoAConstValueWithConf = cms::soa::SoAConstValue<COLUMN_TYPE, C, conditionalAlignment>;
  template <std::size_t VIEW_ALIGNMENT = cms::soa::CacheLineSize::defaultSize,
            bool VIEW_ALIGNMENT_ENFORCEMENT = cms::soa::AlignmentEnforcement::relaxed,
            bool RESTRICT_QUALIFY = cms::soa::RestrictQualify::Default,
            bool RANGE_CHECKING = cms::soa::RangeChecking::Default>
  struct ViewTemplateFreeParams;
  void soaToStreamInternal(std::ostream& _soa_impl_os) const {
    _soa_impl_os << "SoAHostDeviceLayoutTemplate"
                    "("
                 << elements_ << " elements, byte alignement= " << alignment << ", @" << mem_ << "): " << std::endl;
    _soa_impl_os << "  sizeof("
                    "SoAHostDeviceLayoutTemplate"
                    "): "
                 << sizeof(SoAHostDeviceLayoutTemplate) << std::endl;
    byte_size_type _soa_impl_offset = 0;
    _soa_impl_os << " Column "
                    "x"
                    " at offset "
                 << _soa_impl_offset << " has size " << sizeof(double) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(double), alignment) - (elements_ * sizeof(double))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    _soa_impl_os << " Column "
                    "y"
                    " at offset "
                 << _soa_impl_offset << " has size " << sizeof(double) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(double), alignment) - (elements_ * sizeof(double))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    _soa_impl_os << " Column "
                    "z"
                    " at offset "
                 << _soa_impl_offset << " has size " << sizeof(double) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(double), alignment) - (elements_ * sizeof(double))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    _soa_impl_os << " Eigen value "
                    "a"
                    " at offset "
                 << _soa_impl_offset << " has dimension "
                 << "(" << Eigen::Vector3d::RowsAtCompileTime << " x " << Eigen::Vector3d::ColsAtCompileTime << ")"
                 << " and per column size " << sizeof(Eigen::Vector3d::Scalar) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) -
                        (elements_ * sizeof(Eigen::Vector3d::Scalar))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_os << " Eigen value "
                    "b"
                    " at offset "
                 << _soa_impl_offset << " has dimension "
                 << "(" << Eigen::Vector3d::RowsAtCompileTime << " x " << Eigen::Vector3d::ColsAtCompileTime << ")"
                 << " and per column size " << sizeof(Eigen::Vector3d::Scalar) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) -
                        (elements_ * sizeof(Eigen::Vector3d::Scalar))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_os << " Eigen value "
                    "r"
                    " at offset "
                 << _soa_impl_offset << " has dimension "
                 << "(" << Eigen::Vector3d::RowsAtCompileTime << " x " << Eigen::Vector3d::ColsAtCompileTime << ")"
                 << " and per column size " << sizeof(Eigen::Vector3d::Scalar) * elements_ << " and padding "
                 << cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) -
                        (elements_ * sizeof(Eigen::Vector3d::Scalar))
                 << std::endl;
    _soa_impl_offset += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_os << " Scalar "
                    "description"
                    " at offset "
                 << _soa_impl_offset << " has size " << sizeof(const char*) << " and padding "
                 << ((sizeof(const char*) - 1) / alignment + 1) * alignment - sizeof(const char*) << std::endl;
    _soa_impl_offset += ((sizeof(const char*) - 1) / alignment + 1) * alignment;
    _soa_impl_os << " Scalar "
                    "someNumber"
                    " at offset "
                 << _soa_impl_offset << " has size " << sizeof(uint32_t) << " and padding "
                 << ((sizeof(uint32_t) - 1) / alignment + 1) * alignment - sizeof(uint32_t) << std::endl;
    _soa_impl_offset += ((sizeof(uint32_t) - 1) / alignment + 1) * alignment;
    _soa_impl_os << "Final offset = " << _soa_impl_offset << " computeDataSize(...): " << computeDataSize(elements_)
                 << std::endl;
    _soa_impl_os << std::endl;
  }
  static constexpr byte_size_type computeDataSize(size_type elements) {
    byte_size_type _soa_impl_ret = 0;
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(double), alignment);
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(double), alignment);
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(double), alignment);
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(Eigen::Vector3d::Scalar), alignment) *
                     Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(Eigen::Vector3d::Scalar), alignment) *
                     Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_ret += cms::soa::alignSize(elements * sizeof(Eigen::Vector3d::Scalar), alignment) *
                     Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    _soa_impl_ret += cms::soa::alignSize(sizeof(const char*), alignment);
    _soa_impl_ret += cms::soa::alignSize(sizeof(uint32_t), alignment);
    return _soa_impl_ret;
  }
  struct Metadata {
    friend SoAHostDeviceLayoutTemplate;
    inline __attribute__((always_inline)) size_type size() const { return parent_.elements_; }
    inline __attribute__((always_inline)) byte_size_type byteSize() const { return parent_.byteSize_; }
    inline __attribute__((always_inline)) byte_size_type alignment() const {
      return SoAHostDeviceLayoutTemplate::alignment;
    }
    inline __attribute__((always_inline)) std::byte* data() { return parent_.mem_; }
    inline __attribute__((always_inline)) const std::byte* data() const { return parent_.mem_; }
    inline __attribute__((always_inline)) std::byte* nextByte() const { return parent_.mem_ + parent_.byteSize_; }
    inline __attribute__((always_inline)) SoAHostDeviceLayoutTemplate
    cloneToNewAddress(std::byte* _soa_impl_addr) const {
      return SoAHostDeviceLayoutTemplate(_soa_impl_addr, parent_.elements_);
    }
    using ParametersTypeOf_x = cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::column>::DataType<double>;
    inline __attribute__((always_inline)) ParametersTypeOf_x parametersOf_x() const {
      return ParametersTypeOf_x(parent_.x_);
    }
    inline __attribute__((always_inline)) double const* addressOf_x() const {
      return parent_.metadata().parametersOf_x().addr_;
    }
    inline __attribute__((always_inline)) double* addressOf_x() { return parent_.metadata().parametersOf_x().addr_; }
    inline __attribute__((always_inline)) byte_size_type xPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(double), ParentClass::alignment);
    }
    using TypeOf_x = double;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_x = cms::soa::SoAColumnType::column;
    using ParametersTypeOf_y = cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::column>::DataType<double>;
    inline __attribute__((always_inline)) ParametersTypeOf_y parametersOf_y() const {
      return ParametersTypeOf_y(parent_.y_);
    }
    inline __attribute__((always_inline)) double const* addressOf_y() const {
      return parent_.metadata().parametersOf_y().addr_;
    }
    inline __attribute__((always_inline)) double* addressOf_y() { return parent_.metadata().parametersOf_y().addr_; }
    inline __attribute__((always_inline)) byte_size_type yPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(double), ParentClass::alignment);
    }
    using TypeOf_y = double;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_y = cms::soa::SoAColumnType::column;
    using ParametersTypeOf_z = cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::column>::DataType<double>;
    inline __attribute__((always_inline)) ParametersTypeOf_z parametersOf_z() const {
      return ParametersTypeOf_z(parent_.z_);
    }
    inline __attribute__((always_inline)) double const* addressOf_z() const {
      return parent_.metadata().parametersOf_z().addr_;
    }
    inline __attribute__((always_inline)) double* addressOf_z() { return parent_.metadata().parametersOf_z().addr_; }
    inline __attribute__((always_inline)) byte_size_type zPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(double), ParentClass::alignment);
    }
    using TypeOf_z = double;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_z = cms::soa::SoAColumnType::column;
    using ParametersTypeOf_a =
        cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::eigen>::DataType<Eigen::Vector3d>;
    inline __attribute__((always_inline)) ParametersTypeOf_a parametersOf_a() const {
      return ParametersTypeOf_a(parent_.a_, parent_.aStride_);
    }
    inline __attribute__((always_inline)) byte_size_type aPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(Eigen::Vector3d::Scalar), ParentClass::alignment) *
             Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    }
    using TypeOf_a = Eigen::Vector3d;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_a = cms::soa::SoAColumnType::eigen;
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar const* addressOf_a() const {
      return parent_.metadata().parametersOf_a().addr_;
    }
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar* addressOf_a() {
      return parent_.metadata().parametersOf_a().addr_;
    }
    using ParametersTypeOf_b =
        cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::eigen>::DataType<Eigen::Vector3d>;
    inline __attribute__((always_inline)) ParametersTypeOf_b parametersOf_b() const {
      return ParametersTypeOf_b(parent_.b_, parent_.bStride_);
    }
    inline __attribute__((always_inline)) byte_size_type bPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(Eigen::Vector3d::Scalar), ParentClass::alignment) *
             Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    }
    using TypeOf_b = Eigen::Vector3d;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_b = cms::soa::SoAColumnType::eigen;
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar const* addressOf_b() const {
      return parent_.metadata().parametersOf_b().addr_;
    }
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar* addressOf_b() {
      return parent_.metadata().parametersOf_b().addr_;
    }
    using ParametersTypeOf_r =
        cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::eigen>::DataType<Eigen::Vector3d>;
    inline __attribute__((always_inline)) ParametersTypeOf_r parametersOf_r() const {
      return ParametersTypeOf_r(parent_.r_, parent_.rStride_);
    }
    inline __attribute__((always_inline)) byte_size_type rPitch() const {
      return cms::soa::alignSize(parent_.elements_ * sizeof(Eigen::Vector3d::Scalar), ParentClass::alignment) *
             Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    }
    using TypeOf_r = Eigen::Vector3d;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_r = cms::soa::SoAColumnType::eigen;
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar const* addressOf_r() const {
      return parent_.metadata().parametersOf_r().addr_;
    }
    inline __attribute__((always_inline)) Eigen::Vector3d::Scalar* addressOf_r() {
      return parent_.metadata().parametersOf_r().addr_;
    }
    byte_size_type descriptionPitch() const { return cms::soa::alignSize(sizeof(const char*), ParentClass::alignment); }
    using TypeOf_description = const char*;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_description = cms::soa::SoAColumnType::scalar;
    inline __attribute__((always_inline)) const char* const* addressOf_description() const {
      return parent_.metadata().parametersOf_description().addr_;
    }
    using ParametersTypeOf_description =
        cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::scalar>::DataType<const char*>;
    inline __attribute__((always_inline)) ParametersTypeOf_description parametersOf_description() const {
      return ParametersTypeOf_description(parent_.description_);
    }
    inline __attribute__((always_inline)) const char** addressOf_description() {
      return parent_.metadata().parametersOf_description().addr_;
    }
    byte_size_type someNumberPitch() const { return cms::soa::alignSize(sizeof(uint32_t), ParentClass::alignment); }
    using TypeOf_someNumber = uint32_t;
    constexpr static cms::soa::SoAColumnType ColumnTypeOf_someNumber = cms::soa::SoAColumnType::scalar;
    inline __attribute__((always_inline)) uint32_t const* addressOf_someNumber() const {
      return parent_.metadata().parametersOf_someNumber().addr_;
    }
    using ParametersTypeOf_someNumber =
        cms::soa::SoAParameters_ColumnType<cms::soa::SoAColumnType::scalar>::DataType<uint32_t>;
    inline __attribute__((always_inline)) ParametersTypeOf_someNumber parametersOf_someNumber() const {
      return ParametersTypeOf_someNumber(parent_.someNumber_);
    }
    inline __attribute__((always_inline)) uint32_t* addressOf_someNumber() {
      return parent_.metadata().parametersOf_someNumber().addr_;
    }
    struct value_element {
      inline __attribute__((always_inline)) value_element(
          double x, double y, double z, Eigen::Vector3d a, Eigen::Vector3d b, Eigen::Vector3d r)
          : x{x}, y{y}, z{z}, a{a}, b{b}, r{r} {}
      double x;
      double y;
      double z;
      Eigen::Vector3d a;
      Eigen::Vector3d b;
      Eigen::Vector3d r;
    };
    Metadata& operator=(const Metadata&) = delete;
    Metadata(const Metadata&) = delete;

  private:
    inline __attribute__((always_inline)) Metadata(const SoAHostDeviceLayoutTemplate& _soa_impl_parent)
        : parent_(_soa_impl_parent) {}
    const SoAHostDeviceLayoutTemplate& parent_;
    using ParentClass = SoAHostDeviceLayoutTemplate;
  };
  friend Metadata;
  inline __attribute__((always_inline)) const Metadata metadata() const { return Metadata(*this); }
  inline __attribute__((always_inline)) Metadata metadata() { return Metadata(*this); }
  template <std::size_t VIEW_ALIGNMENT, bool VIEW_ALIGNMENT_ENFORCEMENT, bool RESTRICT_QUALIFY, bool RANGE_CHECKING>
  struct ConstViewTemplateFreeParams {
    using self_type = ConstViewTemplateFreeParams;
    using SoAHostDeviceLayoutTemplate_parametrized =
        SoAHostDeviceLayoutTemplate<VIEW_ALIGNMENT, VIEW_ALIGNMENT_ENFORCEMENT>;
    using size_type = cms::soa::size_type;
    using byte_size_type = cms::soa::byte_size_type;
    using AlignmentEnforcement = cms::soa::AlignmentEnforcement;
    template <std::size_t, bool, bool, bool>
    friend struct ViewTemplateFreeParams;
    template <std::size_t, bool, bool, bool>
    friend struct ConstViewTemplateFreeParams;
    constexpr static byte_size_type defaultAlignment = cms::soa::CacheLineSize::defaultSize;
    constexpr static byte_size_type alignment = VIEW_ALIGNMENT;
    constexpr static bool alignmentEnforcement = VIEW_ALIGNMENT_ENFORCEMENT;
    constexpr static byte_size_type conditionalAlignment =
        alignmentEnforcement == AlignmentEnforcement::enforced ? alignment : 0;
    constexpr static bool restrictQualify = RESTRICT_QUALIFY;
    constexpr static bool rangeChecking = RANGE_CHECKING;
    template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
    using SoAValueWithConf = cms::soa::SoAValue<COLUMN_TYPE, C, conditionalAlignment, restrictQualify>;
    template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
    using SoAConstValueWithConf = cms::soa::SoAConstValue<COLUMN_TYPE, C, conditionalAlignment, restrictQualify>;
    struct Metadata {
      friend ConstViewTemplateFreeParams;
      inline __attribute__((always_inline)) size_type size() const { return parent_.elements_; }
      using TypeOf_instance_SoAHostDeviceLayoutTemplate = SoAHostDeviceLayoutTemplate_parametrized;
      using TypeOf_x = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_x;
      using ParametersTypeOf_x = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_x;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_x =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_x;
      using ConstAccessorOf_x = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_x = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_x() const { return (parent_.xParameters_); };
      using TypeOf_y = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_y;
      using ParametersTypeOf_y = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_y;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_y =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_y;
      using ConstAccessorOf_y = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_y = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_y() const { return (parent_.yParameters_); };
      using TypeOf_z = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_z;
      using ParametersTypeOf_z = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_z;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_z =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_z;
      using ConstAccessorOf_z = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_z = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_z() const { return (parent_.zParameters_); };
      using TypeOf_a = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_a;
      using ParametersTypeOf_a = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_a;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_a =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_a;
      using ConstAccessorOf_a = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_a = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_a() const { return (parent_.aParameters_); };
      using TypeOf_b = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_b;
      using ParametersTypeOf_b = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_b;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_b =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_b;
      using ConstAccessorOf_b = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_b = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_b() const { return (parent_.bParameters_); };
      using TypeOf_r = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_r;
      using ParametersTypeOf_r = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_r;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_r =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_r;
      using ConstAccessorOf_r = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_r = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_r() const { return (parent_.rParameters_); };
      using TypeOf_description = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_description;
      using ParametersTypeOf_description =
          typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_description;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_description =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_description;
      using ConstAccessorOf_description =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
              ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_description =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
              ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_description() const {
        return (parent_.descriptionParameters_);
      };
      using TypeOf_someNumber = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_someNumber;
      using ParametersTypeOf_someNumber =
          typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_someNumber;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_someNumber =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_someNumber;
      using ConstAccessorOf_someNumber =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
              ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_someNumber =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
              ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_someNumber() const {
        return (parent_.someNumberParameters_);
      };
      inline __attribute__((always_inline)) auto const* addressOf_x() const { return parametersOf_x().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_y() const { return parametersOf_y().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_z() const { return parametersOf_z().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_a() const { return parametersOf_a().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_b() const { return parametersOf_b().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_r() const { return parametersOf_r().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_description() const {
        return parametersOf_description().addr_;
      };
      inline __attribute__((always_inline)) auto const* addressOf_someNumber() const {
        return parametersOf_someNumber().addr_;
      };
      Metadata& operator=(const Metadata&) = delete;
      Metadata(const Metadata&) = delete;

    private:
      inline __attribute__((always_inline)) Metadata(const ConstViewTemplateFreeParams& _soa_impl_parent)
          : parent_(_soa_impl_parent) {}
      const ConstViewTemplateFreeParams& parent_;
    };
    friend Metadata;
    inline __attribute__((always_inline)) const Metadata metadata() const { return Metadata(*this); }
    ConstViewTemplateFreeParams() = default;
    ConstViewTemplateFreeParams(const SoAHostDeviceLayoutTemplate_parametrized& instance_SoAHostDeviceLayoutTemplate)
        : elements_([&]() -> size_type {
            bool set = false;
            size_type ret = 0;
            if (set) {
              if (ret != instance_SoAHostDeviceLayoutTemplate.metadata().size())
                throw std::runtime_error("In constructor by layout: different sizes from layouts.");
            } else {
              ret = instance_SoAHostDeviceLayoutTemplate.metadata().size();
              set = true;
            }
            return ret;
          }()),
          xParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_x();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "x");
            return params;
          }()),
          yParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_y();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "y");
            return params;
          }()),
          zParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_z();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "z");
            return params;
          }()),
          aParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_a();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "a");
            return params;
          }()),
          bParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_b();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "b");
            return params;
          }()),
          rParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_r();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "r");
            return params;
          }()),
          descriptionParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_description();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "description");
            return params;
          }()),
          someNumberParameters_([&]() -> auto {
            auto params = instance_SoAHostDeviceLayoutTemplate.metadata().parametersOf_someNumber();
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (reinterpret_cast<intptr_t>(params.addr_) % alignment)
                throw std::runtime_error(
                    "In constructor by layout: misaligned column: "
                    "someNumber");
            return params;
          }()) {}
    ConstViewTemplateFreeParams(size_type _soa_impl_elements,
                                const typename Metadata::ParametersTypeOf_x::TupleOrPointerType x,
                                const typename Metadata::ParametersTypeOf_y::TupleOrPointerType y,
                                const typename Metadata::ParametersTypeOf_z::TupleOrPointerType z,
                                const typename Metadata::ParametersTypeOf_a::TupleOrPointerType a,
                                const typename Metadata::ParametersTypeOf_b::TupleOrPointerType b,
                                const typename Metadata::ParametersTypeOf_r::TupleOrPointerType r,
                                const typename Metadata::ParametersTypeOf_description::TupleOrPointerType description,
                                const typename Metadata::ParametersTypeOf_someNumber::TupleOrPointerType someNumber)
        : elements_(_soa_impl_elements),
          xParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_x::checkAlignment(x, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "x");
            return x;
          }()),
          yParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_y::checkAlignment(y, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "y");
            return y;
          }()),
          zParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_z::checkAlignment(z, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "z");
            return z;
          }()),
          aParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_a::checkAlignment(a, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "a");
            return a;
          }()),
          bParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_b::checkAlignment(b, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "b");
            return b;
          }()),
          rParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_r::checkAlignment(r, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "r");
            return r;
          }()),
          descriptionParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_description::checkAlignment(description, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "description");
            return description;
          }()),
          someNumberParameters_([&]() -> auto {
            if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
              if (Metadata::ParametersTypeOf_someNumber::checkAlignment(someNumber, alignment))
                throw std::runtime_error(
                    "In constructor by column: misaligned column: "
                    "someNumber");
            return someNumber;
          }()) {}
    ConstViewTemplateFreeParams(ConstViewTemplateFreeParams const&) = default;
    ConstViewTemplateFreeParams& operator=(ConstViewTemplateFreeParams const&) = default;
    template <std::size_t OTHER_VIEW_ALIGNMENT,
              bool OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
              bool OTHER_RESTRICT_QUALIFY,
              bool OTHER_RANGE_CHECKING>
    ConstViewTemplateFreeParams(ConstViewTemplateFreeParams<OTHER_VIEW_ALIGNMENT,
                                                            OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
                                                            OTHER_RESTRICT_QUALIFY,
                                                            OTHER_RANGE_CHECKING> const& other)
        : ConstViewTemplateFreeParams{other.elements_,
                                      const_cast_SoAParametersImpl(other.xParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.yParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.zParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.aParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.bParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.rParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.descriptionParameters_).tupleOrPointer(),
                                      const_cast_SoAParametersImpl(other.someNumberParameters_).tupleOrPointer()} {}
    template <std::size_t OTHER_VIEW_ALIGNMENT,
              bool OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
              bool OTHER_RESTRICT_QUALIFY,
              bool OTHER_RANGE_CHECKING>
    ConstViewTemplateFreeParams& operator=(ConstViewTemplateFreeParams<OTHER_VIEW_ALIGNMENT,
                                                                       OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
                                                                       OTHER_RESTRICT_QUALIFY,
                                                                       OTHER_RANGE_CHECKING> const& other) {
      *this = other;
    }
    ConstViewTemplateFreeParams(ConstViewTemplateFreeParams&&) = default;
    ConstViewTemplateFreeParams& operator=(ConstViewTemplateFreeParams&&) = default;
    ~ConstViewTemplateFreeParams() = default;
    struct const_element {
      inline __attribute__((always_inline)) const_element(
          size_type _soa_impl_index,
          const typename Metadata::ParametersTypeOf_x::ConstType x,
          const typename Metadata::ParametersTypeOf_y::ConstType y,
          const typename Metadata::ParametersTypeOf_z::ConstType z,
          const typename Metadata::ParametersTypeOf_a::ConstType a,
          const typename Metadata::ParametersTypeOf_b::ConstType b,
          const typename Metadata::ParametersTypeOf_r::ConstType r,
          const typename Metadata::ParametersTypeOf_description::ConstType description,
          const typename Metadata::ParametersTypeOf_someNumber::ConstType someNumber)
          : x_(_soa_impl_index, x),
            y_(_soa_impl_index, y),
            z_(_soa_impl_index, z),
            a_(_soa_impl_index, a),
            b_(_soa_impl_index, b),
            r_(_soa_impl_index, r),
            description_(_soa_impl_index, description),
            someNumber_(_soa_impl_index, someNumber) {}
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_x, const typename Metadata::TypeOf_x>::RefToConst
      x() const {
        return x_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_y, const typename Metadata::TypeOf_y>::RefToConst
      y() const {
        return y_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_z, const typename Metadata::TypeOf_z>::RefToConst
      z() const {
        return z_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_a, const typename Metadata::TypeOf_a>::RefToConst
      a() const {
        return a_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_b, const typename Metadata::TypeOf_b>::RefToConst
      b() const {
        return b_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_r, const typename Metadata::TypeOf_r>::RefToConst
      r() const {
        return r_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_description,
                                           const typename Metadata::TypeOf_description>::RefToConst
      description() const {
        return description_();
      }
      inline __attribute__((always_inline))
      const typename SoAConstValueWithConf<Metadata::ColumnTypeOf_someNumber,
                                           const typename Metadata::TypeOf_someNumber>::RefToConst
      someNumber() const {
        return someNumber_();
      }

    private:
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_x, typename Metadata::TypeOf_x>,
                                       Metadata::ColumnTypeOf_x>
          x_;
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_y, typename Metadata::TypeOf_y>,
                                       Metadata::ColumnTypeOf_y>
          y_;
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_z, typename Metadata::TypeOf_z>,
                                       Metadata::ColumnTypeOf_z>
          z_;
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_a, typename Metadata::TypeOf_a>,
                                       Metadata::ColumnTypeOf_a>
          a_;
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_b, typename Metadata::TypeOf_b>,
                                       Metadata::ColumnTypeOf_b>
          b_;
      const cms::soa::ConstValueTraits<SoAConstValueWithConf<Metadata::ColumnTypeOf_r, typename Metadata::TypeOf_r>,
                                       Metadata::ColumnTypeOf_r>
          r_;
      const cms::soa::ConstValueTraits<
          SoAConstValueWithConf<Metadata::ColumnTypeOf_description, typename Metadata::TypeOf_description>,
          Metadata::ColumnTypeOf_description>
          description_;
      const cms::soa::ConstValueTraits<
          SoAConstValueWithConf<Metadata::ColumnTypeOf_someNumber, typename Metadata::TypeOf_someNumber>,
          Metadata::ColumnTypeOf_someNumber>
          someNumber_;
    };
    inline __attribute__((always_inline)) const_element operator[](size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in "
              "ConstViewTemplateFreeParams"
              "::operator[]");
        }
      }
      return const_element{_soa_impl_index,
                           xParameters_,
                           yParameters_,
                           zParameters_,
                           aParameters_,
                           bParameters_,
                           rParameters_,
                           descriptionParameters_,
                           someNumberParameters_};
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<Metadata::ColumnTypeOf_x>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        x() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          Metadata::ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(xParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<Metadata::ColumnTypeOf_x>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        x(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "x"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<Metadata::ColumnTypeOf_x>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(xParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<Metadata::ColumnTypeOf_y>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        y() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          Metadata::ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(yParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<Metadata::ColumnTypeOf_y>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        y(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "y"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<Metadata::ColumnTypeOf_y>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(yParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<Metadata::ColumnTypeOf_z>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        z() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          Metadata::ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(zParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<Metadata::ColumnTypeOf_z>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        z(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "z"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<Metadata::ColumnTypeOf_z>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(zParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<Metadata::ColumnTypeOf_a>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        a() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          Metadata::ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(aParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<Metadata::ColumnTypeOf_a>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        a(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "a"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<Metadata::ColumnTypeOf_a>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(aParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<Metadata::ColumnTypeOf_b>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        b() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          Metadata::ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(bParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<Metadata::ColumnTypeOf_b>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        b(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "b"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<Metadata::ColumnTypeOf_b>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(bParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<Metadata::ColumnTypeOf_r>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        r() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          Metadata::ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(rParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<Metadata::ColumnTypeOf_r>::
        template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        r(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "r"
              "(size_type index)");
        }
      }
      return
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<Metadata::ColumnTypeOf_r>::
              template AccessType<cms::soa::SoAAccessType::constAccess>::template Alignment<
                  conditionalAlignment>::template RestrictQualifier<restrictQualify>(rParameters_)(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
        Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        description() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
          Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              descriptionParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
        Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        description(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "description"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
          Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(descriptionParameters_)(
              _soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
        Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        someNumber() const {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
          Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              someNumberParameters_)();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
        Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        someNumber(size_type _soa_impl_index) const {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in const "
              "someNumber"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
          Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(someNumberParameters_)(
              _soa_impl_index);
    }
    template <typename T>
    friend void dump();

  private:
    size_type elements_ = 0;
    typename Metadata::ParametersTypeOf_x::ConstType xParameters_;
    typename Metadata::ParametersTypeOf_y::ConstType yParameters_;
    typename Metadata::ParametersTypeOf_z::ConstType zParameters_;
    typename Metadata::ParametersTypeOf_a::ConstType aParameters_;
    typename Metadata::ParametersTypeOf_b::ConstType bParameters_;
    typename Metadata::ParametersTypeOf_r::ConstType rParameters_;
    typename Metadata::ParametersTypeOf_description::ConstType descriptionParameters_;
    typename Metadata::ParametersTypeOf_someNumber::ConstType someNumberParameters_;
  };
  template <bool RESTRICT_QUALIFY, bool RANGE_CHECKING>
  using ConstViewTemplate =
      ConstViewTemplateFreeParams<ALIGNMENT, ALIGNMENT_ENFORCEMENT, RESTRICT_QUALIFY, RANGE_CHECKING>;
  using ConstView = ConstViewTemplate<cms::soa::RestrictQualify::Default, cms::soa::RangeChecking::Default>;
  template <std::size_t VIEW_ALIGNMENT, bool VIEW_ALIGNMENT_ENFORCEMENT, bool RESTRICT_QUALIFY, bool RANGE_CHECKING>
  struct ViewTemplateFreeParams
      : public ConstViewTemplateFreeParams<VIEW_ALIGNMENT, VIEW_ALIGNMENT_ENFORCEMENT, RESTRICT_QUALIFY, RANGE_CHECKING> {
    using self_type = ViewTemplateFreeParams;
    using base_type =
        ConstViewTemplateFreeParams<VIEW_ALIGNMENT, VIEW_ALIGNMENT_ENFORCEMENT, RESTRICT_QUALIFY, RANGE_CHECKING>;
    using SoAHostDeviceLayoutTemplate_parametrized =
        SoAHostDeviceLayoutTemplate<VIEW_ALIGNMENT, VIEW_ALIGNMENT_ENFORCEMENT>;
    using size_type = cms::soa::size_type;
    using byte_size_type = cms::soa::byte_size_type;
    using AlignmentEnforcement = cms::soa::AlignmentEnforcement;
    constexpr static byte_size_type defaultAlignment = cms::soa::CacheLineSize::defaultSize;
    constexpr static byte_size_type alignment = VIEW_ALIGNMENT;
    constexpr static bool alignmentEnforcement = VIEW_ALIGNMENT_ENFORCEMENT;
    constexpr static byte_size_type conditionalAlignment =
        alignmentEnforcement == AlignmentEnforcement::enforced ? alignment : 0;
    constexpr static bool restrictQualify = RESTRICT_QUALIFY;
    constexpr static bool rangeChecking = RANGE_CHECKING;
    template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
    using SoAValueWithConf = cms::soa::SoAValue<COLUMN_TYPE, C, conditionalAlignment, restrictQualify>;
    template <cms::soa::SoAColumnType COLUMN_TYPE, class C>
    using SoAConstValueWithConf = cms::soa::SoAConstValue<COLUMN_TYPE, C, conditionalAlignment, restrictQualify>;
    template <std::size_t, bool, bool, bool>
    friend struct ViewTemplateFreeParams;
    struct Metadata {
      friend ViewTemplateFreeParams;
      inline __attribute__((always_inline)) size_type size() const { return parent_.elements_; }
      using TypeOf_instance_SoAHostDeviceLayoutTemplate = SoAHostDeviceLayoutTemplate_parametrized;
      using TypeOf_x = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_x;
      using ParametersTypeOf_x = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_x;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_x =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_x;
      using ConstAccessorOf_x = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_x = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_x() const {
        return const_cast_SoAParametersImpl(parent_.xParameters_);
      };
      using TypeOf_y = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_y;
      using ParametersTypeOf_y = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_y;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_y =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_y;
      using ConstAccessorOf_y = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_y = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_y() const {
        return const_cast_SoAParametersImpl(parent_.yParameters_);
      };
      using TypeOf_z = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_z;
      using ParametersTypeOf_z = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_z;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_z =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_z;
      using ConstAccessorOf_z = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_z = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_z() const {
        return const_cast_SoAParametersImpl(parent_.zParameters_);
      };
      using TypeOf_a = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_a;
      using ParametersTypeOf_a = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_a;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_a =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_a;
      using ConstAccessorOf_a = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_a = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_a() const {
        return const_cast_SoAParametersImpl(parent_.aParameters_);
      };
      using TypeOf_b = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_b;
      using ParametersTypeOf_b = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_b;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_b =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_b;
      using ConstAccessorOf_b = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_b = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_b() const {
        return const_cast_SoAParametersImpl(parent_.bParameters_);
      };
      using TypeOf_r = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_r;
      using ParametersTypeOf_r = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_r;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_r =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_r;
      using ConstAccessorOf_r = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::constAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_r = typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_r() const {
        return const_cast_SoAParametersImpl(parent_.rParameters_);
      };
      using TypeOf_description = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_description;
      using ParametersTypeOf_description =
          typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_description;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_description =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_description;
      using ConstAccessorOf_description =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
              ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::constAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_description =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
              ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_description() const {
        return const_cast_SoAParametersImpl(parent_.descriptionParameters_);
      };
      using TypeOf_someNumber = typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::TypeOf_someNumber;
      using ParametersTypeOf_someNumber =
          typename TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ParametersTypeOf_someNumber;
      constexpr static cms::soa::SoAColumnType ColumnTypeOf_someNumber =
          TypeOf_instance_SoAHostDeviceLayoutTemplate::Metadata::ColumnTypeOf_someNumber;
      using ConstAccessorOf_someNumber =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
              ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::constAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      using MutableAccessorOf_someNumber =
          typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
              ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
              template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>;
      inline __attribute__((always_inline)) const auto parametersOf_someNumber() const {
        return const_cast_SoAParametersImpl(parent_.someNumberParameters_);
      };
      inline __attribute__((always_inline)) auto* addressOf_x() { return parametersOf_x().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_y() { return parametersOf_y().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_z() { return parametersOf_z().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_a() { return parametersOf_a().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_b() { return parametersOf_b().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_r() { return parametersOf_r().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_description() { return parametersOf_description().addr_; };
      inline __attribute__((always_inline)) auto* addressOf_someNumber() { return parametersOf_someNumber().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_x() const { return parametersOf_x().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_y() const { return parametersOf_y().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_z() const { return parametersOf_z().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_a() const { return parametersOf_a().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_b() const { return parametersOf_b().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_r() const { return parametersOf_r().addr_; };
      inline __attribute__((always_inline)) auto const* addressOf_description() const {
        return parametersOf_description().addr_;
      };
      inline __attribute__((always_inline)) auto const* addressOf_someNumber() const {
        return parametersOf_someNumber().addr_;
      };
      Metadata& operator=(const Metadata&) = delete;
      Metadata(const Metadata&) = delete;

    private:
      inline __attribute__((always_inline)) Metadata(const ViewTemplateFreeParams& _soa_impl_parent)
          : parent_(_soa_impl_parent) {}
      const ViewTemplateFreeParams& parent_;
    };
    friend Metadata;
    inline __attribute__((always_inline)) const Metadata metadata() const { return Metadata(*this); }
    inline __attribute__((always_inline)) Metadata metadata() { return Metadata(*this); }
    ViewTemplateFreeParams() = default;
    ViewTemplateFreeParams(SoAHostDeviceLayoutTemplate_parametrized& instance_SoAHostDeviceLayoutTemplate)
        : base_type{instance_SoAHostDeviceLayoutTemplate} {}
    ViewTemplateFreeParams(size_type _soa_impl_elements,
                           typename Metadata::ParametersTypeOf_x::TupleOrPointerType x,
                           typename Metadata::ParametersTypeOf_y::TupleOrPointerType y,
                           typename Metadata::ParametersTypeOf_z::TupleOrPointerType z,
                           typename Metadata::ParametersTypeOf_a::TupleOrPointerType a,
                           typename Metadata::ParametersTypeOf_b::TupleOrPointerType b,
                           typename Metadata::ParametersTypeOf_r::TupleOrPointerType r,
                           typename Metadata::ParametersTypeOf_description::TupleOrPointerType description,
                           typename Metadata::ParametersTypeOf_someNumber::TupleOrPointerType someNumber)
        : base_type{_soa_impl_elements, x, y, z, a, b, r, description, someNumber} {}
    ViewTemplateFreeParams(ViewTemplateFreeParams const&) = default;
    ViewTemplateFreeParams& operator=(ViewTemplateFreeParams const&) = default;
    template <std::size_t OTHER_VIEW_ALIGNMENT,
              bool OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
              bool OTHER_RESTRICT_QUALIFY,
              bool OTHER_RANGE_CHECKING>
    ViewTemplateFreeParams(ViewTemplateFreeParams<OTHER_VIEW_ALIGNMENT,
                                                  OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
                                                  OTHER_RESTRICT_QUALIFY,
                                                  OTHER_RANGE_CHECKING> const& other)
        : base_type{other.elements_,
                    const_cast_SoAParametersImpl(other.xParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.yParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.zParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.aParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.bParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.rParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.descriptionParameters_).tupleOrPointer(),
                    const_cast_SoAParametersImpl(other.someNumberParameters_).tupleOrPointer()} {}
    template <std::size_t OTHER_VIEW_ALIGNMENT,
              bool OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
              bool OTHER_RESTRICT_QUALIFY,
              bool OTHER_RANGE_CHECKING>
    ViewTemplateFreeParams& operator=(ViewTemplateFreeParams<OTHER_VIEW_ALIGNMENT,
                                                             OTHER_VIEW_ALIGNMENT_ENFORCEMENT,
                                                             OTHER_RESTRICT_QUALIFY,
                                                             OTHER_RANGE_CHECKING> const& other) {
      static_cast<base_type>(*this) = static_cast<base_type>(other);
    }
    ViewTemplateFreeParams(ViewTemplateFreeParams&&) = default;
    ViewTemplateFreeParams& operator=(ViewTemplateFreeParams&&) = default;
    ~ViewTemplateFreeParams() = default;
    using const_element = typename base_type::const_element;
    using base_type::operator[];
    struct element {
      inline __attribute__((always_inline)) element(size_type _soa_impl_index,
                                                    typename Metadata::ParametersTypeOf_x x,
                                                    typename Metadata::ParametersTypeOf_y y,
                                                    typename Metadata::ParametersTypeOf_z z,
                                                    typename Metadata::ParametersTypeOf_a a,
                                                    typename Metadata::ParametersTypeOf_b b,
                                                    typename Metadata::ParametersTypeOf_r r,
                                                    typename Metadata::ParametersTypeOf_description description,
                                                    typename Metadata::ParametersTypeOf_someNumber someNumber)
          : x(_soa_impl_index, x),
            y(_soa_impl_index, y),
            z(_soa_impl_index, z),
            a(_soa_impl_index, a),
            b(_soa_impl_index, b),
            r(_soa_impl_index, r),
            description(_soa_impl_index, description),
            someNumber(_soa_impl_index, someNumber) {}
      inline __attribute__((always_inline)) element& operator=(const element& _soa_impl_other) {
        if constexpr (Metadata::ColumnTypeOf_x != cms::soa::SoAColumnType::scalar)
          x() = _soa_impl_other.x();
        if constexpr (Metadata::ColumnTypeOf_y != cms::soa::SoAColumnType::scalar)
          y() = _soa_impl_other.y();
        if constexpr (Metadata::ColumnTypeOf_z != cms::soa::SoAColumnType::scalar)
          z() = _soa_impl_other.z();
        if constexpr (Metadata::ColumnTypeOf_a != cms::soa::SoAColumnType::scalar)
          a() = _soa_impl_other.a();
        if constexpr (Metadata::ColumnTypeOf_b != cms::soa::SoAColumnType::scalar)
          b() = _soa_impl_other.b();
        if constexpr (Metadata::ColumnTypeOf_r != cms::soa::SoAColumnType::scalar)
          r() = _soa_impl_other.r();
        if constexpr (Metadata::ColumnTypeOf_description != cms::soa::SoAColumnType::scalar)
          description() = _soa_impl_other.description();
        if constexpr (Metadata::ColumnTypeOf_someNumber != cms::soa::SoAColumnType::scalar)
          someNumber() = _soa_impl_other.someNumber();
        return *this;
      }
      inline __attribute__((always_inline)) element& operator=(const const_element& _soa_impl_other) {
        if constexpr (Metadata::ColumnTypeOf_x != cms::soa::SoAColumnType::scalar)
          x() = _soa_impl_other.x();
        if constexpr (Metadata::ColumnTypeOf_y != cms::soa::SoAColumnType::scalar)
          y() = _soa_impl_other.y();
        if constexpr (Metadata::ColumnTypeOf_z != cms::soa::SoAColumnType::scalar)
          z() = _soa_impl_other.z();
        if constexpr (Metadata::ColumnTypeOf_a != cms::soa::SoAColumnType::scalar)
          a() = _soa_impl_other.a();
        if constexpr (Metadata::ColumnTypeOf_b != cms::soa::SoAColumnType::scalar)
          b() = _soa_impl_other.b();
        if constexpr (Metadata::ColumnTypeOf_r != cms::soa::SoAColumnType::scalar)
          r() = _soa_impl_other.r();
        if constexpr (Metadata::ColumnTypeOf_description != cms::soa::SoAColumnType::scalar)
          description() = _soa_impl_other.description();
        if constexpr (Metadata::ColumnTypeOf_someNumber != cms::soa::SoAColumnType::scalar)
          someNumber() = _soa_impl_other.someNumber();
        return *this;
      }
      inline __attribute__((always_inline)) constexpr element& operator=(
          const typename SoAHostDeviceLayoutTemplate_parametrized::Metadata::value_element _soa_impl_value) {
        x() = _soa_impl_value.x;
        y() = _soa_impl_value.y;
        z() = _soa_impl_value.z;
        a() = _soa_impl_value.a;
        b() = _soa_impl_value.b;
        r() = _soa_impl_value.r;
        return *this;
      }
      SoAValueWithConf<Metadata::ColumnTypeOf_x, typename Metadata::TypeOf_x> x;
      SoAValueWithConf<Metadata::ColumnTypeOf_y, typename Metadata::TypeOf_y> y;
      SoAValueWithConf<Metadata::ColumnTypeOf_z, typename Metadata::TypeOf_z> z;
      SoAValueWithConf<Metadata::ColumnTypeOf_a, typename Metadata::TypeOf_a> a;
      SoAValueWithConf<Metadata::ColumnTypeOf_b, typename Metadata::TypeOf_b> b;
      SoAValueWithConf<Metadata::ColumnTypeOf_r, typename Metadata::TypeOf_r> r;
      SoAValueWithConf<Metadata::ColumnTypeOf_description, typename Metadata::TypeOf_description> description;
      SoAValueWithConf<Metadata::ColumnTypeOf_someNumber, typename Metadata::TypeOf_someNumber> someNumber;
    };
    inline __attribute__((always_inline)) element operator[](size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in "
              "ViewTemplateFreeParams"
              "::operator[]");
        }
      }
      return element{_soa_impl_index,
                     const_cast_SoAParametersImpl(base_type::xParameters_),
                     const_cast_SoAParametersImpl(base_type::yParameters_),
                     const_cast_SoAParametersImpl(base_type::zParameters_),
                     const_cast_SoAParametersImpl(base_type::aParameters_),
                     const_cast_SoAParametersImpl(base_type::bParameters_),
                     const_cast_SoAParametersImpl(base_type::rParameters_),
                     const_cast_SoAParametersImpl(base_type::descriptionParameters_),
                     const_cast_SoAParametersImpl(base_type::someNumberParameters_)};
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<Metadata::ColumnTypeOf_x>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        x() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          Metadata::ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::xParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<Metadata::ColumnTypeOf_x>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        x(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "x"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_x>::template ColumnType<
          Metadata::ColumnTypeOf_x>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::xParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<Metadata::ColumnTypeOf_y>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        y() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          Metadata::ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::yParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<Metadata::ColumnTypeOf_y>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        y(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "y"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_y>::template ColumnType<
          Metadata::ColumnTypeOf_y>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::yParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<Metadata::ColumnTypeOf_z>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        z() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          Metadata::ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::zParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<Metadata::ColumnTypeOf_z>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        z(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "z"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_z>::template ColumnType<
          Metadata::ColumnTypeOf_z>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::zParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<Metadata::ColumnTypeOf_a>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        a() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          Metadata::ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::aParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<Metadata::ColumnTypeOf_a>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        a(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "a"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_a>::template ColumnType<
          Metadata::ColumnTypeOf_a>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::aParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<Metadata::ColumnTypeOf_b>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        b() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          Metadata::ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::bParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<Metadata::ColumnTypeOf_b>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        b(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "b"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_b>::template ColumnType<
          Metadata::ColumnTypeOf_b>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::bParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<Metadata::ColumnTypeOf_r>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        r() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          Metadata::ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::rParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<Metadata::ColumnTypeOf_r>::
        template AccessType<cms::soa::SoAAccessType::mutableAccess>::template Alignment<
            conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        r(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "r"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_r>::template ColumnType<
          Metadata::ColumnTypeOf_r>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::rParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
        Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        description() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
          Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::descriptionParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
        Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        description(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "description"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_description>::template ColumnType<
          Metadata::ColumnTypeOf_description>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::descriptionParameters_))(_soa_impl_index);
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
        Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::NoParamReturnType
        someNumber() {
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
          Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::someNumberParameters_))();
    }
    inline __attribute__((always_inline))
    typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
        Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
        template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>::ParamReturnType
        someNumber(size_type _soa_impl_index) {
      if constexpr (rangeChecking == cms::soa::RangeChecking::enabled) {
        if (_soa_impl_index >= base_type::elements_ or _soa_impl_index < 0) {
          throw std::out_of_range(
              "Out of range index in mutable "
              "someNumber"
              "(size_type index)");
        }
      }
      return typename cms::soa::SoAAccessors<typename Metadata::TypeOf_someNumber>::template ColumnType<
          Metadata::ColumnTypeOf_someNumber>::template AccessType<cms::soa::SoAAccessType::mutableAccess>::
          template Alignment<conditionalAlignment>::template RestrictQualifier<restrictQualify>(
              const_cast_SoAParametersImpl(base_type::someNumberParameters_))(_soa_impl_index);
    }
    template <typename T>
    friend void dump();
  };
  template <bool RESTRICT_QUALIFY, bool RANGE_CHECKING>
  using ViewTemplate = ViewTemplateFreeParams<ALIGNMENT, ALIGNMENT_ENFORCEMENT, RESTRICT_QUALIFY, RANGE_CHECKING>;
  using View = ViewTemplate<cms::soa::RestrictQualify::Default, cms::soa::RangeChecking::Default>;
  SoAHostDeviceLayoutTemplate()
      : mem_(nullptr),
        elements_(0),
        byteSize_(0),
        x_(nullptr),
        y_(nullptr),
        z_(nullptr),
        aElementsWithPadding_(0),
        a_(nullptr),
        aStride_(0),
        bElementsWithPadding_(0),
        b_(nullptr),
        bStride_(0),
        rElementsWithPadding_(0),
        r_(nullptr),
        rStride_(0),
        description_(nullptr),
        someNumber_(nullptr) {}
  SoAHostDeviceLayoutTemplate(std::byte* mem, size_type elements) : mem_(mem), elements_(elements), byteSize_(0) {
    organizeColumnsFromBuffer();
  }
  SoAHostDeviceLayoutTemplate(SoAHostDeviceLayoutTemplate const& _soa_impl_other)
      : mem_(_soa_impl_other.mem_),
        elements_(_soa_impl_other.elements_),
        byteSize_(_soa_impl_other.byteSize_),
        x_{_soa_impl_other.x_},
        y_{_soa_impl_other.y_},
        z_{_soa_impl_other.z_},
        aElementsWithPadding_{_soa_impl_other.aElementsWithPadding_},
        a_{_soa_impl_other.a_},
        aStride_{_soa_impl_other.aStride_},
        bElementsWithPadding_{_soa_impl_other.bElementsWithPadding_},
        b_{_soa_impl_other.b_},
        bStride_{_soa_impl_other.bStride_},
        rElementsWithPadding_{_soa_impl_other.rElementsWithPadding_},
        r_{_soa_impl_other.r_},
        rStride_{_soa_impl_other.rStride_},
        description_{_soa_impl_other.description_},
        someNumber_{_soa_impl_other.someNumber_} {}
  SoAHostDeviceLayoutTemplate& operator=(SoAHostDeviceLayoutTemplate const& _soa_impl_other) {
    mem_ = _soa_impl_other.mem_;
    elements_ = _soa_impl_other.elements_;
    byteSize_ = _soa_impl_other.byteSize_;
    x_ = _soa_impl_other.x_;
    y_ = _soa_impl_other.y_;
    z_ = _soa_impl_other.z_;
    aElementsWithPadding_ = _soa_impl_other.aElementsWithPadding_;
    a_ = _soa_impl_other.a_;
    aStride_ = _soa_impl_other.aStride_;
    bElementsWithPadding_ = _soa_impl_other.bElementsWithPadding_;
    b_ = _soa_impl_other.b_;
    bStride_ = _soa_impl_other.bStride_;
    rElementsWithPadding_ = _soa_impl_other.rElementsWithPadding_;
    r_ = _soa_impl_other.r_;
    rStride_ = _soa_impl_other.rStride_;
    description_ = _soa_impl_other.description_;
    someNumber_ = _soa_impl_other.someNumber_;
    return *this;
  }
  template <typename T>
  void ROOTReadStreamer(T& onfile) {
    memcpy(x_, onfile.x_, sizeof(double) * onfile.elements_);
    memcpy(y_, onfile.y_, sizeof(double) * onfile.elements_);
    memcpy(z_, onfile.z_, sizeof(double) * onfile.elements_);
    memcpy(a_, onfile.a_, sizeof(Eigen::Vector3d::Scalar) * aElementsWithPadding_);
    memcpy(b_, onfile.b_, sizeof(Eigen::Vector3d::Scalar) * bElementsWithPadding_);
    memcpy(r_, onfile.r_, sizeof(Eigen::Vector3d::Scalar) * rElementsWithPadding_);
    memcpy(description_, onfile.description_, sizeof(const char*));
    memcpy(someNumber_, onfile.someNumber_, sizeof(uint32_t));
  }
  void ROOTStreamerCleaner() {
    delete[] x_;
    x_ = nullptr;
    delete[] y_;
    y_ = nullptr;
    delete[] z_;
    z_ = nullptr;
    delete[] a_;
    a_ = nullptr;
    delete[] b_;
    b_ = nullptr;
    delete[] r_;
    r_ = nullptr;
    delete[] description_;
    description_ = nullptr;
    delete[] someNumber_;
    someNumber_ = nullptr;
  }
  template <typename T>
  friend void dump();

private:
  void organizeColumnsFromBuffer() {
    if constexpr (alignmentEnforcement == cms::soa::AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(mem_) % alignment)
        throw std::runtime_error(
            "In "
            "SoAHostDeviceLayoutTemplate"
            "::"
            "SoAHostDeviceLayoutTemplate"
            ": misaligned buffer");
    auto _soa_impl_curMem = mem_;
    x_ = reinterpret_cast<double*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(x_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "x");
    y_ = reinterpret_cast<double*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(y_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "y");
    z_ = reinterpret_cast<double*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(double), alignment);
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(z_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "z");
    aStride_ =
        cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) / sizeof(Eigen::Vector3d::Scalar);
    aElementsWithPadding_ = aStride_ * Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    a_ = reinterpret_cast<Eigen::Vector3d::Scalar*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(a_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "a");
    bStride_ =
        cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) / sizeof(Eigen::Vector3d::Scalar);
    bElementsWithPadding_ = bStride_ * Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    b_ = reinterpret_cast<Eigen::Vector3d::Scalar*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(b_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "b");
    rStride_ =
        cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) / sizeof(Eigen::Vector3d::Scalar);
    rElementsWithPadding_ = rStride_ * Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    r_ = reinterpret_cast<Eigen::Vector3d::Scalar*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(elements_ * sizeof(Eigen::Vector3d::Scalar), alignment) *
                        Eigen::Vector3d::RowsAtCompileTime * Eigen::Vector3d::ColsAtCompileTime;
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(r_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "r");
    description_ = reinterpret_cast<const char**>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(sizeof(const char*), alignment);
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(description_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "description");
    someNumber_ = reinterpret_cast<uint32_t*>(_soa_impl_curMem);
    _soa_impl_curMem += cms::soa::alignSize(sizeof(uint32_t), alignment);
    if constexpr (alignmentEnforcement == AlignmentEnforcement::enforced)
      if (reinterpret_cast<intptr_t>(someNumber_) % alignment)
        throw std::runtime_error(
            "In layout constructor: misaligned column: "
            "someNumber");
    byteSize_ = computeDataSize(elements_);
    if (mem_ + byteSize_ != _soa_impl_curMem)
      throw std::runtime_error(
          "In "
          "SoAHostDeviceLayoutTemplate"
          "::"
          "SoAHostDeviceLayoutTemplate"
          ": unexpected end pointer.");
  }
  std::byte* mem_;
  size_type elements_;
  size_type const scalar_ = 1;
  byte_size_type byteSize_;
  double* x_ = nullptr;
  double* y_ = nullptr;
  double* z_ = nullptr;
  size_type aElementsWithPadding_ = 0;
  Eigen::Vector3d::Scalar* a_ = nullptr;
  byte_size_type aStride_ = 0;
  size_type bElementsWithPadding_ = 0;
  Eigen::Vector3d::Scalar* b_ = nullptr;
  byte_size_type bStride_ = 0;
  size_type rElementsWithPadding_ = 0;
  Eigen::Vector3d::Scalar* r_ = nullptr;
  byte_size_type rStride_ = 0;
  const char** description_ = nullptr;
  uint32_t* someNumber_ = nullptr;
};
using SoAHostDeviceLayout = SoAHostDeviceLayoutTemplate<>;
using SoAHostDeviceView = SoAHostDeviceLayout::View;
using SoAHostDeviceRangeCheckingView =
    SoAHostDeviceLayout::ViewTemplate<cms::soa::RestrictQualify::enabled, cms::soa::RangeChecking::enabled>;
using SoAHostDeviceConstView = SoAHostDeviceLayout::ConstView;
void printSoAView(SoAHostDeviceView view) {
  std::cout << "SoAHostDeviceView:" << std::endl;
  std::cout << "description: " << view.description() << std::endl;
  std::cout << "someNumber: " << view.someNumber() << std::endl;
  for (auto i = 0; i < view.metadata().size(); ++i) {
    std::cout << "Element " << i << ": ";
    std::cout << "x = " << view.x()[i] << ", ";
    std::cout << "y = " << view.y()[i] << ", ";
    std::cout << "z = " << view.z()[i] << std::endl;
    std::cout << "a = " << view[i].a().transpose() << ", ";
    std::cout << "b = " << view[i].b().transpose() << ", ";
    std::cout << "r = " << view[i].r().transpose() << std::endl;
  }
}
int main() {
  std::size_t numElements = 16;
  std::size_t hostDeviceSize = SoAHostDeviceLayout::computeDataSize(numElements);
  std::unique_ptr<std::byte, decltype(std::free)*> slBuffer{
      reinterpret_cast<std::byte*>(aligned_alloc(SoAHostDeviceLayout::alignment, hostDeviceSize)), std::free};
  SoAHostDeviceLayout h_soa(slBuffer.get(), numElements);
  SoAHostDeviceLayout::View h_soav{h_soa};
  SoAHostDeviceLayout::ConstView soacv{h_soa};
  h_soav.x()[0] = h_soav.y()[0] = h_soav.z()[0] = 0.;
  Eigen::Vector3d vec_a;
  vec_a.setConstant(1.);
  for (size_t i = 1; i < numElements; i++) {
    h_soav.x()[i] = static_cast<double>(i);
    h_soav.y()[i] = static_cast<double>(i) * 2.0;
    h_soav.z()[i] = static_cast<double>(i) * 3.0;
    h_soav[i].a() = vec_a;
    for (size_t j = 0; j < 3; ++j) {
      h_soav[i].b()(j) = 0.2 * i * (j + 1);
      h_soav[i].r()(j) = 0.3 * i * (j + 1);
    }
  }
  h_soav.description() = "Example SoA";
  h_soav.someNumber() = 1;
  printSoAView(h_soav);
  std::cout << std::endl << "Memory information: " << std::endl << std::endl;
  h_soa.soaToStreamInternal(std::cout);
  return 0;
}
